hash_id,title,content
3bc6836e02,Computer science,"Computer science is the study of computation, automation, and information. Computer science spans theoretical disciplines (such as algorithms, theory of computation, information theory, and automation) to practical disciplines (including the design and implementation of hardware and software). Computer science is generally considered an academic discipline and distinct from computer programming which is considered to be a technical field.Algorithms and data structures are central to computer science.
The theory of computation concerns abstract models of computation and general classes of problems that can be solved using them. The fields of cryptography and computer security involve studying the means for secure communication and for preventing security vulnerabilities. Computer graphics and computational geometry address the generation of images. Programming language theory considers different ways to describe computational processes, and database theory concerns the management of repositories of data. Human–computer interaction investigates the interfaces through which humans and computers interact, and software engineering focuses on the design and principles behind developing software. Areas such as operating systems, networks and embedded systems investigate the principles and design behind complex systems. Computer architecture describes the construction of computer components and computer-operated equipment. Artificial intelligence and machine learning aim to synthesize goal-orientated processes such as problem-solving, decision-making, environmental adaptation, planning and learning found in humans and animals. Within artificial intelligence, computer vision aims to understand and process image and video data, while natural language processing aims to understand and process textual and linguistic data.
The fundamental concern of computer science is determining what can and cannot be automated. The Turing Award is generally recognized as the highest distinction in computer science.


== History ==

 

The earliest foundations of what would become computer science predate the invention of the modern digital computer. Machines for calculating fixed numerical tasks such as the abacus have existed since antiquity, aiding in computations such as multiplication and division. Algorithms for performing computations have existed since antiquity, even before the development of sophisticated computing equipment.Wilhelm Schickard designed and constructed the first working mechanical calculator in 1623. In 1673, Gottfried Leibniz demonstrated a digital mechanical calculator, called the Stepped Reckoner. Leibniz may be considered the first computer scientist and information theorist, because of various reasons, including the fact that he documented the binary number system. In 1820, Thomas de Colmar launched the mechanical calculator industry when he invented his simplified arithmometer, the first calculating machine strong enough and reliable enough to be used daily in an office environment. Charles Babbage started the design of the first automatic mechanical calculator, his Difference Engine, in 1822, which eventually gave him the idea of the first programmable mechanical calculator, his Analytical Engine. He started developing this machine in 1834, and ""in less than two years, he had sketched out many of the salient features of the modern computer"". ""A crucial step was the adoption of a punched card system derived from the Jacquard loom"" making it infinitely programmable. In 1843, during the translation of a French article on the Analytical Engine, Ada Lovelace wrote, in one of the many notes she included, an algorithm to compute the Bernoulli numbers, which is considered to be the first published algorithm ever specifically tailored for implementation on a computer. Around 1885, Herman Hollerith invented the tabulator, which used punched cards to process statistical information; eventually his company became part of IBM. Following Babbage, although unaware of his earlier work, Percy Ludgate in 1909 published the 2nd of the only two designs for mechanical analytical engines in history. In 1937, one hundred years after Babbage's impossible dream, Howard Aiken convinced IBM, which was making all kinds of punched card equipment and was also in the calculator business to develop his giant programmable calculator, the ASCC/Harvard Mark I, based on Babbage's Analytical Engine, which itself used cards and a central computing unit. When the machine was finished, some hailed it as ""Babbage's dream come true"".
During the 1940s, with the development of new and more powerful computing machines such as the Atanasoff–Berry computer and ENIAC, the term computer came to refer to the machines rather than their human predecessors. As it became clear that computers could be used for more than just mathematical calculations, the field of computer science broadened to study computation in general. In 1945, IBM founded the Watson Scientific Computing Laboratory at Columbia University in New York City. The renovated fraternity house on Manhattan's West Side was IBM's first laboratory devoted to pure science. The lab is the forerunner of IBM's Research Division, which today operates research facilities around the world. Ultimately, the close relationship between IBM and Columbia University was instrumental in the emergence of a new scientific discipline, with Columbia offering one of the first academic-credit courses in computer science in 1946. Computer science began to be established as a distinct academic discipline in the 1950s and early 1960s. The world's first computer science degree program, the Cambridge Diploma in Computer Science, began at the University of Cambridge Computer Laboratory in 1953. The first computer science department in the United States was formed at Purdue University in 1962. Since practical computers became available, many applications of computing have become distinct areas of study in their own rights.


== Etymology ==

Although first proposed in 1956, the term ""computer science"" appears in a 1959 article in Communications of the ACM,
in which Louis Fein argues for the creation of a Graduate School in Computer Sciences analogous to the creation of Harvard Business School in 1921. Louis justifies the name by arguing that, like management science, the subject is applied and interdisciplinary in nature, while having the characteristics typical of an academic discipline.
His efforts, and those of others such as numerical analyst George Forsythe, were rewarded: universities went on to create such departments, starting with Purdue in 1962. Despite its name, a significant amount of computer science does not involve the study of computers themselves. Because of this, several alternative names have been proposed. Certain departments of major universities prefer the term computing science, to emphasize precisely that difference. Danish scientist Peter Naur suggested the term datalogy, to reflect the fact that the scientific discipline revolves around data and data treatment, while not necessarily involving computers. The first scientific institution to use the term was the Department of Datalogy at the University of Copenhagen, founded in 1969, with Peter Naur being the first professor in datalogy. The term is used mainly in the Scandinavian countries. An alternative term, also proposed by Naur, is data science; this is now used for a multi-disciplinary field of data analysis, including statistics and databases.
In the early days of computing, a number of terms for the practitioners of the field of computing were suggested in the Communications of the ACM—turingineer, turologist, flow-charts-man, applied meta-mathematician, and applied epistemologist. Three months later in the same journal, comptologist was suggested, followed next year by hypologist. The term computics has also been suggested. In Europe, terms derived from contracted translations of the expression ""automatic information"" (e.g. ""informazione automatica"" in Italian) or ""information and mathematics"" are often used, e.g. informatique (French), Informatik (German), informatica (Italian, Dutch), informática (Spanish, Portuguese), informatika (Slavic languages and Hungarian) or pliroforiki (πληροφορική, which means informatics) in Greek. Similar words have also been adopted in the UK (as in the School of Informatics, University of Edinburgh). ""In the U.S., however, informatics is linked with applied computing, or computing in the context of another domain.""A folkloric quotation, often attributed to—but almost certainly not first formulated by—Edsger Dijkstra, states that ""computer science is no more about computers than astronomy is about telescopes."" The design and deployment of computers and computer systems is generally considered the province of disciplines other than computer science. For example, the study of computer hardware is usually considered part of computer engineering, while the study of commercial computer systems and their deployment is often called information technology or information systems. However, there has been exchange of ideas between the various computer-related disciplines. Computer science research also often intersects other disciplines, such as cognitive science, linguistics, mathematics, physics, biology, Earth science, statistics, philosophy, and logic.
Computer science is considered by some to have a much closer relationship with mathematics than many scientific disciplines, with some observers saying that computing is a mathematical science. Early computer science was strongly influenced by the work of mathematicians such as Kurt Gödel, Alan Turing, John von Neumann, Rózsa Péter and Alonzo Church and there continues to be a useful interchange of ideas between the two fields in areas such as mathematical logic, category theory, domain theory, and algebra.The relationship between Computer Science and Software Engineering is a contentious issue, which is further muddied by disputes over what the term ""Software Engineering"" means, and how computer science is defined. David Parnas, taking a cue from the relationship between other engineering and science disciplines, has claimed that the principal focus of computer science is studying the properties of computation in general, while the principal focus of software engineering is the design of specific computations to achieve practical goals, making the two separate but complementary disciplines.The academic, political, and funding aspects of computer science tend to depend on whether a department is formed with a mathematical emphasis or with an engineering emphasis. Computer science departments with a mathematics emphasis and with a numerical orientation consider alignment with computational science. Both types of departments tend to make efforts to bridge the field educationally if not across all research.


== Philosophy ==


=== Epistemology of computer science ===
Despite the word ""science"" in its name, there is debate over whether or not computer science is a discipline of science, mathematics, or engineering. Allen Newell and Herbert A. Simon argued in 1975, Computer science is an empirical discipline. We would have called it an experimental science, but like astronomy, economics, and geology, some of its unique forms of observation and experience do not fit a narrow stereotype of the experimental method. Nonetheless, they are experiments. Each new machine that is built is an experiment. Actually constructing the machine poses a question to nature; and we listen for the answer by observing the machine in operation and analyzing it by all analytical and measurement means available. It has since been argued that computer science can be classified as an empirical science since it makes use of empirical testing to evaluate the correctness of programs, but a problem remains in defining the laws and theorems of computer science (if any exist) and defining the nature of experiments in computer science. Proponents of classifying computer science as an engineering discipline argue that the reliability of computational systems is investigated in the same way as bridges in civil engineering and airplanes in aerospace engineering. They also argue that while empirical sciences observe what presently exists, computer science observes what is possible to exist and while scientists discover laws from observation, no proper laws have been found in computer science and it is instead concerned with creating phenomena.Proponents of classifying computer science as a mathematical discipline argue that computer programs are physical realizations of mathematical entities and programs can be deductively reasoned through mathematical formal methods. Computer scientists Edsger W. Dijkstra and Tony Hoare regard instructions for computer programs as mathematical sentences and interpret formal semantics for programming languages as mathematical axiomatic systems.


=== Paradigms of computer science ===
A number of computer scientists have argued for the distinction of three separate paradigms in computer science. Peter Wegner argued that those paradigms are science, technology, and mathematics. Peter Denning's working group argued that they are theory, abstraction (modeling), and design. Amnon H. Eden described them as the ""rationalist paradigm"" (which treats computer science as a branch of mathematics, which is prevalent in theoretical computer science, and mainly employs deductive reasoning), the ""technocratic paradigm"" (which might be found in engineering approaches, most prominently in software engineering), and the ""scientific paradigm"" (which approaches computer-related artifacts from the empirical perspective of natural sciences, identifiable in some branches of artificial intelligence).
Computer science focuses on methods involved in design, specification, programming, verification, implementation and testing of human-made computing systems.


== Fields ==

As a discipline, computer science spans a range of topics from theoretical studies of algorithms and the limits of computation to the practical issues of implementing computing systems in hardware and software.CSAB, formerly called Computing Sciences Accreditation Board—which is made up of representatives of the Association for Computing Machinery (ACM), and the IEEE Computer Society (IEEE CS)—identifies four areas that it considers crucial to the discipline of computer science: theory of computation, algorithms and data structures, programming methodology and languages, and computer elements and architecture. In addition to these four areas, CSAB also identifies fields such as software engineering, artificial intelligence, computer networking and communication, database systems, parallel computation, distributed computation, human–computer interaction, computer graphics, operating systems, and numerical and symbolic computation as being important areas of computer science.
Computer science is no more about computers than astronomy is about telescopes.


=== Theoretical computer science ===

Theoretical Computer Science is mathematical and abstract in spirit, but it derives its motivation from the practical and everyday computation. Its aim is to understand the nature of computation and, as a consequence of this understanding, provide more efficient methodologies.


==== Theory of computation ====

According to Peter Denning, the fundamental question underlying computer science is, ""What can be automated?"" Theory of computation is focused on answering fundamental questions about what can be computed and what amount of resources are required to perform those computations. In an effort to answer the first question, computability theory examines which computational problems are solvable on various theoretical models of computation. The second question is addressed by computational complexity theory, which studies the time and space costs associated with different approaches to solving a multitude of computational problems.
The famous P = NP? problem, one of the Millennium Prize Problems, is an open problem in the theory of computation.


==== Information and coding theory ====

Information theory, closely related to probability and statistics, is related to the quantification of information. This was developed by Claude Shannon to find fundamental limits on signal processing operations such as compressing data and on reliably storing and communicating data.
Coding theory is the study of the properties of codes (systems for converting information from one form to another) and their fitness for a specific application. Codes are used for data compression, cryptography, error detection and correction, and more recently also for network coding. Codes are studied for the purpose of designing efficient and reliable data transmission methods.


==== Data structures and algorithms ====
Data structures and algorithms are the studies of commonly used computational methods and their computational efficiency.


==== Programming language theory and formal methods ====

Programming language theory is a branch of computer science that deals with the design, implementation, analysis, characterization, and classification of programming languages and their individual features. It falls within the discipline of computer science, both depending on and affecting mathematics, software engineering, and linguistics. It is an active research area, with numerous dedicated academic journals.
Formal methods are a particular kind of mathematically based technique for the specification, development and verification of software and hardware systems. The use of formal methods for software and hardware design is motivated by the expectation that, as in other engineering disciplines, performing appropriate mathematical analysis can contribute to the reliability and robustness of a design. They form an important theoretical underpinning for software engineering, especially where safety or security is involved. Formal methods are a useful adjunct to software testing since they help avoid errors and can also give a framework for testing. For industrial use, tool support is required. However, the high cost of using formal methods means that they are usually only used in the development of high-integrity and life-critical systems, where safety or security is of utmost importance. Formal methods are best described as the application of a fairly broad variety of theoretical computer science fundamentals, in particular logic calculi, formal languages, automata theory, and program semantics, but also type systems and algebraic data types to problems in software and hardware specification and verification.


=== Applied computer science ===


==== Computer graphics and visualization ====

Computer graphics is the study of digital visual contents and involves the synthesis and manipulation of image data. The study is connected to many other fields in computer science, including computer vision, image processing, and computational geometry, and is heavily applied in the fields of special effects and video games.


==== Image and sound processing ====

Information can take the form of images, sound, video or other multimedia. Bits of information can be streamed via signals. Its processing is the central notion of informatics, the European view on computing, which studies information processing algorithms independently of the type of information carrier - whether it is electrical, mechanical or biological. This field plays important role in information theory, telecommunications, information engineering and has applications in medical image computing and speech synthesis, among others. What is the lower bound on the complexity of fast Fourier transform algorithms? is one of unsolved problems in theoretical computer science.


==== Computational science, finance and engineering ====

Scientific computing (or computational science) is the field of study concerned with constructing mathematical models and quantitative analysis techniques and using computers to analyze and solve scientific problems. A major usage of scientific computing is simulation of various processes, including computational fluid dynamics, physical, electrical, and electronic systems and circuits, as well as societies and social situations (notably war games) along with their habitats, among many others. Modern computers enable optimization of such designs as complete aircraft. Notable in electrical and electronic circuit design are SPICE, as well as software for physical realization of new (or modified) designs. The latter includes essential design software for integrated circuits.


==== Social computing and human–computer interaction ====

Social computing is an area that is concerned with the intersection of social behavior and computational systems. Human–computer interaction research develops theories, principles, and guidelines for user interface designers.


==== Software engineering ====

Software engineering is the study of designing, implementing, and modifying the software in order to ensure it is of high quality, affordable, maintainable, and fast to build. It is a systematic approach to software design, involving the application of engineering practices to software. Software engineering deals with the organizing and analyzing of software—it does not just deal with the creation or manufacture of new software, but its internal arrangement and maintenance. For example software testing, systems engineering, technical debt and software development processes.


==== Artificial intelligence ====

Artificial intelligence (AI) aims to or is required to synthesize goal-orientated processes such as problem-solving, decision-making, environmental adaptation, learning, and communication found in humans and animals. From its origins in cybernetics and in the Dartmouth Conference (1956), artificial intelligence research has been necessarily cross-disciplinary, drawing on areas of expertise such as applied mathematics, symbolic logic, semiotics, electrical engineering, philosophy of mind, neurophysiology, and social intelligence. AI is associated in the popular mind with robotic development, but the main field of practical application has been as an embedded component in areas of software development, which require computational understanding. The starting point in the late 1940s was Alan Turing's question ""Can computers think?"", and the question remains effectively unanswered, although the Turing test is still used to assess computer output on the scale of human intelligence. But the automation of evaluative and predictive tasks has been increasingly successful as a substitute for human monitoring and intervention in domains of computer application involving complex real-world data.


=== Computer systems ===


==== Computer architecture and organization ====

Computer architecture, or digital computer organization, is the conceptual design and fundamental operational structure of a computer system. It focuses largely on the way by which the central processing unit performs internally and accesses addresses in memory. Computer engineers study computational logic and design of computer hardware, from individual processor components, microcontrollers, personal computers to supercomputers and embedded systems. The term ""architecture"" in computer literature can be traced to the work of Lyle R. Johnson and Frederick P. Brooks, Jr., members of the Machine Organization department in IBM's main research center in 1959.


==== Concurrent, parallel and distributed computing ====

Concurrency is a property of systems in which several computations are executing simultaneously, and potentially interacting with each other. A number of mathematical models have been developed for general concurrent computation including Petri nets, process calculi and the Parallel Random Access Machine model. When multiple computers are connected in a network while using concurrency, this is known as a distributed system. Computers within that distributed system have their own private memory, and information can be exchanged to achieve common goals.


==== Computer networks ====

This branch of computer science aims to manage networks between computers worldwide.


==== Computer security and cryptography ====

Computer security is a branch of computer technology with the objective of protecting information from unauthorized access, disruption, or modification while maintaining the accessibility and usability of the system for its intended users.
Historical cryptography is the art of writing and deciphering secret messages. Modern cryptography is the scientific study of problems relating to distributed computations that can be attacked. Technologies studied in modern cryptography include symmetric and asymmetric encryption, digital signatures, cryptographic hash functions, key-agreement protocols, blockchain, zero-knowledge proofs, and garbled circuits.


==== Databases and data mining ====

A database is intended to organize, store, and retrieve large amounts of data easily. Digital databases are managed using database management systems to store, create, maintain, and search data, through database models and query languages. Data mining is a process of discovering patterns in large data sets.


== Discoveries ==
The philosopher of computing Bill Rapaport noted three Great Insights of Computer Science:
Gottfried Wilhelm Leibniz's, George Boole's, Alan Turing's, Claude Shannon's, and Samuel Morse's insight: there are only two objects that a computer has to deal with in order to represent ""anything"".All the information about any computable problem can be represented using only 0 and 1 (or any other bistable pair that can flip-flop between two easily distinguishable states, such as ""on/off"", ""magnetized/de-magnetized"", ""high-voltage/low-voltage"", etc.).
Alan Turing's insight: there are only five actions that a computer has to perform in order to do ""anything"".Every algorithm can be expressed in a language for a computer consisting of only five basic instructions:move left one location;
move right one location;
read symbol at current location;
print 0 at current location;
print 1 at current location.
Corrado Böhm and Giuseppe Jacopini's insight: there are only three ways of combining these actions (into more complex ones) that are needed in order for a computer to do ""anything"".Only three rules are needed to combine any set of basic instructions into more complex ones:
sequence: first do this, then do that;
 selection: IF such-and-such is the case, THEN do this, ELSE do that;
repetition: WHILE such-and-such is the case, DO this.
Note that the three rules of Boehm's and Jacopini's insight can be further simplified with the use of goto (which means it is more elementary than structured programming).


== Programming paradigms ==

Programming languages can be used to accomplish different tasks in different ways. Common programming paradigms include:

Functional programming, a style of building the structure and elements of computer programs that treats computation as the evaluation of mathematical functions and avoids state and mutable data. It is a declarative programming paradigm, which means programming is done with expressions or declarations instead of statements.
Imperative programming, a programming paradigm that uses statements that change a program's state. In much the same way that the imperative mood in natural languages expresses commands, an imperative program consists of commands for the computer to perform. Imperative programming focuses on describing how a program operates.
Object-oriented programming, a programming paradigm based on the concept of ""objects"", which may contain data, in the form of fields, often known as attributes; and code, in the form of procedures, often known as methods. A feature of objects is that an object's procedures can access and often modify the data fields of the object with which they are associated. Thus object-oriented computer programs are made out of objects that interact with one another.
Service-oriented programming, a programming paradigm that uses ""services"" as the unit of computer work, to design and implement integrated business applications and mission critical software programsMany languages offer support for multiple paradigms, making the distinction more a matter of style than of technical capabilities.


== Research ==

Conferences are important events for computer science research. During these conferences, researchers from the public and private sectors present their recent work and meet. Unlike in most other academic fields, in computer science, the prestige of conference papers is greater than that of journal publications. One proposed explanation for this is the quick development of this relatively new field requires rapid review and distribution of results, a task better handled by conferences than by journals.


== Education ==

Computer Science, known by its near synonyms, Computing, Computer Studies, has been taught in UK schools since the days of batch processing, mark sensitive cards and paper tape but usually to a select few students. In 1981, the BBC produced a micro-computer and classroom network and Computer Studies became common for GCE O level students (11–16-year-old), and Computer Science to A level students. Its importance was recognised, and it became a compulsory part of the National Curriculum, for Key Stage 3 & 4. In September 2014 it became an entitlement for all pupils over the age of 4.In the US, with 14,000 school districts deciding the curriculum, provision was fractured. According to a 2010 report by the Association for Computing Machinery (ACM) and Computer Science Teachers Association (CSTA), only 14 out of 50 states have adopted significant education standards for high school computer science. According to a 2021 report, only 51% of high schools in the US offer computer science.Israel, New Zealand, and South Korea have included computer science in their national secondary education curricula, and several others are following.


== See also ==


== Notes ==


== References ==


== Further reading ==


== External links ==

Computer science at Curlie
Scholarly Societies in Computer Science Archived June 23, 2011, at the Wayback Machine
What is Computer Science?
Best Papers Awards in Computer Science since 1996
Photographs of computer scientists by Bertrand Meyer
EECS.berkeley.edu


=== Bibliography and academic search engines ===
CiteSeerx (article): search engine, digital library and repository for scientific and academic papers with a focus on computer and information science.
DBLP Computer Science Bibliography (article): computer science bibliography website hosted at Universität Trier, in Germany.
The Collection of Computer Science Bibliographies (Collection of Computer Science Bibliographies)


=== Professional organizations ===
Association for Computing Machinery
IEEE Computer Society
Informatics Europe
AAAI
AAAS Computer Science


=== Misc ===
Computer Science—Stack Exchange: a community-run question-and-answer site for computer science
What is computer science Archived February 18, 2015, at the Wayback Machine
Is computer science science?
Computer Science (Software) Must be Considered as an Independent Discipline."
70893819f5,Heuristic (computer science),"In mathematical optimization and computer science, heuristic (from Greek εὑρίσκω ""I find, discover"") is a technique designed for solving a problem more quickly when classic methods are too slow for finding an approximate solution, or when classic methods fail to find any exact solution.  This is achieved by trading optimality, completeness, accuracy, or precision for speed.  In a way, it can be considered a shortcut.
A heuristic function, also simply called a heuristic, is a function that ranks alternatives in search algorithms at each branching step based on available information to decide which branch to follow. For example, it may approximate the exact solution.


== Definition and motivation ==
The objective of a heuristic is to produce a solution in a reasonable time frame that is good enough for solving the problem at hand.  This solution may not be the best of all the solutions to this problem, or it may simply approximate the exact solution. But it is still valuable because finding it does not require a prohibitively long time.
Heuristics may produce results by themselves, or they may be used in conjunction with optimization algorithms to improve their efficiency (e.g., they may be used to generate good seed values).
Results about NP-hardness in theoretical computer science make heuristics the only viable option for a variety of complex optimization problems that need to be routinely solved in real-world applications.
Heuristics underlie the whole field of Artificial Intelligence and the computer simulation of thinking, as they may be used in situations where there are no known algorithms.


== Trade-off ==
The trade-off criteria for deciding whether to use a heuristic for solving a given problem include the following:

Optimality: When several solutions exist for a given problem, does the heuristic guarantee that the best solution will be found? Is it actually necessary to find the best solution?
Completeness: When several solutions exist for a given problem, can the heuristic find them all? Do we actually need all solutions? Many heuristics are only meant to find one solution.
Accuracy and precision: Can the heuristic provide a confidence interval for the purported solution? Is the error bar on the solution unreasonably large?
Execution time: Is this the best known heuristic for solving this type of problem? Some heuristics converge faster than others. Some heuristics are only marginally quicker than classic methods, in which case the 'overhead' on calculating the heuristic might have negative impact.In some cases, it may be difficult to decide whether the solution found by the heuristic is good enough, because the theory underlying heuristics is not very elaborate.


== Examples ==


=== Simpler problem ===
One way of achieving the computational performance gain expected of a heuristic consists of solving a simpler problem whose solution is also a solution to the initial problem.


=== Travelling salesman problem ===
An example of approximation is described by Jon Bentley for solving the travelling salesman problem (TSP):

""Given a list of cities and the distances between each pair of cities, what is the shortest possible route that visits each city exactly once and returns to the origin city?""so as to select the order to draw using a pen plotter. TSP is known to be NP-hard so an optimal solution for even a moderate size problem is difficult to solve. Instead, the greedy algorithm can be used to give a good but not optimal solution (it is an approximation to the optimal answer) in a reasonably short amount of time. The greedy algorithm heuristic says to pick whatever is currently the best next step regardless of whether that prevents (or even makes impossible) good steps later. It is a heuristic in the sense that practice indicates it is a good enough solution, while theory indicates that there are better solutions (and even indicates how much better, in some cases).


=== Search ===
Another example of heuristic making an algorithm faster occurs in certain search problems. Initially, the heuristic tries every possibility at each step, like the full-space search algorithm. But it can stop the search at any time if the current possibility is already worse than the best solution already found. In such search problems, a heuristic can be used to try good choices first so that bad paths can be eliminated early (see alpha-beta pruning). In the case of best-first search algorithms, such as A* search, the heuristic improves the algorithm's convergence while maintaining its correctness as long as the heuristic is admissible.


=== Newell and Simon: heuristic search hypothesis ===
In their Turing Award acceptance speech, Allen Newell and Herbert A. Simon discuss the heuristic search hypothesis: a physical symbol system will repeatedly generate and modify known symbol structures until the created structure matches the solution structure. Each following step depends upon the step before it, thus the heuristic search learns what avenues to pursue and which ones to disregard by measuring how close the current step is to the solution. Therefore, some possibilities will never be generated as they are measured to be less likely to complete the solution.
A heuristic method can accomplish its task by using search trees. However, instead of generating all possible solution branches, a heuristic selects branches more likely to produce outcomes than other branches. It is selective at each decision point, picking branches that are more likely to produce solutions.


=== Antivirus software ===
Antivirus software often uses heuristic rules for detecting viruses and other forms of malware. Heuristic scanning looks for code and/or behavioral patterns common to a class or family of viruses, with different sets of rules for different viruses. If a file or executing process is found to contain matching code patterns and/or to be performing that set of activities, then the scanner infers that the file is infected. The most advanced part of behavior-based heuristic scanning is that it can work against highly randomized self-modifying/mutating (polymorphic) viruses that cannot be easily detected by simpler string scanning methods. Heuristic scanning has the potential to detect future viruses without requiring the virus to be first detected somewhere else, submitted to the virus scanner developer, analyzed, and a detection update for the scanner provided to the scanner's users.


== Pitfalls ==
Some heuristics have a strong underlying theory; they are either derived in a top-down manner from the theory or are arrived at based on either experimental or real world data. Others are just rules of thumb based on real-world observation or experience without even a glimpse of theory. The latter are exposed to a larger number of pitfalls.
When a heuristic is reused in various contexts because it has been seen to ""work"" in one context, without having been mathematically proven to meet a given set of requirements, it is possible that the current data set does not necessarily represent future data sets (see: overfitting) and that purported ""solutions"" turn out to be akin to noise.
Statistical analysis can be conducted when employing heuristics to estimate the probability of incorrect outcomes. To use a heuristic for solving a search problem or a knapsack problem, it is necessary to check that the heuristic is admissible. Given a heuristic function 
  
    
      
        h
        (
        
          v
          
            i
          
        
        ,
        
          v
          
            g
          
        
        )
      
    
    {\displaystyle h(v_{i},v_{g})}
   meant to approximate the true optimal distance 
  
    
      
        
          d
          
            ⋆
          
        
        (
        
          v
          
            i
          
        
        ,
        
          v
          
            g
          
        
        )
      
    
    {\displaystyle d^{\star }(v_{i},v_{g})}
   to the goal node 
  
    
      
        
          v
          
            g
          
        
      
    
    {\displaystyle v_{g}}
   in a directed graph 
  
    
      
        G
      
    
    {\displaystyle G}
   containing 
  
    
      
        n
      
    
    {\displaystyle n}
   total nodes or vertices labeled 
  
    
      
        
          v
          
            0
          
        
        ,
        
          v
          
            1
          
        
        ,
        ⋯
        ,
        
          v
          
            n
          
        
      
    
    {\displaystyle v_{0},v_{1},\cdots ,v_{n}}
  , ""admissible"" means roughly that the heuristic underestimates the cost to the goal or formally that 
  
    
      
        h
        (
        
          v
          
            i
          
        
        ,
        
          v
          
            g
          
        
        )
        ≤
        
          d
          
            ⋆
          
        
        (
        
          v
          
            i
          
        
        ,
        
          v
          
            g
          
        
        )
      
    
    {\displaystyle h(v_{i},v_{g})\leq d^{\star }(v_{i},v_{g})}
   for all 
  
    
      
        (
        
          v
          
            i
          
        
        ,
        
          v
          
            g
          
        
        )
      
    
    {\displaystyle (v_{i},v_{g})}
   where 
  
    
      
        
          i
          ,
          g
        
        ∈
        [
        0
        ,
        1
        ,
        .
        .
        .
        ,
        n
        ]
      
    
    {\displaystyle {i,g}\in [0,1,...,n]}
  .
If a heuristic is not admissible, it may never find the goal, either by ending up in a dead end of graph 
  
    
      
        G
      
    
    {\displaystyle G}
   or by skipping back and forth between two nodes 
  
    
      
        
          v
          
            i
          
        
      
    
    {\displaystyle v_{i}}
   and 
  
    
      
        
          v
          
            j
          
        
      
    
    {\displaystyle v_{j}}
   where 
  
    
      
        
          i
          ,
          j
        
        ≠
        g
      
    
    {\displaystyle {i,j}\neq g}
  .


== Etymology ==

The word ""heuristic"" came into usage in the early 19th century. It is formed irregularly from the Greek word heuriskein, meaning ""to find"".


== See also ==
Algorithm
Constructive heuristic
Genetic algorithm
Heuristic
Heuristic routing
Heuristic evaluation: Method for identifying usability problems in user interfaces.
Metaheuristic: Methods for controlling and tuning basic heuristic algorithms, usually with usage of memory and learning.
Matheuristics: Optimization algorithms made by the interoperation of metaheuristics and mathematical programming (MP) techniques.
Reactive search optimization: Methods using online machine learning principles for self-tuning of heuristics.
Recursion (computer science)
Macro (computer science)


== References =="
da0ffb854b,Computer graphics (computer science),"Computer graphics is a sub-field of computer science which studies methods for digitally synthesizing and manipulating visual content.  Although the term often refers to the study of three-dimensional computer graphics, it also encompasses two-dimensional graphics and image processing. 


== Overview ==
Computer graphics studies manipulation of visual and geometric information using computational techniques.  It focuses on the mathematical and computational foundations of image generation and processing rather than purely aesthetic issues.  Computer graphics is often differentiated from the field of visualization, although the two fields have many similarities.
Connected studies include:

Applied mathematics
Computational geometry
Computational topology
Computer vision
Image processing
Information visualization
Scientific visualizationApplications of computer graphics include:

Print design
Digital art
Special effects
Video games
Visual effects


== History ==

There are several international conferences and journals where the most significant results in computer graphics are published. Among them are the SIGGRAPH and Eurographics conferences and the Association for Computing Machinery (ACM) Transactions on Graphics journal. The joint Eurographics and ACM SIGGRAPH symposium series features the major venues for the more specialized sub-fields: Symposium on Geometry Processing, Symposium on Rendering, Symposium on Computer Animation, and High Performance Graphics.As in the rest of computer science, conference publications in computer graphics are generally more significant than journal publications (and subsequently have lower acceptance rates).


== Subfields ==
A broad classification of major subfields in computer graphics might be:

Geometry: ways to represent and process surfaces
Animation: ways to represent and manipulate motion
Rendering: algorithms to reproduce light transport
Imaging: image acquisition or image editing


=== Geometry ===

The subfield of geometry studies the representation of three-dimensional objects in a discrete digital setting.  Because the appearance of an object depends largely on its exterior, boundary representations are most commonly used.  Two dimensional surfaces are a good representation for most objects, though they may be non-manifold.  Since surfaces are not finite, discrete digital approximations are used. Polygonal meshes (and to a lesser extent subdivision surfaces) are by far the most common representation, although point-based representations have become more popular recently (see for instance the Symposium on Point-Based Graphics). These representations are Lagrangian, meaning the spatial locations of the samples are independent.  Recently, Eulerian surface descriptions (i.e., where spatial samples are fixed) such as level sets have been developed into a useful representation for deforming surfaces which undergo many topological changes (with fluids being the most notable example).Geometry subfields include:

Implicit surface modeling – an older subfield which examines the use of algebraic surfaces, constructive solid geometry, etc., for surface representation.
Digital geometry processing – surface reconstruction, simplification, fairing, mesh repair, parameterization, remeshing, mesh generation, surface compression, and surface editing all fall under this heading.
Discrete differential geometry – a nascent field which defines geometric quantities for the discrete surfaces used in computer graphics.
Point-based graphics – a recent field which focuses on points as the fundamental representation of surfaces.
Subdivision surfaces
Out-of-core mesh processing – another recent field which focuses on mesh datasets that do not fit in main memory.


=== Animation ===
The subfield of animation studies descriptions for surfaces (and other phenomena) that move or deform over time.  Historically, most work in this field has focused on parametric and data-driven models, but recently physical simulation has become more popular as computers have become more powerful computationally.
Animation subfields include:

Performance capture
Character animation
Physical simulation (e.g. cloth modeling,  animation of fluid dynamics, etc.)


=== Rendering ===

Rendering generates images from a model.  Rendering may simulate light transport to create realistic images or it may create images that have a particular artistic style in non-photorealistic rendering.  The two basic operations in realistic rendering are transport (how much light passes from one place to another) and scattering (how surfaces interact with light).  See Rendering (computer graphics) for more information.
Rendering subfields include:

Transport describes how illumination in a scene gets from one place to another. Visibility is a major component of light transport.
Scattering: Models of scattering (how light interacts with the surface at a given point) and shading (how material properties vary across the surface) are used to describe the appearance of a surface.  In graphics these problems are often studied within the context of rendering since they can substantially affect the design of rendering algorithms.  Descriptions of scattering are usually given in terms of a bidirectional scattering distribution function (BSDF).  The latter issue addresses how different types of scattering are distributed across the surface (i.e., which scattering function applies where).  Descriptions of this kind are typically expressed with a program called a shader.  (There is some confusion since the word ""shader"" is sometimes used for programs that describe local geometric variation.)
Non-photorealistic rendering
Physically based rendering – concerned with generating images according to the laws of geometric optics
Real-time rendering – focuses on rendering for interactive applications, typically using specialized hardware like GPUs
Relighting – recent area concerned with quickly re-rendering scenes


== Notable researchers ==


== Applications for their use ==
Bitmap Design / Image Editing

Adobe Photoshop
Corel Photo-Paint
GIMP
KritaVector drawing

Adobe Illustrator
CorelDRAW
Inkscape
Affinity Designer
SketchArchitecture

VariCAD
FreeCAD
AutoCAD
QCAD
LibreCAD
DataCAD
Corel DesignerVideo editing

Adobe Premiere Pro
Sony Vegas
Final Cut
DaVinci Resolve
Cinelerra
VirtualDubSculpting, Animation, and 3D Modeling

Blender 3D
Wings 3D
ZBrush
Sculptris
SolidWorks
Rhino3D
SketchUp
Houdini
3ds Max
Cinema 4D
Maya
HoudiniDigital composition

Nuke
Blackmagic Fusion
Adobe After Effects
NatronRendering

V-Ray
RedShift
RenderMan
Octane Render
Mantra
Lumion (Architectural visualization)Other applications examples

ACIS - geometric core
Autodesk Softimage
POV-Ray
Scribus
Silo
Hexagon
Lightwave


== See also ==


== References ==


== Further reading ==
Foley et al. Computer Graphics: Principles and Practice.
Shirley. Fundamentals of Computer Graphics.
Watt. 3D Computer Graphics.


== External links ==

A Critical History of Computer Graphics and Animation
History of Computer Graphics series of articles


=== Industry ===
Industrial labs doing ""blue sky"" graphics research include:

Adobe Advanced Technology Labs
MERL
Microsoft Research – Graphics
Nvidia ResearchMajor film studios notable for graphics research include:

ILM
PDI/Dreamworks Animation
Pixar"
45d8304a48,Integer (computer science),"In computer science, an integer is a datum of integral data type, a data type that represents some range of mathematical integers. Integral data types may be of different sizes and may or may not be allowed to contain negative values. Integers are commonly represented in a computer as a group of binary digits (bits). The size of the grouping varies so the set of integer sizes available varies between different types of computers. Computer hardware nearly always provides a way to represent a processor register or memory address as an integer.


== Value and representation ==
The value of an item with an integral type is the mathematical integer that it corresponds to. Integral types may be unsigned (capable of representing only non-negative integers) or signed (capable of representing negative integers as well).An integer value is typically specified in the source code of a program as a sequence of digits optionally prefixed with + or −. Some programming languages allow other notations, such as hexadecimal (base 16) or octal (base 8). Some programming languages also permit digit group separators.The internal representation of this datum is the way the value is stored in the computer's memory. Unlike mathematical integers, a typical datum in a computer has some minimal and maximum possible value.
The most common representation of a positive integer is a string of bits, using the binary numeral system. The order of the memory bytes storing the bits varies; see endianness. The width or precision of an integral type is the number of bits in its representation. An integral type with n bits can encode 2n numbers; for example an unsigned type typically represents the non-negative values 0 through 2n−1. Other encodings of integer values to bit patterns are sometimes used, for example binary-coded decimal or Gray code, or as printed character codes such as ASCII.
There are four well-known ways to represent signed numbers in a binary computing system. The most common is two's complement, which allows a signed integral type with n bits to represent numbers from −2(n−1) through 2(n−1)−1. Two's complement arithmetic is convenient because there is a perfect one-to-one correspondence between representations and values (in particular, no separate +0 and −0), and because addition, subtraction and multiplication do not need to distinguish between signed and unsigned types. Other possibilities include offset binary, sign-magnitude, and ones' complement.
Some computer languages define integer sizes in a machine-independent way; others have varying definitions depending on the underlying processor word size. Not all language implementations define variables of all integer sizes, and defined sizes may not even be distinct in a particular implementation. An integer in one programming language may be a different size in a different language or on a different processor.
Some older computer architectures used decimal representations of integers, stored in binary-coded decimal (BCD) or other format. These values generally require data sizes of 4 bits per decimal digit (sometimes called a nibble), usually with additional bits for a sign. Many modern CPUs provide limited support for decimal integers as an extended datatype, providing instructions for converting such values to and from binary values. Depending on the architecture, decimal integers may have fixed sizes (e.g., 7 decimal digits plus a sign fit into a 32-bit word), or may be variable-length (up to some maximum digit size), typically occupying two digits per byte (octet).


== Common integral data types ==
Different CPUs support different integral data types. Typically, hardware will support both signed and unsigned types, but only a small, fixed set of widths.
The table above lists integral type widths that are supported in hardware by common processors. High level programming languages provide more possibilities. It is common to have a 'double width' integral type that has twice as many bits as the biggest hardware-supported type. Many languages also have bit-field types (a specified number of bits, usually constrained to be less than the maximum hardware-supported width) and range types (that can represent only the integers in a specified range).
Some languages, such as Lisp, Smalltalk, REXX, Haskell, Python, and Raku, support arbitrary precision integers (also known as infinite precision integers or bignums). Other languages that do not support this concept as a top-level construct may have libraries available to represent very large numbers using arrays of smaller variables, such as Java's BigInteger class or Perl's ""bigint"" package. These use as much of the computer's memory as is necessary to store the numbers; however, a computer has only a finite amount of storage, so they, too, can only represent a finite subset of the mathematical integers. These schemes support very large numbers; for example one kilobyte of memory could be used to store numbers up to 2466 decimal digits long.
A Boolean or Flag type is a type that can represent only two values: 0 and 1, usually identified with false and true respectively.  This type can be stored in memory using a single bit, but is often given a full byte for convenience of addressing and speed of access.
A four-bit quantity is known as a nibble (when eating, being smaller than a bite) or nybble (being a pun on the form of the word byte). One nibble corresponds to one digit in hexadecimal and holds one digit or a sign code in binary-coded decimal.


=== Bytes and octets ===

The term byte initially meant 'the smallest addressable unit of memory'. In the past, 5-, 6-, 7-, 8-, and 9-bit bytes have all been used. There have also been computers that could address individual bits ('bit-addressed machine'), or that could only address 16- or 32-bit quantities ('word-addressed machine'). The term byte was usually not used at all in connection with bit- and word-addressed machines.
The term octet always refers to an 8-bit quantity. It is mostly used in the field of computer networking, where computers with different byte widths might have to communicate.
In modern usage byte almost invariably means eight bits, since all other sizes have fallen into disuse; thus byte has come to be synonymous with octet.


=== Words ===

The term 'word' is used for a small group of bits that are handled simultaneously by processors of a particular architecture. The size of a word is thus CPU-specific. Many different word sizes have been used, including 6-, 8-, 12-, 16-, 18-, 24-, 32-, 36-, 39-, 40-, 48-, 60-, and 64-bit. Since it is architectural, the size of a word is usually set by the first CPU in a family, rather than the characteristics of a later compatible CPU. The meanings of terms derived from word, such as longword, doubleword, quadword, and halfword, also vary with the CPU and OS.Practically all new desktop processors are capable of using 64-bit words, though embedded processors with 8- and 16-bit word size are still common. The 36-bit word length was common in the early days of computers.
One important cause of non-portability of software is the incorrect assumption that all computers have the same word size as the computer used by the programmer. For example, if a programmer using the C language incorrectly declares as int a variable that will be used to store values greater than 215−1, the program will fail on computers with 16-bit integers. That variable should have been declared as long, which has at least 32 bits on any computer. Programmers may also incorrectly assume that a pointer can be converted to an integer without loss of information, which may work on (some) 32-bit computers, but fail on 64-bit computers with 64-bit pointers and 32-bit integers. This issue is resolved by C99 in stdint.h in the form of intptr_t.


=== Short integer ===
A short integer can represent a whole number that may take less storage, while having a smaller range, compared with a standard integer on the same machine.
In C, it is denoted by short. It is required to be at least 16 bits, and is often smaller than a standard integer, but this is not required. A conforming program can assume that it can safely store values between −(215−1) and 215−1, but it may not assume that the range is not larger. In Java, a short is always a 16-bit integer. In the Windows API, the datatype SHORT is defined as a 16-bit signed integer on all machines.


=== Long integer ===
A long integer can represent a whole integer whose range is greater than or equal to that of a standard integer on the same machine.
In C, it is denoted by long. It is required to be at least 32 bits, and may or may not be larger than a standard integer. A conforming program can assume that it can safely store values between −(231−1) and 231−1, but it may not assume that the range is not larger.


=== Long long ===

In the C99 version of the C programming language and the C++11 version of C++, a long long type is supported that has double the minimum capacity of the standard long. This type is not supported by compilers that require C code to be compliant with the previous C++ standard, C++03, because the long long type did not exist in C++03. For an ANSI/ISO compliant compiler, the minimum requirements for the specified ranges, that is, −(263−1) to 263−1 for signed and 0 to 264−1 for unsigned, must be fulfilled; however, extending this range is permitted. This can be an issue when exchanging code and data between platforms, or doing direct hardware access. Thus, there are several sets of headers providing platform independent exact width types. The C standard library provides stdint.h; this was introduced in C99 and C++11.


== Syntax ==
Literals for integers can be written as regular Arabic numerals, consisting of a sequence of digits and with negation indicated by a minus sign before the value. However, most programming languages disallow use of commas or spaces for digit grouping. Examples of integer literals are:

42
10000
-233000There are several alternate methods for writing integer literals in many programming languages:

Many programming languages, especially those influenced by C, prefix an integer literal with 0X or 0x to represent a hexadecimal value, e.g. 0xDEADBEEF. Other languages may use a different notation, e.g. some assembly languages append an H or h to the end of a hexadecimal value.
Perl, Ruby, Java, Julia, D, Go, Rust and Python (starting from version 3.6) allow embedded underscores for clarity, e.g. 10_000_000, and fixed-form Fortran ignores embedded spaces in integer literals. C (starting from C23) and C++ use single quotes for this purpose.
In C and C++, a leading zero indicates an octal value, e.g. 0755. This was primarily intended to be used with Unix modes; however, it has been criticized because normal integers may also lead with zero. As such, Python, Ruby, Haskell, and OCaml prefix octal values with 0O or 0o, following the layout used by hexadecimal values.
Several languages, including Java, C#, Scala, Python, Ruby, OCaml, C (starting from C23) and C++ can represent binary values by prefixing a number with 0B or 0b.


== See also ==
Arbitrary-precision arithmetic
Binary-coded decimal (BCD)
C data types
Integer overflow
Signed number representations


== Notes ==


== References =="
dea998ab8a,Ontology (computer science),"In computer science and information science, an ontology encompasses a representation, formal naming, and definition of the categories, properties, and relations between the concepts, data, and entities that substantiate one, many, or all domains of discourse. More simply, an ontology is a way of showing the properties of a subject area and how they are related, by defining a set of concepts and categories that represent the subject.
Every academic discipline or field creates ontologies to limit complexity and organize data into information and knowledge. 
Each uses ontological assumptions to frame explicit theories, research and applications. New ontologies may improve problem solving within that domain. Translating research papers within every field is a problem made easier when experts from different countries maintain a controlled vocabulary of jargon between each of their languages.For instance, the definition and ontology of economics is a primary concern in Marxist economics, but also in other subfields of economics. An example of economics relying on information science occurs in cases where a simulation or model is intended to enable economic decisions, such as determining what capital assets are at risk and by how much (see risk management).
What ontologies in both computer science and philosophy have in common is the attempt to represent entities, ideas and events, with all their interdependent properties and relations, according to a system of categories. In both fields, there is considerable work on problems of ontology engineering (e.g., Quine and Kripke in philosophy, Sowa and Guarino in computer science), and debates concerning to what extent normative ontology is possible (e.g., foundationalism and coherentism in philosophy, BFO and Cyc in artificial intelligence).
Applied ontology is considered a successor to prior work in philosophy, however many current efforts are more concerned with establishing controlled vocabularies of narrow domains than first principles, the existence of fixed essences or whether enduring objects (e.g., perdurantism and endurantism) may be ontologically more primary than processes. Artificial intelligence has retained the most attention regarding applied ontology in subfields like natural language processing within machine translation and knowledge representation, but ontology editors are being used often in a range of fields like education without the intent to contribute to AI.


== Etymology ==

The compound word ontology combines onto-, from the Greek ὄν, on (gen. ὄντος, ontos), i.e. ""being; that which is"", which is the present participle of the verb εἰμί, eimí, i.e. ""to be, I am"", and -λογία, -logia, i.e. ""logical discourse"", see classical compounds for this type of word formation.While the etymology is Greek, the oldest extant record of the word itself, the New Latin form ontologia, appeared in 1606 in the work Ogdoas Scholastica by Jacob Lorhard (Lorhardus) and in 1613 in the Lexicon philosophicum by Rudolf Göckel (Goclenius).
The first occurrence in English of ontology as recorded by the OED (Oxford English Dictionary, online edition, 2008) came in Archeologia Philosophica Nova or New Principles of Philosophy by Gideon Harvey.


== History ==

Ontologies arise out of the branch of philosophy known as metaphysics, which deals with questions like ""what exists?"" and ""what is the nature of reality?"". One of five traditional branches of philosophy, metaphysics is concerned with exploring existence through properties, entities and relations such as those between particulars and universals, intrinsic and extrinsic properties, or essence and existence. Metaphysics has been an ongoing topic of discussion since recorded history.
Since the mid-1970s, researchers in the field of artificial intelligence (AI) have recognized that knowledge engineering is the key to building large and powerful AI systems. AI researchers argued that they could create new ontologies as computational models that enable certain kinds of automated reasoning, which was only marginally successful. In the 1980s, the AI community began to use the term ontology to refer to both a theory of a modeled world and a component of knowledge-based systems. In particular, David Powers introduced the word ontology to AI to refer to real world or robotic grounding, publishing in 1990 literature reviews emphasizing grounded ontology in association with the call for papers for a AAAI Summer Symposium Machine Learning of Natural Language and Ontology, with an expanded version published in SIGART Bulletin and included as a preface to the proceedings.  Some researchers, drawing inspiration from philosophical ontologies, viewed computational ontology as a kind of applied philosophy.
In 1993, the widely cited web page and paper ""Toward Principles for the Design of Ontologies Used for Knowledge Sharing"" by Tom Gruber used ontology as a technical term in computer science closely related to earlier idea of semantic networks and taxonomies. Gruber introduced the term as a specification of a conceptualization: An ontology is a description (like a formal specification of a program) of the concepts and relationships that can formally exist for an agent or a community of agents. This definition is consistent with the usage of ontology as set of concept definitions, but more general. And it is a different sense of the word than its use in philosophy.
Attempting to distance ontologies from taxonomies and similar efforts in knowledge modeling that rely on classes and inheritance, Gruber stated (1993): Ontologies are often equated with taxonomic hierarchies of classes, class definitions, and the subsumption relation, but ontologies need not be limited to these forms. Ontologies are also not limited to conservative definitions — that is, definitions in the traditional logic sense that only introduce terminology and do not add any knowledge about the world. To specify a conceptualization, one needs to state axioms that do constrain the possible interpretations for the defined terms.
As refinement of Gruber's definition Feilmayr and Wöß (2016) stated: ""An ontology is a formal, explicit specification of a shared conceptualization that is characterized by high semantic expressiveness required for increased complexity.""


== Components ==

Contemporary ontologies share many structural similarities, regardless of the language in which they are expressed.  Most ontologies describe individuals (instances), classes (concepts), attributes and relations.  In this section each of these components is discussed in turn.
Common components of ontologies include:

Individuals
Instances or objects (the basic or ""ground level"" objects)
Classes
Sets, collections, concepts, classes in programming, types of objects or kinds of things
Attributes
Aspects, properties, features, characteristics or parameters that objects (and classes) can have
Relations
Ways in which classes and individuals can be related to one another
Function terms
Complex structures formed from certain relations that can be used in place of an individual term in a statement
Restrictions
Formally stated descriptions of what must be true in order for some assertion to be accepted as input
Rules
Statements in the form of an if-then (antecedent-consequent) sentence that describe the logical inferences that can be drawn from an assertion in a particular form
Axioms
Assertions (including rules) in a logical form that together comprise the overall theory that the ontology describes in its domain of application. This definition differs from that of ""axioms"" in generative grammar and formal logic.  In those disciplines, axioms include only statements asserted as a priori knowledge.  As used here, ""axioms"" also include the theory derived from axiomatic statements
Events
The changing of attributes or relationsOntologies are commonly encoded using ontology languages.


== Types ==


=== Domain ontology ===
A domain ontology (or domain-specific ontology) represents concepts which belong to a realm of the world, such as biology or politics. Each domain ontology typically models domain-specific definitions of terms. For example, the word card has many different meanings. An ontology about the domain of poker would model the ""playing card"" meaning of the word, while an ontology about the domain of computer hardware would model the ""punched card"" and ""video card"" meanings.
Since domain ontologies are written by different people, they represent concepts in very specific and unique ways, and are often incompatible within the same project. As systems that rely on domain ontologies expand, they often need to merge domain ontologies by hand-tuning each entity or using a combination of software merging and hand-tuning. This presents a challenge to the ontology designer. Different ontologies in the same domain arise due to different languages, different intended usage of the ontologies, and different perceptions of the domain (based on cultural background, education, ideology, etc.).
At present, merging ontologies that are not developed from a common upper ontology is a largely manual process and therefore time-consuming and expensive. Domain ontologies that use the same upper ontology to provide a set of basic elements with which to specify the meanings of the domain ontology entities can be merged with less effort. There are studies on generalized techniques for merging ontologies, but this area of research is still ongoing, and it's a recent event to see the issue sidestepped by having multiple domain ontologies using the same upper ontology like the OBO Foundry.


=== Upper ontology ===

An upper ontology (or foundation ontology) is a model of the commonly shared relations and objects that are generally applicable across a wide range of domain ontologies. It usually employs a core glossary that overarches the terms and associated object descriptions as they are used in various relevant domain ontologies.
Standardized upper ontologies available for use include BFO, BORO method, Dublin Core, GFO, Cyc, SUMO, UMBEL, the Unified Foundational Ontology (UFO), and DOLCE. WordNet has been considered an upper ontology by some and has been used as a linguistic tool for learning domain ontologies.


=== Hybrid ontology ===
The Gellish ontology is an example of a combination of an upper and a domain ontology.


== Visualization ==
A survey of ontology visualization methods is presented by Katifori et al. An updated survey of ontology visualization methods and tools was published by Dudás et al. The most established ontology visualization methods, namely indented tree and graph visualization are evaluated by Fu et al. A visual language for ontologies represented in OWL is specified by the Visual Notation for OWL Ontologies (VOWL).


== Engineering ==

Ontology engineering (also called ontology building)  is a set of tasks related to the development of ontologies for a particular domain. It is a subfield of knowledge engineering that studies the ontology development process, the ontology life cycle, the methods and methodologies for building ontologies, and the tools and languages that support them.Ontology engineering aims to make explicit the knowledge contained in software applications, and organizational procedures for a particular domain. Ontology engineering offers a direction for overcoming semantic obstacles, such as those related to the definitions of business terms and software classes. Known challenges with ontology engineering include:

Ensuring the ontology is current with domain knowledge and term use
Providing sufficient specificity and concept coverage for the domain of interest, thus minimizing the content completeness problem
Ensuring the ontology can support its use cases


=== Editors ===
Ontology editors are applications designed to assist in the creation or manipulation of ontologies. It is common for ontology editors to use one or more ontology languages.
Aspects of ontology editors include: visual navigation possibilities within the knowledge model, inference engines and information extraction; support for modules; the import and export of foreign knowledge representation languages for ontology matching; and the support of meta-ontologies such as OWL-S, Dublin Core, etc.


=== Learning ===

Ontology learning is the automatic or semi-automatic creation of ontologies, including extracting a domain's terms from natural language text. As building ontologies manually is extremely labor-intensive and time-consuming, there is great motivation to automate the process.  Information extraction and text mining have been explored to automatically link ontologies to documents, for example in the context of the BioCreative challenges.


=== Research ===

Epistemological assumptions, which in research asks ""What do you know? or ""How do you know it?"", creates the foundation researchers use when approaching a certain topic or area for potential research. As epistemology is directly linked to knowledge and how we come about accepting certain truths, individuals conducting academic research must understand what allows them to begin theory building. Simply, epistemological assumptions force researchers to question how they arrive at the knowledge they have.


== Languages ==

An ontology language is a formal language used to encode an ontology. There are a number of such languages for ontologies, both proprietary and standards-based:

Common Algebraic Specification Language is a general logic-based specification language developed within the IFIP working group 1.3 ""Foundations of System Specifications"" and is a de facto standard language for software specifications. It is now being applied to ontology specifications in order to provide modularity and structuring mechanisms.
Common logic is ISO standard 24707, a specification of a family of ontology languages that can be accurately translated into each other.
The Cyc project has its own ontology language called CycL, based on first-order predicate calculus with some higher-order extensions.
DOGMA (Developing Ontology-Grounded Methods and Applications) adopts the fact-oriented modeling approach to provide a higher level of semantic stability.
The Gellish language includes rules for its own extension and thus integrates an ontology with an ontology language.
IDEF5 is a software engineering method to develop and maintain usable, accurate, domain ontologies.
KIF is a syntax for first-order logic that is based on S-expressions.  SUO-KIF is a derivative version supporting the Suggested Upper Merged Ontology.
MOF and UML are standards of the OMG
Olog is a category theoretic approach to ontologies, emphasizing translations between ontologies using functors.
OBO, a language used for biological and biomedical ontologies.
OntoUML is an ontologically well-founded profile of UML for conceptual modeling of domain ontologies.
OWL is a language for making ontological statements, developed as a follow-on from RDF and RDFS, as well as earlier ontology language projects including OIL, DAML, and DAML+OIL. OWL is intended to be used over the World Wide Web, and all its elements (classes, properties and individuals) are defined as RDF resources, and identified by URIs.
Rule Interchange Format (RIF) and F-Logic combine ontologies and rules.
Semantic Application Design Language (SADL) captures a subset of the expressiveness of OWL, using an English-like language entered via an Eclipse Plug-in.
SBVR (Semantics of Business Vocabularies and Rules) is an OMG standard adopted in industry to build ontologies.
TOVE Project, TOronto Virtual Enterprise project


== Published examples ==
Arabic Ontology, a linguistic ontology for Arabic, which can be used as an Arabic Wordnet but with ontologically-clean content.
AURUM - Information Security Ontology, An ontology for information security knowledge sharing, enabling users to collaboratively understand and extend the domain knowledge body. It may serve as a basis for automated information security risk and compliance management.
BabelNet, a very large multilingual semantic network and ontology, lexicalized in many languages
Basic Formal Ontology, a formal upper ontology designed to support scientific research
BioPAX, an ontology for the exchange and interoperability of biological pathway (cellular processes) data
BMO, an e-Business Model Ontology based on a review of enterprise ontologies and business model literature
SSBMO, a Strongly Sustainable Business Model Ontology based on a review of the systems based natural and social science literature (including business).  Includes critique of and significant extensions to the Business Model Ontology (BMO).
CCO and GexKB, Application Ontologies (APO) that integrate diverse types of knowledge with the Cell Cycle Ontology (CCO) and the Gene Expression Knowledge Base (GexKB)
CContology (Customer Complaint Ontology), an e-business ontology to support online customer complaint management
CIDOC Conceptual Reference Model, an ontology for cultural heritage
COSMO, a Foundation Ontology (current version in OWL) that is designed to contain representations of all of the primitive concepts needed to logically specify the meanings of any domain entity.  It is intended to serve as a basic ontology that can be used to translate among the representations in other ontologies or databases.  It started as a merger of the basic elements of the OpenCyc and SUMO ontologies, and has been supplemented with other ontology elements (types, relations) so as to include representations of all of the words in the Longman dictionary defining vocabulary.
Computer Science Ontology, an automatically generated ontology of research topics in the field of Computer Science
Cyc, a large Foundation Ontology for formal representation of the universe of discourse
Disease Ontology, designed to facilitate the mapping of diseases and associated conditions to particular medical codes
DOLCE, a Descriptive Ontology for Linguistic and Cognitive Engineering
Drammar, ontology of drama
Dublin Core, a simple ontology for documents and publishing
Financial Industry Business Ontology (FIBO),  a business conceptual ontology for the financial industry
Foundational, Core and Linguistic Ontologies
Foundational Model of Anatomy, an ontology for human anatomy
Friend of a Friend, an ontology for describing persons, their activities and their relations to other people and objects
Gene Ontology for genomics
Gellish English dictionary, an ontology that includes a dictionary and taxonomy that includes an upper ontology and a lower ontology that focusses on industrial and business applications in engineering, technology and procurement.
Geopolitical ontology, an ontology describing geopolitical information created by Food and Agriculture Organization(FAO). The geopolitical ontology includes names in multiple languages (English, French, Spanish, Arabic, Chinese, Russian and Italian); maps standard coding systems (UN, ISO, FAOSTAT, AGROVOC, etc.); provides relations among territories (land borders, group membership, etc.); and tracks historical changes. In addition, FAO provides web services of geopolitical ontology and a module maker to download modules of the geopolitical ontology into different formats (RDF, XML, and EXCEL). See more information at FAO Country Profiles.
GAO (General Automotive Ontology) - an ontology for the automotive industry that includes 'car' extensions
GOLD, General Ontology for Linguistic Description
GUM (Generalized Upper Model), a linguistically motivated ontology for mediating between clients systems and natural language technology
IDEAS Group, a formal ontology for enterprise architecture being developed by the Australian, Canadian, UK and U.S. Defence Depts.
Linkbase, a formal representation of the biomedical domain, founded upon Basic Formal Ontology.
LPL, Landmark Pattern Language
NCBO Bioportal, biological and biomedical ontologies and associated tools to search, browse and visualise
NIFSTD Ontologies from the Neuroscience Information Framework: a modular set of ontologies for the neuroscience domain.
OBO-Edit, an ontology browser for most of the Open Biological and Biomedical Ontologies
OBO Foundry, a suite of interoperable reference ontologies in biology and biomedicine
OMNIBUS Ontology, an ontology of learning, instruction, and instructional design
Ontology for Biomedical Investigations, an open-access, integrated ontology of biological and clinical investigations
ONSTR, Ontology for Newborn Screening Follow-up and Translational Research, Newborn Screening Follow-up Data Integration Collaborative, Emory University, Atlanta.
Plant Ontology for plant structures and growth/development stages, etc.
POPE, Purdue Ontology for Pharmaceutical Engineering
PRO, the Protein Ontology of the Protein Information Resource, Georgetown University
ProbOnto, knowledge base and ontology of probability distributions.
Program abstraction taxonomy
Protein Ontology for proteomics
RXNO Ontology, for name reactions in chemistry
SCDO, the Sickle Cell Disease Ontology, facilitates data sharing and collaborations within the SDC community, amongst other applications (see list on SCDO website).
Sequence Ontology, for representing genomic feature types found on biological sequences
SNOMED CT (Systematized Nomenclature of Medicine—Clinical Terms)
Suggested Upper Merged Ontology, a formal upper ontology
Systems Biology Ontology (SBO), for computational models in biology
SWEET, Semantic Web for Earth and Environmental Terminology
SSN/SOSA, The Semantic Sensor Network Ontology (SSN) and Sensor, Observation, Sample, and Actuator Ontology (SOSA) are W3C Recommendation  and OGC Standards for describing sensors and their observations.
ThoughtTreasure ontology
TIME-ITEM, Topics for Indexing Medical Education
Uberon, representing animal anatomical structures
UMBEL, a lightweight reference structure of 20,000 subject concept classes and their relationships derived from OpenCyc
WordNet, a lexical reference system
YAMATO, Yet Another More Advanced Top-level OntologyThe W3C Linking Open Data community project coordinates attempts to converge different ontologies into worldwide Semantic Web.


== Libraries ==
The development of ontologies has led to the emergence of services providing lists or directories of ontologies called ontology libraries.
The following are libraries of human-selected ontologies.

COLORE is an open repository of first-order ontologies in Common Logic with formal links between ontologies in the repository.
DAML Ontology Library maintains a legacy of ontologies in DAML.
Ontology Design Patterns portal is a wiki repository of reusable components and practices for ontology design, and also maintains a list of exemplary ontologies.
Protégé Ontology Library contains a set of OWL, Frame-based and other format ontologies.
SchemaWeb is a directory of RDF schemata expressed in RDFS, OWL and DAML+OIL.The following are both directories and search engines.

OBO Foundry is a suite of interoperable reference ontologies in biology and biomedicine.
Bioportal (ontology repository of NCBO)
OntoSelect Ontology Library offers similar services for RDF/S, DAML and OWL ontologies.
Ontaria is a ""searchable and browsable directory of semantic web data"" with a focus on RDF vocabularies with OWL ontologies. (NB Project ""on hold"" since 2004).
Swoogle is a directory and search engine for all RDF resources available on the Web, including ontologies.
Open Ontology Repository initiative
ROMULUS is a foundational ontology repository aimed at improving semantic interoperability. Currently there are three foundational ontologies in the repository: DOLCE, BFO and GFO.


== Examples of applications ==
In general, ontologies can be used beneficially in several fields.

Enterprise applications. A more concrete example is SAPPHIRE (Health care) or Situational Awareness and Preparedness for Public Health Incidences and Reasoning Engines which is a semantics-based health information system capable of tracking and evaluating situations and occurrences that may affect public health.
Geographic information systems bring together data from different sources and benefit therefore from ontological metadata which helps to connect the semantics of the data.
Domain-specific ontologies are extremely important in biomedical research, which requires named entity disambiguation of various biomedical terms and abbreviations that have the same string of characters but represent different biomedical concepts. For example, CSF can represent Colony Stimulating Factor or Cerebral Spinal Fluid, both of which are represented by the same term, CSF, in biomedical literature. This is why a large number of public ontologies are related to the life sciences. Life science data science tools that fail to implement these types of biomedical ontologies will not be able to accurately determine causal relationships between concepts.


== See also ==

Related philosophical conceptsAlphabet of human thought
Characteristica universalis
Interoperability
Level of measurement
Metalanguage
Natural semantic metalanguage


== References ==


== Further reading ==
Oberle, D.; Guarino, N.; Staab, S. (2009). ""What is an ontology?"" (PDF). Staab & Studer 2009. pp. 1–17. doi:10.1007/978-3-540-92673-3_0. ISBN 978-3-540-70999-2.
Fensel, D.; van Harmelen, F.; Horrocks, I.; McGuinness, D.L.; Patel-Schneider, P.F. (2001). ""OIL: an ontology infrastructure for the Semantic Web"". IEEE Intelligent Systems. 16 (2): 38–45. doi:10.1109/5254.920598.
Gangemi, A.; Presutti, V. ""Ontology Design Patterns"" (PDF). Staab & Studer 2009.
Golemati, M.; Katifori, A.; Vassilakis, C.; Lepouras, G.; Halatsis, C. (2007). ""Creating an Ontology for the User Profile# Method and Applications"" (PDF). Proceedings of the First IEEE International Conference on Research Challenges in Information Science (RCIS), Morocco 2007. CiteSeerX 10.1.1.74.9399. Archived from the original (PDF) on 2008-12-17.
Mizoguchi, R. (2004). ""Tutorial on ontological engineering: Part 3: Advanced course of ontological engineering"" (PDF). New Gener Comput. 22: 193–220. doi:10.1007/BF03040960. S2CID 23747079. Archived from the original (PDF) on 2013-03-09. Retrieved 2009-06-08.
Gruber, T. R. (1993). ""A translation approach to portable ontology specifications"" (PDF). Knowledge Acquisition. 5 (2): 199–220. CiteSeerX 10.1.1.101.7493. doi:10.1006/knac.1993.1008. S2CID 15709015.
Maedche, A.; Staab, S. (2001). ""Ontology learning for the Semantic Web"". IEEE Intelligent Systems. 16 (2): 72–79. doi:10.1109/5254.920602. S2CID 1411149.
Noy, Natalya F.; McGuinness, Deborah L. (March 2001). ""Ontology Development 101: A Guide to Creating Your First Ontology"". Stanford Knowledge Systems Laboratory Technical Report KSL-01-05, Stanford Medical Informatics Technical Report SMI-2001-0880. Archived from the original on 2010-07-14. {{cite journal}}: Cite journal requires |journal= (help)
Chaminda Abeysiriwardana, Prabath; Kodituwakku, Saluka R (2012). ""Ontology Based Information Extraction for Disease Intelligence"". International Journal of Research in Computer Science. 2 (6): 7–19. arXiv:1211.3497. Bibcode:2012arXiv1211.3497C. doi:10.7815/ijorcs.26.2012.051. S2CID 11297019.
Razmerita, L.; Angehrn, A.; Maedche, A. (2003). ""Ontology-Based User Modeling for Knowledge Management Systems"". User Modeling 2003. Lecture Notes in Computer Science. Vol. 2702. Springer. pp. 213–7. CiteSeerX 10.1.1.102.4591. doi:10.1007/3-540-44963-9_29. ISBN 3-540-44963-9.
Soylu, A.; De Causmaecker, Patrick (2009). ""Merging model driven and ontology driven system development approaches pervasive computing perspective"". Proceedings of the 24th International Symposium on Computer and Information Sciences. pp. 730–5. doi:10.1109/ISCIS.2009.5291915. ISBN 978-1-4244-5021-3. S2CID 2267593.
Smith, B. (2008). ""Ontology (Science)"".  In Eschenbach, C.; Gruninger, M. (eds.). Formal Ontology in Information Systems, Proceedings of FOIS 2008. ISO Press. pp. 21–35. CiteSeerX 10.1.1.681.2599.
Staab, S.; Studer, R., eds. (2009). Handbook on Ontologies (2nd ed.). Springer. doi:10.1007/978-3-540-92673-3_0. ISBN 978-3-540-92673-3.
Uschold, Mike; Gruninger, M. (1996). ""Ontologies: Principles, Methods and Applications"". Knowledge Engineering Review. 11 (2): 93–136. CiteSeerX 10.1.1.111.5903. doi:10.1017/S0269888900007797. S2CID 2618234.
Pidcock, W. ""What are the differences between a vocabulary, a taxonomy, a thesaurus, an ontology, and a meta-model?"". Archived from the original on 2009-10-14.
Yudelson, M.; Gavrilova, T.; Brusilovsky, P. (2005). ""Towards User Modeling Meta-ontology"". User Modeling 2005. Lecture Notes in Computer Science. Vol. 3538. Springer. pp. 448–452. CiteSeerX 10.1.1.86.7079. doi:10.1007/11527886_62. ISBN 978-3-540-31878-1.
Movshovitz-Attias, Dana; Cohen, William W. (2012). ""Bootstrapping Biomedical Ontologies for Scientific Text using NELL"" (PDF). Proceedings of the 2012 Workshop on Biomedical Natural Language Processing. Association for Computational Linguistics. pp. 11–19. CiteSeerX 10.1.1.376.2874.


== External links ==

Knowledge Representation at Open Directory Project
Library of ontologies
GoPubMed using Ontologies for searching
ONTOLOG (a.k.a. ""Ontolog Forum"") - an Open, International, Virtual Community of Practice on Ontology, Ontological Engineering and Semantic Technology
Use of Ontologies in Natural Language Processing
Ontology Summit - an annual series of events (first started in 2006) that involves the ontology community and communities related to each year's theme chosen for the summit.
Standardization of Ontologies"
d1f729928a,Abstraction (computer science),"In software engineering and computer science, abstraction is:

The process of removing or generalizing physical, spatial, or temporal details or attributes in the study of objects or systems to focus attention on details of greater importance; it is similar in nature to the process of generalization;
the creation of abstract concept-objects by mirroring common features or attributes of various non-abstract objects or systems of study – the result of the process of abstraction.Abstraction, in general, is a fundamental concept in computer science and software development. The process of abstraction can also be referred to as modeling and is closely related to the concepts of theory and design. Models can also be considered types of abstractions per their generalization of aspects of reality.
Abstraction in computer science is closely related to abstraction in mathematics due to their common focus on building abstractions as objects, but is also related to other notions of abstraction used in other fields such as art.Abstractions may also refer to real-world objects and systems, rules of computational systems or rules of programming languages that carry or utilize features of abstraction itself, such as:

the usage of data types to perform data abstraction to separate usage from working representations of data structures within programs;
the concept of procedures, functions, or subroutines which represent a specific of implementing control flow in programs;
the rules commonly named ""abstraction"" that generalize expressions using free and bound variables in the various versions of lambda calculus;
the usage of S-expressions as an abstraction of data structures and programs in the Lisp programming language;
the process of reorganizing common behavior from non-abstract classes into ""abstract classes"" using inheritance to abstract over sub-classes as seen in the object-oriented C++ and Java programming languages.


== Rationale ==
Computing mostly operates independently of the concrete world. The hardware implements a model of computation that is interchangeable with others. The software is structured in architectures to enable humans to create the enormous systems by concentrating on a few issues at a time. These architectures are made of specific choices of abstractions. Greenspun's Tenth Rule is an aphorism on how such an architecture is both inevitable and complex.
A central form of abstraction in computing is language abstraction: new artificial languages are developed to express specific aspects of a system. Modeling languages help in planning. Computer languages can be processed with a computer. An example of this abstraction process is the generational development of programming languages from the machine language to the assembly language and the high-level language. Each stage can be used as a stepping stone for the next stage. The language abstraction continues for example in scripting languages and domain-specific programming languages.
Within a programming language, some features let the programmer create new abstractions. These include subroutines, modules, polymorphism, and software components. Some other abstractions such as software design patterns and architectural styles remain invisible to a translator and operate only in the design of a system.
Some abstractions try to limit the range of concepts a programmer needs to be aware of, by completely hiding the abstractions that they in turn are built on. The software engineer and writer Joel Spolsky has criticised these efforts by claiming that all abstractions are leaky – that they can never completely hide the details below; however, this does not negate the usefulness of abstraction.
Some abstractions are designed to inter-operate with other abstractions – for example, a programming language may contain a foreign function interface for making calls to the lower-level language.


== Abstraction features ==


=== Programming languages ===

Different programming languages provide different types of abstraction, depending on the intended applications for the language. For example:

In object-oriented programming languages such as C++, Object Pascal, or Java, the concept of abstraction has itself become a declarative statement – using the syntax function(parameters) = 0; (in C++) or the keywords abstract and interface (in Java). After such a declaration, it is the responsibility of the programmer to implement a class to instantiate the object of the declaration.
Functional programming languages commonly exhibit abstractions related to functions, such as lambda abstractions (making a term into a function of some variable) and higher-order functions (parameters are functions).
Modern members of the Lisp programming language family such as Clojure, Scheme and Common Lisp support macro systems to allow syntactic abstraction. Other programming languages such as Scala also have macros, or very similar metaprogramming features (for example, Haskell has Template Haskell, and OCaml has MetaOCaml). These can allow a programmer to eliminate boilerplate code, abstract away tedious function call sequences, implement new control flow structures, and implement Domain Specific Languages (DSLs), which allow domain-specific concepts to be expressed in concise and elegant ways. All of these, when used correctly, improve both the programmer's efficiency and the clarity of the code by making the intended purpose more explicit. A consequence of syntactic abstraction is also that any Lisp dialect and in fact almost any programming language can, in principle, be implemented in any modern Lisp with significantly reduced (but still non-trivial in most cases) effort when compared to ""more traditional"" programming languages such as Python, C or Java.


=== Specification methods ===

Analysts have developed various methods to formally specify software systems.  Some known methods include:

Abstract-model based method (VDM, Z);
Algebraic techniques (Larch, CLEAR, OBJ, ACT ONE, CASL);
Process-based techniques (LOTOS, SDL, Estelle);
Trace-based techniques (SPECIAL, TAM);
Knowledge-based techniques (Refine, Gist).


=== Specification languages ===

Specification languages generally rely on abstractions of one kind or another, since specifications are typically defined earlier in a project, (and at a more abstract level) than an eventual implementation. The UML specification language, for example, allows the definition of abstract classes, which in a waterfall project, remain abstract during the architecture and specification phase of the project.


== Control abstraction ==

Programming languages offer control abstraction as one of the main purposes of their use. Computer machines understand operations at the very low level such as moving some bits from one location of the memory to another location and producing the sum of two sequences of bits. Programming languages allow this to be done in the higher level. For example, consider this statement written in a Pascal-like fashion:

a := (1 + 2) * 5To a human, this seems a fairly simple and obvious calculation (""one plus two is three, times five is fifteen""). However, the low-level steps necessary to carry out this evaluation, and return the value ""15"", and then assign that value to the variable ""a"", are actually quite subtle and complex. The values need to be converted to binary representation (often a much more complicated task than one would think) and the calculations decomposed (by the compiler or interpreter) into assembly instructions (again, which are much less intuitive to the programmer: operations such as shifting a binary register left, or adding the binary complement of the contents of one register to another, are simply not how humans think about the abstract arithmetical operations of addition or multiplication). Finally, assigning the resulting value of ""15"" to the variable labeled ""a"", so that ""a"" can be used later, involves additional 'behind-the-scenes' steps of looking up a variable's label and the resultant location in physical or virtual memory, storing the binary representation of ""15"" to that memory location, etc.
Without control abstraction, a programmer would need to specify all the register/binary-level steps each time they simply wanted to add or multiply a couple of numbers and assign the result to a variable. Such duplication of effort has two serious negative consequences:

it forces the programmer to constantly repeat fairly common tasks every time a similar operation is needed
it forces the programmer to program for the particular hardware and instruction set


=== Structured programming ===

Structured programming involves the splitting of complex program tasks into smaller pieces with clear flow-control and interfaces between components, with a reduction of the complexity potential for side-effects.
In a simple program, this may aim to ensure that loops have single or obvious exit points and (where possible) to have single exit points from functions and procedures.
In a larger system, it may involve breaking down complex tasks into many different modules. Consider a system which handles payroll on ships and at shore offices:

The uppermost level may feature a menu of typical end-user operations.
Within that could be standalone executables or libraries for tasks such as signing on and off employees or printing checks.
Within each of those standalone components there could be many different source files, each containing the program code to handle a part of the problem, with only selected interfaces available to other parts of the program. A sign on program could have source files for each data entry screen and the database interface (which may itself be a standalone third party library or a statically linked set of library routines).
Either the database or the payroll application also has to initiate the process of exchanging data with between ship and shore, and that data transfer task will often contain many other components.These layers produce the effect of isolating the implementation details of one component and its assorted internal methods from the others. Object-oriented programming embraces and extends this concept.


== Data abstraction ==

Data abstraction enforces a clear separation between the abstract properties of a data type and the concrete details of its implementation. The abstract properties are those that are visible to client code that makes use of the data type—the interface to the data type—while the concrete implementation is kept entirely private, and indeed can change, for example to incorporate efficiency improvements over time. The idea is that such changes are not supposed to have any impact on client code, since they involve no difference in the abstract behaviour.
For example, one could define an abstract data type called lookup table which uniquely associates keys with values, and in which values may be retrieved by specifying their corresponding keys. Such a lookup table may be implemented in various ways: as a hash table, a binary search tree, or even a simple linear list of (key:value) pairs. As far as client code is concerned, the abstract properties of the type are the same in each case.
Of course, this all relies on getting the details of the interface right in the first place, since any changes there can have major impacts on client code. As one way to look at this: the interface forms a contract on agreed behaviour between the data type and client code; anything not spelled out in the contract is subject to change without notice.


== Manual data abstraction ==
While much of data abstraction occurs through computer science and automation, there are times when this process is done manually and without programming intervention. One way this can be understood is through data abstraction within the process of conducting a systematic review of the literature. In this methodology, data is abstracted by one or several abstractors when conducting a meta-analysis, with errors reduced through dual data abstraction followed by independent checking, known as adjudication.


== Abstraction in object oriented programming ==

In object-oriented programming theory, abstraction involves the facility to define objects that represent abstract ""actors"" that can perform work, report on and change their state, and ""communicate"" with other objects in the system. The term encapsulation refers to the hiding of state details, but extending the concept of data type from earlier programming languages to associate behavior most strongly with the data, and standardizing the way that different data types interact, is the beginning of abstraction.  When abstraction proceeds into the operations defined, enabling objects of different types to be substituted, it is called polymorphism. When it proceeds in the opposite direction, inside the types or classes, structuring them to simplify a complex set of relationships, it is called delegation or inheritance.
Various object-oriented programming languages offer similar facilities for abstraction, all to support a general strategy of polymorphism in object-oriented programming, which includes the substitution of one type for another in the same or similar role. Although not as generally supported, a configuration or image or package may predetermine a great many of these bindings at compile-time, link-time, or loadtime. This would leave only a minimum of such bindings to change at run-time.
Common Lisp Object System or Self, for example, feature less of a class-instance distinction and more use of delegation for polymorphism. Individual objects and functions are abstracted more flexibly to better fit with a shared functional heritage from Lisp.
C++ exemplifies another extreme: it relies heavily on templates and overloading and other static bindings at compile-time, which in turn has certain flexibility problems.
Although these examples offer alternate strategies for achieving the same abstraction, they do not fundamentally alter the need to support abstract nouns in code – all programming relies on an ability to abstract verbs as functions, nouns as data structures, and either as processes.
Consider for example a sample Java fragment to represent some common farm ""animals"" to a level of abstraction suitable to model simple aspects of their hunger and feeding. It defines an Animal class to represent both the state of the animal and its functions:

With the above definition, one could create objects of type Animal and call their methods like this:

In the above example, the class Animal is an abstraction used in place of an actual animal, LivingThing is a further abstraction (in this case a generalisation) of Animal.
If one requires a more differentiated hierarchy of animals – to differentiate, say, those who provide milk from those who provide nothing except meat at the end of their lives – that is an intermediary level of abstraction, probably DairyAnimal (cows, goats) who would eat foods suitable to giving good milk, and MeatAnimal (pigs, steers) who would eat foods to give the best meat-quality.
Such an abstraction could remove the need for the application coder to specify the type of food, so they could concentrate instead on the feeding schedule. The two classes could be related using inheritance or stand alone, and the programmer could define varying degrees of polymorphism between the two types. These facilities tend to vary drastically between languages, but in general each can achieve anything that is possible with any of the others. A great many operation overloads, data type by data type, can have the same effect at compile-time as any degree of inheritance or other means to achieve polymorphism. The class notation is simply a coder's convenience.


=== Object-oriented design ===

Decisions regarding what to abstract and what to keep under the control of the coder become the major concern of object-oriented design and domain analysis—actually determining the relevant relationships in the real world is the concern of object-oriented analysis or legacy analysis.
In general, to determine appropriate abstraction, one must make many small decisions about scope (domain analysis), determine what other systems one must cooperate with (legacy analysis), then perform a detailed object-oriented analysis which is expressed within project time and budget constraints as an object-oriented design. In our simple example, the domain is the barnyard, the live pigs and cows and their eating habits are the legacy constraints, the detailed analysis is that coders must have the flexibility to feed the animals what is available and thus there is no reason to code the type of food into the class itself, and the design is a single simple Animal class of which pigs and cows are instances with the same functions. A decision to differentiate DairyAnimal would change the detailed analysis but the domain and legacy analysis would be unchanged—thus it is entirely under the control of the programmer, and it is called an abstraction in object-oriented programming as distinct from abstraction in domain or legacy analysis.


== Considerations ==
When discussing formal semantics of programming languages, formal methods or abstract interpretation, abstraction refers to the act of considering a less detailed, but safe, definition of the observed program behaviors. For instance, one may observe only the final result of program executions instead of considering all the intermediate steps of executions. Abstraction is defined to a concrete (more precise) model of execution.
Abstraction may be exact or faithful with respect to a property if one can answer a question about the property equally well on the concrete or abstract model. For instance, if one wishes to know what the result of the evaluation of a mathematical expression involving only integers +, -, ×, is worth modulo n, then one needs only perform all operations modulo n (a familiar form of this abstraction is casting out nines).
Abstractions, however, though not necessarily exact, should be sound. That is, it should be possible to get sound answers from them—even though the abstraction may simply yield a result of undecidability. For instance, students in a class may be abstracted by their minimal and maximal ages; if one asks whether a certain person belongs to that class, one may simply compare that person's age with the minimal and maximal ages; if his age lies outside the range, one may safely answer that the person does not belong to the class; if it does not, one may only answer ""I don't know"".
The level of abstraction included in a programming language can influence its overall usability. The Cognitive dimensions framework includes the concept of abstraction gradient in a formalism. This framework allows the designer of a programming language to study the trade-offs between abstraction and other characteristics of the design, and how changes in abstraction influence the language usability.
Abstractions can prove useful when dealing with computer programs, because non-trivial properties of computer programs are essentially undecidable (see Rice's theorem). As a consequence, automatic methods for deriving information on the behavior of computer programs either have to drop termination (on some occasions, they may fail, crash or never yield out a result), soundness (they may provide false information), or precision (they may answer ""I don't know"" to some questions).
Abstraction is the core concept of abstract interpretation. Model checking generally takes place on abstract versions of the studied systems.


== Levels of abstraction ==

Computer science commonly presents levels (or, less commonly, layers) of abstraction, wherein each level represents a different model of the same information and processes, but with varying amounts of detail. Each level uses a system of expression involving a unique set of objects and compositions that apply only to a particular domain.

Each relatively abstract, ""higher"" level builds on a relatively concrete, ""lower"" level, which tends to provide an increasingly ""granular"" representation. For example, gates build on electronic circuits, binary on gates, machine language on binary, programming language on machine language, applications and operating systems on programming languages. Each level is embodied, but not determined, by the level beneath it, making it a language of description that is somewhat self-contained.


=== Database systems ===

Since many users of database systems lack in-depth familiarity with computer data-structures, database developers often hide complexity through the following levels:

Physical level: The lowest level of abstraction describes how a system actually stores data. The physical level describes complex low-level data structures in detail.
Logical level: The next higher level of abstraction describes what data the database stores, and what relationships exist among those data. The logical level thus describes an entire database in terms of a small number of relatively simple structures. Although implementation of the simple structures at the logical level may involve complex physical level structures, the user of the logical level does not need to be aware of this complexity. This is referred to as physical data independence. Database administrators, who must decide what information to keep in a database, use the logical level of abstraction.
View level: The highest level of abstraction describes only part of the entire database. Even though the logical level uses simpler structures, complexity remains because of the variety of information stored in a large database. Many users of a database system do not need all this information; instead, they need to access only a part of the database. The view level of abstraction exists to simplify their interaction with the system. The system may provide many views for the same database.


=== Layered architecture ===

The ability to provide a design of different levels of abstraction can

simplify the design considerably
enable different role players to effectively work at various levels of abstraction
support the portability of software artifacts (model-based ideally)Systems design and business process design can both use this. Some design processes specifically generate designs that contain various levels of abstraction.
Layered architecture partitions the concerns of the application into stacked groups (layers).
It is a technique used in designing computer software, hardware, and communications in which system or network components are isolated in layers so that changes can be made in one layer without affecting the others.


== See also ==
Abstraction principle (computer programming)
Abstraction inversion for an anti-pattern of one danger in abstraction
Abstract data type for an abstract description of a set of data
Algorithm for an abstract description of a computational procedure
Bracket abstraction for making a term into a function of a variable
Data modeling for structuring data independent of the processes that use it
Encapsulation for abstractions that hide implementation details
Greenspun's Tenth Rule for an aphorism about an (the?) optimum point in the space of abstractions
Higher-order function for abstraction where functions produce or consume other functions
Lambda abstraction for making a term into a function of some variable
List of abstractions (computer science)
Refinement for the opposite of abstraction in computing
Integer (computer science)
Heuristic (computer science)


== References ==


== Further reading ==


== External links ==
SimArch example of layered architecture for distributed simulation systems."
a9ea0f0f7d,Computer science and engineering,"Computer Science and Engineering (CSE) is an academic program at many universities which comprises scientific and engineering aspects of computing. CSE is also a term often used in Europe to translate the name of engineering informatics academic programs. It is offered in both Undergraduate as well Postgraduate with specializations.


== Academic courses ==
Academic programs vary between colleges, but typically include a combination of topics in computer science, computer engineering, and electrical engineering. Undergraduate courses usually include programming, algorithms and data structures, computer architecture, operating systems, computer networks, parallel computing, embedded systems, algorithms design, circuit analysis and electronics, digital logic and processor design, computer graphics, scientific computing, software engineering, database systems, digital signal processing, virtualization, computer simulations and games programming. CSE programs also include core subjects of theoretical computer science such as theory of computation, numerical methods, machine learning, programming theory and paradigms. Modern academic programs also cover emerging computing fields like image processing, data science, robotics, bio-inspired computing, computational biology, autonomic computing and artificial intelligence. Most CSE programs require introductory mathematical knowledge, hence the first year of study is dominated by mathematical courses, primarily discrete mathematics, mathematical analysis, linear algebra, probability, and statistics, as well as the basics of electrical and electronic engineering, physics, and electromagnetism.


== Example universities with CSE majors and departments ==
American International University-Bangladesh
American University of Beirut
Amrita Vishwa Vidyapeetham
Bangladesh University of Engineering and Technology
BRAC University
Brainware University
Bucknell University
Delft University of Technology
Green University of Bangladesh
Indian Institute of Technology Kanpur
Indian Institute of Technology Bombay
Indian Institute of Technology Delhi
Indian Institute of Technology Madras
Lund University
Massachusetts Institute of Technology
North South University
Ohio State University
Santa Clara University
Seoul National University
UC Davis
UC Irvine
UCLA
UC Merced
UC San Diego
UC Santa Cruz
University of Iowa
University of Michigan
University of New South Wales
University of Nevada
University of Notre Dame
University of Ulm
University of Washington
Shahid Beheshti University


== See also ==
Computer science
Computer engineering
Computer graphics (computer science)
Bachelor of Technology


== References =="
b98dd77323,Macro (computer science),"In computer programming, a macro (short for ""macro instruction""; from Greek  μακρο- 'long, large') is a rule or pattern that specifies how a certain input should be mapped to a replacement output. Applying a macro to an input is known as macro expansion. The input and output may be a sequence of lexical tokens or characters, or a syntax tree. Character macros are supported in software applications to make it easy to invoke common command sequences. Token and tree macros are supported in some programming languages to enable code reuse or to extend the language, sometimes for domain-specific languages.
Macros are used to make a sequence of computing instructions available to the programmer as a single program statement, making the programming task less tedious and less error-prone. (Thus, they are called ""macros"" because a ""big"" block of code can be expanded from a ""small"" sequence of characters.) Macros often allow positional or keyword parameters that dictate what the conditional assembler program generates and have been used to create entire programs or program suites according to such variables as operating system, platform or other factors. The term derives from ""macro instruction"", and such expansions were originally used in generating assembly language code.


== Keyboard and mouse macros ==
Keyboard macros and mouse macros allow short sequences of keystrokes and mouse actions to transform into other, usually more time-consuming, sequences of keystrokes and mouse actions. In this way, frequently used or repetitive sequences of keystrokes and mouse movements can be automated. Separate programs for creating these macros are called macro recorders.
During the 1980s, macro programs – originally SmartKey, then SuperKey, KeyWorks, Prokey – were very popular, first as a means to automatically format screenplays, then for a variety of user input tasks. These programs were based on the terminate-and-stay-resident mode of operation and applied to all keyboard input, no matter in which context it occurred. They have to some extent fallen into obsolescence following the advent of mouse-driven user interfaces and the availability of keyboard and mouse macros in applications such as word processors and spreadsheets, making it possible to create application-sensitive keyboard macros.
Keyboard macros can be used in massively multiplayer online role-playing games (MMORPGs) to perform repetitive, but lucrative tasks, thus accumulating resources.  As this is done without human effort, it can skew the economy of the game. For this reason, use of macros is a violation of the TOS or EULA of most MMORPGs, and their administrators spend considerable effort to suppress them.


=== Application macros and scripting ===
Keyboard and mouse macros that are created using an application's built-in macro features are sometimes called application macros. They are created by carrying out the sequence once and letting the application record the actions. An underlying macro programming language, most commonly a scripting language, with direct access to the features of the application may also exist.
The programmers' text editor, Emacs, (short for ""editing macros"") follows this idea to a conclusion. In effect, most of the editor is made of macros. Emacs was originally devised as a set of macros in the editing language TECO; it was later ported to dialects of Lisp.
Another programmers' text editor, Vim (a descendant of vi), also has an implementation of keyboard macros. It can record into a register (macro) what a person types on the keyboard and it can be replayed or edited just like VBA macros for Microsoft Office. Vim also has a scripting language called Vimscript to create macros.
Visual Basic for Applications (VBA) is a programming language included in Microsoft Office from Office 97 through Office 2019 (although it was available in some components of Office prior to Office 97). However, its function has evolved from and replaced the macro languages that were originally included in some of these applications.
XEDIT, running on the Conversational Monitor System (CMS) component of VM, supports macros written in EXEC, EXEC2 and REXX, and some CMS commands were actually wrappers around XEDIT macros. The Hessling Editor (THE), a partial clone of XEDIT, supports Rexx macros using Regina and Open Object REXX (oorexx). Many common applications, and some on PCs, use Rexx as a scripting language.


==== Macro virus ====

VBA has access to most Microsoft Windows system calls and executes when documents are opened. This makes it relatively easy to write computer viruses in VBA, commonly known as macro viruses. In the mid-to-late 1990s, this became one of the most common types of computer virus. However, during the late 1990s and to date, Microsoft has been patching and updating its programs. In addition, current anti-virus programs immediately counteract such attacks.


== Parameterized macro ==
A parameterized macro is a macro that is able to insert given objects into its expansion. This gives the macro some of the power of a function.
As a simple example, in the C programming language, this is a typical macro that is not a parameterized macro:

 #define PI   3.14159

This causes PI to always be replaced with 3.14159 wherever it occurs. An example of a parameterized macro, on the other hand, is this:

 #define pred(x)  ((x)-1)

What this macro expands to depends on what argument x is passed to it. Here are some possible expansions:

 pred(2)    →  ((2)   -1)
 pred(y+2)  →  ((y+2) -1)
 pred(f(5)) →  ((f(5))-1)

Parameterized macros are a useful source-level mechanism for performing in-line expansion, but in languages such as C where they use simple textual substitution, they have a number of severe disadvantages over other mechanisms for performing in-line expansion, such as inline functions.
The parameterized macros used in languages such as Lisp, PL/I and Scheme, on the other hand, are much more powerful, able to make decisions about what code to produce based on their arguments; thus, they can effectively be used to perform run-time code generation.


== Text-substitution macros ==

Languages such as C and some assembly languages have rudimentary macro systems, implemented as preprocessors to the compiler or assembler. C preprocessor macros work by simple textual substitution at the token, rather than the character level. However, the macro facilities of more sophisticated assemblers, e.g., IBM High Level Assembler (HLASM) can't be implemented with a preprocessor; the code for assembling instructions and data is interspersed with the code for assembling macro invocations.
A classic use of macros is in the computer typesetting system TeX and its derivatives, where most of the functionality is based on macros.
MacroML is an experimental system that seeks to reconcile static typing and macro systems. Nemerle has typed syntax macros, and one productive way to think of these syntax macros is as a multi-stage computation.
Other examples:

m4 is a sophisticated stand-alone macro processor.
TRAC
Macro Extension TAL, accompanying Template Attribute Language
SMX: for web pages
ML/1 (Macro Language One)
The General Purpose Macrogenerator is a contextual pattern-matching macro processor, which could be described as a combination of regular expressions, EBNF and AWK
troff and nroff: for typesetting and formatting Unix manpages.
CMS EXEC: for command-line macros and application macros
EXEC 2 in Conversational Monitor System (CMS): for command-line macros and application macros
CLIST in IBM's Time Sharing Option (TSO): for command-line macros and application macros
REXX: for command-line macros and application macros in, e.g., AmigaOS, CMS, OS/2, TSO
SCRIPT: for formatting documents
Various shells for, e.g., LinuxSome major applications have been written as text macro invoked by other applications, e.g., by XEDIT in CMS.


=== Embeddable languages ===
Some languages, such as PHP, can be embedded in free-format text, or the source code of other languages. The mechanism by which the code fragments are recognised (for instance, being bracketed by <?php and ?>) is similar to a textual macro language, but they are much more powerful, fully featured languages.


== Procedural macros ==
Macros in the PL/I language are written in a subset of PL/I itself: the compiler executes ""preprocessor statements"" at compilation time, and the output of this execution forms part of the code that is compiled. The ability to use a familiar procedural language as the macro language gives power much greater than that of text substitution macros, at the expense of a larger and slower compiler.
Frame technology's frame macros have their own command syntax but can also contain text in any language. Each frame is both a generic component in a hierarchy of nested subassemblies, and a procedure for integrating itself with its subassembly frames (a recursive process that resolves integration conflicts in favor of higher level subassemblies). The outputs are custom documents, typically compilable source modules. Frame technology can avoid the proliferation of similar but subtly different components, an issue that has plagued software development since the invention of macros and subroutines.
Most assembly languages have less powerful procedural macro facilities, for example allowing a block of code to be repeated N times for loop unrolling; but these have a completely different syntax from the actual assembly language.


== Syntactic macros ==
Macro systems—such as the C preprocessor described earlier—that work at the level of lexical tokens cannot preserve the lexical structure reliably.
Syntactic macro systems work instead at the level of abstract syntax trees, and preserve the lexical structure of the original program. The most widely used implementations of syntactic macro systems are found in Lisp-like languages. These languages are especially suited for this style of macro due to their uniform, parenthesized syntax (known as S-expressions). In particular, uniform syntax makes it easier to determine the invocations of macros. Lisp macros transform the program structure itself, with the full language available to express such transformations. While syntactic macros are often found in Lisp-like languages, they are also available in other languages such as Prolog, Erlang, Dylan, Scala, Nemerle, Rust, Elixir, Nim, Haxe, and Julia. They are also available as third-party extensions to JavaScript and C#.


=== Early Lisp macros ===
Before Lisp had macros, it had so-called FEXPRs, function-like operators whose inputs were not the values computed by the arguments but rather the syntactic forms of the arguments, and whose output were values to be used in the computation. In other words, FEXPRs were implemented at the same level as EVAL, and provided a window into the meta-evaluation layer. This was generally found to be a difficult model to reason about effectively.In 1963, Timothy Hart proposed adding macros to Lisp 1.5 in AI Memo 57: MACRO Definitions for LISP.


=== Anaphoric macros ===

An anaphoric macro is a type of programming macro that deliberately captures some form supplied to the macro which may be referred to by an anaphor (an expression referring to another). Anaphoric macros first appeared in Paul Graham's On Lisp and their name is a reference to linguistic anaphora—the use of words as a substitute for preceding words.


=== Hygienic macros ===

In the mid-eighties, a number of papers introduced the notion of hygienic macro expansion (syntax-rules), a pattern-based system where the syntactic environments of the macro definition and the macro use are distinct, allowing macro definers and users not to worry about inadvertent variable capture (cf. referential transparency). Hygienic macros have been standardized for Scheme in the R5RS, R6RS, and R7RS standards. A number of competing implementations of hygienic macros exist such as syntax-rules, syntax-case, explicit renaming, and syntactic closures. Both syntax-rules and syntax-case have been standardized in the Scheme standards.
Recently, Racket has combined the notions of hygienic macros with a ""tower of evaluators"", so that the syntactic expansion time of one macro system is the ordinary runtime of another block of code, and showed how to apply interleaved expansion and parsing in a non-parenthesized language.A number of languages other than Scheme either implement hygienic macros or implement partially hygienic systems. Examples include Scala, Rust, Elixir, Julia, Dylan, Nim, and Nemerle.


=== Applications ===
Evaluation order
Macro systems have a range of uses. Being able to choose the order of evaluation (see lazy evaluation and non-strict functions) enables the creation of new syntactic constructs (e.g. control structures) indistinguishable from those built into the language. For instance, in a Lisp dialect that has cond but lacks if, it is possible to define the latter in terms of the former using macros. For example, Scheme has both continuations and hygienic macros, which enables a programmer to design their own control abstractions, such as looping and early exit constructs, without the need to build them into the language.
Data sub-languages and domain-specific languages
Next, macros make it possible to define data languages that are immediately compiled into code, which means that constructs such as state machines can be implemented in a way that is both natural and efficient.
Binding constructs
Macros can also be used to introduce new binding constructs. The most well-known example is the transformation of let into the application of a function to a set of arguments.Felleisen conjectures that these three categories make up the primary legitimate uses of macros in such a system. Others have proposed alternative uses of macros, such as anaphoric macros in macro systems that are unhygienic or allow selective unhygienic transformation.
The interaction of macros and other language features has been a productive area of research. For example, components and modules are useful for large-scale programming, but the interaction of macros and these other constructs must be defined for their use together. Module and component-systems that can interact with macros have been proposed for Scheme and other languages with macros. For example, the Racket language extends the notion of a macro system to a syntactic tower, where macros can be written in languages including macros, using hygiene to ensure that syntactic layers are distinct and allowing modules to export macros to other modules.


== Macros for machine-independent software ==
Macros are normally used to map a short string (macro invocation) to a longer sequence of instructions. Another, less common, use of macros is to do the reverse: to map a sequence of instructions to a macro string. This was the approach taken by the STAGE2 Mobile Programming System, which used a rudimentary macro compiler (called SIMCMP) to map the specific instruction set of a given computer into machine-independent macros. Applications (notably compilers) written in these machine-independent macros can then be run without change on any computer equipped with the rudimentary macro compiler. The first application run in such a context is a more sophisticated and powerful macro compiler, written in the machine-independent macro language. This macro compiler is applied to itself, in a bootstrap fashion, to produce a compiled and much more efficient version of itself. The advantage of this approach is that complex applications can be ported from one computer to a very different computer with very little effort (for each target machine architecture, just the writing of the rudimentary macro compiler). The advent of modern programming languages, notably C, for which compilers are available on virtually all computers, has rendered such an approach superfluous. This was, however, one of the first instances (if not the first) of compiler bootstrapping.


== Assembly language ==
While macro instructions can be defined by a programmer for any set of native assembler program instructions, typically macros are associated with macro libraries delivered with the operating system allowing access to operating system functions such as

peripheral access by access methods (including macros such as OPEN, CLOSE, READ and WRITE)
operating system functions such as ATTACH, WAIT and POST for subtask creation and synchronization. Typically such macros expand into executable code, e.g., for the EXIT macroinstruction,
a list of define constant instructions, e.g., for the DCB macro—DTF (Define The File) for DOS—or a combination of code and constants, with the details of the expansion depending on the parameters of the macro instruction (such as a reference to a file and a data area for a READ instruction);
the executable code often terminated in either a branch and link register instruction to call a routine, or a supervisor call instruction to call an operating system function directly.
Generating a Stage 2 job stream for system generation in, e.g., OS/360. Unlike typical macros, sysgen stage 1 macros do not generate data or code to be loaded into storage, but rather use the PUNCH statement to output JCL and associated data.In older operating systems such as those used on IBM mainframes, full operating system functionality was only available to assembler language programs, not to high level language programs (unless assembly language subroutines were used, of course), as the standard macro instructions did not always have counterparts in routines available to high-level languages.


== History ==
In the mid-1950s, when assembly language programming was commonly used to write programs for digital computers, the use of macro instructions was initiated for two main purposes: to reduce the amount of program coding that had to be written by generating several assembly language statements from one macro instruction and to enforce program writing standards, e.g. specifying input/output commands in standard ways. Macro instructions were effectively a middle step between assembly language programming and the high-level programming languages that followed, such as FORTRAN and COBOL. Two of the earliest programming installations to develop ""macro languages"" for the IBM 705 computer were at Dow Chemical Corp. in Delaware and the Air Material Command, Ballistics Missile Logistics Office in California. A macro instruction written in the format of the target assembly language would be processed by a macro compiler, which was a pre-processor to the assembler, to generate one or more assembly language instructions to be processed next by the assembler program that would translate the assembly language instructions into machine language instructions.By the late 1950s the macro language was followed by the Macro Assemblers. This was a combination of both where one program served both functions, that of a macro pre-processor and an assembler in the same package.In 1959, Douglas E. Eastwood and Douglas McIlroy of Bell Labs introduced conditional and recursive macros into the popular SAP assembler, creating what is known as Macro SAP. McIlroy's 1960 paper was seminal in the area of extending any (including high-level) programming languages through macro processors.Macro Assemblers allowed assembly language programmers to implement their own macro-language and allowed limited portability of code between two machines running the same CPU but different operating systems, for example, early versions of MSDOS and CPM-86. The macro library would need to be written for each target machine but not the overall assembly language program. Note that more powerful macro assemblers allowed use of conditional assembly constructs in macro instructions that could generate different code on different machines or different operating systems, reducing the need for multiple libraries.In the 1980s and early 1990s, desktop PCs were only running at a few MHz and assembly language routines were commonly used to speed up programs written in C, Fortran, Pascal and others. These languages, at the time, used different calling conventions. Macros could be used to interface routines written in assembly language to the front end of applications written in almost any language. Again, the basic assembly language code remained the same, only the macro libraries needed to be written for each target language.In modern operating systems such as Unix and its derivatives, operating system access is provided through subroutines, usually provided by dynamic libraries. High-level languages such as C offer comprehensive access to operating system functions, obviating the need for assembler language programs for such functionality.


== See also ==
Anaphoric macros
Assembly language § Macros (the origin of the concept of macros)
Extensible programming
Hygienic macros
Programming by demonstration – Technique for teaching a computer or a robot new behaviors
String interpolation – Replacing placeholders in a string with values
Computer science and engineering
Computer science


== References ==


== External links ==
How to write Macro Instructions
Rochester Institute of Technology, Professors Powerpoint"
6e9eedfc66,Scope (computer science),"In computer programming, the scope of a name binding (an association of a name to an entity, such as a variable) is the part of a program where the name binding is valid; that is, where the name can be used to refer to the entity. In other parts of the program, the name may refer to a different entity (it may have a different binding), or to nothing at all (it may be unbound). Scope helps prevent name collisions by allowing the same name to refer to different objects – as long as the names have separate scopes. The scope of a name binding is also known as the visibility of an entity, particularly in older or more technical literature—this is from the perspective of the referenced entity, not the referencing name.
The term ""scope"" is also used to refer to the set of all name bindings that are valid within a part of a program or at a given point in a program, which is more correctly referred to as context or environment.Strictly speaking and in practice for most programming languages, ""part of a program"" refers to a portion of source code (area of text), and is known as lexical scope. In some languages, however, ""part of a program"" refers to a portion of run time (time period during execution), and is known as dynamic scope. Both of these terms are somewhat misleading—they misuse technical terms, as discussed in the definition—but the distinction itself is accurate and precise, and these are the standard respective terms. Lexical scope is the main focus of this article, with dynamic scope understood by contrast with lexical scope.
In most cases, name resolution based on lexical scope is relatively straightforward to use and to implement, as in use one can read backwards in the source code to determine to which entity a name refers, and in implementation one can maintain a list of names and contexts when compiling or interpreting a program. Difficulties arise in name masking, forward declarations, and hoisting, while considerably subtler ones arise with non-local variables, particularly in closures.


== Definition ==
The strict definition of the (lexical) ""scope"" of a name (identifier) is unambiguous: lexical scope is ""the portion of source code in which a binding of a name with an entity applies"". This is virtually unchanged from its 1960 definition in the specification of ALGOL 60. Representative language specifications follow:

ALGOL 60 (1960)
The following kinds of quantities are distinguished: simple variables, arrays, labels, switches, and procedures. The scope of a quantity is the set of statements and expressions in which the declaration of the identifier associated with that quantity is valid.
C (2007)
An identifier can denote an object; a function; a tag or a member of a structure, union, or enumeration; a typedef name; a label name; a macro name; or a macro parameter. The same identifier can denote different entities at different points in the program. [...] For each different entity that an identifier designates, the identifier is visible (i.e., can be used) only within a region of program text called its scope.
Go (2013)
A declaration binds a non-blank identifier to a constant, type, variable, function, label, or package. [...] The scope of a declared identifier is the extent of source text in which the identifier denotes the specified constant, type, variable, function, label, or package.Most commonly ""scope"" refers to when a given name can refer to a given variable—when a declaration has effect—but can also apply to other entities, such as functions, types, classes, labels, constants, and enumerations.


=== Lexical scope vs. dynamic scope ===
A fundamental distinction in scope is what ""part of a program"" means. In languages with lexical scope (also called static scope), name resolution depends on the location in the source code and the lexical context (also called static context), which is defined by where the named variable or function is defined. In contrast, in languages with dynamic scope the name resolution depends upon the program state when the name is encountered which is determined by the execution context (also called runtime context, calling context or dynamic context). In practice, with lexical scope a name is resolved by searching the local lexical context, then if that fails, by searching the outer lexical context, and so on; whereas with dynamic scope, a name is resolved by searching the local execution context, then if that fails, by searching the outer execution context, and so on, progressing up the call stack.Most modern languages use lexical scope for variables and functions, though dynamic scope is used in some languages, notably some dialects of Lisp, some ""scripting"" languages, and some template languages.  Perl 5 offers both lexical and dynamic scope. Even in lexically scoped languages, scope for closures can be confusing to the uninitiated, as these depend on the lexical context where the closure is defined, not where it is called.
Lexical resolution can be determined at compile time, and is also known as early binding, while dynamic resolution can in general only be determined at run time, and thus is known as late binding.


=== Related concepts ===
In object-oriented programming, dynamic dispatch selects an object method at runtime, though whether the actual name binding is done at compile time or run time depends on the language. De facto dynamic scope is common in macro languages, which do not directly do name resolution, but instead expand in place.
Some programming frameworks like AngularJS use the term ""scope"" to mean something entirely different than how it is used in this article. In those frameworks the scope is just an object of the programming language that they use (JavaScript in case of AngularJS) that is used in certain ways by the framework to emulate dynamic scope in a language that uses lexical scope for its variables. Those AngularJS scopes can themselves be in context or not in context (using the usual meaning of the term) in any given part of the program, following the usual rules of variable scope of the language like any other object, and using their own inheritance and transclusion rules. In the context of AngularJS, sometimes the term ""$scope"" (with a dollar sign) is used to avoid confusion, but using the dollar sign in variable names is often discouraged by the style guides.


== Use ==
Scope is an important component of name resolution, which is in turn fundamental to language semantics. Name resolution (including scope) varies between programming languages, and within a programming language, varies by type of entity; the rules for scope are called scope rules (or scoping rules). Together with namespaces, scope rules are crucial in modular programming, so a change in one part of the program does not break an unrelated part.


== Overview ==

When discussing scope, there are three basic concepts: scope, extent, and context. ""Scope"" and ""context"" in particular are frequently confused: scope is a property of a name binding, while context is a property of a part of a program, that is either a portion of source code (lexical context or static context) or a portion of run time (execution context, runtime context, calling context or dynamic context). Execution context consists of lexical context (at the current execution point) plus additional runtime state such as the call stack. Strictly speaking, during execution a program enters and exits various name bindings' scopes, and at a point in execution name bindings are ""in context"" or ""not in context"", hence name bindings ""come into context"" or ""go out of context"" as the program execution enters or exits the scope. However, in practice usage is much looser.
Scope is a source-code level concept, and a property of name bindings, particularly variable or function name bindings—names in the source code are references to entities in the program—and is part of the behavior of a compiler or interpreter of a language. As such, issues of scope are similar to pointers, which are a type of reference used in programs more generally. Using the value of a variable when the name is in context but the variable is uninitialized is analogous to dereferencing (accessing the value of) a wild pointer, as it is undefined. However, as variables are not destroyed until they go out of context, the analog of a dangling pointer does not exist.
For entities such as variables, scope is a subset of lifetime (also known as extent)—a name can only refer to a variable that exists (possibly with undefined value), but variables that exist are not necessarily visible: a variable may exist but be inaccessible (the value is stored but not referred to within a given context), or accessible but not via the given name, in which case it is not in context (the program is ""out of the scope of the name""). In other cases ""lifetime"" is irrelevant—a label (named position in the source code) has lifetime identical with the program (for statically compiled languages), but may be in context or not at a given point in the program, and likewise for static variables—a static global variable is in context for the entire program, while a static local variable is only in context within a function or other local context, but both have lifetime of the entire run of the program.
Determining which entity a name refers to is known as name resolution or name binding (particularly in object-oriented programming), and varies between languages. Given a name, the language (properly, the compiler or interpreter) checks all entities that are in context for matches; in case of ambiguity (two entities with the same name, such as a global and local variable with the same name), the name resolution rules are used to distinguish them. Most frequently, name resolution relies on an ""inner-to-outer context"" rule, such as the Python LEGB (Local, Enclosing, Global, Built-in) rule: names implicitly resolves to the narrowest relevant context. In some cases name resolution can be explicitly specified, such as by the global and nonlocal keywords in Python; in other cases the default rules cannot be overridden.
When two identical names are in context at the same time, referring to different entities, one says that name masking is occurring, where the higher-priority name (usually innermost) is ""masking"" the lower-priority name. At the level of variables, this is known as variable shadowing. Due to the potential for logic errors from masking, some languages disallow or discourage masking, raising an error or warning at compile time or run time.
Various programming languages have various different scope rules for different kinds of declarations and names. Such scope rules have a large effect on language semantics and, consequently, on the behavior and correctness of programs. In languages like C++, accessing an unbound variable does not have well-defined semantics and may result in undefined behavior, similar to referring to a dangling pointer; and declarations or names used outside their scope will generate syntax errors.
Scopes are frequently tied to other language constructs and determined implicitly, but many languages also offer constructs specifically for controlling scope.


== Levels of scope ==
Scope can vary from as little as a single expression to as much as the entire program, with many possible gradations in between. The simplest scope rule is global scope—all entities are visible throughout the entire program. The most basic modular scope rule is two-level scope, with a global scope anywhere in the program, and local scope within a function. More sophisticated modular programming allows a separate module scope, where names are visible within the module (private to the module) but not visible outside it. Within a function, some languages, such as C, allow block scope to restrict scope to a subset of a function; others, notably functional languages, allow expression scope, to restrict scope to a single expression. Other scopes include file scope (notably in C) which behaves similarly to module scope, and block scope outside of functions (notably in Perl).
A subtle issue is exactly when a scope begins and ends. In some languages, such as C, a name's scope begins at the name declaration, and thus different names declared within a given block can have different scopes. This requires declaring functions before use, though not necessarily defining them, and requires forward declaration in some cases, notably for mutual recursion. In other languages, such as Python, a name's scope begins at the start of the relevant block where the name is declared (such as the start of a function), regardless of where it is defined, so all names within a given block have the same scope. In JavaScript, the scope of a name declared with let or const begins at the name declaration, and the scope of a name declared with var begins at the start of the function where the name is declared, which is known as variable hoisting. Behavior of names in context that have undefined value differs: in Python use of undefined names yields a runtime error, while in JavaScript undefined names declared with var are usable throughout the function because they are implicitly bound to the value undefined.


=== Expression scope ===
The scope of a name binding is an expression, which is known as expression scope. Expression scope is available in many languages, especially functional languages which offer a feature called let-expressions allowing a declaration's scope to be a single expression. This is convenient if, for example, an intermediate value is needed for a computation. For example, in Standard ML, if f() returns 12, then let val x = f() in x * x end is an expression that evaluates to 144, using a temporary variable named x to avoid calling f() twice. Some languages with block scope approximate this functionality by offering syntax for a block to be embedded into an expression; for example, the aforementioned Standard ML expression could be written in Perl as do { my $x = f(); $x * $x }, or in GNU C as ({ int x = f(); x * x; }).
In Python, auxiliary variables in generator expressions and list comprehensions (in Python 3) have expression scope.
In C, variable names in a function prototype have expression scope, known in this context as function protocol scope. As the variable names in the prototype are not referred to (they may be different in the actual definition)—they are just dummies—these are often omitted, though they may be used for generating documentation, for instance.


=== Block scope ===
The scope of a name binding is a block, which is known as block scope. Block scope is available in many, but not all, block-structured programming languages. This began with ALGOL 60, where ""[e]very declaration ... is valid only for that block."", and today is particularly associated with languages in the Pascal and C families and traditions. Most often this block is contained within a function, thus restricting the scope to a part of a function, but in some cases, such as Perl, the block may not be within a function.

A representative example of the use of block scope is the C code shown here, where two variables are scoped to the loop: the loop variable n, which is initialized once and incremented on each iteration of the loop, and the auxiliary variable n_squared, which is initialized at each iteration. The purpose is to avoid adding variables to the function scope that are only relevant to a particular block—for example, this prevents errors where the generic loop variable i has accidentally already been set to another value. In this example the expression n * n would generally not be assigned to an auxiliary variable, and the body of the loop would simply be written ret += n * n but in more complicated examples auxiliary variables are useful.
Blocks are primarily used for control flow, such as with if, while, and for loops, and in these cases block scope means the scope of variable depends on the structure of a function's flow of execution. However, languages with block scope typically also allow the use of ""naked"" blocks, whose sole purpose is to allow fine-grained control of variable scope. For example, an auxiliary variable may be defined in a block, then used (say, added to a variable with function scope) and discarded when the block ends, or a while loop might be enclosed in a block that initializes variables used inside the loop that should only be initialized once.
A subtlety of several programming languages, such as Algol 68 and C (demonstrated in this example and standardized since C99), is that block-scope variables can be declared not only within the body of the block, but also within the control statement, if any. This is analogous to function parameters, which are declared in the function declaration (before the block of the function body starts), and in scope for the whole function body. This is primarily used in for loops, which have an initialization statement separate from the loop condition, unlike while loops, and is a common idiom.
Block scope can be used for shadowing. In this example, inside the block the auxiliary variable could also have been called n, shadowing the parameter name, but this is considered poor style due to the potential for errors. Furthermore, some descendants of C, such as Java and C#, despite having support for block scope (in that a local variable can be made to go out of context before the end of a function), do not allow one local variable to hide another. In such languages, the attempted declaration of the second n would result in a syntax error, and one of the n variables would have to be renamed.
If a block is used to set the value of a variable, block scope requires that the variable be declared outside of the block. This complicates the use of conditional statements with single assignment. For example, in Python, which does not use block scope, one may initialize a variable as such:

where a is accessible after the if statement.
In Perl, which has block scope, this instead requires declaring the variable prior to the block:

Often this is instead rewritten using multiple assignment, initializing the variable to a default value. In Python (where it is not necessary) this would be:

while in Perl this would be:

In case of a single variable assignment, an alternative is to use the ternary operator to avoid a block, but this is not in general possible for multiple variable assignments, and is difficult to read for complex logic.
This is a more significant issue in C, notably for string assignment, as string initialization can automatically allocate memory, while string assignment to an already initialized variable requires allocating memory, a string copy, and checking that these are successful.

Some languages allow the concept of block scope to be applied, to varying extents, outside of a function. For example, in the Perl snippet at right, $counter is a variable name with block scope (due to the use of the my keyword), while increment_counter is a function name with global scope. Each call to increment_counter will increase the value of $counter by one, and return the new value. Code outside of this block can call increment_counter, but cannot otherwise obtain or alter the value of $counter. This idiom allows one to define closures in Perl.


=== Function scope ===
When the scope of variables declared within a function does not extend beyond that function, this is known as function scope. Function scope is available in most programming languages which offer a way to create a local variable in a function or subroutine: a variable whose scope ends (that goes out of context) when the function returns. In most cases the lifetime of the variable is the duration of the function call—it is an automatic variable, created when the function starts (or the variable is declared), destroyed when the function returns—while the scope of the variable is within the function, though the meaning of ""within"" depends on whether scope is lexical or dynamic. However, some languages, such as C, also provide for static local variables, where the lifetime of the variable is the entire lifetime of the program, but the variable is only in context when inside the function. In the case of static local variables, the variable is created when the program initializes, and destroyed only when the program terminates, as with a static global variable, but is only in context within a function, like an automatic local variable.
Importantly, in lexical scope a variable with function scope has scope only within the lexical context of the function: it goes out of context when another function is called within the function, and comes back into context when the function returns—called functions have no access to the local variables of calling functions, and local variables are only in context within the body of the function in which they are declared. By contrast, in dynamic scope, the scope extends to the execution context of the function: local variables stay in context when another function is called, only going out of context when the defining function ends, and thus local variables are in context of the function in which they are defined and all called functions. In languages with lexical scope and nested functions, local variables are in context for nested functions, since these are within the same lexical context, but not for other functions that are not lexically nested. A local variable of an enclosing function is known as a non-local variable for the nested function. Function scope is also applicable to anonymous functions.

For example, in the snippet of Python code on the right, two functions are defined: square and sum_of_squares. square computes the square of a number; sum_of_squares computes the sum of all squares up to a number. (For example, square(4) is 42 = 16, and sum_of_squares(4) is 02 + 12 + 22 + 32 + 42 = 30.)
Each of these functions has a variable named n that represents the argument to the function. These two n variables are completely separate and unrelated, despite having the same name, because they are lexically scoped local variables with function scope: each one's scope is its own, lexically separate function and thus, they don't overlap. Therefore, sum_of_squares can call square without its own n being altered. Similarly, sum_of_squares has variables named total and i; these variables, because of their limited scope, will not interfere with any variables named total or i that might belong to any other function. In other words, there is no risk of a name collision between these names and any unrelated names, even if they are identical.
No name masking is occurring: only one variable named n is in context at any given time, as the scopes do not overlap. By contrast, were a similar fragment to be written in a language with dynamic scope, the n in the calling function would remain in context in the called function—the scopes would overlap—and would be masked (""shadowed"") by the new n in the called function.
Function scope is significantly more complicated if functions are first-class objects and can be created locally to a function and then returned. In this case any variables in the nested function that are not local to it (unbound variables in the function definition, that resolve to variables in an enclosing context) create a closure, as not only the function itself, but also its context (of variables) must be returned, and then potentially called in a different context. This requires significantly more support from the compiler, and can complicate program analysis.


=== File scope ===
The scope of a name binding is a file, which is known as file scope. File scope is largely particular to C (and C++), where scope of variables and functions declared at the top level of a file (not within any function) is for the entire file—or rather for C, from the declaration until the end of the source file, or more precisely translation unit (internal linking). This can be seen as a form of module scope, where modules are identified with files, and in more modern languages is replaced by an explicit module scope. Due to the presence of include statements, which add variables and functions to the internal context and may themselves call further include statements, it can be difficult to determine what is in context in the body of a file.
In the C code snippet above, the function name sum_of_squares has file scope.


=== Module scope ===
The scope of a name binding is a module, which is known as module scope. Module scope is available in modular programming languages where modules (which may span various files) are the basic unit of a complex program, as they allow information hiding and exposing a limited interface. Module scope was pioneered in the Modula family of languages, and Python (which was influenced by Modula) is a representative contemporary example.
In some object-oriented programming languages that lack direct support for modules, such as C++, a similar structure is instead provided by the class hierarchy, where classes are the basic unit of the program, and a class can have private methods. This is properly understood in the context of dynamic dispatch rather than name resolution and scope, though they often play analogous roles. In some cases both these facilities are available, such as in Python, which has both modules and classes, and code organization (as a module-level function or a conventionally private method) is a choice of the programmer.


=== Global scope ===
The scope of a name binding is an entire program, which is known as global scope. Variable names with global scope—called global variables—are frequently considered bad practice, at least in some languages, due to the possibility of name collisions and unintentional masking, together with poor modularity, and function scope or block scope are considered preferable. However, global scope is typically used (depending on the language) for various other sorts of names, such as names of functions, names of classes and names of other data types. In these cases mechanisms such as namespaces are used to avoid collisions.


== Lexical scope vs. dynamic scope ==
The use of local variables — of variable names with limited scope, that only exist within a specific function — helps avoid the risk of a name collision between two identically named variables. However, there are two very different approaches to answering this question: What does it mean to be ""within"" a function?
In lexical scope (or lexical scoping; also called static scope or static scoping), if a variable name's scope is a certain function, then its scope is the program text of the function definition: within that text, the variable name exists, and is bound to the variable's value, but outside that text, the variable name does not exist. By contrast, in dynamic scope (or dynamic scoping), if a variable name's scope is a certain function, then its scope is the time-period during which the function is executing: while the function is running, the variable name exists, and is bound to its value, but after the function returns, the variable name does not exist. This means that if function f invokes a separately defined function g, then under lexical scope, function g does not have access to f's local variables (assuming the text of g is not inside the text of f), while under dynamic scope, function g does have access to f's local variables (since g is invoked during the invocation of f).

Consider, for example, the program on the right. The first line, x=1, creates a global variable x and initializes it to 1. The second line, function g() { echo $x ; x=2 ; }, defines a function g that prints out (""echoes"") the current value of x, and then sets x to 2 (overwriting the previous value). The third line, function f() { local x=3 ; g ; } defines a function f that creates a local variable x (hiding the identically named global variable) and initializes it to 3, and then calls g. The fourth line, f, calls f. The fifth line, echo $x, prints out the current value of x.

So, what exactly does this program print? It depends on the scope rules. If the language of this program is one that uses lexical scope, then g prints and modifies the global variable x (because g is defined outside f), so the program prints 1 and then 2. By contrast, if this language uses dynamic scope, then g prints and modifies f's local variable x (because g is called from within f), so the program prints 3 and then 1. (As it happens, the language of the program is Bash, which uses dynamic scope; so the program prints 3 and then 1. If the same code was run with ksh93 which uses lexical scope, the results would be different.)


== Lexical scope ==
With lexical scope, a name always refers to its lexical context. This is a property of the program text and is made independent of the runtime call stack by the language implementation. Because this matching only requires analysis of the static program text, this type of scope is also called static scope. Lexical scope is standard in all ALGOL-based languages such as Pascal, Modula-2 and Ada as well as in modern functional languages such as ML and Haskell. It is also used in the C language and its syntactic and semantic relatives, although with different kinds of limitations. Static scope allows the programmer to reason about object references such as parameters, variables, constants, types, functions, etc. as simple name substitutions. This makes it much easier to make modular code and reason about it, since the local naming structure can be understood in isolation. In contrast, dynamic scope forces the programmer to anticipate all possible execution contexts in which the module's code may be invoked.

For example, Pascal is lexically scoped. Consider the Pascal program fragment at right. The variable I is visible at all points, because it is never hidden by another variable of the same name. The char variable K is visible only in the main program because it is hidden by the real variable K visible in procedure B and C only. Variable L is also visible only in procedure B and C but it does not hide any other variable. Variable M is only visible in procedure C and therefore not accessible either from procedure B or the main program. Also, procedure C is visible only in procedure B and can therefore not be called from the main program.
There could have been another procedure C declared in the program outside of procedure B. The place in the program where ""C"" is mentioned then determines which of the two procedures named C it represents, thus precisely analogous with the scope of variables.
Correct implementation of lexical scope in languages with first-class nested functions is not trivial, as it requires each function value to carry with it a record of the values of the variables that it depends on (the pair of the function and this context is called a closure). Depending on implementation and computer architecture, variable lookup may become slightly inefficient when very deeply lexically nested functions are used, although there are well-known techniques to mitigate this. Also, for nested functions that only refer to their own arguments and (immediately) local variables, all relative locations can be known at compile time. No overhead at all is therefore incurred when using that type of nested function. The same applies to particular parts of a program where nested functions are not used, and, naturally, to programs written in a language where nested functions are not available (such as in the C language).


=== History ===
Lexical scope was first used in the early 1960s for the imperative language ALGOL 60 and has been picked up in most other imperative languages since then.Languages like Pascal and C have always had lexical scope, since they are both influenced by the ideas that went into ALGOL 60 and ALGOL 68 (although C did not include lexically nested functions).
Perl is a language with dynamic scope that added static scope afterwards.
The original Lisp interpreter (1960) used dynamic scope. Deep binding, which approximates static (lexical) scope, was introduced around 1962 in LISP 1.5 (via the Funarg device developed by Steve Russell, working under John McCarthy).
All early Lisps used dynamic scope, when based on interpreters. In 1982, Guy L. Steele Jr. and the Common LISP Group publish An overview of Common LISP, a short review of the history and the divergent implementations of Lisp up to that moment and a review of the features that a Common Lisp implementation should have. On page 102, we read:

Most LISP implementations are internally inconsistent in that by default the interpreter and compiler may assign different semantics to correct programs; this stems primarily from the fact that the interpreter assumes all variables to be dynamically scoped, while the compiler assumes all variables to be local unless forced to assume otherwise. This has been done for the sake of convenience and efficiency, but can lead to very subtle bugs. The definition of Common LISP avoids such anomalies by explicitly requiring the interpreter and compiler to impose identical semantics on correct programs.
Implementations of Common LISP were thus required to have lexical scope. Again, from An overview of Common LISP:

In addition, Common LISP offers the following facilities (most of which are borrowed from MacLisp, InterLisp or Lisp Machines Lisp): (...) Fully lexically scoped variables. The so-called ""FUNARG problem"" is completely solved, in both the downward and upward cases.
By the same year in which An overview of Common LISP was published (1982), initial designs (also by Guy L. Steele Jr.) of a compiled, lexically scoped Lisp, called Scheme had been published and compiler implementations were being attempted. At that time, lexical scope in Lisp was commonly feared to be inefficient to implement. In A History of T, Olin Shivers writes:

All serious Lisps in production use at that time were dynamically scoped. No one who hadn't carefully read the Rabbit thesis (written by Guy Lewis Steele Jr. in 1978) believed lexical scope would fly; even the few people who had read it were taking a bit of a leap of faith that this was going to work in serious production use.
The term ""lexical scope"" dates at least to 1967, while the term ""lexical scoping"" dates at least to 1970, where it was used in Project MAC to describe the scope rules of the Lisp dialect MDL (then known as ""Muddle"").


== Dynamic scope ==
With dynamic scope, a name refers to execution context.  In technical terms, this means that each name has a global stack of bindings. Introducing a local variable with name x pushes a binding onto the global x stack (which may have been empty), which is popped off when the control flow leaves the scope. Evaluating x in any context always yields the top binding. Note that this cannot be done at compile-time because the binding stack only exists at run-time, which is why this type of scope is called dynamic scope.
Dynamic scope is uncommon in modern languages.Generally, certain blocks are defined to create bindings whose lifetime is the execution time of the block; this adds some features of static scope to the dynamic scope process. However, since a section of code can be called from many different locations and situations, it can be difficult to determine at the outset what bindings will apply when a variable is used (or if one exists at all). This can be beneficial; application of the principle of least knowledge suggests that code avoid depending on the reasons for (or circumstances of) a variable's value, but simply use the value according to the variable's definition. This narrow interpretation of shared data can provide a very flexible system for adapting the behavior of a function to the current state (or policy) of the system. However, this benefit relies on careful documentation of all variables used this way as well as on careful avoidance of assumptions about a variable's behavior, and does not provide any mechanism to detect interference between different parts of a program. Some languages, like Perl and Common Lisp, allow the programmer to choose static or dynamic scope when defining or redefining a variable. Examples of languages that use dynamic scope include Logo, Emacs Lisp, LaTeX and the shell languages bash, dash, and PowerShell.
Dynamic scope is fairly easy to implement. To find an name's value, the program could traverse the runtime stack, checking each activation record (each function's stack frame) for a value for the name. In practice, this is made more efficient via the use of an association list, which is a stack of name/value pairs. Pairs are pushed onto this stack whenever declarations are made, and popped whenever variables go out of context. Shallow binding is an alternative strategy that is considerably faster, making use of a central reference table, which associates each name with its own stack of meanings. This avoids a linear search during run-time to find a particular name, but care should be taken to properly maintain this table. Note that both of these strategies assume a last-in-first-out (LIFO) ordering to bindings for any one variable; in practice all bindings are so ordered.
An even simpler implementation is the representation of dynamic variables with simple global variables. The local binding is performed by saving the original value in an anonymous location on the stack that is invisible to the program. When that binding scope terminates, the original value is restored from this location. In fact, dynamic scope originated in this manner. Early implementations of Lisp used this obvious strategy for implementing local variables, and the practice survives in some dialects which are still in use, such as GNU Emacs Lisp. Lexical scope was introduced into Lisp later. This is equivalent to the above shallow binding scheme, except that the central reference table is simply the global variable binding context, in which the current meaning of the variable is its global value. Maintaining global variables isn't complex. For instance, a symbol object can have a dedicated slot for its global value.
Dynamic scope provides an excellent abstraction for thread-local storage, but if it is used that way it cannot be based on saving and restoring a global variable. A possible implementation strategy is for each variable to have a thread-local key. When the variable is accessed, the thread-local key is used to access the thread-local memory location (by code generated by the compiler, which knows which variables are dynamic and which are lexical). If the thread-local key does not exist for the calling thread, then the global location is used. When a variable is locally bound, the prior value is stored in a hidden location on the stack. The thread-local storage is created under the variable's key, and the new value is stored there. Further nested overrides of the variable within that thread simply save and restore this thread-local location. When the initial, outermost override's context terminates, the thread-local key is deleted, exposing the global version of the variable once again to that thread.
With referential transparency the dynamic scope is restricted to the argument stack of the current function only, and coincides with the lexical scope.


=== Macro expansion ===

In modern languages, macro expansion in a preprocessor is a key example of de facto dynamic scope. The macro language itself only transforms the source code, without resolving names, but since the expansion is done in place, when the names in the expanded text are then resolved (notably free variables), they are resolved based on where they are expanded (loosely ""called""), as if dynamic scope were occurring.
The C preprocessor, used for macro expansion, has de facto dynamic scope, as it does not do name resolution by itself and it is independent of where the macro is defined. For example, the macro:

will expand to add a to the passed variable, with this name only later resolved by the compiler based on where the macro ADD_A is ""called"" (properly, expanded). Properly, the C preprocessor only does lexical analysis, expanding the macro during the tokenization stage, but not parsing into a syntax tree or doing name resolution.
For example, in the following code, the name a in the macro is resolved (after expansion) to the local variable at the expansion site:


== Qualified names ==
As we have seen, one of the key reasons for scope is that it helps prevent name collisions, by allowing identical names to refer to distinct things, with the restriction that the names must have separate scopes. Sometimes this restriction is inconvenient; when many different things need to be accessible throughout a program, they generally all need names with global scope, so different techniques are required to avoid name collisions.
To address this, many languages offer mechanisms for organizing global names. The details of these mechanisms, and the terms used, depend on the language; but the general idea is that a group of names can itself be given a name — a prefix — and, when necessary, an entity can be referred to by a qualified name consisting of the name plus the prefix. Normally such names will have, in a sense, two sets of scopes: a scope (usually the global scope) in which the qualified name is visible, and one or more narrower scopes in which the unqualified name (without the prefix) is visible as well. And normally these groups can themselves be organized into groups; that is, they can be nested.
Although many languages support this concept, the details vary greatly. Some languages have mechanisms, such as namespaces in C++ and C#, that serve almost exclusively to enable global names to be organized into groups. Other languages have mechanisms, such as packages in Ada and structures in Standard ML, that combine this with the additional purpose of allowing some names to be visible only to other members of their group. And object-oriented languages often allow classes or singleton objects to fulfill this purpose (whether or not they also have a mechanism for which this is the primary purpose). Furthermore, languages often meld these approaches; for example, Perl's packages are largely similar to C++'s namespaces, but optionally double as classes for object-oriented programming; and Java organizes its variables and functions into classes, but then organizes those classes into Ada-like packages.


== By language ==
Scope rules for representative languages follow.


=== C ===

In C, scope is traditionally known as linkage or visibility, particularly for variables. C is a lexically scoped language with global scope (known as external linkage), a form of module scope or file scope (known as internal linkage), and local scope (within a function); within a function scopes can further be nested via block scope. However, standard C does not support nested functions.
The lifetime and visibility of a variable are determined by its storage class. There are three types of lifetimes in C: static (program execution), automatic (block execution, allocated on the stack), and manual (allocated on the heap). Only static and automatic are supported for variables and handled by the compiler, while manually allocated memory must be tracked manually across different variables. There are three levels of visibility in C: external linkage (global), internal linkage (roughly file), and block scope (which includes functions); block scopes can be nested, and different levels of internal linkage is possible by use of includes. Internal linkage in C is visibility at the translation unit level, namely a source file after being processed by the C preprocessor, notably including all relevant includes.
C programs are compiled as separate object files, which are then linked into an executable or library via a linker. Thus name resolution is split across the compiler, which resolves names within a translation unit (more loosely, ""compilation unit"", but this is properly a different concept), and the linker, which resolves names across translation units; see linkage for further discussion.
In C, variables with block scope enter context when they are declared (not at the top of the block), go out of context if any (non-nested) function is called within the block, come back into context when the function returns, and go out of context at the end of the block. In the case of automatic local variables, they are also allocated on declaration and deallocated at the end of the block, while for static local variables, they are allocated at program initialization and deallocated at program termination.
The following program demonstrates a variable with block scope coming into context partway through the block, then exiting context (and in fact being deallocated) when the block ends:

The program outputs:

m
m
b
m

There are other levels of scope in C. Variable names used in a function prototype have function prototype visibility, and exit context at the end of the function prototype. Since the name is not used, this is not useful for compilation, but may be useful for documentation. Label names for GOTO statement have function scope, while case label names for switch statements have block scope (the block of the switch).


=== C++ ===
All the variables that we intend to use in a program must have been declared with its type specifier in an earlier
point in the code, like we did in the previous code at the beginning of the body of the function main when we
declared that a, b, and result were of type int.
A variable can be either of global or local scope. A global variable is a variable declared in the main body of the
source code, outside all functions, while a local variable is one declared within the body of a function or a block.
Modern versions allow nested lexical scope.


=== Swift ===
Swift has a similar rule for scopes with C++, but contains different access modifiers.


=== Go ===
Go is lexically scoped using blocks.


=== Java ===
Java is lexically scoped.
A Java class can contain three types of variables:
Local variables
are defined inside a method, or a particular block. These variables are local to where they were defined and lower levels. For example, a loop inside a method can use that method's local variables, but not the other way around. The loop's variables (local to that loop) are destroyed as soon as the loop ends.Member variables
also called fields are variables declared within the class, outside of any method. By default, these variables are available for all methods within that class and also for all classes in the package.Parameters
are variables in method declarations.In general, a set of brackets defines a particular scope, but variables at top level within a class can differ in their behavior depending on the modifier keywords used in their definition.
The following table shows the access to members permitted by each modifier.


=== JavaScript ===
JavaScript has simple scope rules, but variable initialization and name resolution rules can cause problems, and the widespread use of closures for callbacks means the lexical context of a function when defined (which is used for name resolution) can be very different from the lexical context when it is called (which is irrelevant for name resolution). JavaScript objects have name resolution for properties, but this is a separate topic.
JavaScript has lexical scope  nested at the function level, with the global context being the outermost context. This scope is used for both variables and for functions (meaning function declarations, as opposed to variables of function type). Block scope with the let and const keywords is standard since ECMAScript 6. Block scope can be produced by wrapping the entire block in a function and then executing it; this is known as the immediately-invoked function expression (IIFE) pattern.
While JavaScript scope is simple—lexical, function-level—the associated initialization and name resolution rules are a cause of confusion. Firstly, assignment to a name not in scope defaults to creating a new global variable, not a local one. Secondly, to create a new local variable one must use the var keyword; the variable is then created at the top of the function, with value undefined and the variable is assigned its value when the assignment expression is reached:

A variable with an Initialiser is assigned the value of its AssignmentExpression when the VariableStatement is executed, not when the variable is created.This is known as variable hoisting—the declaration, but not the initialization, is hoisted to the top of the function. Thirdly, accessing variables before initialization yields undefined, rather than a syntax error. Fourthly, for function declarations, the declaration and the initialization are both hoisted to the top of the function, unlike for variable initialization. For example, the following code produces a dialog with output undefined, as the local variable declaration is hoisted, shadowing the global variable, but the initialization is not, so the variable is undefined when used:

Further, as functions are first-class objects in JavaScript and are frequently assigned as callbacks or returned from functions, when a function is executed, the name resolution depends on where it was originally defined (the lexical context of the definition), not the lexical context or execution context where it is called. The nested scopes of a particular function (from most global to most local) in JavaScript, particularly of a closure, used as a callback, are sometimes referred to as the scope chain, by analogy with the prototype chain of an object.
Closures can be produced in JavaScript by using nested functions, as functions are first-class objects. Returning a nested function from an enclosing function includes the local variables of the enclosing function as the (non-local) lexical context of the returned function, yielding a closure. For example:

Closures are frequently used in JavaScript, due to being used for callbacks. Indeed, any hooking of a function in the local context as a callback or returning it from a function creates a closure if there are any unbound variables in the function body (with the context of the closure based on the nested scopes of the current lexical context, or ""scope chain""); this may be accidental. When creating a callback based on parameters, the parameters must be stored in a closure, otherwise it will accidentally create a closure that refers to the variables in the enclosing context, which may change.Name resolution of properties of JavaScript objects is based on inheritance in the prototype tree—a path to the root in the tree is called a prototype chain—and is separate from name resolution of variables and functions.


=== Lisp ===
Lisp dialects have various rules for scope.
The original Lisp used dynamic scope; it was Scheme, inspired by ALGOL, that introduced static (lexical) scope to the Lisp family.
Maclisp used dynamic scope by default in the interpreter and lexical scope by default in compiled code, though compiled code could access dynamic bindings by use of SPECIAL declarations for particular variables. However, Maclisp treated lexical binding more as an optimization than one would expect in modern languages, and it did not come with the closure feature one might expect of lexical scope in modern Lisps. A separate operation, *FUNCTION, was available to somewhat clumsily work around some of that issue.Common Lisp adopted lexical scope from Scheme, as did Clojure.
ISLISP has lexical scope for ordinary variables. It also has dynamic variables, but they are in all cases explicitly marked; they must be defined by a defdynamic special form, bound by a dynamic-let special form, and accessed by an explicit dynamic special form.Some other dialects of Lisp, like Emacs Lisp, still use dynamic scope by default. Emacs Lisp now has lexical scope available on a per-buffer basis.


=== Python ===
For variables, Python has function scope, module scope, and global scope. Names enter context at the start of a scope (function, module, or global scope), and exit context when a non-nested function is called or the scope ends. If a name is used prior to variable initialization, this raises a runtime exception. If a variable is simply accessed (not assigned to), name resolution follows the LEGB (Local, Enclosing, Global, Built-in) rule which resolves names to the narrowest relevant context. However, if a variable is assigned to, it defaults to declaring a variable whose scope starts at the start of the level (function, module, or global), not at the assignment. Both these rules can be overridden with a global or nonlocal (in Python 3) declaration prior to use, which allows accessing global variables even if there is a masking nonlocal variable, and assigning to global or nonlocal variables.
As a simple example, a function resolves a variable to the global scope:

Note that x is defined before f is called, so no error is raised, even though it is defined after its reference in the definition of f. Lexically this is a forward reference, which is allowed in Python.
Here assignment creates a new local variable, which does not change the value of the global variable:

Assignment to a variable within a function causes it to be declared local to the function, hence its scope is the entire function, and thus using it prior to this assignment raises an error. This differs from C, where the scope of the local variable start at its declaration. This code raises an error:

The default name resolution rules can be overridden with the global or nonlocal (in Python 3) keywords. In the below code, the global x declaration in g means that x resolves to the global variable. It thus can be accessed (as it has already been defined), and assignment assigns to the global variable, rather than declaring a new local variable. Note that no global declaration is needed in f—since it does not assign to the variable, it defaults to resolving to the global variable.

global can also be used for nested functions. In addition to allowing assignment to a global variable, as in an unnested function, this can also be used to access the global variable in the presence of a nonlocal variable:

For nested functions, there is also the nonlocal declaration, for assigning to a nonlocal variable, similar to using global in an unnested function:


=== R ===
R is a lexically scoped language, unlike other implementations of S where the values of free variables are determined by a set of global variables, while in R they are determined by the context in which the function was created. The scope contexts may be accessed using a variety of features (such as parent.frame()) which can simulate the experience of dynamic scope should the programmer desire.
There is no block scope:

Functions have access to scope they were created in:

Variables created or modified within a function stay there:

Variables created or modified within a function stay there unless assignment to enclosing scope is explicitly requested:

Although R has lexical scope by default, function scopes can be changed:


== See also ==
Closure (computer science)
Global variable
Local variable
Let expression
Non-local variable
Name binding
Name resolution (programming languages)
Variables (scope and extent)
Information hiding
Immediately-invoked function expressions in Javascript
Object lifetime


== Notes ==


== References =="
adfad3225d,Polymorphism (computer science),"In programming language theory and type theory, polymorphism is the provision of a single interface to entities of different types  or the use of a single symbol to represent multiple different types. The concept is borrowed from a principle in biology where an organism or species can have many different forms or stages.The most commonly recognized major classes of polymorphism are:

Ad hoc polymorphism: defines a common interface for an arbitrary set of individually specified types.
Parametric polymorphism: not specifying concrete types and instead use abstract symbols that can substitute for any type.
Subtyping (also called subtype polymorphism or inclusion polymorphism): when a name denotes instances of many different classes related by some common superclass.


== History ==
Interest in polymorphic type systems developed significantly in the 1990s, with practical implementations beginning to appear by the end of the decade.  Ad hoc polymorphism and parametric polymorphism were originally described in Christopher Strachey's Fundamental Concepts in Programming Languages, where they are listed as ""the two main classes"" of polymorphism.  Ad hoc polymorphism was a feature of Algol 68, while parametric polymorphism was the core feature of ML's type system.
In a 1985 paper, Peter Wegner and Luca Cardelli introduced the term inclusion polymorphism to model subtypes and inheritance, citing Simula as the first programming language to implement it.


== Types ==


=== Ad hoc polymorphism ===

Christopher Strachey chose the term ad hoc polymorphism to refer to polymorphic functions that can be applied to arguments of different types, but that behave differently depending on the type of the argument to which they are applied (also known as function overloading or operator overloading). The term ""ad hoc"" in this context is not intended to be pejorative; it refers simply to the fact that this type of polymorphism is not a fundamental feature of the type system. In the Pascal / Delphi example below, the Add functions seem to work generically over various types when looking at the invocations, but are considered to be two entirely distinct functions by the compiler for all intents and purposes:

In dynamically typed languages the situation can be more complex as the correct function that needs to be invoked might only be determinable at run time.
Implicit type conversion has also been defined as a form of polymorphism, referred to as ""coercion polymorphism"".


=== Parametric polymorphism ===

Parametric polymorphism allows a function or a data type to be written generically, so that it can handle values uniformly without depending on their type. Parametric polymorphism is a way to make a language more expressive while still maintaining full static type-safety.
The concept of parametric polymorphism applies to both data types and functions. A function that can evaluate to or be applied to values of different types is known as a polymorphic function. A data type that can appear to be of a generalized type (e.g. a list with elements of arbitrary type) is designated polymorphic data type like the generalized type from which such specializations are made.
Parametric polymorphism is ubiquitous in functional programming, where it is often simply referred to as ""polymorphism"". The following example in Haskell shows a parameterized list data type and two parametrically polymorphic functions on them:

Parametric polymorphism is also available in several object-oriented languages. For instance, templates in C++ and D, or under the name generics in C#, Delphi, Java and Go:

John C. Reynolds (and later Jean-Yves Girard) formally developed this notion of polymorphism as an extension to lambda calculus (called the polymorphic lambda calculus or System F). Any parametrically polymorphic function is necessarily restricted in what it can do, working on the shape of the data instead of its value, leading to the concept of parametricity.


=== Subtyping ===

Some languages employ the idea of subtyping (also called subtype polymorphism or inclusion polymorphism) to restrict the range of types that can be used in a particular case of polymorphism. In these languages, subtyping allows a function to be written to take an object of a certain type T, but also work correctly, if passed an object that belongs to a type S that is a subtype of T (according to the Liskov substitution principle). This type relation is sometimes written S <: T. Conversely, T is said to be a supertype of S—written T :> S. Subtype polymorphism is usually resolved dynamically (see below).
In the following Java example we make cats and dogs subtypes of animals. The procedure letsHear() accepts an animal, but will also work correctly if a subtype is passed to it:

In another example, if Number, Rational, and Integer are types such that Number :> Rational and Number :> Integer, a function written to take a Number will work equally well when passed an Integer or Rational as when passed a Number. The actual type of the object can be hidden from clients into a black box, and accessed via object identity.
In fact, if the Number type is abstract, it may not even be possible to get your hands on an object whose most-derived type is Number (see abstract data type, abstract class). This particular kind of type hierarchy is known—especially in the context of the Scheme programming language—as a numerical tower, and usually contains many more types.
Object-oriented programming languages offer subtype polymorphism using subclassing (also known as inheritance). In typical implementations, each class contains what is called a virtual table—a table of functions that implement the polymorphic part of the class interface—and each object contains a pointer to the ""vtable"" of its class, which is then consulted whenever a polymorphic method is called. This mechanism is an example of:

late binding, because virtual function calls are not bound until the time of invocation;
single dispatch (i.e. single-argument polymorphism), because virtual function calls are bound simply by looking through the vtable provided by the first argument (the this object), so the runtime types of the other arguments are completely irrelevant.The same goes for most other popular object systems. Some, however, such as Common Lisp Object System, provide multiple dispatch, under which method calls are polymorphic in all arguments.
The interaction between parametric polymorphism and subtyping leads to the concepts of variance and bounded quantification.


=== Row polymorphism ===

Row polymorphism is a similar, but distinct concept from subtyping. It deals with structural types.  It allows the usage of all values whose types have certain properties, without losing the remaining type information.


=== Polytypism ===

A related concept is polytypism (or data type genericity). A polytypic function is more general than polymorphic, and in such a function, ""though one can provide fixed ad hoc cases for specific data types, an ad hoc combinator is absent"".


=== Rank polymorphism ===
Rank polymorphism is one of the defining features of the array programming languages, like APL. The essence of the rank-polymorphic programming model is implicitly treating all operations as aggregate operations, usable on arrays with arbitrarily many dimensions, which is to say that rank polymorphism allows functions to  be defined to operate on arrays of any shape and size.


== Implementation aspects ==


=== Static and dynamic polymorphism ===

Polymorphism can be distinguished by when the implementation is selected: statically (at compile time) or dynamically (at run time, typically via a virtual function). This is known respectively as static dispatch and dynamic dispatch, and the corresponding forms of polymorphism are accordingly called static polymorphism and dynamic polymorphism.
Static polymorphism executes faster, because there is no dynamic dispatch overhead, but requires additional compiler support. Further, static polymorphism allows greater static analysis by compilers (notably for optimization), source code analysis tools, and human readers (programmers). Dynamic polymorphism is more flexible but slower—for example, dynamic polymorphism allows duck typing, and a dynamically linked library may operate on objects without knowing their full type.
Static polymorphism typically occurs in ad hoc polymorphism and parametric polymorphism, whereas dynamic polymorphism is usual for subtype polymorphism. However, it is possible to achieve static polymorphism with subtyping through more sophisticated use of template metaprogramming, namely the curiously recurring template pattern.
When polymorphism is exposed via a library, static polymorphism becomes impossible for dynamic libraries as there is no way of knowing what types the parameters are when the shared object is built. While languages like C++ and Rust use monomorphized templates, the Swift programming language makes extensive use of dynamic dispatch to build the application binary interface for these libraries by default. As a result, more code can be shared for a reduced system size at the cost of runtime overhead.


== See also ==
Duck typing for polymorphism without (static) types
Polymorphic code (computer virus terminology)
System F for a lambda calculus with parametric polymorphism.
Type class
Type theory
Virtual inheritance


== References ==


== External links ==
C++ examples of polymorphism
Objects and Polymorphism (Visual Prolog)
Polymorphism on MSDN
Polymorphism Java Documentation on Oracle"
1f679fc1c9,Theoretical computer science,"Theoretical computer science (TCS) is a subset of general computer science and mathematics that focuses on mathematical aspects of computer science such as the theory of computation, lambda calculus, and type theory.
It is difficult to circumscribe the theoretical areas precisely. The ACM's Special Interest Group on Algorithms and Computation Theory (SIGACT) provides the following description:
TCS covers a wide variety of topics including algorithms, data structures, computational complexity, parallel and distributed computation, probabilistic computation, quantum computation, automata theory, information theory, cryptography, program semantics and verification, algorithmic game theory, machine learning, computational biology, computational economics, computational geometry, and computational number theory and algebra. Work in this field is often distinguished by its emphasis on mathematical technique and rigor.


== History ==

While logical inference and mathematical proof had existed previously, in 1931 Kurt Gödel proved with his incompleteness theorem that there are fundamental limitations on what statements could be proved or disproved.
Information theory was added to the field with a 1948 mathematical theory of communication by Claude Shannon. In the same decade, Donald Hebb introduced a mathematical model of learning in the brain. With mounting biological data supporting this hypothesis with some modification, the fields of neural networks and parallel distributed processing were established. In 1971, Stephen Cook and, working independently, Leonid Levin, proved that there exist practically relevant problems that are NP-complete – a landmark result in computational complexity theory.
With the development of quantum mechanics in the beginning of the 20th century came the concept that mathematical operations could be performed on an entire particle wavefunction. In other words, one could compute functions on multiple states simultaneously. This led to the concept of a quantum computer in the latter half of the 20th century that took off in the 1990s when Peter Shor showed that such methods could be used to factor large numbers in polynomial time, which, if implemented, would render some modern public key cryptography algorithms like RSA insecure.Modern theoretical computer science research is based on these basic developments, but includes many other mathematical and interdisciplinary problems that have been posed, as shown below:


== Topics ==


=== Algorithms ===

An algorithm is a step-by-step procedure for calculations.  Algorithms are used for calculation, data processing, and automated reasoning.
An algorithm is an effective method expressed as a finite list of well-defined instructions for calculating a function.  Starting from an initial state and initial input (perhaps empty), the instructions describe a computation that, when executed, proceeds through a finite number of well-defined successive states, eventually producing ""output"" and terminating at a final ending state. The transition from one state to the next is not necessarily deterministic; some algorithms, known as randomized algorithms, incorporate random input.


=== Automata theory ===

Automata theory is the study of abstract machines and automata, as well as the computational problems that can be solved using them. It is a theory in theoretical computer science, under discrete mathematics (a section of mathematics and also of computer science). Automata comes from the Greek word αὐτόματα meaning ""self-acting"".
Automata Theory is the study of self-operating virtual machines to help in the logical understanding of input and output process, without or with intermediate stage(s) of computation (or any function/process).


=== Coding theory ===

Coding theory is the study of the properties of codes and their fitness for a specific application. Codes are used for data compression, cryptography, error-correction and more recently also for network coding. Codes are studied by various scientific disciplines—such as information theory, electrical engineering,  mathematics, and computer science—for the purpose of designing efficient and reliable data transmission methods. This typically involves the removal of redundancy and the correction (or detection) of errors in the transmitted data.


=== Computational biology ===

Computational biology involves the development and application of data-analytical and theoretical methods, mathematical modeling and computational simulation techniques to the study of biological, behavioral, and social systems. The field is broadly defined and includes foundations in computer science, applied mathematics, animation, statistics, biochemistry, chemistry, biophysics, molecular biology, genetics, genomics, ecology, evolution, anatomy, neuroscience, and visualization.Computational biology is different from biological computation, which is a subfield of computer science and computer engineering using bioengineering and biology to build computers, but is similar to bioinformatics, which is an interdisciplinary science using computers to store and process biological data.


=== Computational complexity theory ===

Computational complexity theory is a branch of the theory of computation that focuses on classifying computational problems according to their inherent difficulty, and relating those classes to each other. A computational problem is understood to be a task that is in principle amenable to being solved by a computer, which is equivalent to stating that the problem may be solved by mechanical application of mathematical steps, such as an algorithm.
A problem is regarded as inherently difficult if its solution requires significant resources, whatever the algorithm used. The theory formalizes this intuition, by introducing mathematical models of computation to study these problems and quantifying the amount of resources needed to solve them, such as time and storage. Other complexity measures are also used, such as the amount of communication (used in communication complexity), the number of gates in a circuit (used in circuit complexity) and the number of processors (used in parallel computing). One of the roles of computational complexity theory is to determine the practical limits on what computers can and cannot do.


=== Computational geometry ===

Computational geometry is a branch of computer science devoted to the study of algorithms that can be stated in terms of geometry. Some purely geometrical problems arise out of the study of computational geometric algorithms, and such problems are also considered to be part of computational geometry. 
The main impetus for the development of computational geometry as a discipline was progress in computer graphics and computer-aided design and manufacturing (CAD/CAM), but many problems in computational geometry are classical in nature, and may come from mathematical visualization.
Other important applications of computational geometry include robotics (motion planning and visibility problems), geographic information systems (GIS) (geometrical location and search, route planning), integrated circuit design (IC geometry design and verification), computer-aided engineering (CAE) (mesh generation), computer vision (3D reconstruction).


=== Computational learning theory ===

Theoretical results in machine learning mainly deal with a type of inductive learning called supervised learning.  In supervised learning, an algorithm is given samples that are labeled in some
useful way.  For example, the samples might be descriptions of mushrooms, and the labels could be whether or not the mushrooms are edible.  The algorithm takes these previously labeled samples and
uses them to induce a classifier.  This classifier is a function that assigns labels to samples including the samples that have never been previously seen by the algorithm.  The goal of the supervised learning algorithm is to optimize some measure of performance such as minimizing the number of mistakes made on new samples.


=== Computational number theory ===

Computational number theory, also known as algorithmic number theory, is the study of algorithms for performing number theoretic computations. The best known problem in the field is integer factorization.


=== Cryptography ===

Cryptography  is the practice and study of techniques for secure communication in the presence of third parties (called adversaries). More generally, it is about constructing and analyzing protocols that overcome the influence of adversaries and that are related to various aspects in information security such as data confidentiality, data integrity, authentication, and non-repudiation. Modern cryptography intersects the disciplines of mathematics, computer science, and electrical engineering. Applications of cryptography include ATM cards, computer passwords, and electronic commerce.
Modern cryptography is heavily based on mathematical theory and computer science practice; cryptographic algorithms are designed around computational hardness assumptions, making such algorithms hard to break in practice by any adversary. It is theoretically possible to break such a system, but it is infeasible to do so by any known practical means. These schemes are therefore termed computationally secure; theoretical advances, e.g., improvements in integer factorization algorithms, and faster computing technology require these solutions to be continually adapted. There exist information-theoretically secure schemes that provably cannot be broken even with unlimited computing power—an example is the one-time pad—but these schemes are more difficult to implement than the best theoretically breakable but computationally secure mechanisms.


=== Data structures ===

A data structure is a particular way of organizing data in a computer so that it can be used efficiently.Different kinds of data structures are suited to different kinds of applications, and some are highly specialized to specific tasks. For example, databases use B-tree indexes for small percentages of data retrieval and compilers and databases use dynamic hash tables as look up tables.
Data structures provide a means to manage large amounts of data efficiently for uses such as large databases and internet indexing services. Usually, efficient data structures are key to designing efficient algorithms. Some formal design methods and programming languages emphasize data structures, rather than algorithms, as the key organizing factor in software design. Storing and retrieving can be carried out on data stored in both main memory and in secondary memory.


=== Distributed computation ===

Distributed computing studies distributed systems. A distributed system is a software system in which components located on networked computers communicate and coordinate their actions by passing messages. The components interact with each other in order to achieve a common goal. Three significant characteristics of distributed systems are: concurrency of components, lack of a global clock, and independent failure of components. Examples of distributed systems vary from SOA-based systems to massively multiplayer online games to  peer-to-peer applications, and blockchain networks like Bitcoin.
A computer program that runs in a distributed system is called a distributed program, and distributed programming is the process of writing such programs. There are many alternatives for the message passing mechanism, including RPC-like connectors and message queues.  An important goal and challenge of distributed systems is location transparency.


=== Information-based complexity ===

Information-based complexity (IBC) studies optimal algorithms and computational complexity for continuous problems. IBC has studied continuous problems as path integration, partial differential equations, systems of ordinary differential equations, nonlinear equations, integral equations, fixed points, and very-high-dimensional integration.


=== Formal methods ===

Formal methods are a particular kind of mathematics based techniques for the specification, development and verification of software and hardware systems. The use of formal methods for software and hardware design is motivated by the expectation that, as in other engineering disciplines, performing appropriate mathematical analysis can contribute to the reliability and robustness of a design.Formal methods are best described as the application of a fairly broad variety of theoretical computer science fundamentals, in particular logic calculi, formal languages, automata theory, and program semantics, but also type systems and algebraic data types to problems in software and hardware specification and verification.


=== Information theory ===

Information theory is a branch of applied mathematics, electrical engineering, and computer science involving the quantification of information.  Information theory was developed by Claude E. Shannon to find fundamental limits on signal processing operations such as compressing data and on reliably storing and communicating data. Since its inception it has broadened to find applications in many other areas, including statistical inference, natural language processing, cryptography, neurobiology, the evolution and function of molecular codes, model selection in statistics, thermal physics, quantum computing, linguistics, plagiarism detection, pattern recognition, anomaly detection and other forms of data analysis.Applications of fundamental topics of information theory include lossless data compression (e.g. ZIP files), lossy data compression (e.g. MP3s and JPEGs), and channel coding (e.g. for Digital Subscriber Line (DSL)).  The field is at the intersection of mathematics, statistics, computer science, physics, neurobiology, and electrical engineering. Its impact has been crucial to the success of the Voyager missions to deep space, the invention of the compact disc, the feasibility of mobile phones, the development of the Internet, the study of linguistics and of human perception, the understanding of black holes, and numerous other fields. Important sub-fields of information theory are source coding, channel coding, algorithmic complexity theory, algorithmic information theory, information-theoretic security, and measures of information.


=== Machine learning ===

Machine learning is a scientific discipline that deals with the construction and study of algorithms that can learn from data. Such algorithms operate by building a model based on inputs: 2  and using that to make predictions or decisions, rather than following only explicitly programmed instructions.
Machine learning can be considered a subfield of computer science and statistics. It has strong ties to artificial intelligence and optimization, which deliver methods, theory and application domains to the field. Machine learning is employed in a range of computing tasks where designing and programming explicit, rule-based algorithms is infeasible. Example applications include spam filtering, optical character recognition (OCR), search engines and computer vision. Machine learning is sometimes conflated with data mining, although that focuses more on exploratory data analysis. Machine learning and pattern recognition ""can be viewed as two facets of
the same field."": vii 


=== Parallel computation ===

Parallel computing is a form of computation in which many calculations are carried out simultaneously, operating on the principle that large problems can often be divided into smaller ones, which are then solved ""in parallel"". There are several different forms of parallel computing: bit-level, instruction level, data, and task parallelism. Parallelism has been employed for many years, mainly in high-performance computing, but interest in it has grown lately due to the physical constraints preventing frequency scaling. As power consumption (and consequently heat generation) by computers has become a concern in recent years, parallel computing has become the dominant paradigm in computer architecture, mainly in the form of multi-core processors.Parallel computer programs are more difficult to write than sequential ones, because concurrency introduces several new classes of potential software bugs, of which race conditions are the most common. Communication and synchronization between the different subtasks are typically some of the greatest obstacles to getting good parallel program performance.
The maximum possible speed-up of a single program as a result of parallelization is known as Amdahl's law.


=== Program semantics ===

In programming language theory, semantics is the field concerned with the rigorous mathematical study of the meaning of programming languages. It does so by evaluating the meaning of syntactically legal strings defined by a specific programming language, showing the computation involved. In such a case that the evaluation would be of syntactically illegal strings, the result would be non-computation. Semantics describes the processes a computer follows when executing a program in that specific language. This can be shown by describing the relationship between the input and output of a program, or an explanation of how the program will execute on a certain platform, hence creating a model of computation.


=== Quantum computation ===

A quantum computer is a computation system that makes direct use of quantum-mechanical phenomena, such as superposition and entanglement, to perform operations on data. Quantum computers are different from digital computers based on transistors. Whereas digital computers require data to be encoded into binary digits (bits), each of which is always in one of two definite states (0 or 1), quantum computation uses qubits (quantum bits), which can be in superpositions of states. A theoretical model is the quantum Turing machine, also known as the universal quantum computer.  Quantum computers share theoretical similarities with non-deterministic and probabilistic computers; one example is the ability to be in more than one state simultaneously.  The field of quantum computing was first introduced by Yuri Manin in 1980 and Richard Feynman in 1982. A quantum computer with spins as quantum bits was also formulated for use as a quantum space–time in 1968.As of 2014, quantum computing is still in its infancy but experiments have been carried out in which quantum computational operations were executed on a very small number of qubits. Both practical and theoretical research continues, and many national governments and military funding agencies support quantum computing research to develop quantum computers for both civilian and national security purposes, such as cryptanalysis.


=== Symbolic computation ===

Computer algebra, also called symbolic computation or algebraic computation is a scientific area that refers to the study and development of algorithms and software for manipulating mathematical expressions and other mathematical objects. Although, properly speaking, computer algebra should be a subfield of scientific computing, they are generally considered as distinct fields because scientific computing is usually based on numerical computation with approximate floating point numbers, while symbolic computation emphasizes exact computation with expressions containing variables that have not any given value and are thus manipulated as symbols (therefore the name of symbolic computation).
Software applications that perform symbolic calculations are called computer algebra systems, with the term system alluding to the complexity of the main applications  that include, at least, a method to represent mathematical data in a computer, a user programming language (usually different from the language used for the implementation), a dedicated memory manager, a user interface for the input/output of mathematical expressions, a large set of routines to perform usual operations, like simplification of expressions, differentiation using chain rule, polynomial factorization, indefinite integration, etc.


=== Very-large-scale integration ===

Very-large-scale integration (VLSI) is the process of creating an integrated circuit (IC) by combining thousands of transistors into a single chip. VLSI began in the 1970s when complex semiconductor and communication technologies were being developed. The microprocessor is a VLSI device. Before the introduction of VLSI technology most ICs had a limited set of functions they could perform. An electronic circuit might consist of a CPU, ROM, RAM and other glue logic. VLSI allows IC makers to add all of these circuits into one chip.


== Organizations ==
European Association for Theoretical Computer Science
SIGACT
Simons Institute for the Theory of Computing


== Journals and newsletters ==
Discrete Mathematics and Theoretical Computer Science
Information and Computation
Theory of Computing (open access journal)
Formal Aspects of Computing
Journal of the ACM
SIAM Journal on Computing (SICOMP)
SIGACT News
Theoretical Computer Science
Theory of Computing Systems
TheoretiCS (open access journal)
International Journal of Foundations of Computer Science
Chicago Journal of Theoretical Computer Science (open access journal)
Foundations and Trends in Theoretical Computer Science
Journal of Automata, Languages and Combinatorics
Acta Informatica
Fundamenta Informaticae
ACM Transactions on Computation Theory
Computational Complexity
Journal of Complexity
ACM Transactions on Algorithms
Information Processing Letters
Open Computer Science (open access journal)


== Conferences ==
Annual ACM Symposium on Theory of Computing (STOC)
Annual IEEE Symposium on Foundations of Computer Science (FOCS)
Innovations in Theoretical Computer Science (ITCS)
Mathematical Foundations of Computer Science (MFCS)
International Computer Science Symposium in Russia (CSR)
ACM–SIAM Symposium on Discrete Algorithms (SODA)
IEEE Symposium on Logic in Computer Science (LICS)
Computational Complexity Conference (CCC)
International Colloquium on Automata, Languages and Programming (ICALP)
Annual Symposium on Computational Geometry (SoCG)
ACM Symposium on Principles of Distributed Computing (PODC)
ACM Symposium on Parallelism in Algorithms and Architectures (SPAA)
Annual Conference on Learning Theory (COLT)
Symposium on Theoretical Aspects of Computer Science (STACS)
European Symposium on Algorithms (ESA)
Workshop on Approximation Algorithms for Combinatorial Optimization Problems (APPROX)
Workshop on Randomization and Computation (RANDOM)
International Symposium on Algorithms and Computation (ISAAC)
International Symposium on Fundamentals of Computation Theory (FCT)
International Workshop on Graph-Theoretic Concepts in Computer Science (WG)


== See also ==
Formal science
Unsolved problems in computer science
Sun–Ni law


== Notes ==


== Further reading ==
Martin Davis, Ron Sigal, Elaine J. Weyuker, Computability, complexity, and languages: fundamentals of theoretical computer science, 2nd ed., Academic Press, 1994, ISBN 0-12-206382-1. Covers theory of computation, but also program semantics and quantification theory. Aimed at graduate students.


== External links ==
SIGACT directory of additional theory links
Theory Matters Wiki Theoretical Computer Science (TCS) Advocacy Wiki
List of academic conferences in the area of theoretical computer science at confsearch
Theoretical Computer Science – StackExchange, a Question and Answer site for researchers in theoretical computer science
Computer Science Animated
Theory of computation @ Massachusetts Institute of Technology"
64be1d63cb,Glossary of computer science,"This glossary of computer science is a list of definitions of terms and concepts used in computer science, its sub-disciplines, and related fields, including terms relevant to software, data science, and computer programming.


== A ==
abstract data type (ADT)
A mathematical model for data types in which a data type is defined by its behavior (semantics) from the point of view of a user of the data, specifically in terms of possible values, possible operations on data of this type, and the behavior of these operations. This contrasts with data structures, which are concrete representations of data from the point of view of an implementer rather than a user.

abstract method
One with only a signature and no implementation body. It is often used to specify that a subclass must provide an implementation of the method. Abstract methods are used to specify interfaces in some computer languages.

abstraction
1.  In software engineering and computer science, the process of removing physical, spatial, or temporal details or attributes in the study of objects or systems in order to more closely attend to other details of interest; it is also very similar in nature to the process of generalization.
2.  The result of this process: an abstract concept-object created by keeping common features or attributes to various concrete objects or systems of study.

agent architecture
A blueprint for software agents and intelligent control systems depicting the arrangement of components. The architectures implemented by intelligent agents are referred to as cognitive architectures.

agent-based model (ABM)
A class of computational models for simulating the actions and interactions of autonomous agents (both individual or collective entities such as organizations or groups) with a view to assessing their effects on the system as a whole. It combines elements of game theory, complex systems, emergence, computational sociology, multi-agent systems, and evolutionary programming. Monte Carlo methods are used to introduce randomness.

aggregate function
In database management, a function in which the values of multiple rows are grouped together to form a single value of more significant meaning or measurement, such as a sum, count, or max.

agile software development
An approach to software development under which requirements and solutions evolve through the collaborative effort of self-organizing and cross-functional teams and their customer(s)/end user(s). It advocates adaptive planning, evolutionary development, early delivery, and continual improvement, and it encourages rapid and flexible response to change.

algorithm
An unambiguous specification of how to solve a class of problems. Algorithms can perform calculation, data processing, and automated reasoning tasks. They are ubiquitous in computing technologies.

algorithm design
A method or mathematical process for problem-solving and for engineering algorithms. The design of algorithms is part of many solution theories of operation research, such as dynamic programming and divide-and-conquer. Techniques for designing and implementing algorithm designs are also called algorithm design patterns, such as the template method pattern and decorator pattern.

algorithmic efficiency
A property of an algorithm which relates to the number of computational resources used by the algorithm. An algorithm must be analyzed to determine its resource usage, and the efficiency of an algorithm can be measured based on usage of different resources. Algorithmic efficiency can be thought of as analogous to engineering productivity for a repeating or continuous process.

American Standard Code for Information Interchange (ASCII)
A character encoding standard for electronic communications. ASCII codes represent text in computers, telecommunications equipment, and other devices. Most modern character-encoding schemes are based on ASCII, although they support many additional characters.

application programming interface (API)
A set of subroutine definitions, communication protocols, and tools for building software. In general terms, it is a set of clearly defined methods of communication among various components. A good API makes it easier to develop a computer program by providing all the building blocks, which are then put together by the programmer.

application software
Also simply application or app.
Computer software designed to perform a group of coordinated functions, tasks, or activities for the benefit of the user. Common examples of applications include word processors, spreadsheets, accounting applications, web browsers, media players, aeronautical flight simulators, console games, and photo editors. This contrasts with system software, which is mainly involved with managing the computer's most basic running operations, often without direct input from the user. The collective noun application software refers to all applications collectively.

array data structure
Also simply array.
A data structure consisting of a collection of elements (values or variables), each identified by at least one array index or key. An array is stored such that the position of each element can be computed from its index tuple by a mathematical formula. The simplest type of data structure is a linear array, also called a one-dimensional array.

artifact
One of many kinds of tangible by-products produced during the development of software. Some artifacts (e.g. use cases, class diagrams, and other Unified Modeling Language (UML) models, requirements, and design documents) help describe the function, architecture, and design of software. Other artifacts are concerned with the process of development itself—such as project plans, business cases, and risk assessments.

artificial intelligence (AI)
Also machine intelligence.
Intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and other animals. In computer science, AI research is defined as the study of ""intelligent agents"": devices capable of perceiving their environment and taking actions that maximize the chance of successfully achieving their goals. Colloquially, the term ""artificial intelligence"" is applied when a machine mimics ""cognitive"" functions that humans associate with other human minds, such as ""learning"" and ""problem solving"".

ASCII
See American Standard Code for Information Interchange.

assertion
In computer programming, a statement that a predicate (Boolean-valued function, i.e. a true–false expression) is always true at that point in code execution. It can help a programmer read the code, help a compiler compile it, or help the program detect its own defects. For the latter, some programs check assertions by actually evaluating the predicate as they run and if it is not in fact true – an assertion failure – the program considers itself to be broken and typically deliberately crashes or throws an assertion failure exception.

associative array
An associative array, map, symbol table, or dictionary is an abstract data type composed of a collection of (key, value) pairs, such that each possible key appears at most once in the collection.

Operations associated with this data type allow:the addition of a pair to the collection
the removal of a pair from the collection
the modification of an existing pair
the lookup of a value associated with a particular key

automata theory
The study of abstract machines and automata, as well as the computational problems that can be solved using them. It is a theory in theoretical computer science and discrete mathematics (a subject of study in both mathematics and computer science).

automated reasoning
An area of computer science and mathematical logic dedicated to understanding different aspects of reasoning. The study of automated reasoning helps produce computer programs that allow computers to reason completely, or nearly completely, automatically. Although automated reasoning is considered a sub-field of artificial intelligence, it also has connections with theoretical computer science, and even philosophy.


== B ==
bandwidth
The maximum rate of data transfer across a given path. Bandwidth may be characterized as network bandwidth, data bandwidth, or digital bandwidth.

Bayesian programming
A formalism and a methodology for having a technique to specify probabilistic models and solve problems when less than the necessary information is available.

benchmark
The act of running a computer program, a set of programs, or other operations, in order to assess the relative performance of an object, normally by running a number of standard tests and trials against it. The term benchmark is also commonly utilized for the purposes of elaborately designed benchmarking programs themselves.

best, worst and average case
Expressions of what the resource usage is at least, at most, and on average, respectively, for a given algorithm. Usually the resource being considered is running time, i.e. time complexity, but it could also be memory or some other resource. Best case is the function which performs the minimum number of steps on input data of n elements; worst case is the function which performs the maximum number of steps on input data of size n; average case is the function which performs an average number of steps on input data of n elements.

big data
A term used to refer to data sets that are too large or complex for traditional data-processing application software to adequately deal with. Data with many cases (rows) offer greater statistical power, while data with higher complexity (more attributes or columns) may lead to a higher false discovery rate.

big O notation
A mathematical notation that describes the limiting behavior of a function when the argument tends towards a particular value or infinity. It is a member of a family of notations invented by Paul Bachmann, Edmund Landau, and others, collectively called Bachmann–Landau notation or asymptotic notation.

binary number
In mathematics and digital electronics, a number expressed in the base-2 numeral system or binary numeral system, which uses only two symbols: typically 0 (zero) and 1 (one).

binary search algorithm
Also simply binary search, half-interval search, logarithmic search, or binary chop.
A search algorithm that finds the position of a target value within a sorted array.

binary tree
A tree data structure in which each node has at most two children, which are referred to as the left child and the right child. A recursive definition using just set theory notions is that a (non-empty) binary tree is a tuple (L, S, R), where L and R are binary trees or the empty set and S is a singleton set. Some authors allow the binary tree to be the empty set as well.

bioinformatics
An interdisciplinary field that combines biology, computer science, information engineering, mathematics, and statistics to develop methods and software tools for analyzing and interpreting biological data. Bioinformatics is widely used for in silico analyses of biological queries using mathematical and statistical techniques.

bit
A basic unit of information used in computing and digital communications; a portmanteau of binary digit. A binary digit can have one of two possible values, and may be physically represented with a two-state device. These state values are most commonly represented as either a 0or1.

bit rate (R)

Also bitrate.
In telecommunications and computing, the number of bits that are conveyed or processed per unit of time.

blacklist
Also block list.
In computing, a basic access control mechanism that allows through all elements (email addresses, users, passwords, URLs, IP addresses, domain names, file hashes, etc.), except those explicitly mentioned in a list of prohibited elements. Those items on the list are denied access. The opposite is a whitelist, which means only items on the list are allowed through whatever gate is being used while all other elements are blocked. A greylist contains items that are temporarily blocked (or temporarily allowed) until an additional step is performed.

BMP file format
Also bitmap image file, device independent bitmap (DIB) file format, or simply bitmap.
A raster graphics image file format used to store bitmap digital images independently of the display device (such as a graphics adapter), used especially on Microsoft Windows and OS/2 operating systems.

Boolean data type
A data type that has one of two possible values (usually denoted true and false), intended to represent the two truth values of logic and Boolean algebra. It is named after George Boole, who first defined an algebraic system of logic in the mid-19th century. The Boolean data type is primarily associated with conditional statements, which allow different actions by changing control flow depending on whether a programmer-specified Boolean condition evaluates to true or false. It is a special case of a more general logical data type (see probabilistic logic)—i.e. logic need not always be Boolean.

Boolean expression
An expression used in a programming language that returns a Boolean value when evaluated, that is one of true or false. A Boolean expression may be composed of a combination of the Boolean constants true or false, Boolean-typed variables, Boolean-valued operators, and Boolean-valued functions.

Boolean algebra
In mathematics and mathematical logic, the branch of algebra in which the values of the variables are the truth values true and false, usually denoted 1 and 0, respectively. Contrary to elementary algebra, where the values of the variables are numbers and the prime operations are addition and multiplication, the main operations of Boolean algebra are the conjunction and (denoted as ∧), the disjunction or (denoted as ∨), and the negation not (denoted as ¬). It is thus a formalism for describing logical relations in the same way that elementary algebra describes numeric relations.

byte
A unit of digital information that most commonly consists of eight bits, representing a binary number. Historically, the byte was the number of bits used to encode a single character of text in a computer and for this reason it is the smallest addressable unit of memory in many computer architectures.

booting
The procedures implemented in starting up a computer or computer appliance until it can be used. It can be initiated by hardware such as a button press or by a software command. After the power is switched on, the computer is relatively dumb and can read only part of its storage called read-only memory. There, a small program is stored called firmware. It does power-on self-tests and, most importantly, allows access to other types of memory like a hard disk and main memory. The firmware loads bigger programs into the computer's main memory and runs it.


== C ==
callback
Also a call-after function.
Any executable code that is passed as an argument to other code that is expected to ""call back"" (execute) the argument at a given time. This execution may be immediate, as in a synchronous callback, or it might happen at a later time, as in an asynchronous callback.

central processing unit (CPU)
The electronic circuitry within a computer that carries out the instructions of a computer program by performing the basic arithmetic, logic, controlling, and input/output (I/O) operations specified by the instructions. The computer industry has used the term ""central processing unit"" at least since the early 1960s. Traditionally, the term ""CPU"" refers to a processor, more specifically to its processing unit and control unit (CU), distinguishing these core elements of a computer from external components such as main memory and I/O circuitry.

character
A unit of information that roughly corresponds to a grapheme, grapheme-like unit, or symbol, such as in an alphabet or syllabary in the written form of a natural language.

cipher
Also cypher.
In cryptography, an algorithm for performing encryption or decryption—a series of well-defined steps that can be followed as a procedure.

class
In object-oriented programming, an extensible program-code-template for creating objects, providing initial values for state (member variables) and implementations of behavior (member functions or methods). In many languages, the class name is used as the name for the class (the template itself), the name for the default constructor of the class (a subroutine that creates objects), and as the type of objects generated by instantiating the class; these distinct concepts are easily conflated.

class-based programming
Also class-orientation.
A style of object-oriented programming (OOP) in which inheritance occurs via defining ""classes"" of objects, instead of via the objects alone (compare prototype-based programming).

client
A piece of computer hardware or software that accesses a service made available by a server. The server is often (but not always) on another computer system, in which case the client accesses the service by way of a network. The term applies to the role that programs or devices play in the client–server model.

cleanroom software engineering
A software development process intended to produce software with a certifiable level of reliability. The cleanroom process was originally developed by Harlan Mills and several of his colleagues including Alan Hevner at IBM. The focus of the cleanroom process is on defect prevention, rather than defect removal.

closure
Also lexical closure or function closure.
A technique for implementing lexically scoped name binding in a language with first-class functions. Operationally, a closure is a record storing a function together with an environment.

cloud computing
Shared pools of configurable computer system resources and higher-level services that can be rapidly provisioned with minimal management effort, often over the Internet.  Cloud computing relies on sharing of resources to achieve coherence and economies of scale, similar to a public utility.

code library
A collection of non-volatile resources used by computer programs, often for software development. These may include configuration data, documentation, help data, message templates, pre-written code and subroutines, classes, values or type specifications. In IBM's OS/360 and its successors they are referred to as partitioned data sets.

coding
Computer programming is the process of designing and building an executable computer program for accomplishing a specific computing task. Programming involves tasks such as analysis, generating algorithms, profiling algorithms' accuracy and resource consumption, and the implementation of algorithms in a chosen programming language (commonly referred to as coding). The source code of a program is written in one or more programming languages. The purpose of programming is to find a sequence of instructions that will automate the performance of a task for solving a given problem. The process of programming thus often requires expertise in several different subjects, including knowledge of the application domain, specialized algorithms, and formal logic.

coding theory
The study of the properties of codes and their respective fitness for specific applications. Codes are used for data compression, cryptography, error detection and correction, data transmission and data storage. Codes are studied by various scientific disciplines—such as information theory, electrical engineering, mathematics, linguistics, and computer science—for the purpose of designing efficient and reliable data transmission methods. This typically involves the removal of redundancy and the correction or detection of errors in the transmitted data.

cognitive science
The interdisciplinary, scientific study of the mind and its processes. It examines the nature, the tasks, and the functions of cognition (in a broad sense). Cognitive scientists study intelligence and behavior, with a focus on how nervous systems represent, process, and transform information. Mental faculties of concern to cognitive scientists include language, perception, memory, attention, reasoning, and emotion; to understand these faculties, cognitive scientists borrow from fields such as linguistics, psychology, artificial intelligence, philosophy, neuroscience, and anthropology.

collection
A collection or container is a grouping of some variable number of data items (possibly zero) that have some shared significance to the problem being solved and need to be operated upon together in some controlled fashion.  Generally, the data items will be of the same type or, in languages supporting inheritance, derived from some common ancestor type. A collection is a concept applicable to abstract data types, and does not prescribe a specific implementation as a concrete data structure, though often there is a conventional choice (see Container for type theory discussion).

comma-separated values (CSV)
A delimited text file that uses a comma to separate values. A CSV file stores tabular data (numbers and text) in plain text.  Each line of the file is a data record.  Each record consists of one or more fields, separated by commas. The use of the comma as a field separator is the source of the name for this file format.

compiler
A computer program that transforms computer code written in one programming language (the source language) into another programming language (the target language). Compilers are a type of translator that support digital devices, primarily computers. The name compiler is primarily used for programs that translate source code from a high-level programming language to a lower-level language (e.g. assembly language, object code, or machine code) to create an executable program.

computability theory
also known as recursion theory, is a branch of mathematical logic, of computer science, and of the theory of computation that originated in the 1930s with the study of computable functions and Turing degrees. The field has since expanded to include the study of generalized computability and definability. In these areas, recursion theory overlaps with proof theory and effective descriptive set theory.

computation
Any type of calculation that includes both arithmetical and non-arithmetical steps and follows a well-defined model, e.g. an algorithm. The study of computation is paramount to the discipline of computer science.

computational biology
Involves the development and application of data-analytical and theoretical methods, mathematical modelling and computational simulation techniques to the study of biological, ecological, behavioural, and social systems. The field is broadly defined and includes foundations in biology, applied mathematics, statistics, biochemistry, chemistry, biophysics, molecular biology, genetics, genomics, computer science, and evolution.  Computational biology is different from biological computing, which is a subfield of computer science and computer engineering using bioengineering and biology to build computers.

computational chemistry
A branch of chemistry that uses computer simulation to assist in solving chemical problems. It uses methods of theoretical chemistry, incorporated into efficient computer programs, to calculate the structures and properties of molecules and solids.

computational complexity theory
A subfield of computational science which focuses on classifying computational problems according to their inherent difficulty, and relating these classes to each other. A computational problem is a task solved by a computer. A computation problem is solvable by mechanical application of mathematical steps, such as an algorithm.

computational model
A mathematical model in computational science that requires extensive computational resources to study the behavior of a complex system by computer simulation.

computational neuroscience
Also theoretical neuroscience or mathematical neuroscience.
A branch of neuroscience which employs mathematical models, theoretical analysis, and abstractions of the brain to understand the principles that govern the development, structure, physiology, and cognitive abilities of the nervous system.

computational physics
Is the study and implementation of numerical analysis to solve problems in physics for which a quantitative theory already exists. Historically, computational physics was the first application of modern computers in science, and is now a subset of computational science.

computational science
Also scientific computing and scientific computation (SC).
An interdisciplinary field that uses advanced computing capabilities to understand and solve complex problems. It is an area of science which spans many disciplines, but at its core it involves the development of computer models and simulations to understand complex natural systems.

computational steering
Is the practice of manually intervening with an otherwise autonomous computational process, to change its outcome.

computer
A device that can be instructed to carry out sequences of arithmetic or logical operations automatically via computer programming. Modern computers have the ability to follow generalized sets of operations, called programs. These programs enable computers to perform an extremely wide range of tasks.

computer architecture
A set of rules and methods that describe the functionality, organization, and implementation of computer systems. Some definitions of architecture define it as describing the capabilities and programming model of a computer but not a particular implementation. In other definitions computer architecture involves instruction set architecture design, microarchitecture design, logic design, and implementation.

computer data storage
Also simply storage or memory.
A technology consisting of computer components and recording media that are used to retain digital data. Data storage is a core function and fundamental component of all modern computer systems.: 15–16 

computer ethics
A part of practical philosophy concerned with how computing professionals should make decisions regarding professional and social conduct.

computer graphics
Pictures and films created using computers. Usually, the term refers to computer-generated image data created with the help of specialized graphical hardware and software. It is a vast and recently developed area of computer science.

computer network
Also data network.
A digital telecommunications network which allows nodes to share resources. In computer networks, computing devices exchange data with each other using connections (data links) between nodes. These data links are established over cable media such as wires or optic cables, or wireless media such as Wi-Fi.

computer program
Is a collection of instructions that can be executed by a computer to perform a specific task. 

computer programming
The process of designing and building an executable computer program for accomplishing a specific computing task. Programming involves tasks such as analysis, generating algorithms, profiling algorithms' accuracy and resource consumption, and the implementation of algorithms in a chosen programming language (commonly referred to as coding). The source code of a program is written in one or more programming languages. The purpose of programming is to find a sequence of instructions that will automate the performance of a task for solving a given problem. The process of programming thus often requires expertise in several different subjects, including knowledge of the application domain, specialized algorithms, and formal logic.

computer science
The theory, experimentation, and engineering that form the basis for the design and use of computers. It involves the study of algorithms that process, store, and communicate digital information. A computer scientist specializes in the theory of computation and the design of computational systems.

computer scientist
A person who has acquired the knowledge of computer science, the study of the theoretical foundations of information and computation and their application.

computer security
Also cybersecurity or information technology security (IT security).
The protection of computer systems from theft or damage to their hardware, software, or electronic data, as well as from disruption or misdirection of the services they provide.

computer vision
An interdisciplinary scientific field that deals with how computers can be made to gain high-level understanding from digital images or videos. From the perspective of engineering, it seeks to automate tasks that the human visual system can do.

computing
Is any goal-oriented activity requiring, benefiting from, or creating computing machinery. It includes study of algorithmic processes and development of both hardware and software. It has scientific, engineering, mathematical, technological and social aspects. Major computing fields include computer engineering, computer science, cybersecurity, data science, information systems, information technology and software engineering.

concatenation
In formal language theory and computer programming, string concatenation  is the operation of joining character strings end-to-end.  For example, the concatenation of ""snow"" and ""ball"" is ""snowball"". In certain formalisations of concatenation theory, also called string theory, string concatenation is a primitive notion.

Concurrency
The ability of different parts or units of a program, algorithm, or problem to be executed out-of-order or in partial order, without affecting the final outcome.  This allows for parallel execution of the concurrent units, which can significantly improve overall speed of the execution in multi-processor and multi-core systems. In more technical terms, concurrency refers to the decomposability property of a program, algorithm, or problem into order-independent or partially-ordered components or units.

conditional
Also conditional statement, conditional expression, and conditional construct.
A feature of a programming language which performs different computations or actions depending on whether a programmer-specified Boolean condition evaluates to true or false. Apart from the case of branch predication, this is always achieved by selectively altering the control flow based on some condition.

container
Is a class, a data structure, or an abstract data type (ADT) whose instances are collections of other objects. In other words, they store objects in an organized way that follows specific access rules. The size of the container depends on the number of objects (elements) it contains. Underlying (inherited) implementations of various container types may vary in size and complexity, and provide flexibility in choosing the right implementation for any given scenario.

continuation-passing style (CPS)
A style of functional programming in which control is passed explicitly in the form of a continuation. This is contrasted with direct style, which is the usual style of programming. Gerald Jay Sussman and Guy L. Steele, Jr. coined the phrase in AI Memo 349 (1975), which sets out the first version of the Scheme programming language.

control flow
Also flow of control.
The order in which individual statements, instructions or function calls of an imperative program are executed or evaluated. The emphasis on explicit control flow distinguishes an imperative programming language from a declarative programming language.

Creative Commons (CC)
An American non-profit organization devoted to expanding the range of creative works available for others to build upon legally and to share. The organization has released several copyright-licenses, known as Creative Commons licenses, free of charge to the public.

cryptography
Or cryptology,  is the practice and study of techniques for secure communication in the presence of third parties called adversaries. More generally, cryptography is about constructing and analyzing protocols that prevent third parties or the public from reading private messages; various aspects in information security such as data confidentiality, data integrity, authentication, and non-repudiation are central to modern cryptography. Modern cryptography exists at the intersection of the disciplines of mathematics, computer science, electrical engineering, communication science, and physics. Applications of cryptography include electronic commerce, chip-based payment cards, digital currencies, computer passwords, and military communications.

CSV
See comma-separated values.

cyberbullying
Also cyberharassment or online bullying.
A form of bullying or harassment using electronic means.

cyberspace
Widespread, interconnected digital technology.


== D ==
daemon
In multitasking computer operating systems, a daemon ( or ) is a computer program that runs as a background process, rather than being under the direct control of an interactive user. Traditionally, the process names of a daemon end with the letter d, for clarification that the process is in fact a daemon, and for differentiation between a daemon and a normal computer program. For example, syslogd is a daemon that implements system logging facility, and sshd is a daemon that serves incoming SSH connections.

data center
Also data centre.
A dedicated space used to house computer systems and associated components, such as telecommunications and data storage systems. It generally includes redundant or backup components and infrastructure for power supply, data communications connections, environmental controls (e.g. air conditioning and fire suppression) and various security devices.

database
An organized collection of data, generally stored and accessed electronically from a computer system. Where databases are more complex, they are often developed using formal design and modeling techniques.

data mining
Is a process of discovering patterns in large data sets involving methods at the intersection of machine learning, statistics, and database systems. Data mining is an interdisciplinary subfield of computer science and statistics with an overall goal to extract information (with intelligent methods) from a data set and transform the information into a comprehensible structure for further use. Data mining is the analysis step of the ""knowledge discovery in databases"" process, or KDD. Aside from the raw analysis step, it also involves database and data management aspects, data pre-processing, model and inference considerations, interestingness metrics, complexity considerations, post-processing of discovered structures, visualization, and online updating. 

data science
An interdisciplinary field that uses scientific methods, processes, algorithms, and systems to extract knowledge and insights from data in various forms, both structured and unstructured, similar to data mining. Data science is a ""concept to unify statistics, data analysis, machine learning and their related methods"" in order to ""understand and analyze actual phenomena"" with data. It employs techniques and theories drawn from many fields within the context of mathematics, statistics, information science, and computer science.

data structure
A data organization, management, and storage format that enables efficient access and modification. More precisely, a data structure is a collection of data values, the relationships among them, and the functions or operations that can be applied to the data.

data type
Also simply type.
An attribute of data which tells the compiler or interpreter how the programmer intends to use the data. Most programming languages support common data types of real, integer, and Boolean. A data type constrains the values that an expression, such as a variable or a function, might take. This data type defines the operations that can be done on the data, the meaning of the data, and the way values of that type can be stored. A type of value from which an expression may take its value.

debugging
The process of finding and resolving defects or problems within a computer program that prevent correct operation of computer software or the system as a whole. Debugging tactics can involve interactive debugging, control flow analysis, unit testing, integration testing, log file analysis, monitoring at the application or system level, memory dumps, and profiling.

declaration
In computer programming, a language construct that specifies properties of an identifier: it declares what a word (identifier) ""means"". Declarations are most commonly used for functions, variables, constants, and classes, but can also be used for other entities such as enumerations and type definitions. Beyond the name (the identifier itself) and the kind of entity (function, variable, etc.), declarations typically specify the data type (for variables and constants), or the type signature (for functions); types may also include dimensions, such as for arrays. A declaration is used to announce the existence of the entity to the compiler; this is important in those strongly typed languages that require functions, variables, and constants, and their types, to be specified with a declaration before use, and is used in forward declaration. The term ""declaration"" is frequently contrasted with the term ""definition"", but meaning and usage varies significantly between languages.

digital data
In information theory and information systems, the discrete, discontinuous representation of information or works. Numbers and letters are commonly used representations.

digital signal processing (DSP)
The use of digital processing, such as by computers or more specialized digital signal processors, to perform a wide variety of signal processing operations.  The signals processed in this manner are a sequence of numbers that represent samples of a continuous variable in a domain such as time, space, or frequency.

discrete event simulation (DES)
A model of the operation of a system as a discrete sequence of events in time. Each event occurs at a particular instant in time and marks a change of state in the system. Between consecutive events, no change in the system is assumed to occur; thus the simulation can directly jump in time from one event to the next.

disk storage
(Also sometimes called drive storage) is a general category of storage mechanisms where data is recorded by various electronic, magnetic, optical, or mechanical changes to a surface layer of one or more rotating disks. A disk drive is a device implementing such a storage mechanism. Notable types are the hard disk drive (HDD) containing a non-removable disk, the  floppy disk drive (FDD) and its removable floppy disk, and various optical disc drives (ODD) and associated optical disc media.

distributed computing
A field of computer science that studies distributed systems. A distributed system is a system whose components are located on different networked computers, which communicate and coordinate their actions by passing messages to one another. The components interact with one another in order to achieve a common goal. Three significant characteristics of distributed systems are: concurrency of components, lack of a global clock, and independent failure of components. Examples of distributed systems vary from SOA-based systems to massively multiplayer online games to peer-to-peer applications.

divide and conquer algorithm
An algorithm design paradigm based on multi-branched recursion. A divide-and-conquer algorithm works by recursively breaking down a problem into two or more sub-problems of the same or related type, until these become simple enough to be solved directly. The solutions to the sub-problems are then combined to give a solution to the original problem.

DNS
See Domain Name System.

documentation
Written text or illustration that accompanies computer software or is embedded in the source code. It either explains how it operates or how to use it, and may mean different things to people in different roles.

domain
Is the targeted subject area of a computer program. It is a term used in software engineering. Formally it represents the target subject of a specific programming project, whether narrowly or broadly defined.

Domain Name System (DNS)
A hierarchical and decentralized naming system for computers, services, or other resources connected to the Internet or to a private network. It associates various information with domain names assigned to each of the participating entities. Most prominently, it translates more readily memorized domain names to the numerical IP addresses needed for locating and identifying computer services and devices with the underlying network protocols. By providing a worldwide, distributed directory service, the Domain Name System has been an essential component of the functionality of the Internet since 1985.

double-precision floating-point format
A computer number format. It represents a wide dynamic range of numerical values by using a floating radix point.

download
In computer networks, to receive data from a remote system, typically a server such as a web server, an FTP server, an email server, or other similar systems. This contrasts with uploading, where data is sent to a remote server. A download is a file offered for downloading or that has been downloaded, or the process of receiving such a file.


== E ==
edge device
A device which provides an entry point into enterprise or service provider core networks. Examples include routers, routing switches, integrated access devices (IADs), multiplexers, and a variety of metropolitan area network (MAN) and wide area network (WAN) access devices.  Edge devices also provide connections into carrier and service provider networks. An edge device that connects a local area network to a high speed switch or backbone (such as an ATM switch) may be called an edge concentrator.

encryption
In cryptography, encryption is the process of encoding information. This process converts the original representation of the information, known as plaintext, into an alternative form known as ciphertext. Ideally, only authorized parties can decipher a ciphertext back to plaintext and access the original information. Encryption does not itself prevent interference but denies the intelligible content to a would-be interceptor. For technical reasons, an encryption scheme usually uses a pseudo-random encryption key generated by an algorithm. It is possible to decrypt the message without possessing the key, but, for a well-designed encryption scheme, considerable computational resources and skills are required. An authorized recipient can easily decrypt the message with the key provided by the originator to recipients but not to unauthorized users. Historically, various forms of encryption have been used to aid in cryptography. Early encryption techniques were often utilized in military messaging. Since then, new techniques have emerged and become commonplace in all areas of modern computing. Modern encryption schemes utilize the concepts of public-key and symmetric-key. Modern encryption techniques ensure security because modern computers are inefficient at cracking the encryption.

event
An action or occurrence recognized by software, often originating asynchronously from the external environment, that may be handled by the software. Because an event is an entity which encapsulates the action and the contextual variables triggering the action, the acrostic mnemonic ""Execution Variable Encapsulating Named Trigger"" is often used to clarify the concept.

event-driven programming
A programming paradigm in which the flow of the program is determined by events such as user actions (mouse clicks, key presses), sensor outputs, or messages from other programs or threads. Event-driven programming is the dominant paradigm used in graphical user interfaces and other applications (e.g. JavaScript web applications) that are centered on performing certain actions in response to user input. This is also true of programming for device drivers (e.g. P in USB device driver stacks).

evolutionary computing
A family of algorithms for global optimization inspired by biological evolution, and the subfield of artificial intelligence and soft computing studying these algorithms. In technical terms, they are a family of population-based trial-and-error problem-solvers with a metaheuristic or stochastic optimization character.

executable
Also executable code, executable file, executable program, or simply executable.
Causes a computer ""to perform indicated tasks according to encoded instructions,"" as opposed to a data file that must be parsed by a program to be meaningful. The exact interpretation depends upon the use - while ""instructions"" is traditionally taken to mean machine code instructions for a physical CPU, in some contexts a file containing bytecode or scripting language instructions may also be considered executable.

executable module

execution
In computer and software engineering is the process by which a computer or  virtual machine executes the instructions of a computer program. Each instruction of a program is a description of a particular 
action which to be carried out in order for a specific problem to be solved; as instructions of a program and therefore the actions they describe are being carried out by an executing machine, specific effects are produced in accordance to the semantics of the instructions being executed. 

exception handling
The process of responding to the occurrence, during computation, of exceptions – anomalous or exceptional conditions requiring special processing – often disrupting the normal flow of program execution. It is provided by specialized programming language constructs, computer hardware mechanisms like interrupts, or operating system IPC facilities like signals.

Existence detection
An existence check before reading a file can catch and/or prevent a fatal error.

expression
In a programming language, a combination of one or more constants, variables, operators, and functions that the programming language interprets (according to its particular rules of precedence and of association) and computes to produce (""to return"", in a stateful environment) another value. This process, as for mathematical expressions, is called evaluation.

external library


== F ==
fault-tolerant computer system
A system designed around the concept of fault tolerance. In essence, they must be able to continue working to a level of satisfaction in the presence of errors or breakdowns.

feasibility study
An investigation which aims to objectively and rationally uncover the strengths and weaknesses of an existing business or proposed venture, opportunities and threats present in the natural environment, the resources required to carry through, and ultimately the prospects for success. In its simplest terms, the two criteria to judge feasibility are cost required and value to be attained.

field
Data that has several parts, known as a record, can be divided into fields. Relational databases arrange data as sets of database records, so called rows. Each record consists of several fields; the fields of all records form the columns.
Examples of fields: name, gender, hair colour. 

filename extension
An identifier specified as a suffix to the name of a computer file. The extension indicates a characteristic of the file contents or its intended use.

filter (software)
A computer program or subroutine to process a stream, producing another stream. While a single filter can be used individually, they are frequently strung together to form a pipeline.

floating point arithmetic
In computing, floating-point arithmetic (FP) is arithmetic using formulaic representation of real numbers as an approximation to support a trade-off between range and precision. For this reason, floating-point computation is often found in systems which include very small and very large real numbers, which require fast processing times. A number is, in general, represented approximately to a fixed number of significant digits (the significand) and scaled using an exponent in some fixed base; the base for the scaling is normally two, ten, or sixteen. A number that can be represented exactly is of the following form:

  
    
      
        
          significand
        
        ×
        
          
            base
          
          
            exponent
          
        
        ,
      
    
    {\displaystyle {\text{significand}}\times {\text{base}}^{\text{exponent}},}
  
where significand is an integer, base is an integer greater than or equal to two, and exponent is also an integer.
For example:

  
    
      
        1.2345
        =
        
          
            
              12345
              ⏟
            
          
          
            significand
          
        
        ×
        
          
            
              10
              ⏟
            
          
          
            base
          
        
        
        
        
        
        
        
          
          
            
              
                
                  
                    −
                    4
                  
                  ⏞
                
              
              
                exponent
              
            
          
        
        .
      
    
    {\displaystyle 1.2345=\underbrace {12345} _{\text{significand}}\times \underbrace {10} _{\text{base}}\!\!\!\!\!\!^{\overbrace {-4} ^{\text{exponent}}}.}
  for loop
Also for-loop. 
A control flow statement for specifying iteration, which allows code to be executed repeatedly. Various keywords are used to specify this statement: descendants of ALGOL use ""for"", while descendants of Fortran use ""do"". There are also other possibilities, e.g. COBOL uses ""PERFORM VARYING"".

formal methods
A set of mathematically based techniques for the specification, development, and verification of software and hardware systems. The use of formal methods for software and hardware design is motivated by the expectation that, as in other engineering disciplines, performing appropriate mathematical analysis can contribute to the reliability and robustness of a design.

formal verification
The act of proving or disproving the correctness of intended algorithms underlying a system with respect to a certain formal specification or property, using formal methods of mathematics.

functional programming
A programming paradigm—a style of building the structure and elements of computer programs–that treats computation as the evaluation of mathematical functions and avoids changing-state and mutable data. It is a declarative programming paradigm in that programming is done with expressions or declarations instead of statements.


== G ==
game theory
The study of mathematical models of strategic interaction between rational decision-makers. It has applications in all fields of social science, as well as in logic and computer science. Originally, it addressed zero-sum games, in which each participant's gains or losses are exactly balanced by those of the other participants. Today, game theory applies to a wide range of behavioral relations, and is now an umbrella term for the science of logical decision making in humans, animals, and computers.

garbage in, garbage out (GIGO)
A term used to describe the concept that flawed or nonsense input data produces nonsense output or ""garbage"". It can also refer to the unforgiving nature of programming, in which a poorly written program might produce nonsensical behavior.

Graphics Interchange Format

gigabyte
A multiple of the unit byte for digital information. The prefix giga means 109 in the International System of Units (SI). Therefore, one gigabyte is 1000000000bytes.  The unit symbol for the gigabyte is GB.

global variable
In computer programming, a variable with global scope, meaning that it is visible (hence accessible) throughout the program, unless shadowed. The set of all global variables is known as the global environment or global state. In compiled languages, global variables are generally static variables, whose extent (lifetime) is the entire runtime of the program, though in interpreted languages (including command-line interpreters), global variables are generally dynamically allocated when declared, since they are not known ahead of time.

graph theory
In mathematics, the study of graphs, which are mathematical structures used to model pairwise relations between objects. A graph in this context is made up of vertices (also called nodes or points) which are connected by edges (also called links or lines). A distinction is made between undirected graphs, where edges link two vertices symmetrically, and directed graphs, where edges link two vertices asymmetrically.


== H ==
handle
In computer programming, a handle is an abstract reference to a resource that is used when application software references blocks of memory or objects that are managed by another system like a database or an operating system.

hard problem
Computational complexity theory focuses on classifying computational problems according to their inherent difficulty, and relating these classes to each other. A computational problem is a task solved by a computer. A computation problem is solvable by mechanical application of mathematical steps, such as an algorithm.

hash function
Any function that can be used to map data of arbitrary size to data of a fixed size. The values returned by a hash function are called hash values, hash codes, digests, or simply hashes. Hash functions are often used in combination with a hash table, a common data structure used in computer software for rapid data lookup. Hash functions accelerate table or database lookup by detecting duplicated records in a large file.

hash table
In computing, a hash table (hash map) is a data structure that implements an associative array abstract data type, a structure that can map keys to values. A hash table uses a hash function to compute an index into an array of buckets or slots, from which the desired value can be found.

heap
A specialized tree-based data structure which is essentially an almost complete tree that satisfies the heap property: if P is a parent node of C, then the key (the value) of P is either greater than or equal to (in a max heap) or less than or equal to (in a min heap) the key of C. The node at the ""top"" of the heap (with no parents) is called the root node.

heapsort
A comparison-based sorting algorithm. Heapsort can be thought of as an improved selection sort: like that algorithm, it divides its input into a sorted and an unsorted region, and it iteratively shrinks the unsorted region by extracting the largest element and moving that to the sorted region. The improvement consists of the use of a heap data structure rather than a linear-time search to find the maximum.

human-computer interaction (HCI)
Researches the design and use of computer technology, focused on the interfaces between people (users) and computers. Researchers in the field of HCI both observe the ways in which humans interact with computers and design technologies that let humans interact with computers in novel ways. As a field of research, human–computer interaction is situated at the intersection of computer science, behavioral sciences, design, media studies, and several other fields of study.


== I ==
identifier
In computer languages, identifiers are tokens (also called symbols) which name language entities. Some of the kinds of entities an identifier might denote include variables, types, labels, subroutines,  and packages.

IDE
Integrated development environment.

image processing

imperative programming
A programming paradigm that uses statements that change a program's state. In much the same way that the imperative mood in natural languages expresses commands, an imperative program consists of commands for the computer to perform. Imperative programming focuses on describing how a program operates.

incremental build model
A method of software development where the product is designed, implemented and tested incrementally (a little more is added each time) until the product is finished. It involves both development and maintenance. The product is defined as finished when it satisfies all of its requirements. This model combines the elements of the waterfall model with the iterative philosophy of prototyping.

information space analysis
A deterministic method, enhanced by machine intelligence, for locating and assessing resources for team-centric efforts.

information visualization

inheritance
In object-oriented programming, the mechanism of basing an object or class upon another object (prototype-based inheritance) or class (class-based inheritance), retaining similar implementation. Also defined as deriving new classes (sub classes) from existing ones (super class or base class) and forming them into a hierarchy of classes.

input/output (I/O)
Also informally io or IO. 
The communication between an information processing system, such as a computer, and the outside world, possibly a human or another information processing system. Inputs are the signals or data received by the system and outputs are the signals or data sent from it. The term can also be used as part of an action; to ""perform I/O"" is to perform an input or output operation.

insertion sort
A simple sorting algorithm that builds the final sorted array (or list) one item at a time.

instruction cycle
Also fetch–decode–execute cycle or simply fetch-execute cycle.
The cycle which the central processing unit (CPU) follows from boot-up until the computer has shut down in order to process instructions. It is composed of three main stages: the fetch stage, the decode stage, and the execute stage.

integer
A datum of integral data type, a data type that represents some range of mathematical integers. Integral data types may be of different sizes and may or may not be allowed to contain negative values. Integers are commonly represented in a computer as a group of binary digits (bits). The size of the grouping varies so the set of integer sizes available varies between different types of computers. Computer hardware, including virtual machines, nearly always provide a way to represent a processor register or memory address as an integer.

integrated development environment (IDE)
A software application that provides comprehensive facilities to computer programmers for software development. An IDE normally consists of at least a source code editor, build automation tools, and a debugger.

integration testing
(sometimes called integration and testing, abbreviated I&T) is the phase in software testing in which individual software modules are combined and tested as a group. Integration testing is conducted to evaluate the compliance of a system or component with specified functional requirements. It occurs after unit testing and before validation testing. Integration testing takes as its input modules that have been unit tested, groups them in larger aggregates, applies tests defined in an integration test plan to those aggregates, and delivers as its output the integrated system ready for system testing.

intellectual property (IP)
A category of legal property that includes intangible creations of the human intellect. There are many types of intellectual property, and some countries recognize more than others. The most well-known types are copyrights, patents, trademarks, and trade secrets.

intelligent agent
In artificial intelligence, an intelligent agent (IA) refers to an autonomous entity which acts, directing its activity towards achieving goals (i.e. it is an agent), upon an environment using observation through sensors and consequent actuators (i.e. it is intelligent). Intelligent agents may also learn or use knowledge to achieve their goals. They may be very simple or very complex. A reflex machine, such as a thermostat, is considered an example of an intelligent agent.

interface
A shared boundary across which two or more separate components of a computer system exchange information. The exchange can be between software, computer hardware, peripheral devices, humans, and combinations of these. Some computer hardware devices, such as a touchscreen, can both send and receive data through the interface, while others such as a mouse or microphone may only provide an interface to send data to a given system.

internal documentation
Computer software is said to have Internal Documentation if the notes on how and why various parts of code operate is included within the source code as comments.  It is often combined with meaningful variable names with the intention of providing potential future programmers a means of understanding the workings of the code. This contrasts with external documentation, where programmers keep their notes and explanations in a separate document.

internet
The global system of interconnected computer networks that use the Internet protocol suite (TCP/IP) to link devices worldwide. It is a network of networks that consists of private, public, academic, business, and government networks of local to global scope, linked by a broad array of electronic, wireless, and optical networking technologies.

internet bot
Also web robot, robot, or simply bot.
A software application that runs automated tasks (scripts) over the Internet. Typically, bots perform tasks that are both simple and structurally repetitive, at a much higher rate than would be possible for a human alone. The largest use of bots is in web spidering (web crawler), in which an automated script fetches, analyzes and files information from web servers at many times the speed of a human.

interpreter
A computer program that directly executes instructions written in a programming or scripting language, without requiring them to have been previously compiled into a machine language program.

invariant
One can encounter invariants that can be relied upon to be true during the execution of a program, or during some portion of it. It is a logical assertion that is always held to be true during a certain phase of execution. For example, a loop invariant is a condition that is true at the beginning and the end of every execution of a loop.

iteration
Is the repetition of a process in order to generate an outcome. The sequence will approach some end point or end value. Each repetition of the process is a single iteration, and the outcome of each iteration is then the starting point of the next iteration.  In mathematics and computer science, iteration (along with the related technique of recursion) is a standard element of algorithms.


== J ==
Java
A general-purpose programming language that is class-based, object-oriented(although not a pure OO language), and designed to have as few implementation dependencies as possible. It is intended to let application developers ""write once, run anywhere"" (WORA), meaning that compiled Java code can run on all platforms that support Java without the need for recompilation.


== K ==
kernel
The first section of an operating system to load into memory. As the center of the operating system, the kernel needs to be small, efficient, and loaded into a protected area in the memory so that it cannot be overwritten. It may be responsible for such essential tasks as disk drive management, file management, memory management, process management, etc.


== L ==
library (computing)
A collection of non-volatile resources used by computer programs, often for software development. These may include configuration data, documentation, help data, message templates, pre-written code and subroutines, classes, values, or type specifications.

linear search
Also sequential search.
A method for finding an element within a list. It sequentially checks each element of the list until a match is found or the whole list has been searched.

linked list
A linear collection of data elements, whose order is not given by their physical placement in memory. Instead, each element points to the next. It is a data structure consisting of a collection of nodes which together represent a sequence.

linker
 or link editor, is a computer utility program that takes one or more object files generated by a compiler or an assembler and combines them into a single executable file, library file, or another 'object' file.  A simpler version that writes its output directly to memory is called the loader, though loading is typically considered a separate process.

list
An abstract data type that represents a countable number of ordered values, where the same value may occur more than once. An instance of a list is a computer representation of the mathematical concept of a finite sequence; the (potentially) infinite analog of a list is a stream.: §3.5  Lists are a basic example of containers, as they contain other values. If the same value occurs multiple times, each occurrence is considered a distinct item.

loader
The part of an operating system that is responsible for loading programs and libraries. It is one of the essential stages in the process of starting a program, as it places programs into memory and prepares them for execution. Loading a program involves reading the contents of the executable file containing the program instructions into memory, and then carrying out other required preparatory tasks to prepare the executable for running. Once loading is complete, the operating system starts the program by passing control to the loaded program code.

logic error
In computer programming, a bug in a program that causes it to operate incorrectly, but not to terminate abnormally (or crash). A logic error produces unintended or undesired output or other behaviour, although it may not immediately be recognized as such.

logic programming
A type of programming paradigm which is largely based on formal logic. Any program written in a logic programming language is a set of sentences in logical form, expressing facts and rules about some problem domain.  Major logic programming language families include Prolog, answer set programming (ASP), and Datalog.


== M ==
machine learning (ML)
The scientific study of algorithms and statistical models that computer systems use to perform a specific task without using explicit instructions, relying on patterns and inference instead. It is seen as a subset of artificial intelligence. Machine learning algorithms build a mathematical model based on sample data, known as ""training data"", in order to make predictions or decisions without being explicitly programmed to perform the task.

machine vision (MV)
The technology and methods used to provide imaging-based automatic inspection and analysis for such applications as automatic inspection, process control, and robot guidance, usually in industry. Machine vision refers to many technologies, software and hardware products, integrated systems, actions, methods and expertise. Machine vision as a systems engineering discipline can be considered distinct from computer vision, a form of computer science. It attempts to integrate existing technologies in new ways and apply them to solve real world problems. The term is the prevalent one for these functions in industrial automation environments but is also used for these functions in other environments such as security and vehicle guidance.

mathematical logic
A subfield of mathematics exploring the applications of formal logic to mathematics.  It bears close connections to metamathematics, the foundations of mathematics, and theoretical computer science. The unifying themes in mathematical logic include the study of the expressive power of formal systems and the deductive power of formal proof systems.

matrix
In mathematics, a matrix, (plural matrices), is a rectangular array (see irregular matrix) of numbers, symbols, or expressions, arranged in rows and columns.

memory
Computer data storage, often called storage, is a technology consisting of computer components and recording media that are used to retain digital data. It is a core function and fundamental component of computers.: 15–16 

merge sort
Also mergesort.
An efficient, general-purpose, comparison-based sorting algorithm. Most implementations produce a stable sort, which means that the order of equal elements is the same in the input and output. Merge sort is a divide and conquer algorithm that was invented by John von Neumann in 1945. A detailed description and analysis of bottom-up mergesort appeared in a report by Goldstine and von Neumann as early as 1948.

method
In object-oriented programming (OOP), a procedure associated with a message and an object. An object consists of data and behavior. The data and behavior comprise an interface, which specifies how the object may be utilized by any of various consumers of the object.

methodology
In software engineering, a software development process is the process of dividing software development work into distinct phases to improve design, product management, and project management. It is also known as a software development life cycle (SDLC). The methodology may include the pre-definition of specific deliverables and artifacts that are created and completed by a project team to develop or maintain an application.

modem
Portmanteau of modulator-demodulator.
A hardware device that converts data into a format suitable for a transmission medium so that it can be transmitted from one computer to another (historically along telephone wires). A modem modulates one or more carrier wave signals to encode digital information for transmission and demodulates signals to decode the transmitted information. The goal is to produce a signal that can be transmitted easily and decoded reliably to reproduce the original digital data. Modems can be used with almost any means of transmitting analog signals from light-emitting diodes to radio. A common type of modem is one that turns the digital data of a computer into modulated electrical signal for transmission over telephone lines and demodulated by another modem at the receiver side to recover the digital data.


== N ==
natural language processing (NLP)
A subfield of linguistics, computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data.  Challenges in natural language processing frequently involve speech recognition, natural language understanding, and natural language generation.

node
Is a basic unit of a data structure, such as a linked list or tree data structure. Nodes contain data and also may link to other nodes. Links between nodes are often implemented by pointers.

number theory
A branch of pure mathematics devoted primarily to the study of the integers and integer-valued functions.

numerical analysis
The study of algorithms that use numerical approximation (as opposed to symbolic manipulations) for the problems of mathematical analysis (as distinguished from discrete mathematics).

numerical method
In numerical analysis, a numerical method is a mathematical tool designed to solve numerical problems. The implementation of a numerical method with an appropriate convergence check in a programming language is called a numerical algorithm.


== O ==
object
An object can be a variable, a data structure, a function, or a method, and as such, is a value in memory referenced by an identifier.  In the class-based object-oriented programming paradigm, object refers to a particular instance of a class, where the object can be a combination of variables, functions, and data structures.  In relational database management, an object can be a table or column, or an association between data and a database entity (such as relating a person's age to a specific person).

object code
Also object module.
The product of a compiler. In a general sense object code is a sequence of statements or instructions in a computer language, usually a machine code language (i.e., binary) or an intermediate language such as register transfer language (RTL). The term indicates that the code is the goal or result of the compiling process, with some early sources referring to source code as a ""subject program.""

object-oriented analysis and design (OOAD)
A technical approach for analyzing and designing an application, system, or business by applying object-oriented programming, as well as using visual modeling throughout the software development process to guide stakeholder communication and product quality.

object-oriented programming (OOP)
A programming paradigm based on the concept of ""objects"", which can contain data, in the form of fields (often known as attributes or properties), and code, in the form of procedures (often known as methods). A feature of objects is an object's procedures that can access and often modify the data fields of the object with which they are associated (objects have a notion of ""this"" or ""self""). In OOP, computer programs are designed by making them out of objects that interact with one another. OOP languages are diverse, but the most popular ones are class-based, meaning that objects are instances of classes, which also determine their types.

open-source software (OSS)
A type of computer software in which source code is released under a license in which the copyright holder grants users the rights to study, change, and distribute the software to anyone and for any purpose. Open-source software may be developed in a collaborative public manner. Open-source software is a prominent example of open collaboration.

operating system (OS)
System software that manages computer hardware, software resources, and provides common services for computer programs.

optical fiber
A flexible, transparent fiber made by drawing glass (silica) or plastic to a diameter slightly thicker than that of a human hair. Optical fibers are used most often as a means to transmit light between the two ends of the fiber and find wide usage in fiber-optic communications, where they permit transmission over longer distances and at higher bandwidths (data rates) than electrical cables. Fibers are used instead of metal wires because signals travel along them with less loss; in addition, fibers are immune to electromagnetic interference, a problem from which metal wires suffer.


== P ==
pair programming
An agile software development technique in which two programmers work together at one workstation. One, the driver, writes code while the other, the observer or navigator, reviews each line of code as it is typed in. The two programmers switch roles frequently.

parallel computing
A type of computation in which many calculations or the execution of processes are carried out simultaneously. Large problems can often be divided into smaller ones, which can then be solved at the same time. There are several different forms of parallel computing: bit-level, instruction-level, data, and task parallelism.

parameter
Also formal argument.
In computer programming, a special kind of variable, used in a subroutine to refer to one of the pieces of data provided as input to the subroutine. These pieces of data are the values of the arguments (often called actual arguments or actual parameters) with which the subroutine is going to be called/invoked. An ordered list of parameters is usually included in the definition of a subroutine, so that, each time the subroutine is called, its arguments for that call are evaluated, and the resulting values can be assigned to the corresponding parameters.

peripheral
Any auxiliary or ancillary device connected to or integrated within a computer system and used to send information to or retrieve information from the computer. An input device sends data or instructions to the computer; an output device provides output from the computer to the user; and an input/output device performs both functions.

pointer
Is an object in many programming languages that stores a memory address. This can be that of another value located in computer memory, or in some cases, that of memory-mapped computer hardware. A pointer references a location in memory, and obtaining the value stored at that location is known as dereferencing the pointer. As an analogy, a page number in a book's index could be considered a pointer to the corresponding page; dereferencing such a pointer would be done by flipping to the page with the given page number and reading the text found on that page. The actual format and content of a pointer variable is dependent on the underlying computer architecture.

postcondition
In computer programming, a condition or predicate that must always be true just after the execution of some section of code or after an operation in a formal specification. Postconditions are sometimes tested using assertions within the code itself. Often, postconditions are simply included in the documentation of the affected section of code.

precondition
In computer programming, a condition or predicate that must always be true just prior to the execution of some section of code or before an operation in a formal specification.  If a precondition is violated, the effect of the section of code becomes undefined and thus may or may not carry out its intended work.  Security problems can arise due to incorrect preconditions.

primary storage
(Also known as main memory, internal memory or prime memory), often referred to simply as memory, is the only one directly accessible to the CPU. The CPU continuously reads instructions stored there and executes them as required. Any data actively operated on is also stored there in uniform manner.

primitive data type

priority queue
An abstract data type which is like a regular queue or stack data structure, but where additionally each element has a ""priority"" associated with it. In a priority queue, an element with high priority is served before an element with low priority. In some implementations, if two elements have the same priority, they are served according to the order in which they were enqueued, while in other implementations, ordering of elements with the same priority is undefined.

procedural programming

procedure
In computer programming, a subroutine is a sequence of program instructions that performs a specific task, packaged as a unit. This unit can then be used in programs wherever that particular task should be performed.  Subroutines may be defined within programs, or separately in libraries that can be used by many programs.  In different programming languages, a subroutine may be called a routine, subprogram, function, method, or procedure. Technically, these terms all have different definitions. The generic, umbrella term  callable unit is sometimes used.

program lifecycle phase
Program lifecycle phases are the stages a computer program undergoes, from initial creation to deployment and execution. The phases are edit time, compile time, link time, distribution time, installation time, load time, and run time.

programming language
A formal language, which comprises a set of instructions that produce various kinds of output. Programming languages are used in computer programming to implement algorithms.

programming language implementation
Is a system for executing computer programs. There are two general approaches to programming language implementation: interpretation and compilation.

programming language theory
(PLT) is a branch of computer science that deals with the design, implementation, analysis, characterization, and classification of programming languages and of their individual features.  It falls within the discipline of computer science, both depending on and affecting mathematics, software engineering, linguistics and even cognitive science.  It has become a well-recognized branch of computer science, and an active research area, with results published in numerous journals dedicated to PLT, as well as in general computer science and engineering publications.

Prolog
Is a logic programming language associated with artificial intelligence and computational linguistics.  Prolog has its roots in first-order logic, a formal logic, and unlike many other programming languages, Prolog is intended primarily as a declarative programming language: the program logic is expressed in terms of relations, represented as facts and rules.  A computation is initiated by running a query over these relations.

Python
Is an interpreted, high-level and general-purpose programming language. Created by Guido van Rossum and first released in 1991, Python's design philosophy emphasizes code readability with its notable use of significant whitespace. Its language constructs and object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects.


== Q ==
quantum computing
The use of quantum-mechanical phenomena such as superposition and entanglement to perform computation. A quantum computer is used to perform such computation, which can be implemented theoretically or physically.: I-5 

queue
A collection in which the entities in the collection are kept in order and the principal (or only) operations on the collection are the addition of entities to the rear terminal position, known as enqueue, and removal of entities from the front terminal position, known as dequeue.

quicksort
Also partition-exchange sort.
An efficient sorting algorithm which serves as a systematic method for placing the elements of a random access file or an array in order.


== R ==
R programming language
R is a programming language and free software environment for statistical computing and graphics supported by the R Foundation for Statistical Computing. The R language is widely used among statisticians and data miners for developing statistical software and data analysis.

radix
Also base.
In digital numeral systems, the number of unique digits, including the digit zero, used to represent numbers in a positional numeral system. For example, in the decimal/denary system (the most common system in use today) the radix (base number) is ten, because it uses the ten digits from 0 through 9, and all other numbers are uniquely specified by positional combinations of these ten base digits; in the binary system that is the standard in computing, the radix is two, because it uses only two digits, 0 and 1, to uniquely specify each number.

record
A record (also called a structure,  struct, or compound data) is a basic data structure. Records in a database or spreadsheet are usually called ""rows"".

recursion
Occurs when a thing is defined in terms of itself or of its type. Recursion is used in a variety of disciplines ranging from linguistics to logic. The most common application of recursion is in mathematics and computer science, where a function being defined is applied within its own definition. While this apparently defines an infinite number of instances (function values), it is often done in such a way that no infinite loop or infinite chain of references can occur.

reference
Is a value that enables a program to indirectly access a particular datum, such as a variable's value or a record, in the computer's memory or in some other storage device.  The reference is said to refer to the datum, and accessing the datum is called dereferencing the reference.

reference counting
A programming technique of storing the number of references, pointers, or handles to a resource, such as an object, a block of memory, disk space, and others. In garbage collection algorithms, reference counts may be used to deallocate objects which are no longer needed.

relational database
Is a digital database based on the relational model of data, as proposed by E. F. Codd in 1970.
A software system used to maintain relational databases is a relational database management system (RDBMS). Many relational database systems have an option of using the SQL (Structured Query Language) for querying and maintaining the database.

reliability engineering
A sub-discipline of systems engineering that emphasizes dependability in the lifecycle management of a product. Reliability describes the ability of a system or component to function under stated conditions for a specified period of time. Reliability is closely related to availability, which is typically described as the ability of a component or system to function at a specified moment or interval of time.

regression testing
(rarely non-regression testing) is re-running functional and non-functional tests to ensure that previously developed and tested software still performs after a change. If not, that would be called a regression. Changes that may require regression testing include bug fixes, software enhancements, configuration changes, and even substitution of electronic components. As regression test suites tend to grow with each found defect, test automation is frequently involved. Sometimes a change impact analysis is performed to determine an appropriate subset of tests (non-regression analysis).

requirements analysis
In systems engineering and software engineering, requirements analysis focuses on the tasks that determine the needs or conditions to meet the new or altered product or project, taking account of the possibly conflicting requirements of the various stakeholders, analyzing, documenting, validating and managing software or system requirements.

robotics
An interdisciplinary branch of engineering and science that includes mechanical engineering, electronic engineering, information engineering, computer science, and others. Robotics involves design, construction, operation, and use of robots, as well as computer systems for their perception, control, sensory feedback, and information processing. The goal of robotics is to design intelligent machines that can help and assist humans in their day-to-day lives and keep everyone safe.

round-off error
Also rounding error.
The difference between the result produced by a given algorithm using exact arithmetic and the result produced by the same algorithm using finite-precision, rounded arithmetic. Rounding errors are due to inexactness in the representation of real numbers and the arithmetic operations done with them. This is a form of quantization error. When using approximation equations or algorithms, especially when using finitely many digits to represent real numbers (which in theory have infinitely many digits), one of the goals of numerical analysis is to estimate computation errors. Computation errors, also called numerical errors, include both truncation errors and roundoff errors.

router
A networking device that forwards data packets between computer networks. Routers perform the traffic directing functions on the Internet.  Data sent through the internet, such as a web page or email, is in the form of data packets.   A packet is typically forwarded from one router to another router through the networks that constitute an internetwork (e.g. the Internet) until it reaches its destination node.

routing table
In computer networking a routing table, or routing information base (RIB), is a data table stored in a router or a network host that lists the routes to particular network destinations, and in some cases, metrics (distances) associated with those routes. The routing table contains information about the topology of the network immediately around it.

run time
Runtime, run time, or execution time is the final phase of a computer program's life cycle, in which the code is being executed on the computer's central processing unit (CPU) as machine code. In other words, ""runtime"" is the running phase of a program.

run time error
A runtime error is detected after or during the execution (running state) of a program, whereas a compile-time error is detected by the compiler before the program is ever executed. Type checking, register allocation, code generation, and code optimization are typically done at compile time, but may be done at runtime depending on the particular language and compiler. Many other runtime errors exist and are handled differently by different programming languages, such as division by zero errors, domain errors, array subscript out of bounds errors, arithmetic underflow errors, several types of underflow and overflow errors, and many other runtime errors generally considered as software bugs which may or may not be caught and handled by any particular computer language.


== S ==
search algorithm
Any algorithm which solves the search problem, namely, to retrieve information stored within some data structure, or calculated in the search space of a problem domain, either with discrete or continuous values.

secondary storage
Also known as external memory or auxiliary storage, differs from primary storage in that it is not directly accessible by the CPU. The computer usually uses its input/output channels to access secondary storage and transfer the desired data to primary storage. Secondary storage is non-volatile (retaining data when power is shut off). Modern computer systems typically have two orders of magnitude more secondary storage than primary storage because secondary storage is less expensive.

selection sort
Is an in-place comparison sorting algorithm. It has an O(n2) time complexity, which makes it inefficient on large lists, and generally performs worse than the similar insertion sort. Selection sort is noted for its simplicity and has performance advantages over more complicated algorithms in certain situations, particularly where auxiliary memory is limited.

semantics
In programming language theory, semantics is the field concerned with the rigorous mathematical study of the meaning of programming languages. It does so by evaluating the meaning of syntactically valid strings defined by a specific programming language, showing the computation involved. In such a case that the evaluation would be of syntactically invalid strings, the result would be non-computation. Semantics describes the processes a computer follows when executing a program in that specific language. This can be shown by describing the relationship between the input and output of a program, or an explanation of how the program will be executed on a certain platform, hence creating a model of computation.

sequence
In mathematics, a sequence is an enumerated collection of objects in which repetitions are allowed and order does matter.  Like a set, it contains members (also called elements, or terms).  The number of elements (possibly infinite) is called the length of the sequence.  Unlike a set, the same elements can appear multiple times at different positions in a sequence, and order does matter.  Formally, a sequence can be defined as a function whose domain is either the set of the natural numbers (for infinite sequences) or the set of the first n natural numbers (for a sequence of finite length n).

The position of an element in a sequence is its rank or index; it is the natural number for which the element is the image. The first element has index 0 or 1, depending on the context or a specific convention.  When a symbol is used to denote a sequence, the nth element of the sequence is denoted by this symbol with n as subscript; for example, the nth element of the Fibonacci sequence F is generally denoted Fn.

For example, (M, A, R, Y) is a sequence of letters with the letter 'M' first and 'Y' last.  This sequence differs from (A, R, M, Y).  Also, the sequence (1, 1, 2, 3, 5, 8), which contains the number 1 at two different positions, is a valid sequence.  Sequences can be finite, as in these examples, or infinite, such as the sequence of all even positive integers (2, 4, 6, ...).  In computing and computer science, finite sequences are sometimes called strings, words or lists, the different names commonly corresponding to different ways to represent them in computer memory; infinite sequences are called streams.  The empty sequence ( ) is included in most notions of sequence, but may be excluded depending on the context.

serializability
In concurrency control of databases, transaction processing (transaction management), and various transactional applications (e.g., transactional memory and software transactional memory), both centralized and distributed, a transaction schedule is serializable if its outcome (e.g., the resulting database state) is equal to the outcome of its transactions executed serially, i.e. without overlapping in time. Transactions are normally executed concurrently (they overlap), since this is the most efficient way. Serializability is the major correctness criterion for concurrent transactions' executions. It is considered the highest level of isolation between transactions, and plays an essential role in concurrency control. As such it is supported in all general purpose database systems. Strong strict two-phase locking (SS2PL) is a popular serializability mechanism utilized in most of the database systems (in various variants) since their early days in the 1970s.

serialization
Is the process of translating data structures or object state into a format that can be stored (for example, in a file or memory buffer) or transmitted (for example, across a network connection link) and reconstructed later (possibly in a different computer environment). When the resulting series of bits is reread according to the serialization format, it can be used to create a semantically identical clone of the original object. For many complex objects, such as those that make extensive use of references, this process is not straightforward. Serialization of object-oriented objects does not include any of their associated methods with which they were previously linked.

This process of serializing an object is also called marshalling an object in some situations.[2][3] The opposite operation, extracting a data structure from a series of bytes, is deserialization, (also called unserialization or unmarshalling).

service level agreement
(SLA), is a commitment between a service provider and a client. Particular aspects of the service – quality, availability, responsibilities – are agreed between the service provider and the service user. The most common component of an SLA is that the services should be provided to the customer as agreed upon in the contract. As an example, Internet service providers and telcos will commonly include service level agreements within the terms of their contracts with customers to define the level(s) of service being sold in plain language terms. In this case the SLA will typically have a technical definition in  mean time between failures (MTBF), mean time to repair or mean time to recovery (MTTR); identifying which party is responsible for reporting faults or paying fees; responsibility for various data rates; throughput; jitter; or similar measurable details.

set
Is an abstract data type that can store unique values, without any particular order. It is a computer implementation of the mathematical concept of a finite set. Unlike most other collection types, rather than retrieving a specific element from a set, one typically tests a value for membership in a set.

singleton variable
A variable that is referenced only once. May be used as a dummy argument in a function call, or when its address is assigned to another variable which subsequently accesses its allocated storage. Singleton variables sometimes occur because a mistake has been made – such as assigning a value to a variable and forgetting to use it later, or mistyping one instance of the variable name. Some compilers and lint-like tools flag occurrences of singleton variables.

soft computing

software
Computer software, or simply software, is a collection of data or computer instructions that tell the computer how to work. This is in contrast to physical hardware, from which the system is built and actually performs the work. In computer science and software engineering, computer software is all information processed by computer systems, programs and data. Computer software includes computer programs, libraries and related non-executable data, such as online documentation or digital media. Computer hardware and software require each other and neither can be realistically used on its own.

software agent
Is a computer program that acts for a user or other program in a relationship of agency, which derives from the Latin agere (to do): an agreement to act on one's behalf. Such ""action on behalf of"" implies the authority to decide which, if any, action is appropriate. Agents are colloquially known as bots, from robot. They may be embodied, as when execution is paired with a robot body, or  as software such as a chatbot
executing on a phone (e.g. Siri)  or other computing device.  Software agents may be autonomous or work together with other agents or people.  Software agents interacting with people (e.g. chatbots, human-robot interaction environments) may possess human-like qualities such as natural language understanding and speech, personality or embody humanoid form (see Asimo).

software construction
Is a software engineering discipline. It is the detailed creation of working meaningful software through a combination of coding, verification, unit testing, integration testing, and debugging. It is linked to all the other software engineering disciplines, most strongly to software design and software testing.

software deployment
Is all of the activities that make a software system available for use.

software design
Is the process by which an agent creates a specification of a software artifact, intended to accomplish goals, using a set of primitive components and subject to constraints. Software design may refer to either ""all the activity involved in conceptualizing, framing, implementing, commissioning, and ultimately modifying complex systems"" or ""the activity following requirements specification and before programming, as ... [in] a stylized software engineering process.""

software development
Is the process of conceiving, specifying, designing, programming, documenting, testing, and bug fixing involved in creating and maintaining applications, frameworks, or other software components. Software development is a process of writing and maintaining the source code, but in a broader sense, it includes all that is involved between the conception of the desired software through to the final manifestation of the software, sometimes in a planned and structured process. Therefore, software development may include research, new development, prototyping, modification, reuse, re-engineering, maintenance, or any other activities that result in software products.

software development process
In software engineering, a software development process is the process of dividing software development work into distinct phases to improve design, product management, and project management.  It is also known as a software development life cycle (SDLC).  The methodology may include the pre-definition of specific deliverables and artifacts that are created and completed by a project team to develop or maintain an application.  Most modern development processes can be vaguely described as agile. Other methodologies include waterfall, prototyping, iterative and incremental development, spiral development, rapid application development, and extreme programming.

software engineering
Is the systematic application of engineering approaches to the development of software. Software engineering is a computing discipline.

software maintenance
In software engineering is the modification of a software product after delivery to correct faults, to improve performance or other attributes.

software prototyping
Is the activity of creating prototypes of software applications, i.e., incomplete versions of the software program being developed. It is an activity that can occur in software development and is comparable to prototyping as known from other fields, such as mechanical engineering or manufacturing.  A prototype typically simulates only a few aspects of, and may be completely different from, the final product. 

software requirements specification
(SRS), is a description of a software system to be  developed. The software requirements specification lays out functional and non-functional requirements, and it may include a set of use cases that describe user interactions that the software must provide to the user for perfect interaction.

software testing
Is an investigation conducted to provide stakeholders with information about the quality of the software product or service under test. Software testing can also provide an objective, independent view of the software to allow the business to appreciate and understand the risks of software implementation. Test techniques include the process of executing a program or application with the intent of finding software bugs (errors or other defects), and verifying that the software product is fit for use. 

sorting algorithm
Is an algorithm that puts elements of a list in a certain order. The most frequently used orders are numerical order and lexicographical order. Efficient sorting is important for optimizing the efficiency of other algorithms (such as search and merge algorithms) that require input data to be in sorted lists. Sorting is also often useful for canonicalizing data and for producing human-readable output. More formally, the output of any sorting algorithm must satisfy two conditions:

The output is in nondecreasing order (each element is no smaller than the previous element according to the desired total order);
The output is a permutation (a reordering, yet retaining all of the original elements) of the input.

Further, the input data is often stored in an array, which allows random access, rather than a list, which only allows sequential access; though many algorithms can be applied to either type of data after suitable modification.

source code
In computing, source code is any collection of code, with or without comments, written using a human-readable programming language, usually as plain text. The source code of a program is specially designed to facilitate the work of computer programmers, who specify the actions to be performed by a computer mostly by writing source code. The source code is often transformed by an assembler or compiler into binary machine code that can be executed by the computer. The machine code might then be stored for execution at a later time. Alternatively, source code may be interpreted and thus immediately executed.

spiral model
Is a risk-driven software development process model. Based on the unique risk patterns of a given project, the spiral model guides a team to adopt elements of one or more process models, such as incremental, waterfall, or evolutionary prototyping.

stack
Is an abstract data type that serves as a collection of elements, with two main principal operations:
push, which adds an element to the collection, and
pop, which removes the most recently added element that was not yet removed.
The order in which elements come off a stack gives rise to its alternative name, LIFO (last in, first out). Additionally, a peek operation may give access to the top without modifying the stack. The name ""stack"" for this type of structure comes from the analogy to a set of physical items stacked on top of each other. This structure makes it easy to take an item off the top of the stack, while getting to an item deeper in the stack may require taking off multiple other items first.

state
In information technology and computer science, a system is described as stateful if it is designed to remember preceding events or user interactions; the remembered information is called the state of the system.

statement
In computer programming, a statement is a syntactic unit of an imperative programming language that expresses some action to be carried out. A program written in such a language is formed by a sequence of one or more statements. A statement may have internal components (e.g., expressions).

storage
Computer data storage is a technology consisting of computer components and recording media that are used to retain digital data. It is a core function and fundamental component of computers.: 15–16 

stream
Is a sequence of data elements made available over time. A stream can be thought of as items on a conveyor belt being processed one at a time rather than in large batches.

string
In computer programming, a string is traditionally a sequence of characters, either as a literal constant or as some kind of variable. The latter may allow its elements to be mutated and the length changed, or it may be fixed (after creation). A string is generally considered as a data type and is often implemented as an array data structure of bytes (or words) that stores a sequence of elements, typically characters, using some character encoding. String may also denote more general arrays or other sequence (or list) data types and structures.

structured storage
A NoSQL (originally referring to ""non-SQL"" or ""non-relational"") database provides a mechanism for storage and retrieval of data that is modeled in means other than the tabular relations used in relational databases. Such databases have existed since the late 1960s, but the name ""NoSQL"" was only coined in the early 21st century, triggered by the needs of Web 2.0 companies. NoSQL databases are increasingly used in big data and real-time web applications.  NoSQL systems are also sometimes called ""Not only SQL"" to emphasize that they may support SQL-like query languages or sit alongside SQL databases in polyglot-persistent architectures.

subroutine
In computer programming, a subroutine is a sequence of program instructions that performs a specific task, packaged as a unit. This unit can then be used in programs wherever that particular task should be performed.  Subroutines may be defined within programs, or separately in libraries that can be used by many programs.  In different programming languages, a subroutine may be called a routine, subprogram, function, method, or procedure. Technically, these terms all have different definitions. The generic, umbrella term  callable unit is sometimes used.

symbolic computation
In mathematics and computer science, computer algebra, also called symbolic computation or algebraic computation, is a scientific area that refers to the study and development of algorithms and software for manipulating mathematical expressions and other mathematical objects. Although computer algebra could be considered a subfield of scientific computing, they are generally considered as distinct fields because scientific computing is usually based on numerical computation with approximate floating point numbers, while symbolic computation emphasizes exact computation with expressions containing variables that have no given value and are manipulated as symbols.

syntax
The syntax of a computer language is the set of rules that defines the combinations of symbols that are considered to be correctly structured statements or expressions in that language. This applies both to programming languages, where the document represents source code, and to markup languages, where the document represents data.

syntax error
Is an error in the syntax of a sequence of characters or tokens that is intended to be written in compile-time. A program will not compile until all syntax errors are corrected. For interpreted languages, however, a syntax error may be detected during program execution, and an interpreter's error messages might not differentiate syntax errors from errors of other kinds. There is some disagreement as to just what errors are ""syntax errors"". For example, some would say that the use of an uninitialized variable's value in Java code is a syntax error, but many others would disagree and would classify this as a (static) semantic error.

system console
The system console, computer console, root console, operator's console, or simply console is the text entry and display device for system administration messages, particularly those from the BIOS or boot loader, the kernel, from the init system and from the system logger. It is a physical device consisting of a keyboard and a screen, and traditionally is a text terminal, but may also be a graphical terminal. System consoles are generalized to computer terminals, which are abstracted respectively by virtual consoles and terminal emulators. Today communication with system consoles is generally done abstractly, via the standard streams (stdin, stdout, and stderr), but there may be system-specific interfaces, for example those used by the system kernel.


== T ==
technical documentation
In engineering, any type of documentation that describes handling, functionality, and architecture of a technical product or a product under development or use. The intended recipient for product technical documentation is both the (proficient) end user as well as the administrator/service or maintenance technician. In contrast to a mere ""cookbook"" manual, technical documentation aims at providing enough information for a user to understand inner and outer dependencies of the product at hand.

third-generation programming language
A third-generation programming language (3GL) is a high-level computer programming language that tends to be more machine-independent and programmer-friendly than the machine code of the first-generation and assembly languages of the second-generation, while having a less specific focus to the fourth and fifth generations. Examples of common and historical third-generation programming languages are ALGOL, BASIC, C, COBOL, Fortran, Java, and Pascal.

top-down and bottom-up design

tree
A widely used abstract data type (ADT) that simulates a hierarchical tree structure, with a root value and subtrees of children with a parent node, represented as a set of linked nodes.

type theory
In mathematics, logic, and computer science, a type theory is any of a class of formal systems, some of which can serve as alternatives to set theory as a foundation for all mathematics. In type theory, every ""term"" has a ""type"" and operations are restricted to terms of a certain type.


== U ==
upload
In computer networks, to send data to a remote system such as a server or another client so that the remote system can store a copy. Contrast download.

Uniform Resource Locator (URL)
Colloquially web address.
A reference to a web resource that specifies its location on a computer network and a mechanism for retrieving it. A URL is a specific type of Uniform Resource Identifier (URI), although many people use the two terms interchangeably. URLs occur most commonly to reference web pages (http), but are also used for file transfer (ftp), email (mailto), database access (JDBC), and many other applications.

user
Is a person who utilizes a computer or network service. Users of computer systems and software products generally lack the technical expertise required to fully understand how they work. Power users use advanced features of programs, though they are not necessarily capable of computer programming and system administration.

user agent
Software (a software agent) that acts on behalf of a user, such as a web browser that ""retrieves, renders and facilitates end user interaction with Web content"". An email reader is a mail user agent.

user interface (UI)
The space where interactions between humans and machines occur. The goal of this interaction is to allow effective operation and control of the machine from the human end, whilst the machine simultaneously feeds back information that aids the operators' decision-making process. Examples of this broad concept of user interfaces include the interactive aspects of computer operating systems, hand tools, heavy machinery operator controls, and process controls. The design considerations applicable when creating user interfaces are related to or involve such disciplines as ergonomics and psychology.

user interface design
Also user interface engineering.
The design of user interfaces for machines and software, such as computers, home appliances, mobile devices, and other electronic devices, with the focus on maximizing usability and the user experience. The goal of user interface design is to make the user's interaction as simple and efficient as possible, in terms of accomplishing user goals (user-centered design).


== V ==
variable
In computer programming, a variable, or scalar, is a storage location (identified by a memory address) paired with an associated symbolic name (an identifier), which contains some known or unknown quantity of information referred to as a value. The variable name is the usual way to reference the stored value, in addition to referring to the variable itself, depending on the context. This separation of name and content allows the name to be used independently of the exact information it represents. The identifier in computer source code can be bound to a value during run time, and the value of the variable may therefore change during the course of program execution.

virtual machine (VM)
An emulation of a computer system. Virtual machines are based on computer architectures and attempt to provide the same functionality as a physical computer. Their implementations may involve specialized hardware, software, or a combination of both.

V-Model
A software development process that may be considered an extension of the waterfall model, and is an example of the more general V-model. Instead of moving down in a linear way, the process steps are bent upwards after the coding phase, to form the typical V shape. The V-Model demonstrates the relationships between each phase of the development life cycle and its associated phase of testing. The horizontal and vertical axes represent time or project completeness (left-to-right) and level of abstraction (coarsest-grain abstraction uppermost), respectively.


== W ==
waterfall model
A breakdown of project activities into linear sequential phases, where each phase depends on the deliverables of the previous one and corresponds to a specialisation of tasks.  The approach is typical for certain areas of engineering design. In software development, it tends to be among the less iterative and flexible approaches, as progress flows in largely one direction (""downwards"" like a waterfall) through the phases of conception, initiation, analysis, design, construction, testing, deployment and maintenance.

Waveform Audio File Format
Also WAVE or WAV due to its filename extension.
An audio file format standard, developed by Microsoft and IBM, for storing an audio bitstream on PCs. It is an application of the Resource Interchange File Format (RIFF) bitstream format method for storing data in ""chunks"", and thus is also close to the 8SVX and the AIFF format used on Amiga and Macintosh computers, respectively. It is the main format used on Microsoft Windows systems for raw and typically uncompressed audio. The usual bitstream encoding is the linear pulse-code modulation (LPCM) format.

web crawler
Also spider, spiderbot, or simply crawler.
An Internet bot that systematically browses the World Wide Web, typically for the purpose of Web indexing (web spidering).

Wi-Fi
A family of wireless networking technologies, based on the IEEE 802.11 family of standards, which are commonly used for local area networking of devices and Internet access. Wi‑Fi is a trademark of the non-profit Wi-Fi Alliance, which restricts the use of the term Wi-Fi Certified to products that successfully complete interoperability certification testing.


== X ==
XHTML
Abbreviaton of eXtensible HyperText Markup Language.
Part of the family of XML markup languages. It mirrors or extends versions of the widely used HyperText Markup Language (HTML), the language in which web pages are formulated.


== See also ==
Outline of computer science


== References ==


== Notes =="
c917dd0003,Lock (computer science),"In computer science, a lock or mutex (from mutual exclusion) is a synchronization primitive: a mechanism that enforces limits on access to a resource when there are many threads of execution. A lock is designed to enforce a mutual exclusion concurrency control policy, and with a variety of possible methods there exists multiple unique implementations for different applications.


== Types ==
Generally, locks are advisory locks, where each thread cooperates by acquiring the lock before accessing the corresponding data. Some systems also implement mandatory locks, where attempting unauthorized access to a locked resource will force an exception in the entity attempting to make the access.
The simplest type of lock is a binary semaphore. It provides exclusive access to the locked data. Other schemes also provide shared access for reading data. Other widely implemented access modes are exclusive, intend-to-exclude and intend-to-upgrade.
Another way to classify locks is by what happens when the lock strategy prevents the progress of a thread. Most locking designs block the execution of the thread requesting the lock until it is allowed to access the locked resource. With a spinlock, the thread simply waits (""spins"") until the lock becomes available. This is efficient if threads are blocked for a short time, because it avoids the overhead of operating system process re-scheduling. It is inefficient if the lock is held for a long time, or if the progress of the thread that is holding the lock depends on preemption of the locked thread.
Locks typically require hardware support for efficient implementation. This support usually takes the form of one or more atomic instructions such as ""test-and-set"", ""fetch-and-add"" or ""compare-and-swap"". These instructions allow a single process to test if the lock is free, and if free, acquire the lock in a single atomic operation.
Uniprocessor architectures have the option of using uninterruptible sequences of instructions—using special instructions or instruction prefixes to disable interrupts temporarily—but this technique does not work for multiprocessor shared-memory machines. Proper support for locks in a multiprocessor environment can require quite complex hardware or software support, with substantial synchronization issues.
The reason an atomic operation is required is because of concurrency, where more than one task executes the same logic. For example, consider the following C code:

The above example does not guarantee that the task has the lock, since more than one task can be testing the lock at the same time. Since both tasks will detect that the lock is free, both tasks will attempt to set the lock, not knowing that the other task is also setting the lock. Dekker's or Peterson's algorithm are possible substitutes if atomic locking operations are not available.
Careless use of locks can result in deadlock or livelock. A number of strategies can be used to avoid or recover from deadlocks or livelocks, both at design-time and at run-time. (The most common strategy is to standardize the lock acquisition sequences so that combinations of inter-dependent locks are always acquired in a specifically defined ""cascade"" order.)
Some languages do support locks syntactically. An example in C# follows:

The code lock(this) can lead to problems if the instance can be accessed publicly.Similar to Java, C# can also synchronize entire methods, by using the MethodImplOptions.Synchronized attribute.


== Granularity ==
Before being introduced to lock granularity, one needs to understand three concepts about locks:

lock overhead: the extra resources for using locks, like the memory space allocated for locks, the CPU time to initialize and destroy locks, and the time for acquiring or releasing locks. The more locks a program uses, the more overhead associated with the usage;
lock contention: this occurs whenever one process or thread attempts to acquire a lock held by another process or thread. The more fine-grained the available locks, the less likely one process/thread will request a lock held by the other. (For example, locking a row rather than the entire table, or locking a cell rather than the entire row);
deadlock: the situation when each of at least two tasks is waiting for a lock that the other task holds. Unless something is done, the two tasks will wait forever.There is a tradeoff between decreasing lock overhead and decreasing lock contention when choosing the number of locks in synchronization.
An important property of a lock is its granularity. The granularity is a measure of the amount of data the lock is protecting. In general, choosing a coarse granularity (a small number of locks, each protecting a large segment of data) results in less lock overhead when a single process is accessing the protected data, but worse performance when multiple processes are running concurrently. This is because of increased lock contention. The more coarse the lock, the higher the likelihood that the lock will stop an unrelated process from proceeding. Conversely, using a fine granularity (a larger number of locks, each protecting a fairly small amount of data) increases the overhead of the locks themselves but reduces lock contention. Granular locking where each process must hold multiple locks from a common set of locks can create subtle lock dependencies. This subtlety can increase the chance that a programmer will unknowingly introduce a deadlock.In a database management system, for example, a lock could protect, in order of decreasing granularity, part of a field, a field, a record, a data page, or an entire table. Coarse granularity, such as using table locks, tends to give the best performance for a single user, whereas fine granularity, such as record locks, tends to give the best performance for multiple users.


== Database locks ==

Database locks can be used as a means of ensuring transaction synchronicity. i.e. when making transaction processing concurrent (interleaving transactions), using 2-phased locks ensures that the concurrent execution of the transaction turns out equivalent to some serial ordering of the transaction. However, deadlocks become an unfortunate side-effect of locking in databases. Deadlocks are either prevented by pre-determining the locking order between transactions or are detected using waits-for graphs. An alternate to locking for database synchronicity while avoiding deadlocks involves the use of totally ordered global timestamps.
There are mechanisms employed to manage the actions of multiple concurrent users on a database—the purpose is to prevent lost updates and dirty reads. The two types of locking are pessimistic locking and optimistic locking:

Pessimistic locking: a user who reads a record with the intention of updating it places an exclusive lock on the record to prevent other users from manipulating it. This means no one else can manipulate that record until the user releases the lock. The downside is that users can be locked out for a very long time, thereby slowing the overall system response and causing frustration.Where to use pessimistic locking: this is mainly used in environments where data-contention (the degree of users request to the database system at any one time) is heavy; where the cost of protecting data through locks is less than the cost of rolling back transactions, if concurrency conflicts occur. Pessimistic concurrency is best implemented when lock times will be short, as in programmatic processing of records. Pessimistic concurrency requires a persistent connection to the database and is not a scalable option when users are interacting with data, because records might be locked for relatively large periods of time. It is not appropriate for use in Web application development.Optimistic locking: this allows multiple concurrent users access to the database whilst the system keeps a copy of the initial-read made by each user. When a user wants to update a record, the application determines whether another user has changed the record since it was last read. The application does this by comparing the initial-read held in memory to the database record to verify any changes made to the record. Any discrepancies between the initial-read and the database record violates concurrency rules and hence causes the system to disregard any update request. An error message is generated and the user is asked to start the update process again. It improves database performance by reducing the amount of locking required, thereby reducing the load on the database server. It works efficiently with tables that require limited updates since no users are locked out. However, some updates may fail. The downside is constant update failures due to high volumes of update requests from multiple concurrent users - it can be frustrating for users.Where to use optimistic locking: this is appropriate in environments where there is low contention for data, or where read-only access to data is required. Optimistic concurrency is used extensively in .NET to address the needs of mobile and disconnected applications, where locking data rows for prolonged periods of time would be infeasible. Also, maintaining record locks requires a persistent connection to the database server, which is not possible in disconnected applications.


== Disadvantages ==
Lock-based resource protection and thread/process synchronization have many disadvantages:

Contention: some threads/processes have to wait until a lock (or a whole set of locks) is released. If one of the threads holding a lock dies, stalls, blocks, or enters an infinite loop, other threads waiting for the lock may wait indefinitely until the computer is power cycled.
Overhead: the use of locks adds overhead for each access to a resource, even when the chances for collision are very rare. (However, any chance for such collisions is a race condition.)
Debugging: bugs associated with locks are time dependent and can be very subtle and extremely hard to replicate, such as deadlocks.
Instability: the optimal balance between lock overhead and lock contention can be unique to the problem domain (application) and sensitive to design, implementation, and even low-level system architectural changes. These balances may change over the life cycle of an application and may entail tremendous changes to update (re-balance).
Composability: locks are only composable (e.g., managing multiple concurrent locks in order to atomically delete item X from table A and insert X into table B) with relatively elaborate (overhead) software support and perfect adherence by applications programming to rigorous conventions.
Priority inversion: a low-priority thread/process holding a common lock can prevent high-priority threads/processes from proceeding. Priority inheritance can be used to reduce priority-inversion duration. The priority ceiling protocol can be used on uniprocessor systems to minimize the worst-case priority-inversion duration, as well as prevent deadlock.
Convoying: all other threads have to wait if a thread holding a lock is descheduled due to a time-slice interrupt or page fault.Some concurrency control strategies avoid some or all of these problems. For example, a funnel or serializing tokens can avoid the biggest problem: deadlocks. Alternatives to locking include non-blocking synchronization methods, like lock-free programming techniques and transactional memory. However, such alternative methods often require that the actual lock mechanisms be implemented at a more fundamental level of the operating software. Therefore, they may only relieve the application level from the details of implementing locks, with the problems listed above still needing to be dealt with beneath the application.
In most cases, proper locking depends on the CPU providing a method of atomic instruction stream synchronization (for example, the addition or deletion of an item into a pipeline requires that all contemporaneous operations needing to add or delete other items in the pipe be suspended during the manipulation of the memory content required to add or delete the specific item). Therefore, an application can often be more robust when it recognizes the burdens it places upon an operating system and is capable of graciously recognizing the reporting of impossible demands.


=== Lack of composability ===
One of lock-based programming's biggest problems is that ""locks don't compose"": it is hard to combine small, correct lock-based modules into equally correct larger programs without modifying the modules or at least knowing about their internals. Simon Peyton Jones (an advocate of software transactional memory) gives the following example of a banking application:
design a class Account that allows multiple concurrent clients to deposit or withdraw money to an account; and give an algorithm to transfer money from one account to another. The lock-based solution to the first part of the problem is:

class Account:
    member balance: Integer
    member mutex: Lock

    method deposit(n: Integer)
           mutex.lock()
           balance ← balance + n
           mutex.unlock()

    method withdraw(n: Integer)
           deposit(−n)

The second part of the problem is much more complicated. A transfer routine that is correct for sequential programs would be

function transfer(from: Account, to: Account, amount: Integer)
    from.withdraw(amount)
    to.deposit(amount)

In a concurrent program, this algorithm is incorrect because when one thread is halfway through transfer, another might observe a state where amount has been withdrawn from the first account, but not yet deposited into the other account: money has gone missing from the system. This problem can only be fixed completely by taking locks on both account prior to changing any of the two accounts, but then the locks have to be taken according to some arbitrary, global ordering to prevent deadlock:

function transfer(from: Account, to: Account, amount: Integer)
    if from < to    // arbitrary ordering on the locks
        from.lock()
        to.lock()
    else
        to.lock()
        from.lock()
    from.withdraw(amount)
    to.deposit(amount)
    from.unlock()
    to.unlock()

This solution gets more complicated when more locks are involved, and the transfer function needs to know about all of the locks, so they cannot be hidden.


== Language support ==

Programming languages vary in their support for synchronization:

Ada provides protected objects that have visible protected subprograms or entries as well as rendezvous.
The ISO/IEC C standard provides a standard mutual exclusion (locks) API since C11. The current ISO/IEC C++ standard supports threading facilities since C++11. The OpenMP standard is supported by some compilers, and allows critical sections to be specified using pragmas. The POSIX pthread API provides lock support. Visual C++ provides the synchronize attribute of methods to be synchronized, but this is specific to COM objects in the Windows architecture and Visual C++ compiler.  C and C++ can easily access any native operating system locking features.
C# provides the lock keyword on a thread to ensure its exclusive access to a resource.
VB.NET provides a SyncLock keyword like C#'s lock keyword.
Java provides the keyword synchronized to lock code blocks, methods or objects and libraries featuring concurrency-safe data structures.
Objective-C provides the keyword @synchronized to put locks on blocks of code and also provides the classes NSLock, NSRecursiveLock, and NSConditionLock along with the NSLocking protocol for locking as well.
PHP provides a file-based locking  as well as a Mutex class in the pthreads extension. 
Python provides a low-level mutex mechanism with a Lock class from the threading module.
The ISO/IEC Fortran standard (ISO/IEC 1539-1:2010) provides the lock_type derived type in the intrinsic module iso_fortran_env and the lock/unlock statements since Fortran 2008.
Ruby provides a low-level mutex object and no keyword.
Rust provides the Mutex<T> struct.
x86 assembly provides the LOCK prefix on certain operations to guarantee their atomicity.
Haskell implements locking via a mutable data structure called an MVar, which can either be empty or contain a value, typically a reference to a resource. A thread that wants to use the resource ‘takes’ the value of the MVar, leaving it empty, and puts it back when it is finished. Attempting to take a resource from an empty MVar results in the thread blocking until the resource is available. As an alternative to locking, an implementation of software transactional memory also exists.
Go provides a low-level Mutex object in standard's library sync package. It can be used for locking code blocks, methods or objects.


== Mutexes vs. semaphores ==


== See also ==
Critical section
Double-checked locking
File locking
Lock-free and wait-free algorithms
Monitor (synchronization)
Mutual exclusion
Read/write lock pattern


== References ==


== External links ==
Tutorial on Locks and Critical Sections"
a7c574c8a7,String (computer science),"In computer programming, a string is traditionally a sequence of characters, either as a literal constant or as some kind of variable. The latter may allow its elements to be mutated and the length changed, or it may be fixed (after creation). A string is generally considered as a data type and is often implemented as an array data structure of bytes (or words) that stores a sequence of elements, typically characters, using some character encoding. String may also denote more general arrays or other sequence (or list) data types and structures.
Depending on the programming language and precise data type used, a variable declared to be a string may either cause storage in memory to be statically allocated for a predetermined maximum length or employ dynamic allocation to allow it to hold a variable number of elements.
When a string appears literally in source code, it is known as a string literal or an anonymous string.In formal languages, which are used in mathematical logic and theoretical computer science, a string is a finite sequence of symbols that are chosen from a set called an alphabet.


== Purpose ==
A primary purpose of strings is to store human-readable text, like words and sentences. Strings are used to communicate information from a computer program to the user of the program. A program may also accept string input from its user. Further, strings may store data expressed as characters yet not intended for human reading.
Example strings and their purposes:

A message like ""file upload complete"" is a string that software shows to end users. In the program's source code, this message would likely appear as a string literal.
User-entered text, like ""I got a new job today"" as a status update on a social media service. Instead of a string literal, the software would likely store this string in a database.
Alphabetical data, like ""AGATGCCGT"" representing nucleic acid sequences of DNA.
Computer settings or parameters, like ""?action=edit"" as a URL query string. Often these are intended to be somewhat human-readable, though their primary purpose is to communicate to computers.The term string may also designate a sequence of data or computer records other than characters — like a ""string of bits"" — but when used without qualification it refers to strings of characters.


== History ==
Use of the word ""string"" to mean any items arranged in a line, series or succession dates back centuries. In 19th-Century typesetting, compositors used the term ""string"" to denote a length of type printed on paper; the string would be measured to determine the compositor's pay.Use of the word ""string"" to mean ""a sequence of symbols or linguistic elements in a definite order"" emerged from mathematics, symbolic logic, and linguistic theory to speak about the formal behavior of symbolic systems, setting aside the symbols' meaning.For example, logician C. I. Lewis wrote in 1918:

A mathematical system is any set of strings of recognisable marks in which some of the strings are taken initially and the remainder derived from these by operations performed according to rules which are independent of any meaning assigned to the marks. That a system should consist of 'marks' instead of sounds or odours is immaterial.

According to Jean E. Sammet, ""the first realistic string handling and pattern matching language"" for computers was COMIT in the 1950s, followed by the SNOBOL language of the early 1960s.


== String datatypes ==

A string datatype is a datatype modeled on the idea of a formal string. Strings are such an important and useful datatype that they are implemented in nearly every programming language. In some languages they are available as primitive types and in others as composite types. The syntax of most high-level programming languages allows for a string, usually quoted in some way, to represent an instance of a string datatype; such a meta-string is called a literal or string literal.


=== String length ===
Although formal strings can have an arbitrary finite length, the length of strings in real languages is often constrained to an artificial maximum. In general, there are two types of string datatypes: fixed-length strings, which have a fixed maximum length to be determined at compile time and which use the same amount of memory whether this maximum is needed or not, and variable-length strings, whose length is not arbitrarily fixed and which can use varying amounts of memory depending on the actual requirements at run time (see Memory management). Most strings in modern programming languages are variable-length strings. Of course, even variable-length strings are limited in length – by the size of available computer memory. The string length can be stored as a separate integer (which may put another artificial limit on the length) or implicitly through a termination character, usually a character value with all bits zero such as in C programming language. See also ""Null-terminated"" below.


=== Character encoding ===
String datatypes have historically allocated one byte per character, and, although the exact character set varied by region, character encodings were similar enough that programmers could often get away with ignoring this, since characters a program treated specially (such as period and space and comma) were in the same place in all the encodings a program would encounter. These character sets were typically based on ASCII or EBCDIC. If text in one encoding was displayed on a system using a different encoding, text was often mangled, though often somewhat readable and some computer users learned to read the mangled text.
Logographic languages such as Chinese, Japanese, and Korean (known collectively as CJK) need far more than 256 characters (the limit of a one 8-bit byte per-character encoding) for reasonable representation. The normal solutions involved keeping single-byte representations for ASCII and using two-byte representations for CJK ideographs. Use of these with existing code led to problems with matching and cutting of strings, the severity of which depended on how the character encoding was designed. Some encodings such as the EUC family guarantee that a byte value in the ASCII range will represent only that ASCII character, making the encoding safe for systems that use those characters as field separators. Other encodings such as ISO-2022 and Shift-JIS do not make such guarantees, making matching on byte codes unsafe. These encodings also were not ""self-synchronizing"", so that locating character boundaries required backing up to the start of a string, and pasting two strings together could result in corruption of the second string.
Unicode has simplified the picture somewhat. Most programming languages now have a datatype for Unicode strings. Unicode's preferred byte stream format UTF-8 is designed not to have the problems described above for older multibyte encodings. UTF-8, UTF-16 and UTF-32 require the programmer to know that the fixed-size code units are different than the ""characters"", the main difficulty currently is incorrectly designed APIs that attempt to hide this difference (UTF-32 does make code points fixed-sized, but these are not ""characters"" due to composing codes).


=== Implementations ===

Some languages, such as C++, Perl and Ruby, normally allow the contents of a string to be changed after it has been created; these are termed mutable strings.  In other languages, such as Java, JavaScript, Lua, Python, and Go, the value is fixed and a new string must be created if any alteration is to be made; these are termed immutable strings. Some of these languages with immutable strings also provide another type that is mutable, such as Java and .NET's StringBuilder, the thread-safe Java StringBuffer, and the Cocoa NSMutableString. There are both advantages and disadvantages to immutability: although immutable strings may require inefficiently creating many copies, they are simpler and completely thread-safe.
Strings are typically implemented as arrays of bytes, characters, or code units, in order to allow fast access to individual units or substrings—including characters when they have a fixed length.  A few languages such as Haskell implement them as linked lists instead.
Some languages, such as Prolog and Erlang, avoid implementing a dedicated string datatype at all, instead adopting the convention of representing strings as lists of character codes.


=== Representations ===
Representations of strings depend heavily on the choice of character repertoire and the method of character encoding. Older string implementations were designed to work with repertoire and encoding defined by ASCII, or more recent extensions like the ISO 8859 series. Modern implementations often use the extensive repertoire defined by Unicode along with a variety of complex encodings such as UTF-8 and UTF-16.
The term byte string usually indicates a general-purpose string of bytes, rather than strings of only (readable) characters, strings of bits, or such. Byte strings often imply that bytes can take any value and any data can be stored as-is, meaning that there should be no value interpreted as a termination value.
Most string implementations are very similar to variable-length arrays with the entries storing the character codes of corresponding characters. The principal difference is that, with certain encodings, a single logical character may take up more than one entry in the array. This happens for example with UTF-8, where single codes (UCS code points) can take anywhere from one to four bytes, and single characters can take an arbitrary number of codes. In these cases, the logical length of the string (number of characters) differs from the physical length of the array (number of bytes in use). UTF-32 avoids the first part of the problem.


==== Null-terminated ====

The length of a string can be stored implicitly by using a special terminating character; often this is the null character (NUL), which has all bits zero, a convention used and perpetuated by the popular C programming language. Hence, this representation is commonly referred to as a C string. This representation of an n-character string takes n + 1 space (1 for the terminator), and is thus an implicit data structure.
In terminated strings, the terminating code is not an allowable character in any string. Strings with length field do not have this limitation and can also store arbitrary binary data.
An example of a null-terminated string stored in a 10-byte buffer, along with its ASCII (or more modern UTF-8) representation as 8-bit hexadecimal numbers is:

The length of the string in the above example, ""FRANK"", is 5 characters, but it occupies 6 bytes. Characters after the terminator do not form part of the representation; they may be either part of other data or just garbage. (Strings of this form are sometimes called ASCIZ strings, after the original assembly language directive used to declare them.)


==== Byte- and bit-terminated ====
Using a special byte other than null for terminating strings has historically appeared in both hardware and software, though sometimes with a value that was also a printing character. $ was used by many assembler systems, : used by CDC systems (this character had a value of zero), and the ZX80 used "" since this was the string delimiter in its BASIC language.
Somewhat similar, ""data processing"" machines like the IBM 1401 used a special word mark bit to delimit strings at the left, where the operation would start at the right. This bit had to be clear in all other parts of the string. This meant that, while the IBM 1401 had a seven-bit word, almost no-one ever thought to use this as a feature, and override the assignment of the seventh bit to (for example) handle ASCII codes.
Early microcomputer software relied upon the fact that ASCII codes do not use the high-order bit, and set it to indicate the end of a string. It must be reset to 0 prior to output.


==== Length-prefixed ====
The length of a string can also be stored explicitly, for example by prefixing the string with the length as a byte value. This convention is used in many Pascal dialects; as a consequence, some people call such a string a Pascal string or P-string. Storing the string length as byte limits the maximum string length to 255. To avoid such limitations, improved implementations of P-strings use 16-, 32-, or 64-bit words to store the string length. When the length field covers the address space, strings are limited only by the available memory.
If the length is bounded, then it can be encoded in constant space, typically a machine word, thus leading to an implicit data structure, taking n + k space, where k is the number of characters in a word (8 for 8-bit ASCII on a 64-bit machine, 1 for 32-bit UTF-32/UCS-4 on a 32-bit machine, etc.).
If the length is not bounded, encoding a length n takes log(n) space (see fixed-length code), so length-prefixed strings are a succinct data structure, encoding a string of length n in log(n) + n space.
In the latter case, the length-prefix field itself doesn't have fixed length, therefore the actual string data needs to be moved when the string grows such that the length field needs to be increased.
Here is a Pascal string stored in a 10-byte buffer, along with its ASCII / UTF-8 representation:


==== Strings as records ====
Many languages, including object-oriented ones, implement strings as records with an internal structure like:

However, since the implementation is usually hidden, the string must be accessed and modified through member functions. text is a pointer to a dynamically allocated memory area, which might be expanded as needed. See also string (C++).


==== Other representations ====
Both character termination and length codes limit strings: For example, C character arrays that contain null (NUL) characters cannot be handled directly by C string library functions: Strings using a length code are limited to the maximum value of the length code.
Both of these limitations can be overcome by clever programming.
It is possible to create data structures and functions that manipulate them that do not have the problems associated with character termination and can in principle overcome length code bounds. It is also possible to optimize the string represented using techniques from run length encoding (replacing repeated characters by the character value and a length) and Hamming encoding.
While these representations are common, others are possible. Using ropes makes certain string operations, such as insertions, deletions, and concatenations more efficient.
The core data structure in a text editor is the one that manages the string (sequence of characters) that represents the current state of the file being edited.
While that state could be stored in a single long consecutive array of characters, a typical text editor instead uses an alternative representation as its sequence data structure—a gap buffer, a linked list of lines, a piece table, or a rope—which makes certain string operations, such as insertions, deletions, and undoing previous edits, more efficient.


=== Security concerns ===
The differing memory layout and storage requirements of strings can affect the security of the program accessing the string data. String representations requiring a terminating character are commonly susceptible to buffer overflow problems if the terminating character is not present, caused by a coding error or an attacker deliberately altering the data. String representations adopting a separate length field are also susceptible if the length can be manipulated. In such cases, program code accessing the string data requires bounds checking to ensure that it does not inadvertently access or change data outside of the string memory limits.
String data is frequently obtained from user input to a program. As such, it is the responsibility of the program to validate the string to ensure that it represents the expected format. Performing limited or no validation of user input can cause a program to be vulnerable to code injection attacks.


== Literal strings ==

Sometimes, strings need to be embedded inside a text file that is both human-readable and intended for consumption by a machine.  This is needed in, for example, source code of programming languages, or in configuration files. In this case, the NUL character doesn't work well as a terminator since it is normally invisible (non-printable) and is difficult to input via a keyboard.  Storing the string length would also be inconvenient as manual computation and tracking of the length is tedious and error-prone.
Two common representations are:

Surrounded by quotation marks (ASCII 0x22 double quote ""str"" or ASCII 0x27 single quote 'str'), used by most programming languages. To be able to include special characters such as the quotation mark itself, newline characters, or non-printable characters, escape sequences are often available, usually prefixed with the backslash character (ASCII 0x5C).
Terminated by a newline sequence, for example in Windows INI files.


== Non-text strings ==
While character strings are very common uses of strings, a string in computer science may refer generically to any sequence of homogeneously typed data. A bit string or byte string, for example, may be used to represent non-textual binary data retrieved from a communications medium. This data may or may not be represented by a string-specific datatype, depending on the needs of the application, the desire of the programmer, and the capabilities of the programming language being used. If the programming language's string implementation is not 8-bit clean, data corruption may ensue.
C programmers draw a sharp distinction between a ""string"", aka a ""string of characters"", which by definition is always null terminated, vs. a ""byte string"" or ""pseudo string"" which may be stored in the same array but is often not null terminated.
Using C string handling functions on such a ""byte string"" often seems to work, but later leads to security problems.


== String processing algorithms ==

There are many algorithms for processing strings, each with various trade-offs. Competing algorithms can be analyzed with respect to run time, storage requirements, and so forth. The name stringology was coined in 1984 by computer scientist Zvi Galil for the theory of algorithms and data structures used for string processing.Some categories of algorithms include:

String searching algorithms for finding a given substring or pattern
String manipulation algorithms
Sorting algorithms
Regular expression algorithms
Parsing a string
Sequence miningAdvanced string algorithms often employ complex mechanisms and data structures, among them suffix trees and finite-state machines.


== Character string-oriented languages and utilities ==
Character strings are such a useful datatype that several languages have been designed in order to make string processing applications easy to write. Examples include the following languages:

awk
Icon
MUMPS
Perl
Rexx
Ruby
sed
SNOBOL
Tcl
TTMMany Unix utilities perform simple string manipulations and can be used to easily program some powerful string processing algorithms. Files and finite streams may be viewed as strings.
Some APIs like Multimedia Control Interface, embedded SQL or printf use strings to hold commands that will be interpreted.
Many scripting programming languages, including Perl, Python, Ruby, and Tcl employ regular expressions to facilitate text operations. Perl is particularly noted for its regular expression use, and many other languages and applications implement Perl compatible regular expressions.
Some languages such as Perl and Ruby support string interpolation, which permits arbitrary expressions to be evaluated and included in string literals.


== Character string functions ==

String functions are used to create strings or change the contents of a mutable string. They also are used to query information about a string. The set of functions and their names varies depending on the computer programming language.
The most basic example of a string function is the string length function – the function that returns the length of a string (not counting any terminator characters or any of the string's internal structural information) and does not modify the string. This function is often named length or len. For example, length(""hello world"") would return 11. Another common function is concatenation, where a new string is created by appending two strings, often this is the + addition operator.
Some microprocessor's instruction set architectures contain direct support for string operations, such as block copy (e.g. In intel x86m REPNZ MOVSB).


== Formal theory ==

Let Σ be a finite set of symbols (alternatively called characters), called the alphabet. No assumption is made about the nature of the symbols. A string (or word) over Σ is any finite sequence of symbols from Σ. For example, if Σ = {0, 1}, then 01011 is a string over Σ.
The length of a string s is the number of symbols in s (the length of the sequence) and can be any non-negative integer; it is often denoted as |s|.  The empty string is the unique string over Σ of length 0, and is denoted ε or λ.The set of all strings over Σ of length n is denoted Σn.  For example, if Σ = {0, 1}, then Σ2 = {00, 01, 10, 11}.  Note that Σ0 = {ε} for any alphabet Σ.
The set of all strings over Σ of any length is the Kleene closure of Σ and is denoted Σ*.  In terms of Σn,

  
    
      
        
          Σ
          
            ∗
          
        
        =
        
          ⋃
          
            n
            ∈
            
              N
            
            ∪
            {
            0
            }
          
        
        
          Σ
          
            n
          
        
      
    
    {\displaystyle \Sigma ^{*}=\bigcup _{n\in \mathbb {N} \cup \{0\}}\Sigma ^{n}}
  For example, if Σ = {0, 1}, then Σ* = {ε, 0, 1, 00, 01, 10, 11, 000, 001, 010, 011, ...}.  Although the set Σ* itself is countably infinite, each element of Σ* is a string of finite length.
A set of strings over Σ (i.e. any subset of Σ*) is called a formal language over Σ.  For example, if Σ = {0, 1}, the set of strings with an even number of zeros, {ε, 1, 00, 11, 001, 010, 100, 111, 0000, 0011, 0101, 0110, 1001, 1010, 1100, 1111, ...}, is a formal language over Σ.


=== Concatenation and substrings ===
Concatenation is an important binary operation on Σ*.  For any two strings s and t in Σ*, their concatenation is defined as the sequence of symbols in s followed by the sequence of characters in t, and is denoted st.  For example, if Σ = {a, b, ..., z}, s = bear, and t = hug, then st = bearhug and ts = hugbear.
String concatenation is an associative, but non-commutative operation. The empty string ε serves as the identity element; for any string s, εs = sε = s.  Therefore, the set Σ* and the concatenation operation form a monoid, the free monoid generated by Σ.  In addition, the length function defines a monoid homomorphism from Σ* to the non-negative integers (that is, a function 
  
    
      
        L
        :
        
          Σ
          
            ∗
          
        
        ↦
        
          N
        
        ∪
        {
        0
        }
      
    
    {\displaystyle L:\Sigma ^{*}\mapsto \mathbb {N} \cup \{0\}}
  , such that 
  
    
      
        L
        (
        s
        t
        )
        =
        L
        (
        s
        )
        +
        L
        (
        t
        )
        
        ∀
        s
        ,
        t
        ∈
        
          Σ
          
            ∗
          
        
      
    
    {\displaystyle L(st)=L(s)+L(t)\quad \forall s,t\in \Sigma ^{*}}
  ).
A string s is said to be a substring or factor of t if there exist (possibly empty) strings u and v such that t = usv.  The relation ""is a substring of"" defines a partial order on Σ*, the least element of which is the empty string.


=== Prefixes and suffixes ===
A string s is said to be a prefix of t if there exists a string u such that t = su. If u is nonempty, s is said to be a proper prefix of t. Symmetrically, a string s is said to be a suffix of t if there exists a string u such that t = us. If u is nonempty, s is said to be a proper suffix of t. Suffixes and prefixes are substrings of t. Both the relations ""is a prefix of"" and ""is a suffix of"" are prefix orders.


=== Reversal ===
The reverse of a string is a string with the same symbols but in reverse order. For example, if s = abc (where a, b, and c are symbols of the alphabet), then the reverse of s is cba. A string that is the reverse of itself (e.g., s = madam) is called a palindrome, which also includes the empty string and all strings of length 1.


=== Rotations ===
A string s = uv is said to be a rotation of t if t = vu. For example, if Σ = {0, 1} the string 0011001 is a rotation of 0100110, where u = 00110 and v = 01. As another example, the string abc has three different rotations, viz. abc itself (with u=abc, v=ε), bca (with u=bc, v=a), and cab (with u=c, v=ab).


=== Lexicographical ordering ===
It is often useful to define an ordering on a set of strings. If the alphabet Σ has a total order (cf. alphabetical order) one can define a total order on Σ* called lexicographical order. For example, if Σ = {0, 1} and 0 < 1, then the lexicographical order on Σ* includes the relationships ε < 0 < 00 < 000 < ... < 0001 < 001 < 01 < 010 < 011 < 0110 < 01111 < 1 < 10 < 100 < 101 < 111 < 1111 < 11111 ... The lexicographical order is total if the alphabetical order is, but isn't well-founded for any nontrivial alphabet, even if the alphabetical order is.
See Shortlex for an alternative string ordering that preserves well-foundedness.


=== String operations ===
A number of additional operations on strings commonly occur in the formal theory. These are given in the article on string operations.


=== Topology ===

Strings admit the following interpretation as nodes on a graph, where k is the number of symbols in Σ:

Fixed-length strings of length n can be viewed as the integer locations in an n-dimensional hypercube with sides of length k-1.
Variable-length strings (of finite length) can be viewed as nodes on a perfect k-ary tree.
Infinite strings (otherwise not considered here) can be viewed as infinite paths on a k-node complete graph.The natural topology on the set of fixed-length strings or variable-length strings is the discrete topology, but the natural topology on the set of infinite strings is the limit topology, viewing the set of infinite strings as the inverse limit of the sets of finite strings. This is the construction used for the p-adic numbers and some constructions of the Cantor set, and yields the same topology.
Isomorphisms between string representations of topologies can be found by normalizing according to the lexicographically minimal string rotation.


== See also ==
Binary-safe — a property of string manipulating functions treating their input as raw data stream
Bit array — a string of binary digits
C string handling — overview of C string handling
C++ string handling — overview of C++ string handling
Comparison of programming languages (string functions)
Connection string — passed to a driver to initiate a connection (e.g., to a database)
Empty string — its properties and representation in programming languages
Incompressible string — a string that cannot be compressed by any algorithm
Rope (data structure) — a data structure for efficiently manipulating long strings
String metric — notions of similarity between strings


== References =="
4e3e34d458,Recursion (computer science),"In computer science, recursion is a method of solving a computational problem where the solution depends on solutions to smaller instances of the same problem. Recursion solves such recursive problems by using functions that call themselves from within their own code. The approach can be applied to many types of problems, and recursion is one of the central ideas of computer science.
The power of recursion evidently lies in the possibility of defining an infinite set of objects by a finite statement.  In the same manner, an infinite number of computations can be described by a finite recursive program, even if this program contains no explicit repetitions.
Most computer programming languages support recursion by allowing a function to call itself from within its own code. Some functional programming languages (for instance, Clojure) do not define any looping constructs but rely solely on recursion to repeatedly call code. It is proved in computability theory that these recursive-only languages are Turing complete; this means that they are as powerful (they can be used to solve the same problems) as imperative languages based on control structures such as while and for.
Repeatedly calling a function from within itself may cause the call stack to have a size equal to the sum of the input sizes of all involved calls. It follows that, for problems that can be solved easily by iteration, recursion is generally less efficient, and, for large problems, it is fundamental to use optimization techniques such as tail call optimization.


== Recursive functions and algorithms ==
A common algorithm design tactic is to divide a problem into sub-problems of the same type as the original, solve those sub-problems, and combine the results. This is often referred to as the divide-and-conquer method; when combined with a lookup table that stores the results of previously solved sub-problems (to avoid solving them repeatedly and incurring extra computation time), it can be referred to as dynamic programming or memoization.


=== Base case ===
A recursive function definition has one or more base cases, meaning input(s) for which the function produces a result trivially (without recurring), and one or more recursive cases, meaning input(s) for which the program recurs (calls itself).  For example, the factorial function can be defined recursively by the equations 0! = 1 and, for all n > 0, n! = n(n − 1)!. Neither equation by itself constitutes a complete definition; the first is the base case, and the second is the recursive case. Because the base case breaks the chain of recursion, it is sometimes also called the ""terminating case"".
The job of the recursive cases can be seen as breaking down complex inputs into simpler ones.  In a properly designed recursive function, with each recursive call, the input problem must be simplified in such a way that eventually the base case must be reached.  (Functions that are not intended to terminate under normal circumstances—for example, some system and server processes—are an exception to this.)  Neglecting to write a base case, or testing for it incorrectly, can cause an infinite loop.
For some functions (such as one that computes the series for e = 1/0! + 1/1! + 1/2! + 1/3! + ...) there is not an obvious base case implied by the input data; for these one may add a parameter (such as the number of terms to be added, in our series example) to provide a 'stopping criterion' that establishes the base case. Such an example is more naturally treated by corecursion, where successive terms in the output are the partial sums; this can be converted to a recursion by using the indexing parameter to say ""compute the nth term (nth partial sum)"".


== Recursive data types ==
Many computer programs must process or generate an arbitrarily large quantity of data.  Recursion is a technique for representing data whose exact size is unknown to the programmer: the programmer can specify this data with a self-referential definition.  There are two types of self-referential definitions: inductive and coinductive definitions.


=== Inductively defined data ===

An inductively defined recursive data definition is one that specifies how to construct instances of the data.  For example, linked lists can be defined inductively (here, using Haskell syntax):

The code above specifies a list of strings to be either empty, or a structure that contains a string and a list of strings.  The self-reference in the definition permits the construction of lists of any (finite) number of strings.
Another example of inductive definition is the natural numbers (or positive integers):

A natural number is either 1 or n+1, where n is a natural number.
Similarly recursive definitions are often used to model the structure of expressions and statements in programming languages.  Language designers often express grammars in a syntax such as Backus–Naur form; here is such a grammar, for a simple language of arithmetic expressions with multiplication and addition:

This says that an expression is either a number, a product of two expressions, or a sum of two expressions.  By recursively referring to expressions in the second and third lines, the grammar permits arbitrarily complicated arithmetic expressions such as (5 * ((3 * 6) + 8)), with more than one product or sum operation in a single expression.


=== Coinductively defined data and corecursion ===

A coinductive data definition is one that specifies the operations that may be performed on a piece of data; typically, self-referential coinductive definitions are used for data structures of infinite size.
A coinductive definition of infinite streams of strings, given informally, might look like this:

A stream of strings is an object s such that:
 head(s) is a string, and
 tail(s) is a stream of strings.

This is very similar to an inductive definition of lists of strings; the difference is that this definition specifies how to access the contents of the data structure—namely, via the accessor functions head and tail—and what those contents may be, whereas the inductive definition specifies how to create the structure and what it may be created from.
Corecursion is related to coinduction, and can be used to compute particular instances of (possibly) infinite objects.  As a programming technique, it is used most often in the context of lazy programming languages, and can be preferable to recursion when the desired size or precision of a program's output is unknown.  In such cases the program requires both a definition for an infinitely large (or infinitely precise) result, and a mechanism for taking a finite portion of that result.  The problem of computing the first n prime numbers is one that can be solved with a corecursive program (e.g. here).


== Types of recursion ==


=== Single recursion and multiple recursion ===
Recursion that contains only a single self-reference is known as single recursion, while recursion that contains multiple self-references is known as multiple recursion. Standard examples of single recursion include list traversal, such as in a linear search, or computing the factorial function, while standard examples of multiple recursion include tree traversal, such as in a depth-first search.
Single recursion is often much more efficient than multiple recursion, and can generally be replaced by an iterative computation, running in linear time and requiring constant space. Multiple recursion, by contrast, may require exponential time and space, and is more fundamentally recursive, not being able to be replaced by iteration without an explicit stack.
Multiple recursion can sometimes be converted to single recursion (and, if desired, thence to iteration). For example, while computing the Fibonacci sequence naively entails multiple iteration, as each value requires two previous values, it can be computed by single recursion by passing two successive values as parameters. This is more naturally framed as corecursion, building up from the initial values, while tracking two successive values at each step – see corecursion: examples. A more sophisticated example involves using a threaded binary tree, which allows iterative tree traversal, rather than multiple recursion.


=== Indirect recursion ===

Most basic examples of recursion, and most of the examples presented here, demonstrate direct recursion, in which a function calls itself.  Indirect recursion occurs when a function is called not by itself but by another function that it called (either directly or indirectly). For example, if f calls f, that is direct recursion, but if f calls g which calls f, then that is indirect recursion of f. Chains of three or more functions are possible; for example, function 1 calls function 2, function 2 calls function 3, and function 3 calls function 1 again.
Indirect recursion is also called mutual recursion, which is a more symmetric term, though this is simply a difference of emphasis, not a different notion. That is, if f calls g and then g calls f, which in turn calls g again, from the point of view of f alone, f is indirectly recursing, while from the point of view of g alone, it is indirectly recursing, while from the point of view of both, f and g are mutually recursing on each other. Similarly a set of three or more functions that call each other can be called a set of mutually recursive functions.


=== Anonymous recursion ===

Recursion is usually done by explicitly calling a function by name. However, recursion can also be done via implicitly calling a function based on the current context, which is particularly useful for anonymous functions, and is known as anonymous recursion.


=== Structural versus generative recursion ===

Some authors classify recursion as either ""structural"" or ""generative"".  The distinction is related to where a recursive procedure gets the data that it works on, and how it processes that data:

[Functions that consume structured data] typically decompose their arguments into their immediate structural components and then process those components. If one of the immediate components belongs to the same class of data as the input, the function is recursive. For that reason, we refer to these functions as (STRUCTURALLY) RECURSIVE  FUNCTIONS.
Thus, the defining characteristic of a structurally recursive function is that the argument to each recursive call is the content of a field of the original input.  Structural recursion includes nearly all tree traversals, including XML processing, binary tree creation and search, etc. By considering the algebraic structure of the natural numbers (that is, a natural number is either zero or the successor of a natural number), functions such as factorial may also be regarded as structural recursion.
Generative recursion is the alternative:

Many well-known recursive algorithms generate an entirely new piece of data from the given data and recur on it.  HtDP (How to Design Programs) refers to this kind as generative recursion.  Examples of generative recursion include: gcd, quicksort, binary search, mergesort, Newton's method, fractals, and adaptive integration.
This distinction is important in proving termination of a function.

All structurally recursive functions on finite (inductively defined) data structures can easily be shown to terminate, via structural induction: intuitively, each recursive call receives a smaller piece of input data, until a base case is reached.
Generatively recursive functions, in contrast, do not necessarily feed smaller input to their recursive calls, so proof of their termination is not necessarily as simple, and avoiding infinite loops requires greater care. These generatively recursive functions can often be interpreted as corecursive functions – each step generates the new data, such as successive approximation in Newton's method – and terminating this corecursion requires that the data eventually satisfy some condition, which is not necessarily guaranteed.
In terms of loop variants, structural recursion is when there is an obvious loop variant, namely size or complexity, which starts off finite and decreases at each recursive step.
By contrast, generative recursion is when there is not such an obvious loop variant, and termination depends on a function, such as ""error of approximation"" that does not necessarily decrease to zero, and thus termination is not guaranteed without further analysis.


== Implementation issues ==
In actual implementation, rather than a pure recursive function (single check for base case, otherwise recursive step), a number of modifications may be made, for purposes of clarity or efficiency. These include:

Wrapper function (at top)
Short-circuiting the base case, aka ""Arm's-length recursion"" (at bottom)
Hybrid algorithm (at bottom) – switching to a different algorithm once data is small enoughOn the basis of elegance, wrapper functions are generally approved, while short-circuiting the base case is frowned upon, particularly in academia. Hybrid algorithms are often used for efficiency, to reduce the overhead of recursion in small cases, and arm's-length recursion is a special case of this.


=== Wrapper function ===
A wrapper function is a function that is directly called but does not recurse itself, instead calling a separate auxiliary function which actually does the recursion.
Wrapper functions can be used to validate parameters (so the recursive function can skip these), perform initialization (allocate memory, initialize variables), particularly for auxiliary variables such as ""level of recursion"" or partial computations for memoization, and handle exceptions and errors. In languages that support nested functions, the auxiliary function can be nested inside the wrapper function and use a shared scope. In the absence of nested functions, auxiliary functions are instead a separate function, if possible private (as they are not called directly), and information is shared with the wrapper function by using pass-by-reference.


=== Short-circuiting the base case ===

Short-circuiting the base case, also known as arm's-length recursion, consists of checking the base case before making a recursive call – i.e., checking if the next call will be the base case, instead of calling and then checking for the base case. Short-circuiting is particularly done for efficiency reasons, to avoid the overhead of a function call that immediately returns. Note that since the base case has already been checked for (immediately before the recursive step), it does not need to be checked for separately, but one does need to use a wrapper function for the case when the overall recursion starts with the base case itself. For example, in the factorial function, properly the base case is 0! = 1, while immediately returning 1 for 1! is a short circuit, and may miss 0; this can be mitigated by a wrapper function. The box shows C code to shortcut factorial cases 0 and 1.
Short-circuiting is primarily a concern when many base cases are encountered, such as Null pointers in a tree, which can be linear in the number of function calls, hence significant savings for O(n) algorithms; this is illustrated below for a depth-first search. Short-circuiting on a tree corresponds to considering a leaf (non-empty node with no children) as the base case, rather than considering an empty node as the base case. If there is only a single base case, such as in computing the factorial, short-circuiting provides only O(1) savings.
Conceptually, short-circuiting can be considered to either have the same base case and recursive step, checking the base case only before the recursion, or it can be considered to have a different base case (one step removed from standard base case) and a more complex recursive step, namely ""check valid then recurse"", as in considering leaf nodes rather than Null nodes as base cases in a tree. Because short-circuiting has a more complicated flow, compared with the clear separation of base case and recursive step in standard recursion, it is often considered poor style, particularly in academia.


==== Depth-first search ====
A basic example of short-circuiting is given in depth-first search (DFS) of a binary tree; see binary trees section for standard recursive discussion.
The standard recursive algorithm for a DFS is:

base case: If current node is Null, return false
recursive step: otherwise, check value of current node, return true if match, otherwise recurse on childrenIn short-circuiting, this is instead:

check value of current node, return true if match,
otherwise, on children, if not Null, then recurse.In terms of the standard steps, this moves the base case check before the recursive step. Alternatively, these can be considered a different form of base case and recursive step, respectively. Note that this requires a wrapper function to handle the case when the tree itself is empty (root node is Null).
In the case of a perfect binary tree of height h, there are 2h+1−1 nodes and 2h+1 Null pointers as children (2 for each of the 2h leaves), so short-circuiting cuts the number of function calls in half in the worst case.
In C, the standard recursive algorithm may be implemented as:

The short-circuited algorithm may be implemented as:

Note the use of short-circuit evaluation of the Boolean && (AND) operators, so that the recursive call is made only if the node is valid (non-Null). Note that while the first term in the AND is a pointer to a node, the second term is a boolean, so the overall expression evaluates to a boolean. This is a common idiom in recursive short-circuiting. This is in addition to the short-circuit evaluation of the Boolean || (OR) operator, to only check the right child if the left child fails. In fact, the entire control flow of these functions can be replaced with a single Boolean expression in a return statement, but legibility suffers at no benefit to efficiency.


=== Hybrid algorithm ===
Recursive algorithms are often inefficient for small data, due to the overhead of repeated function calls and returns. For this reason efficient implementations of recursive algorithms often start with the recursive algorithm, but then switch to a different algorithm when the input becomes small. An important example is merge sort, which is often implemented by switching to the non-recursive insertion sort when the data is sufficiently small, as in the tiled merge sort. Hybrid recursive algorithms can often be further refined, as in Timsort, derived from a hybrid merge sort/insertion sort.


== Recursion versus iteration ==
Recursion and iteration are equally expressive: recursion can be replaced by iteration with an explicit call stack, while iteration can be replaced with tail recursion. Which approach is preferable depends on the problem under consideration and the language used. In imperative programming, iteration is preferred, particularly for simple recursion, as it avoids the overhead of function calls and call stack management, but recursion is generally used for multiple recursion. By contrast, in functional languages recursion is preferred, with tail recursion optimization leading to little overhead. Implementing an algorithm using iteration may not be easily achievable.
Compare the templates to compute xn defined by xn = f(n, xn-1) from xbase:

For an imperative language the overhead is to define the function, and for a functional language the overhead is to define the accumulator variable x.
For example, a factorial function may be implemented iteratively in C by assigning to a loop index variable and accumulator variable, rather than by passing arguments and returning values by recursion:


=== Expressive power ===
Most programming languages in use today allow the direct specification of recursive functions and procedures. When such a function is called, the program's runtime environment keeps track of the various instances of the function (often using a call stack, although other methods may be used). Every recursive function can be transformed into an iterative function by replacing recursive calls with iterative control constructs and simulating the call stack with a stack explicitly managed by the program.Conversely, all iterative functions and procedures that can be evaluated by a computer (see Turing completeness) can be expressed in terms of recursive functions; iterative control constructs such as while loops and for loops are routinely rewritten in recursive form in functional languages. However, in practice this rewriting depends on tail call elimination, which is not a feature of all languages. C, Java, and Python are notable mainstream languages in which all function calls, including tail calls, may cause stack allocation that would not occur with the use of looping constructs; in these languages, a working iterative program rewritten in recursive form may overflow the call stack, although tail call elimination may be a feature that is not covered by a language's specification, and different implementations of the same language may differ in tail call elimination capabilities.


=== Performance issues ===
In languages (such as C and Java) that favor iterative looping constructs, there is usually significant time and space cost associated with recursive programs, due to the overhead required to manage the stack and the relative slowness of function calls; in functional languages, a function call (particularly a tail call) is typically a very fast operation, and the difference is usually less noticeable.
As a concrete example, the difference in performance between recursive and iterative implementations of the ""factorial"" example above depends highly on the compiler used. In languages where looping constructs are preferred, the iterative version may be as much as several orders of magnitude faster than the recursive one. In functional languages, the overall time difference of the two implementations may be negligible; in fact, the cost of multiplying the larger numbers first rather than the smaller numbers (which the iterative version given here happens to do) may overwhelm any time saved by choosing iteration.


=== Stack space ===
In some programming languages, the maximum size of the call stack is much less than the space available in the heap, and recursive algorithms tend to require more stack space than iterative algorithms. Consequently, these languages sometimes place a limit on the depth of recursion to avoid stack overflows; Python is one such language. Note the caveat below regarding the special case of tail recursion.


=== Vulnerability ===
Because recursive algorithms can be subject to stack overflows, they may be vulnerable to pathological or malicious input. Some malware specifically targets a program's call stack and takes advantage of the stack's inherently recursive nature. Even in the absence of malware, a stack overflow caused by unbounded recursion can be fatal to the program, and exception handling logic may not prevent the corresponding process from being terminated.


=== Multiply recursive problems ===
Multiply recursive problems are inherently recursive, because of prior state they need to track. One example is tree traversal as in depth-first search; though both recursive and iterative methods are used, they contrast with list traversal and linear search in a list, which is a singly recursive and thus naturally iterative method. Other examples include divide-and-conquer algorithms such as Quicksort, and functions such as the Ackermann function. All of these algorithms can be implemented iteratively with the help of an explicit stack, but the programmer effort involved in managing the stack, and the complexity of the resulting program, arguably outweigh any advantages of the iterative solution.


=== Refactoring recursion ===
Recursive algorithms can be replaced with non-recursive counterparts. One method for replacing recursive algorithms is to simulate them using heap memory in place of stack memory. An alternative is to develop a replacement algorithm entirely based on non-recursive methods, which can be challenging. For example, recursive algorithms for matching wildcards, such as Rich Salz' wildmat algorithm, were once typical. Non-recursive algorithms for the same purpose, such as the Krauss matching wildcards algorithm, have been developed to avoid the drawbacks of recursion and have improved only gradually based on techniques such as collecting tests and profiling performance.


== Tail-recursive functions ==
Tail-recursive functions are functions in which all recursive calls are tail calls and hence do not build up any deferred operations. For example, the gcd function (shown again below) is tail-recursive.  In contrast, the factorial function (also below) is not tail-recursive; because its recursive call is not in tail position, it builds up deferred multiplication operations that must be performed after the final recursive call completes.  With a compiler or interpreter that treats tail-recursive calls as jumps rather than function calls, a tail-recursive function such as gcd will execute using constant space.  Thus the program is essentially iterative, equivalent to using imperative language control structures like the ""for"" and ""while"" loops.

The significance of tail recursion is that when making a tail-recursive call (or any tail call), the caller's return position need not be saved on the call stack; when the recursive call returns, it will branch directly on the previously saved return position. Therefore, in languages that recognize this property of tail calls, tail recursion saves both space and time.


== Order of execution ==
Consider these two functions:


=== Function 1 ===


=== Function 2 ===

Function 2 is function 1 with the lines swapped.
In the case of a function calling itself only once, instructions placed before the recursive call are executed once per recursion before any of the instructions placed after the recursive call. The latter are executed repeatedly after the maximum recursion has been reached. 
Also note that the order of the print statements is reversed, which is due to the way the functions and statements are stored on the call stack.


== Recursive procedures ==


=== Factorial ===
A classic example of a recursive procedure is the function used to calculate the factorial of a natural number:

  
    
      
        fact
        ⁡
        (
        n
        )
        =
        
          
            {
            
              
                
                  1
                
                
                  
                    
                      if 
                    
                  
                  n
                  =
                  0
                
              
              
                
                  n
                  ⋅
                  fact
                  ⁡
                  (
                  n
                  −
                  1
                  )
                
                
                  
                    
                      if 
                    
                  
                  n
                  >
                  0
                
              
            
            
          
        
      
    
    {\displaystyle \operatorname {fact} (n)={\begin{cases}1&{\mbox{if }}n=0\\n\cdot \operatorname {fact} (n-1)&{\mbox{if }}n>0\\\end{cases}}}
  The function can also be written as a recurrence relation:

  
    
      
        
          b
          
            n
          
        
        =
        n
        
          b
          
            n
            −
            1
          
        
      
    
    {\displaystyle b_{n}=nb_{n-1}}
  

  
    
      
        
          b
          
            0
          
        
        =
        1
      
    
    {\displaystyle b_{0}=1}
  This evaluation of the recurrence relation demonstrates the computation that would be performed in evaluating the pseudocode above:

This factorial function can also be described without using recursion by making use of the typical looping constructs found in imperative programming languages:

The imperative code above is equivalent to this mathematical definition using an accumulator variable t:

  
    
      
        
          
            
              
                fact
                ⁡
                (
                n
                )
              
              
                
                =
                
                  f
                  a
                  c
                  
                    t
                    
                      a
                      c
                      c
                    
                  
                
                ⁡
                (
                n
                ,
                1
                )
              
            
            
              
                
                  f
                  a
                  c
                  
                    t
                    
                      a
                      c
                      c
                    
                  
                
                ⁡
                (
                n
                ,
                t
                )
              
              
                
                =
                
                  
                    {
                    
                      
                        
                          t
                        
                        
                          
                            
                              if 
                            
                          
                          n
                          =
                          0
                        
                      
                      
                        
                          
                            f
                            a
                            c
                            
                              t
                              
                                a
                                c
                                c
                              
                            
                          
                          ⁡
                          (
                          n
                          −
                          1
                          ,
                          n
                          t
                          )
                        
                        
                          
                            
                              if 
                            
                          
                          n
                          >
                          0
                        
                      
                    
                    
                  
                
              
            
          
        
      
    
    {\displaystyle {\begin{aligned}\operatorname {fact} (n)&=\operatorname {fact_{acc}} (n,1)\\\operatorname {fact_{acc}} (n,t)&={\begin{cases}t&{\mbox{if }}n=0\\\operatorname {fact_{acc}} (n-1,nt)&{\mbox{if }}n>0\\\end{cases}}\end{aligned}}}
  The definition above translates straightforwardly to functional programming languages such as Scheme; this is an example of iteration implemented recursively.


=== Greatest common divisor ===
The Euclidean algorithm, which computes the greatest common divisor of two integers, can be written recursively.
Function definition:

  
    
      
        gcd
        (
        x
        ,
        y
        )
        =
        
          
            {
            
              
                
                  x
                
                
                  
                    
                      if 
                    
                  
                  y
                  =
                  0
                
              
              
                
                  gcd
                  (
                  y
                  ,
                  remainder
                  ⁡
                  (
                  x
                  ,
                  y
                  )
                  )
                
                
                  
                    
                      if 
                    
                  
                  y
                  >
                  0
                
              
            
            
          
        
      
    
    {\displaystyle \gcd(x,y)={\begin{cases}x&{\mbox{if }}y=0\\\gcd(y,\operatorname {remainder} (x,y))&{\mbox{if }}y>0\\\end{cases}}}
  Recurrence relation for greatest common divisor, where 
  
    
      
        x
        %
        y
      
    
    {\displaystyle x\%y}
   expresses the remainder of 
  
    
      
        x
        
          /
        
        y
      
    
    {\displaystyle x/y}
  :

  
    
      
        gcd
        (
        x
        ,
        y
        )
        =
        gcd
        (
        y
        ,
        x
        %
        y
        )
      
    
    {\displaystyle \gcd(x,y)=\gcd(y,x\%y)}
   if 
  
    
      
        y
        ≠
        0
      
    
    {\displaystyle y\neq 0}
  

  
    
      
        gcd
        (
        x
        ,
        0
        )
        =
        x
      
    
    {\displaystyle \gcd(x,0)=x}
  The recursive program above is tail-recursive; it is equivalent to an iterative algorithm, and the computation shown above shows the steps of evaluation that would be performed by a language that eliminates tail calls.  Below is a version of the same algorithm using explicit iteration, suitable for a language that does not eliminate tail calls.  By maintaining its state entirely in the variables x and y and using a looping construct, the program avoids making recursive calls and growing the call stack.

The iterative algorithm requires a temporary variable, and even given knowledge of the Euclidean algorithm it is more difficult to understand the process by simple inspection, although the two algorithms are very similar in their steps.


=== Towers of Hanoi ===

The Towers of Hanoi is a mathematical puzzle whose solution illustrates recursion. There are three pegs which can hold stacks of disks of different diameters. A larger disk may never be stacked on top of a smaller. Starting with n disks on one peg, they must be moved to another peg one at a time. What is the smallest number of steps to move the stack?
Function definition:

  
    
      
        hanoi
        ⁡
        (
        n
        )
        =
        
          
            {
            
              
                
                  1
                
                
                  
                    
                      if 
                    
                  
                  n
                  =
                  1
                
              
              
                
                  2
                  ⋅
                  hanoi
                  ⁡
                  (
                  n
                  −
                  1
                  )
                  +
                  1
                
                
                  
                    
                      if 
                    
                  
                  n
                  >
                  1
                
              
            
            
          
        
      
    
    {\displaystyle \operatorname {hanoi} (n)={\begin{cases}1&{\mbox{if }}n=1\\2\cdot \operatorname {hanoi} (n-1)+1&{\mbox{if }}n>1\\\end{cases}}}
  Recurrence relation for hanoi:

  
    
      
        
          h
          
            n
          
        
        =
        2
        
          h
          
            n
            −
            1
          
        
        +
        1
      
    
    {\displaystyle h_{n}=2h_{n-1}+1}
  

  
    
      
        
          h
          
            1
          
        
        =
        1
      
    
    {\displaystyle h_{1}=1}
  Example implementations:

Although not all recursive functions have an explicit solution, the Tower of Hanoi sequence can be reduced to an explicit formula.


=== Binary search ===
The binary search algorithm is a method of searching a sorted array for a single element by cutting the array in half with each recursive pass.  The trick is to pick a midpoint near the center of the array, compare the data at that point with the data being searched and then responding to one of three possible conditions: the data is found at the midpoint, the data at the midpoint is greater than the data being searched for, or the data at the midpoint is less than the data being searched for.
Recursion is used in this algorithm because with each pass a new array is created by cutting the old one in half.  The binary search procedure is then called recursively, this time on the new (and smaller) array.  Typically the array's size is adjusted by manipulating a beginning and ending index.  The algorithm exhibits a logarithmic order of growth because it essentially divides the problem domain in half with each pass.
Example implementation of binary search in C:


== Recursive data structures (structural recursion) ==

An important application of recursion in computer science is in defining dynamic data structures such as lists and trees.  Recursive data structures can dynamically grow to a theoretically infinite size in response to runtime requirements; in contrast, the size of a static array must be set at compile time.

""Recursive algorithms are particularly appropriate when the underlying problem or the data to be treated are defined in recursive terms.""

The examples in this section illustrate what is known as ""structural recursion"".  This term refers to the fact that the recursive procedures are acting on data that is defined recursively.

As long as a programmer derives the template from a data definition, functions employ structural recursion. That is, the recursions in a function's body consume some immediate piece of a given compound value.


=== Linked lists ===

Below is a C definition of a linked list node structure.  Notice especially how the node is defined in terms of itself.  The ""next"" element of struct node is a pointer to another struct node, effectively creating a list type.

Because the struct node data structure is defined recursively, procedures that operate on it can be implemented naturally as recursive procedures.  The list_print procedure defined below walks down the list until the list is empty (i.e., the list pointer has a value of NULL).  For each node it prints the data element (an integer).  In the C implementation, the list remains unchanged by the list_print procedure.


=== Binary trees ===

Below is a simple definition for a binary tree node.  Like the node for linked lists, it is defined in terms of itself, recursively.  There are two self-referential pointers: left (pointing to the left sub-tree) and right (pointing to the right sub-tree).

Operations on the tree can be implemented using recursion.  Note that because there are two self-referencing pointers (left and right), tree operations may require two recursive calls:

At most two recursive calls will be made for any given call to tree_contains as defined above.

The above example illustrates an in-order traversal of the binary tree.  A Binary search tree is a special case of the binary tree where the data elements of each node are in order.


=== Filesystem traversal ===
Since the number of files in a filesystem may vary, recursion is the only practical way to traverse and thus enumerate its contents.  Traversing a filesystem is very similar to that of tree traversal, therefore the concepts behind tree traversal are applicable to traversing a filesystem.  More specifically, the code below would be an example of a preorder traversal of a filesystem.

This code is both recursion and iteration - the files and directories are iterated, and each directory is opened recursively.
The ""rtraverse"" method is an example of direct recursion, whilst the ""traverse"" method is a wrapper function.
The ""base case"" scenario is that there will always be a fixed number of files and/or directories in a given filesystem.


== Time-efficiency of recursive algorithms ==
The time efficiency of recursive algorithms can be expressed in a recurrence relation of Big O notation.  They can (usually) then be simplified into a single Big-O term.


=== Shortcut rule (master theorem) ===

If the time-complexity of the function is in the form

Then the Big O of the time-complexity is thus:

If 
  
    
      
        f
        (
        n
        )
        =
        O
        (
        
          n
          
            
              log
              
                b
              
            
            ⁡
            a
            −
            ε
          
        
        )
      
    
    {\displaystyle f(n)=O(n^{\log _{b}a-\varepsilon })}
   for some constant 
  
    
      
        ε
        >
        0
      
    
    {\displaystyle \varepsilon >0}
  , then 
  
    
      
        T
        (
        n
        )
        =
        Θ
        (
        
          n
          
            
              log
              
                b
              
            
            ⁡
            a
          
        
        )
      
    
    {\displaystyle T(n)=\Theta (n^{\log _{b}a})}
  
If 
  
    
      
        f
        (
        n
        )
        =
        Θ
        (
        
          n
          
            
              log
              
                b
              
            
            ⁡
            a
          
        
        )
      
    
    {\displaystyle f(n)=\Theta (n^{\log _{b}a})}
  , then 
  
    
      
        T
        (
        n
        )
        =
        Θ
        (
        
          n
          
            
              log
              
                b
              
            
            ⁡
            a
          
        
        log
        ⁡
        n
        )
      
    
    {\displaystyle T(n)=\Theta (n^{\log _{b}a}\log n)}
  
If 
  
    
      
        f
        (
        n
        )
        =
        Ω
        (
        
          n
          
            
              log
              
                b
              
            
            ⁡
            a
            +
            ε
          
        
        )
      
    
    {\displaystyle f(n)=\Omega (n^{\log _{b}a+\varepsilon })}
   for some constant 
  
    
      
        ε
        >
        0
      
    
    {\displaystyle \varepsilon >0}
  , and if 
  
    
      
        a
        ⋅
        f
        (
        n
        
          /
        
        b
        )
        ≤
        c
        ⋅
        f
        (
        n
        )
      
    
    {\displaystyle a\cdot f(n/b)\leq c\cdot f(n)}
   for some constant c < 1 and all sufficiently large n, then 
  
    
      
        T
        (
        n
        )
        =
        Θ
        (
        f
        (
        n
        )
        )
      
    
    {\displaystyle T(n)=\Theta (f(n))}
  where a represents the number of recursive calls at each level of recursion, b represents by what factor smaller the input is for the next level of recursion (i.e. the number of pieces you divide the problem into), and f(n) represents the work that the function does independently of any recursion (e.g. partitioning, recombining) at each level of recursion.


== See also ==
Functional programming
Computational problem
Hierarchical and recursive queries in SQL
Kleene–Rosser paradox
Open recursion
Recursion
Sierpiński curve
McCarthy 91 function
μ-recursive functions
Primitive recursive functions
Tak (function)


== Notes ==


== References =="
0cb941072e,Paxos (computer science),"Paxos is a family of protocols for solving consensus in a network of unreliable or fallible processors.
Consensus is the process of agreeing on one result among a group of participants.  This problem becomes difficult when the participants or their communications may experience failures.Consensus protocols are the basis for the state machine replication approach to distributed computing, as suggested by Leslie Lamport and surveyed by Fred Schneider.  State machine replication is a technique for converting an algorithm into a fault-tolerant, distributed implementation.  Ad-hoc techniques may leave important cases of failures unresolved.  The principled approach proposed by Lamport et al. ensures all cases are handled safely.
The Paxos protocol was first submitted in 1989 and named after a fictional legislative consensus system used on the Paxos island in Greece, where Lamport wrote that the parliament had to function ""even though legislators continually wandered in and out of the parliamentary Chamber"". It was later published as a journal article in 1998.The Paxos family of protocols includes a spectrum of trade-offs between the number of processors, number of message delays before learning the agreed value, the activity level of individual participants, number of messages sent, and types of failures.  Although no deterministic fault-tolerant consensus protocol can guarantee progress in an asynchronous network (a result proved in a paper by Fischer, Lynch and Paterson), Paxos guarantees safety (consistency), and the conditions that could prevent it from making progress are difficult to provoke.
Paxos is usually used where durability is required (for example, to replicate a file or a database), in which the amount of durable state could be large. The protocol attempts to make progress even during periods when some bounded number of replicas are unresponsive. There is also a mechanism to drop a permanently failed replica or to add a new replica.


== History ==
The topic predates the protocol. In 1988, Lynch, Dwork and Stockmeyer had demonstrated  the solvability of consensus in a broad family of ""partially synchronous"" systems.  Paxos has strong similarities to a protocol used for agreement in ""viewstamped replication"", first published by Oki and Liskov in 1988, in the context of distributed transactions.  Notwithstanding this prior work, Paxos offered a particularly elegant formalism, and included one of the earliest proofs of safety for a fault-tolerant distributed consensus protocol.
Reconfigurable state machines have strong ties to prior work on reliable group multicast protocols that support dynamic group membership, for example Birman's work in 1985 and 1987 on the virtually synchronous gbcast protocol. However, gbcast is unusual in supporting durability and addressing partitioning failures.
Most reliable multicast protocols lack these properties, which are required for implementations of the state machine replication model.
This point is elaborated in a paper by Lamport, Malkhi and Zhou.Paxos protocols are members of a theoretical class of solutions to a problem formalized as uniform agreement with crash failures.
Lower bounds for this problem have been proved by Keidar and Shraer.  Derecho, a C++ software library for cloud-scale state machine replication, offers a Paxos protocol that has been integrated with self-managed virtually synchronous membership.  This protocol matches the Keidar and Shraer optimality bounds, and maps efficiently to modern remote DMA (RDMA) datacenter hardware (but uses TCP if RDMA is not available).


== Assumptions ==
In order to simplify the presentation of Paxos, the following assumptions and definitions are made explicit.  Techniques to broaden the applicability are known in the literature, and are not covered in this article.


=== Processors ===
Processors operate at arbitrary speed.
Processors may experience failures.
Processors with stable storage may re-join the protocol after failures (following a crash-recovery failure model).
Processors do not collude, lie, or otherwise attempt to subvert the protocol. (That is, Byzantine failures don't occur. See Byzantine Paxos for a solution that tolerates failures that arise from arbitrary/malicious behavior of the processes.)


=== Network ===
Processors can send messages to any other processor.
Messages are sent asynchronously and may take arbitrarily long to deliver.
Messages may be lost, reordered, or duplicated.
Messages are delivered without corruption. (That is, Byzantine failures don't occur. See Byzantine Paxos for a solution which tolerates corrupted messages that arise from arbitrary/malicious behavior of the messaging channels.)


=== Number of processors ===
In general, a consensus algorithm can make progress using 
  
    
      
        n
        =
        2
        F
        +
        1
      
    
    {\displaystyle n=2F+1}
   processors, despite the simultaneous failure of any 
  
    
      
        F
      
    
    {\displaystyle F}
   processors: in other words, the number of non-faulty processes must be strictly greater than the number of faulty processes. However, using reconfiguration, a protocol may be employed which survives any number of total failures as long as no more than F fail simultaneously. For Paxos protocols, these reconfigurations can be handled as separate configurations.


== Roles ==
Paxos describes the actions of the processors by their roles in the protocol: client, acceptor, proposer, learner, and leader.  In typical implementations, a single processor may play one or more roles at the same time.  This does not affect the correctness of the protocol—it is usual to coalesce roles to improve the latency and/or number of messages in the protocol.

Client
The Client issues a request to the distributed system, and waits for a response.  For instance, a write request on a file in a distributed file server.
 Acceptor (Voters)
The Acceptors act as the fault-tolerant ""memory"" of the protocol. Acceptors are collected into groups called Quorums.  Any message sent to an Acceptor must be sent to a Quorum of Acceptors. Any message received from an Acceptor is ignored unless a copy is received from each Acceptor in a Quorum.
 Proposer
A Proposer advocates a client request, attempting to convince the Acceptors to agree on it, and acting as a coordinator to move the protocol forward when conflicts occur.
Learner
Learners act as the replication factor for the protocol.  Once a Client request has been agreed upon by the Acceptors, the Learner may take action (i.e.: execute the request and send a response to the client).  To improve availability of processing, additional Learners can be added.
 Leader
Paxos requires a distinguished Proposer (called the leader) to make progress.  Many processes may believe they are leaders, but the protocol only guarantees progress if one of them is eventually chosen.  If two processes believe they are leaders, they may stall the protocol by continuously proposing conflicting updates.  However, the safety properties are still preserved in that case.


=== Quorums ===
Quorums express the safety (or consistency) properties of Paxos by ensuring at least some surviving processor retains knowledge of the results.
Quorums are defined as subsets of the set of Acceptors such that any two Quorums share at least one member. Typically, a Quorum is any majority of participating Acceptors. For example, given the set of Acceptors {A,B,C,D}, a majority Quorum would be any three Acceptors:  {A,B,C}, {A,C,D}, {A,B,D}, {B,C,D}. More generally, arbitrary positive weights can be assigned to Acceptors; in that case, a Quorum can be defined as any subset of Acceptors with the summary weight greater than half of the total weight of all Acceptors.


=== Proposal number and agreed value ===
Each attempt to define an agreed value v is performed with proposals which may or may not be accepted by Acceptors. Each proposal is uniquely numbered for a given Proposer. So, e.g., each proposal may be of the form (n, v), where n is the unique identifier of the proposal and v is the actual proposed value. The value corresponding to a numbered proposal can be computed as part of running the Paxos protocol, but need not be.


== Safety and liveness properties ==
In order to guarantee safety (also called ""consistency""), Paxos defines three properties and ensures the first two are always held, regardless of the pattern of failures:

Validity (or non-triviality)
Only proposed values can be chosen and learned.
Agreement (or consistency, or safety)
No two distinct learners can learn different values (or there can't be more than one decided value)
Termination (or liveness)
If value C has been proposed, then eventually learner L will learn some value (if sufficient processors remain non-faulty).Note that Paxos is not guaranteed to terminate, and thus does not have the liveness property. This is supported by the Fischer Lynch Paterson impossibility result (FLP) which states that a consistency protocol can only have two of safety, liveness, and fault tolerance. As Paxos's point is to ensure fault tolerance and it guarantees safety, it cannot also guarantee liveness.


== Typical deployment ==
In most deployments of Paxos, each participating process acts in three roles; Proposer, Acceptor and Learner.  This reduces the message complexity significantly, without sacrificing correctness:

In Paxos, clients send commands to a leader. During normal operation, the leader receives a client's command, assigns it a new command number 
  
    
      
        i
      
    
    {\displaystyle i}
  , and then begins the 
  
    
      
        i
      
    
    {\displaystyle i}
  th instance of the consensus algorithm by sending messages to a set of acceptor processes.
By merging roles, the protocol ""collapses"" into an efficient client-master-replica style deployment, typical of the database community.  The benefit of the Paxos protocols (including implementations with merged roles) is the guarantee of its safety properties.
A typical implementation's message flow is covered in the section Multi-Paxos.


== Basic Paxos ==
This protocol is the most basic of the Paxos family. Each ""instance"" (or ""execution"") of the basic Paxos protocol decides on a single output value. The protocol proceeds over several rounds. A successful round has 2 phases: phase 1 (which is divided into parts a and b) and phase 2 (which is divided into parts a and b). See below the description of the phases. Remember that we assume an asynchronous model, so e.g. a processor may be in one phase while another processor may be in another. 


=== Phase 1 ===


==== Phase 1a: Prepare ====
A Proposer creates a message, which we call a ""Prepare"", identified with a number n. Note that n is not the value to be proposed and maybe agreed on, but just a number which uniquely identifies this initial message by the proposer (to be sent to the acceptors). The number n must be greater than any number used in any of the previous Prepare messages by this Proposer. Then, it sends the Prepare message containing n to at least a Quorum of Acceptors. Note that the Prepare message only contains the number n (that is, it does not have to contain e.g. the proposed value, often denoted by v). The Proposer decides who is in the Quorum. A Proposer should not initiate Paxos if it cannot communicate with at least a Quorum of Acceptors.


==== Phase 1b: Promise ====
Any of the Acceptors waits for a Prepare message from any of the Proposers. If an Acceptor receives a Prepare message, the Acceptor must look at the identifier number n of the just received Prepare message. There are two cases.If n is higher than every previous proposal number received, from any of the Proposers, by the Acceptor, then the Acceptor must return a message, which we call a ""Promise"", to the Proposer, to ignore all future proposals having a number less than n. If the Acceptor accepted a proposal at some point in the past, it must include the previous proposal number, say m, and the corresponding accepted value, say w, in its response to the Proposer.Otherwise (that is, n is less than or equal to any previous proposal number received from any Proposer by the Acceptor) the Acceptor can ignore the received proposal. It does not have to answer in this case for Paxos to work. However, for the sake of optimization, sending a denial (Nack) response would tell the Proposer that it can stop its attempt to create consensus with proposal n.


=== Phase 2 ===


==== Phase 2a: Accept ====
If a Proposer receives Promises from a Quorum of Acceptors, it needs to set a value v to its proposal. If any Acceptors had previously accepted any proposal, then they'll have sent their values to the Proposer, who now must set the value of its proposal, v, to the value associated with the highest proposal number reported by the Acceptors, let's call it z. If none of the Acceptors had accepted a proposal up to this point, then the Proposer may choose the value it originally wanted to propose, say x.The Proposer sends an Accept message, (n, v), to a Quorum of Acceptors with the chosen value for its proposal, v, and the proposal number n (which is the same as the number contained in the Prepare message previously sent to the Acceptors). So, the Accept message is either (n, v=z) or, in case none of the Acceptors previously accepted a value, (n, v=x).This Accept message should be interpreted as a ""request"", as in ""Accept this proposal, please!"".


==== Phase 2b: Accepted ====
If an Acceptor receives an Accept message, (n, v), from a Proposer, it must accept it if and only if it has not already promised (in Phase 1b of the Paxos protocol) to only consider proposals having an identifier greater than n.If the Acceptor has not already promised (in Phase 1b) to only consider proposals having an identifier greater than n, it should register the value v (of the just received Accept message) as the accepted value (of the Protocol), and send an Accepted message to the Proposer and every Learner (which can typically be the Proposers themselves).Else, it can ignore the Accept message or request.Note that consensus is achieved when a majority of Acceptors accept the same identifier number (rather than the same value).  Because each identifier is unique to a Proposer and only one value may be proposed per identifier, all Acceptors that accept the same identifier thereby accept the same value.  These facts result in a few counter-intuitive scenarios that do not impact correctness: Acceptors can accept multiple values, a value may achieve a majority across Acceptors (with different identifiers) only to later be changed, and Acceptors may continue to accept proposals after an identifier has achieved a majority.  However, the Paxos protocol guarantees that consensus is permanent and the chosen value is immutable.


=== When rounds fail ===
Rounds fail when multiple Proposers send conflicting Prepare messages, or when the Proposer does not receive a Quorum of responses (Promise or Accepted).  In these cases, another round must be started with a higher proposal number.


=== Paxos can be used to select a leader ===
Notice that a Proposer in Paxos could propose ""I am the leader,"" (or, for example, ""Proposer X is the leader""). Because of the agreement and validity guarantees of Paxos, if accepted by a Quorum, then the Proposer is now known to be the leader to all other nodes. This satisfies the needs of leader election because there is a single node believing it is the leader and a single node known to be the leader at all times.


=== Graphic representation of the flow of messages in the basic Paxos ===
The following diagrams represent several cases/situations of the application of the Basic Paxos protocol. Some cases show how the Basic Paxos protocol copes with the failure of certain (redundant) components of the distributed system.
Note that the values returned in the Promise message are ""null"" the first time a proposal is made (since no Acceptor has accepted a value before in this round).


==== Basic Paxos without failures ====
In the diagram below, there is 1 Client, 1 Proposer, 3 Acceptors (i.e. the Quorum size is 3) and 2 Learners (represented by the 2 vertical lines). This diagram represents the case of a first round, which is successful (i.e. no process in the network fails).

Here, V is the last of (Va, Vb, Vc).


==== Error cases in basic Paxos ====
The simplest error cases are the failure of an Acceptor (when a Quorum of Acceptors remains alive) and failure of a redundant Learner. In these cases, the protocol requires no ""recovery"" (i.e. it still succeeds): no additional rounds or messages are required, as shown below (in the next two diagrams/cases).


==== Basic Paxos when an Acceptor fails ====
In the following diagram, one of the Acceptors in the Quorum fails, so the Quorum size becomes 2. In this case, the Basic Paxos protocol still succeeds.

Client   Proposer      Acceptor     Learner
   |         |          |  |  |       |  |
   X-------->|          |  |  |       |  |  Request
   |         X--------->|->|->|       |  |  Prepare(1)
   |         |          |  |  !       |  |  !! FAIL !!
   |         |<---------X--X          |  |  Promise(1,{Va, Vb, null})
   |         X--------->|->|          |  |  Accept!(1,V)
   |         |<---------X--X--------->|->|  Accepted(1,V)
   |<---------------------------------X--X  Response
   |         |          |  |          |  |


==== Basic Paxos when a redundant learner fails ====
In the following case, one of the (redundant) Learners fails, but the Basic Paxos protocol still succeeds. 

Client Proposer         Acceptor     Learner
   |         |          |  |  |       |  |
   X-------->|          |  |  |       |  |  Request
   |         X--------->|->|->|       |  |  Prepare(1)
   |         |<---------X--X--X       |  |  Promise(1,{Va,Vb,Vc})
   |         X--------->|->|->|       |  |  Accept!(1,V)
   |         |<---------X--X--X------>|->|  Accepted(1,V)
   |         |          |  |  |       |  !  !! FAIL !!
   |<---------------------------------X     Response
   |         |          |  |  |       |


==== Basic Paxos when a Proposer fails ====
In this case, a Proposer fails after proposing a value, but before the agreement is reached. Specifically, it fails in the middle of the Accept message, so only one Acceptor of the Quorum receives the value. Meanwhile, a new Leader (a Proposer) is elected (but this is not shown in detail). Note that there are 2 rounds in this case (rounds proceed vertically, from the top to the bottom).

Client  Proposer        Acceptor     Learner
   |      |             |  |  |       |  |
   X----->|             |  |  |       |  |  Request
   |      X------------>|->|->|       |  |  Prepare(1)
   |      |<------------X--X--X       |  |  Promise(1,{Va, Vb, Vc})
   |      |             |  |  |       |  |
   |      |             |  |  |       |  |  !! Leader fails during broadcast !!
   |      X------------>|  |  |       |  |  Accept!(1,V)
   |      !             |  |  |       |  |
   |         |          |  |  |       |  |  !! NEW LEADER !!
   |         X--------->|->|->|       |  |  Prepare(2)
   |         |<---------X--X--X       |  |  Promise(2,{V, null, null})
   |         X--------->|->|->|       |  |  Accept!(2,V)
   |         |<---------X--X--X------>|->|  Accepted(2,V)
   |<---------------------------------X--X  Response
   |         |          |  |  |       |  |


==== Basic Paxos when multiple Proposers conflict ====
The most complex case is when multiple Proposers believe themselves to be Leaders.  For instance, the current leader may fail and later recover, but the other Proposers have already re-selected a new leader.  The recovered leader has not learned this yet and attempts to begin one round in conflict with the current leader. In the diagram below, 4 unsuccessful rounds are shown, but there could be more (as suggested at the bottom of the diagram).

Client   Proposer       Acceptor     Learner
   |      |             |  |  |       |  |
   X----->|             |  |  |       |  |  Request
   |      X------------>|->|->|       |  |  Prepare(1)
   |      |<------------X--X--X       |  |  Promise(1,{null,null,null})
   |      !             |  |  |       |  |  !! LEADER FAILS
   |         |          |  |  |       |  |  !! NEW LEADER (knows last number was 1)
   |         X--------->|->|->|       |  |  Prepare(2)
   |         |<---------X--X--X       |  |  Promise(2,{null,null,null})
   |      |  |          |  |  |       |  |  !! OLD LEADER recovers
   |      |  |          |  |  |       |  |  !! OLD LEADER tries 2, denied
   |      X------------>|->|->|       |  |  Prepare(2)
   |      |<------------X--X--X       |  |  Nack(2)
   |      |  |          |  |  |       |  |  !! OLD LEADER tries 3
   |      X------------>|->|->|       |  |  Prepare(3)
   |      |<------------X--X--X       |  |  Promise(3,{null,null,null})
   |      |  |          |  |  |       |  |  !! NEW LEADER proposes, denied
   |      |  X--------->|->|->|       |  |  Accept!(2,Va)
   |      |  |<---------X--X--X       |  |  Nack(3)
   |      |  |          |  |  |       |  |  !! NEW LEADER tries 4
   |      |  X--------->|->|->|       |  |  Prepare(4)
   |      |  |<---------X--X--X       |  |  Promise(4,{null,null,null})
   |      |  |          |  |  |       |  |  !! OLD LEADER proposes, denied
   |      X------------>|->|->|       |  |  Accept!(3,Vb)
   |      |<------------X--X--X       |  |  Nack(4)
   |      |  |          |  |  |       |  |  ... and so on ...


==== Basic Paxos where an Acceptor accepts Two Different Values ====
In the following case, one Proposer achieves acceptance of value V1 by one Acceptor before failing.  A new Proposer prepares the Acceptors that never accepted V1, allowing it to propose V2. Then V2 is accepted by all Acceptors, including the one that initially accepted V1. 

Proposer    Acceptor     Learner
 |  |       |  |  |       |  |
 X--------->|->|->|       |  |  Prepare(1)
 |<---------X--X--X       |  |  Promise(1,{null,null,null})
 x--------->|  |  |       |  |  Accept!(1,V1)
 |  |       X------------>|->|  Accepted(1,V1)
 !  |       |  |  |       |  |  !! FAIL !!
    |       |  |  |       |  |
    X--------->|->|       |  |  Prepare(2)
    |<---------X--X       |  |  Promise(2,{null,null})
    X------>|->|->|       |  |  Accept!(2,V2)
    |<------X--X--X------>|->|  Accepted(2,V2)
    |       |  |  |       |  |


==== Basic Paxos where a multi-identifier majority is insufficient ====
In the following case, one Proposer achieves acceptance of value V1 of one Acceptor before failing.  A new Proposer prepares the Acceptors that never accepted V1, allowing it to propose V2. This Proposer is able to get one Acceptor to accept V2 before failing.  A new Proposer finds a majority that includes the Acceptor that has accepted V1, and must propose it. The Proposer manages to get two Acceptors to accept it before failing.  At this point, three Acceptors have accepted V1, but not for the same identifier.  Finally, a new Proposer prepares the majority that has not seen the largest accepted identifier.  The value associated with the largest identifier in that majority is V2, so it must propose it.  This Proposer then gets all Acceptors to accept V2, achieving consensus. 

  Proposer           Acceptor        Learner
 |  |  |  |       |  |  |  |  |       |  |
 X--------------->|->|->|->|->|       |  |  Prepare(1)
 |<---------------X--X--X--X--X       |  |  Promise(1,{null,null,null,null,null})
 x--------------->|  |  |  |  |       |  |  Accept!(1,V1)
 |  |  |  |       X------------------>|->|  Accepted(1,V1)
 !  |  |  |       |  |  |  |  |       |  |  !! FAIL !!
    |  |  |       |  |  |  |  |       |  |
    X--------------->|->|->|->|       |  |  Prepare(2)
    |<---------------X--X--X--X       |  |  Promise(2,{null,null,null,null})
    X--------------->|  |  |  |       |  |  Accept!(2,V2)
    |  |  |       |  X--------------->|->|  Accepted(2,V2)
    !  |  |       |  |  |  |  |       |  |  !! FAIL !!
       |  |       |  |  |  |  |       |  | 
       X--------->|---->|->|->|       |  |  Prepare(3)
       |<---------X-----X--X--X       |  |  Promise(3,{V1,null,null,null})
       X--------------->|->|  |       |  |  Accept!(3,V1)
       |  |       |  |  X--X--------->|->|  Accepted(3,V1)
       !  |       |  |  |  |  |       |  |  !! FAIL !!
          |       |  |  |  |  |       |  |
          X------>|->|------->|       |  |  Prepare(4)
          |<------X--X--|--|--X       |  |  Promise(4,{V1(1),V2(2),null})
          X------>|->|->|->|->|       |  |  Accept!(4,V2)
          |       X--X--X--X--X------>|->|  Accepted(4,V2)


==== Basic Paxos where new Proposers cannot change an existing consensus ====
In the following case, one Proposer achieves acceptance of value V1 of two Acceptors before failing.  A new Proposer may start another round, but it is now impossible for that proposer to prepare a majority that doesn't include at least one Acceptor that has accepted V1.  As such, even though the Proposer doesn't see the existing consensus, the Proposer's only option is to propose the value already agreed upon.  New Proposers can continually increase the identifier to restart the process, but the consensus can never be changed. 

Proposer    Acceptor     Learner
 |  |       |  |  |       |  |
 X--------->|->|->|       |  |  Prepare(1)
 |<---------X--X--X       |  |  Promise(1,{null,null,null})
 x--------->|->|  |       |  |  Accept!(1,V1)
 |  |       X--X--------->|->|  Accepted(1,V1)
 !  |       |  |  |       |  |  !! FAIL !!
    |       |  |  |       |  |
    X--------->|->|       |  |  Prepare(2)
    |<---------X--X       |  |  Promise(2,{V1,null})
    X------>|->|->|       |  |  Accept!(2,V1)
    |<------X--X--X------>|->|  Accepted(2,V1)
    |       |  |  |       |  |


== Multi-Paxos ==
A typical deployment of Paxos requires a continuous stream of agreed values acting as commands to a distributed state machine.  If each command is the result of a single instance of the Basic Paxos protocol, a significant amount of overhead would result.
If the leader is relatively stable, phase 1 becomes unnecessary. Thus, it is possible to skip phase 1 for future instances of the protocol with the same leader.
To achieve this, the round number I is included along with each value which is incremented in each round by the same Leader.  Multi-Paxos reduces the failure-free message delay (proposal to learning) from 4 delays to 2 delays.


=== Graphic representation of the flow of messages in the Multi-Paxos ===


==== Multi-Paxos without failures ====
In the following diagram, only one instance (or ""execution"") of the basic Paxos protocol, with an initial Leader (a Proposer), is shown. Note that a Multi-Paxos consists of several instances of the basic Paxos protocol.

Client   Proposer      Acceptor     Learner
   |         |          |  |  |       |  | --- First Request ---
   X-------->|          |  |  |       |  |  Request
   |         X--------->|->|->|       |  |  Prepare(N)
   |         |<---------X--X--X       |  |  Promise(N,I,{Va,Vb,Vc})
   |         X--------->|->|->|       |  |  Accept!(N,I,V)
   |         |<---------X--X--X------>|->|  Accepted(N,I,V)
   |<---------------------------------X--X  Response
   |         |          |  |  |       |  |

where V = last of (Va, Vb, Vc).


==== Multi-Paxos when phase 1 can be skipped ====
In this case, subsequent instances of the basic Paxos protocol (represented by I+1) use the same leader, so the phase 1 (of these subsequent instances of the basic Paxos protocol), which consist of the Prepare and Promise sub-phases, is skipped. Note that the Leader should be stable, i.e. it should not crash or change.

Client   Proposer       Acceptor     Learner
   |         |          |  |  |       |  |  --- Following Requests ---
   X-------->|          |  |  |       |  |  Request
   |         X--------->|->|->|       |  |  Accept!(N,I+1,W)
   |         |<---------X--X--X------>|->|  Accepted(N,I+1,W)
   |<---------------------------------X--X  Response
   |         |          |  |  |       |  |


==== Multi-Paxos when roles are collapsed ====
A common deployment of the Multi-Paxos consists in collapsing the role of the Proposers, Acceptors and Learners to ""Servers"". So, in the end, there are only ""Clients"" and ""Servers"".
The following diagram represents the first ""instance"" of a basic Paxos protocol, when the roles of the Proposer, Acceptor and Learner are collapsed to a single role, called the ""Server"".

Client      Servers
   |         |  |  | --- First Request ---
   X-------->|  |  |  Request
   |         X->|->|  Prepare(N)
   |         |<-X--X  Promise(N, I, {Va, Vb})
   |         X->|->|  Accept!(N, I, Vn)
   |         X<>X<>X  Accepted(N, I)
   |<--------X  |  |  Response
   |         |  |  |


==== Multi-Paxos when roles are collapsed and the leader is steady ====
In the subsequent instances of the basic Paxos protocol, with the same leader as in the previous instances of the basic Paxos protocol, the phase 1 can be skipped.

Client      Servers
   X-------->|  |  |  Request
   |         X->|->|  Accept!(N,I+1,W)
   |         X<>X<>X  Accepted(N,I+1)
   |<--------X  |  |  Response
   |         |  |  |


== Optimisations ==
A number of optimisations can be performed to reduce the number of exchanged messages, to improve the performance of the protocol, etc. A few of these optimisations are reported below.

""We can save messages at the cost of an extra message delay by having a single distinguished learner that informs the other learners when it finds out that a value has been chosen. Acceptors then send Accepted messages only to the distinguished learner.  In most applications, the roles of leader and distinguished learner are performed by the same processor.""A leader can send its Prepare and Accept! messages just to a quorum of acceptors. As long as all acceptors in that quorum are working and can communicate with the leader and the learners, there is no need for acceptors not in the quorum to do anything.""Acceptors do not care what value is chosen. They simply respond to Prepare and Accept! messages to ensure that, despite failures, only a single value can be chosen. However, if an acceptor does learn what value has been chosen, it can store the value in stable storage and erase any other information it has saved there. If the acceptor later receives a Prepare or Accept! message, instead of performing its Phase1b or Phase2b action, it can simply inform the leader of the chosen value.""Instead of sending the value v, the leader can send a hash of v to some acceptors in its Accept! messages. A learner will learn that v is chosen if it receives Accepted messages for either v or its hash from a quorum of acceptors, and at least one of those messages contains v rather than its hash. However, a leader could receive Promise messages that tell it the hash of a value v that it must use in its Phase2a action without telling it the actual value of v. If that happens, the leader cannot execute its Phase2a action until it communicates with some process that knows v.""""A proposer can send its proposal only to the leader rather than to all coordinators. However, this requires that the result of the leader-selection algorithm be broadcast to the proposers, which might be expensive. So, it might be better to let the proposer send its proposal to all coordinators. (In that case, only the coordinators themselves need to know who the leader is.)""Instead of each acceptor sending Accepted messages to each learner, acceptors can send their Accepted messages to the leader and the leader can inform the learners when a value has been chosen. However, this adds an extra message delay.""Finally, observe that phase 1 is unnecessary for round 1 .. The leader of round 1 can begin the round by sending an Accept! message with any proposed value.""


== Cheap Paxos ==
Cheap Paxos extends Basic Paxos to tolerate F failures with F+1 main processors and F auxiliary processors by dynamically reconfiguring after each failure.
This reduction in processor requirements comes at the expense of liveness; if too many main processors fail in a short time, the system must halt until the auxiliary processors can reconfigure the system.  During stable periods, the auxiliary processors take no part in the protocol.

""With only two processors p and q, one processor cannot distinguish failure of the other processor from failure of the communication medium. A third processor is needed. However, that third processor does not have to participate in choosing the sequence of commands. It must take action only in case p or q fails, after which it does nothing while either p or q continues to operate the system by itself. The third processor can therefore be a small/slow/cheap one, or a processor primarily devoted to other tasks.""


=== Message flow: Cheap Multi-Paxos ===
An example involving three main acceptors, one auxiliary acceptor and quorum size of three, showing failure of one main processor and subsequent reconfiguration:

            {  Acceptors  }
Proposer     Main       Aux    Learner
|            |  |  |     |       |  -- Phase 2 --
X----------->|->|->|     |       |  Accept!(N,I,V)
|            |  |  !     |       |  --- FAIL! ---
|<-----------X--X--------------->|  Accepted(N,I,V)
|            |  |        |       |  -- Failure detected (only 2 accepted) --
X----------->|->|------->|       |  Accept!(N,I,V)  (re-transmit, include Aux)
|<-----------X--X--------X------>|  Accepted(N,I,V)
|            |  |        |       |  -- Reconfigure : Quorum = 2 --
X----------->|->|        |       |  Accept!(N,I+1,W) (Aux not participating)
|<-----------X--X--------------->|  Accepted(N,I+1,W)
|            |  |        |       |


== Fast Paxos ==
Fast Paxos generalizes Basic Paxos to reduce end-to-end message delays.  In Basic Paxos, the message delay from client request to learning is 3 message delays.  Fast Paxos allows 2 message delays, but requires that (1) the system be composed of 3f+ 1 acceptors to tolerate up to f faults (instead of the classic 2f+1), and (2) the Client to send its request to multiple destinations.
Intuitively, if the leader has no value to propose, then a client could send an Accept! message to the Acceptors directly.  The Acceptors would respond as in Basic Paxos, sending Accepted messages to the leader and every Learner achieving two message delays from Client to Learner.
If the leader detects a collision, it resolves the collision by sending Accept! messages for a new round which are Accepted as usual.  This coordinated recovery technique requires four message delays from Client to Learner.
The final optimization occurs when the leader specifies a recovery technique in advance, allowing the Acceptors to perform the collision recovery themselves.  Thus, uncoordinated collision recovery can occur in three message delays (and only two message delays if all Learners are also Acceptors).


=== Message flow: Fast Paxos, non-conflicting ===
Client    Leader         Acceptor      Learner
   |         |          |  |  |  |       |  |
   |         X--------->|->|->|->|       |  |  Any(N,I,Recovery)
   |         |          |  |  |  |       |  |
   X------------------->|->|->|->|       |  |  Accept!(N,I,W)
   |         |<---------X--X--X--X------>|->|  Accepted(N,I,W)
   |<------------------------------------X--X  Response(W)
   |         |          |  |  |  |       |  |


=== Message flow: Fast Paxos, conflicting proposals ===
Conflicting proposals with coordinated recovery.  Note: the protocol does not specify how to handle the dropped client request.

Client   Leader      Acceptor     Learner
 |  |      |        |  |  |  |      |  |
 |  |      |        |  |  |  |      |  |
 |  |      |        |  |  |  |      |  |  !! Concurrent conflicting proposals
 |  |      |        |  |  |  |      |  |  !!   received in different order
 |  |      |        |  |  |  |      |  |  !!   by the Acceptors
 |  X--------------?|-?|-?|-?|      |  |  Accept!(N,I,V)
 X-----------------?|-?|-?|-?|      |  |  Accept!(N,I,W)
 |  |      |        |  |  |  |      |  |
 |  |      |        |  |  |  |      |  |  !! Acceptors disagree on value
 |  |      |<-------X--X->|->|----->|->|  Accepted(N,I,V)
 |  |      |<-------|<-|<-X--X----->|->|  Accepted(N,I,W)
 |  |      |        |  |  |  |      |  |
 |  |      |        |  |  |  |      |  |  !! Detect collision & recover
 |  |      X------->|->|->|->|      |  |  Accept!(N+1,I,W)
 |  |      |<-------X--X--X--X----->|->|  Accepted(N+1,I,W)
 |<---------------------------------X--X  Response(W)
 |  |      |        |  |  |  |      |  |

Conflicting proposals with uncoordinated recovery. 

Client   Leader      Acceptor     Learner
 |  |      |        |  |  |  |      |  |
 |  |      X------->|->|->|->|      |  |  Any(N,I,Recovery)
 |  |      |        |  |  |  |      |  |
 |  |      |        |  |  |  |      |  |  !! Concurrent conflicting proposals
 |  |      |        |  |  |  |      |  |  !!   received in different order
 |  |      |        |  |  |  |      |  |  !!   by the Acceptors
 |  X--------------?|-?|-?|-?|      |  |  Accept!(N,I,V)
 X-----------------?|-?|-?|-?|      |  |  Accept!(N,I,W)
 |  |      |        |  |  |  |      |  |
 |  |      |        |  |  |  |      |  |  !! Acceptors disagree on value
 |  |      |<-------X--X->|->|----->|->|  Accepted(N,I,V)
 |  |      |<-------|<-|<-X--X----->|->|  Accepted(N,I,W)
 |  |      |        |  |  |  |      |  |
 |  |      |        |  |  |  |      |  |  !! Detect collision & recover
 |  |      |<-------X--X--X--X----->|->|  Accepted(N+1,I,W)
 |<---------------------------------X--X  Response(W)
 |  |      |        |  |  |  |      |  |


=== Message flow: Fast Paxos with uncoordinated recovery, collapsed roles ===
(merged Acceptor/Learner roles)

Client         Servers
 |  |         |  |  |  |
 |  |         X->|->|->|  Any(N,I,Recovery)
 |  |         |  |  |  |
 |  |         |  |  |  |  !! Concurrent conflicting proposals
 |  |         |  |  |  |  !!   received in different order
 |  |         |  |  |  |  !!   by the Servers
 |  X--------?|-?|-?|-?|  Accept!(N,I,V)
 X-----------?|-?|-?|-?|  Accept!(N,I,W)
 |  |         |  |  |  |
 |  |         |  |  |  |  !! Servers disagree on value
 |  |         X<>X->|->|  Accepted(N,I,V)
 |  |         |<-|<-X<>X  Accepted(N,I,W)
 |  |         |  |  |  |
 |  |         |  |  |  |  !! Detect collision & recover
 |  |         X<>X<>X<>X  Accepted(N+1,I,W)
 |<-----------X--X--X--X  Response(W)
 |  |         |  |  |  |


== Generalized Paxos ==
Generalized consensus explores the relationship between the operations of the replicated state machine and the consensus protocol that implements it. The main discovery involves optimizations of Paxos when conflicting proposals could be applied in any order.  i.e., when the proposed operations are commutative operations for the state machine. In such cases, the conflicting operations can both be accepted, avoiding the delays required for resolving conflicts and re-proposing the rejected operations.
This concept is further generalized into ever-growing sequences of commutative operations, some of which are known to be stable (and thus may be executed).  The protocol tracks these sequences ensuring that all proposed operations of one sequence are stabilized before allowing any operation non-commuting with them to become stable.


=== Example ===
In order to illustrate Generalized Paxos, the example below shows a message flow between two concurrently executing clients and a replicated state machine implementing read/write operations over two distinct registers A and B.

Note that  in this table indicates operations which are non-commutative.
A possible sequence of operations :

 <1:Read(A), 2:Read(B), 3:Write(B), 4:Read(B), 5:Read(A), 6:Write(A)> 
Since 5:Read(A) commutes with both 3:Write(B) and 4:Read(B), one possible permutation equivalent to the previous order is the following:

 <1:Read(A), 2:Read(B), 5:Read(A), 3:Write(B), 4:Read(B), 6:Write(A)> 
In practice, a commute occurs only when operations are proposed concurrently.


=== Message flow: Generalized Paxos (example) ===
Responses not shown. Note: message abbreviations differ from previous message flows due to specifics of the protocol, see  for a full discussion.

Client      Leader  Acceptor       Learner
 |  |         |      |  |  |         |  |  !! New Leader Begins Round
 |  |         X----->|->|->|         |  |  Prepare(N)
 |  |         |<-----X- X- X         |  |  Promise(N,null)
 |  |         X----->|->|->|         |  |  Phase2Start(N,null)
 |  |         |      |  |  |         |  | 
 |  |         |      |  |  |         |  |  !! Concurrent commuting proposals
 |  X------- ?|-----?|-?|-?|         |  |  Propose(ReadA)
 X-----------?|-----?|-?|-?|         |  |  Propose(ReadB)
 |  |         X------X-------------->|->|  Accepted(N,<ReadA,ReadB>)
 |  |         |<--------X--X-------->|->|  Accepted(N,<ReadB,ReadA>)
 |  |         |      |  |  |         |  |
 |  |         |      |  |  |         |  |  !! No Conflict, both accepted
 |  |         |      |  |  |         |  |  Stable = <ReadA, ReadB>
 |  |         |      |  |  |         |  |
 |  |         |      |  |  |         |  |  !! Concurrent conflicting proposals
 X-----------?|-----?|-?|-?|         |  |  Propose(<WriteB,ReadA>)
 |  X--------?|-----?|-?|-?|         |  |  Propose(ReadB)
 |  |         |      |  |  |         |  |
 |  |         X------X-------------->|->|  Accepted(N,<WriteB,ReadA> . <ReadB>)
 |  |         |<--------X--X-------->|->|  Accepted(N,<ReadB> . <WriteB,ReadA>)
 |  |         |      |  |  |         |  |
 |  |         |      |  |  |         |  |  !! Conflict detected, leader chooses
 |  |         |      |  |  |         |  |  commutative order:
 |  |         |      |  |  |         |  |  V = <ReadA, WriteB, ReadB>
 |  |         |      |  |  |         |  |
 |  |         X----->|->|->|         |  |  Phase2Start(N+1,V)
 |  |         |<-----X- X- X-------->|->|  Accepted(N+1,V)
 |  |         |      |  |  |         |  |  Stable = <ReadA, ReadB> .
 |  |         |      |  |  |         |  |           <ReadA, WriteB, ReadB>
 |  |         |      |  |  |         |  |
 |  |         |      |  |  |         |  | !! More conflicting proposals
 X-----------?|-----?|-?|-?|         |  |  Propose(WriteA)
 |  X--------?|-----?|-?|-?|         |  |  Propose(ReadA)
 |  |         |      |  |  |         |  |
 |  |         X------X-------------->|->|  Accepted(N+1,<WriteA> . <ReadA>)
 |  |         |<--------X- X-------->|->|  Accepted(N+1,<ReadA> . <WriteA>)
 |  |         |      |  |  |         |  |
 |  |         |      |  |  |         |  |  !! Leader chooses order:
 |  |         |      |  |  |         |  |  W = <WriteA, ReadA>
 |  |         |      |  |  |         |  |
 |  |         X----->|->|->|         |  |  Phase2Start(N+2,W)
 |  |         |<-----X- X- X-------->|->|  Accepted(N+2,W)
 |  |         |      |  |  |         |  |  Stable = <ReadA, ReadB> .
 |  |         |      |  |  |         |  |           <ReadA, WriteB, ReadB> .
 |  |         |      |  |  |         |  |           <WriteA, ReadA>
 |  |         |      |  |  |         |  |


=== Performance ===
The above message flow shows us that Generalized Paxos can leverage operation semantics to avoid collisions when the spontaneous ordering of the network fails. This allows the protocol to be in practice quicker than Fast Paxos. However, when a collision occurs, Generalized Paxos needs two additional round trips to recover. This situation is illustrated with operations WriteB and ReadB in the above schema.
In the general case, such round trips are unavoidable and come from the fact that multiple commands can be accepted during a round. This makes the protocol more expensive than Paxos when conflicts are frequent. Hopefully two possible refinements of Generalized Paxos are possible to improve recovery time.
First, if the coordinator is part of every quorum of acceptors (round N is said centered), then to recover at round N+1 from a collision at round N, the coordinator skips phase 1 and proposes at phase 2 the sequence it accepted last during round N. This reduces the cost of recovery to a single round trip.
Second, if both rounds N and N+1 use a unique and identical centered quorum, when an acceptor detects a collision at round N, it spontaneously proposes at round N+1 a sequence suffixing both (i) the sequence accepted at round N by the coordinator and (ii) the greatest non-conflicting prefix it accepted at round N. For instance, if the coordinator and the acceptor accepted respectively at round N <WriteB, ReadB>  and <ReadB, ReadA> , the acceptor will spontaneously accept <WriteB, ReadB, ReadA> at round N+1. With this variation, the cost of recovery is a single message delay which is obviously optimal. Notice here that the use of a unique quorum at a round does not harm liveness. This comes from the fact that any process in this quorum is a read quorum for the prepare phase of the next rounds.


== Byzantine Paxos ==
Paxos may also be extended to support arbitrary failures of the participants, including lying, fabrication of messages, collusion with other participants, selective non-participation, etc.  These types of failures are called Byzantine failures, after the solution popularized by Lamport.Byzantine Paxos introduced by Castro and Liskov adds an extra message (Verify) which acts to distribute knowledge and verify the actions of the other processors:


=== Message flow: Byzantine Multi-Paxos, steady state ===
Client   Proposer      Acceptor     Learner
   |         |          |  |  |       |  |
   X-------->|          |  |  |       |  |  Request
   |         X--------->|->|->|       |  |  Accept!(N,I,V)
   |         |          X<>X<>X       |  |  Verify(N,I,V) - BROADCAST
   |         |<---------X--X--X------>|->|  Accepted(N,V)
   |<---------------------------------X--X  Response(V)
   |         |          |  |  |       |  |

Fast Byzantine Paxos introduced by Martin and Alvisi removes this extra delay, since the client sends commands directly to the Acceptors.
Note the Accepted message in Fast Byzantine Paxos is sent to all Acceptors and all Learners, while Fast Paxos sends Accepted messages only to Learners):


=== Message flow: Fast Byzantine Multi-Paxos, steady state ===
Client    Acceptor     Learner
   |      |  |  |       |  |
   X----->|->|->|       |  |  Accept!(N,I,V)
   |      X<>X<>X------>|->|  Accepted(N,I,V) - BROADCAST
   |<-------------------X--X  Response(V)
   |      |  |  |       |  |

The failure scenario is the same for both protocols;  Each Learner waits to receive F+1 identical messages from different Acceptors.  If this does not occur, the Acceptors themselves will also be aware of it (since they exchanged each other's messages in the broadcast round), and correct Acceptors will re-broadcast the agreed value:


=== Message flow: Fast Byzantine Multi-Paxos, failure ===
Client    Acceptor     Learner
   |      |  |  !       |  |  !! One Acceptor is faulty
   X----->|->|->!       |  |  Accept!(N,I,V)
   |      X<>X<>X------>|->|  Accepted(N,I,{V,W}) - BROADCAST
   |      |  |  !       |  |  !! Learners receive 2 different commands
   |      |  |  !       |  |  !! Correct Acceptors notice error and choose
   |      X<>X<>X------>|->|  Accepted(N,I,V) - BROADCAST
   |<-------------------X--X  Response(V)
   |      |  |  !       |  |


== Adapting Paxos for RDMA networks ==
With the emergence of very high speed reliable datacenter networks that support remote DMA (RDMA), there has been substantial interest in optimizing Paxos to leverage hardware offloading, in which the network interface card and network routers provide reliability and network-layer congestion control, freeing the host CPU for other tasks.  The Derecho C++ Paxos library is an open-source Paxos implementation that explores this option.Derecho offers both a classic Paxos, with data durability across full shutdown/restart sequences, and vertical Paxos (atomic multicast), for in-memory replication and state-machine synchronization.  The Paxos protocols employed by Derecho needed to be adapted to maximize asynchronous data streaming and remove other sources of delay on the leader's critical path.  So doing enables Derecho to sustain the full bidirectional RDMA data rate.  In contrast, although traditional Paxos protocols can be migrated to an RDMA network by simply mapping the message send operations to native RDMA operations, doing so leaves round-trip delays on the critical path.  In high-speed RDMA networks, even small delays can be large enough to prevent utilization of the full potential bandwidth.


== Production use of Paxos ==
Google uses the Paxos algorithm in their Chubby distributed lock service in order to keep replicas consistent in case of failure.  Chubby is used by Bigtable which is now in production in Google Analytics and other products.
Google Spanner and Megastore use the Paxos algorithm internally.
The OpenReplica replication service uses Paxos to maintain replicas for an open access system that enables users to create fault-tolerant objects. It provides high performance through concurrent rounds and flexibility through dynamic membership changes.
IBM supposedly uses the Paxos algorithm in their IBM SAN Volume Controller product to implement a general purpose fault-tolerant virtual machine used to run the configuration and control components of the storage virtualization services offered by the cluster. (Original MIT & IBM research paper)
Microsoft uses Paxos in the Autopilot cluster management service from Bing, and in Windows Server Failover Clustering.
WANdisco have implemented Paxos within their DConE active-active replication technology.
XtreemFS uses a Paxos-based lease negotiation algorithm for fault-tolerant and consistent replication of file data and metadata.
Heroku uses Doozerd which implements Paxos for its consistent distributed data store.
Ceph uses Paxos as part of the monitor processes to agree which OSDs are up and in the cluster.
The MariaDB Xpand distributed SQL database uses Paxos for distributed transaction resolution.
Neo4j HA graph database implements Paxos, replacing Apache ZooKeeper from v1.9
Apache Cassandra NoSQL database uses Paxos for  Light Weight Transaction feature only
Amazon Elastic Container Services uses Paxos to maintain a consistent view of cluster state
Amazon DynamoDB uses the Paxos algorithm for leader election and consensus.


== See also ==
Chandra–Toueg consensus algorithm
State machine
Raft


== References ==


== External links ==
Leslie Lamport's home page
Paxos Made Simple
Paxos Made Moderately Complex
Revisiting the Paxos Algorithm
Paxos Commit
Google Whitepaper: Chubby Distributed Lock Service
Google Whitepaper: Bigtable A Distributed Storage System for Structured Data
Survey of Paxos Algorithms (2007)
OpenReplica Open Replication Service
FTFile: Fault Tolerant File library
Isis2 library (the SafeSend primitive is a free, open source implementation of Paxos)
Mencius - Circular rotating Paxos for geo-distributed systems
WANdisco - Active-Active Replication solutions for Hadoop, Subversion & GIT
libpaxos, a collection of open source implementations of the Paxos algorithm
libpaxos-cpp, a C++ implementation of the paxos distributed consensus algorithm
JBP - Java Byzantine Paxos
erlpaxos, Paxos by Erlang
paxos - Straight-forward paxos implementation in Python & Java
Manhattan Paxos (mpaxos), Paxos in C, supporting multiple paxos groups and efficient transactions across them.
Clustering with Neo4j
HT-Paxos
PaxosStore, paxos implementation in WeChat
LWT in Cassandra
Google TechTalks: The Paxos Algorithm"
e91903912d,Polling (computer science),"Polling, or polled operation, in computer science, refers to actively sampling the status of an external device by a client program as a synchronous activity. Polling is most often used in terms of input/output (I/O), and is also referred to as polled I/O or software-driven I/O. A good example of hardware implementation is a watchdog timer.


== Description ==
Polling is the process where the computer or controlling device waits for an external device to check for its readiness or state, often with low-level hardware. For example, when a printer is connected via a parallel port, the computer waits until the printer has received the next character. These processes can be as minute as only reading one bit. This is sometimes used synonymously with 'busy-wait' polling. In this situation, when an I/O operation is required, the computer does nothing other than check the status of the I/O device until it is ready, at which point the device is accessed. In other words, the computer waits until the device is ready. Polling also refers to the situation where a device is repeatedly checked for readiness, and if it is not, the computer returns to a different task. Although not as wasteful of CPU cycles as busy waiting, this is generally not as efficient as the alternative to polling, interrupt-driven I/O.
In a simple single-purpose system, even busy-wait is perfectly appropriate if no action is possible until the I/O access, but more often than not this was traditionally a consequence of simple hardware or non-multitasking operating systems.
Polling is often intimately involved with very low-level hardware. For example, polling a parallel printer port to check whether it is ready for another character involves examining as little as one bit of a byte. That bit represents, at the time of reading, whether a single wire in the printer cable is at low or high voltage. The I/O instruction that reads this byte directly transfers the voltage state of eight real world wires to the eight circuits (flip flops) that make up one byte of a CPU register.
Polling has the disadvantage that if there are too many devices to check, the time required to poll them can exceed the time available to service the I/O device.


=== Algorithm ===
Polling can be described in the following steps:
Host actions:

The host repeatedly reads the busy bit of the controller until it becomes clear (with a value of 0).
When clear, the host writes the command into the command register. If the host is sending output, it sets the write bit and writes a byte into the data-out register. If the host is receiving input, it reads the controller-written data from the data-in register, and sets the read bit to 0 as the next command.
The host sets the command-ready bit to 1.Controller actions:

When the controller notices that the command-ready bit is set, it sets the busy bit to 1.
The controller reads the command register. If the write bit inside is set, it reads from the data-out register and performs the necessary I/O operations on the device. If the read bit is set, data from the device is loaded into the data-in register for the host to read.
Once the operations are over, the controller clears the command-ready bit, clears the error bit to show the operation was successful, and clears the busy bit.


== Types ==
A polling cycle is the time in which each element is monitored once. The optimal polling cycle will vary according to several factors, including the desired speed of response and the overhead (e.g., processor time and bandwidth) of the polling.
In roll call polling, the polling device or process queries each element on a list in a fixed sequence. Because it waits for a response from each element, a timing mechanism is necessary to prevent lock-ups caused by non-responding elements. Roll call polling can be inefficient if the overhead for the polling messages is high, there are numerous elements to be polled in each polling cycle and only a few elements are active.
In hub polling, also referred to as token polling, each element polls the next element in some fixed sequence. This continues until the first element is reached, at which time the polling cycle starts all over again.
Polling can be employed in various computing contexts in order to control the execution or transmission sequence of the elements involved. For example, in multitasking operating systems, polling can be used to allocate processor time and other resources to the various competing processes.
In networks, polling is used to determine which nodes want to access the network. It is also used by routing protocols to retrieve routing information, as is the case with EGP (exterior gateway protocol).
An alternative to polling is the use of interrupts, which are signals generated by devices or processes to indicate that they need attention, want to communicate, etc. Although polling can be very simple, in many situations (e.g., multitasking operating systems) it is more efficient to use interrupts because it can reduce processor usage and/or bandwidth consumption.


== Poll message ==
A poll message is a control-acknowledgment message.
In a multidrop line arrangement (a central computer and different terminals in which the terminals share a single communication line to and from the computer), the system uses a master/slave polling arrangement whereby the central computer sends message (called polling message) to a specific terminal on the outgoing line. All terminals listen to the outgoing line, but only the terminal that is polled replies by sending any information that it has ready for transmission on the incoming line.In star networks, which, in its simplest form, consists of one central switch, hub, or computer that acts as a conduit to transmit messages, polling is not required to avoid chaos on the lines, but it is often used to allow the master to acquire input in an orderly fashion. These poll messages differ from those of the multidrop lines case because there are no site addresses needed, and each terminal only receives those polls that are directed to it.


== See also ==
Abstraction (computer science)
Asynchronous I/O
Bit banging
Infinite loop
Interrupt request (PC architecture)
Integer (computer science)
kqueue
Multiple asynchronous periodic polling
Pull technology
select (Unix)
Signal (IPC)


== References =="
e1fbb61f6e,State (computer science),"In information technology and computer science, a system is described as stateful if it is designed to remember preceding events or user interactions; the remembered information is called the state of the system.
The set of states a system can occupy is known as its state space. In a discrete system, the state space is countable and often finite. The system's internal behaviour or interaction with its environment consists of separately occurring individual actions or events, such as accepting input or producing output, that may or may not cause the system to change its state. Examples of such systems are digital logic circuits and components, automata and formal language, computer programs, and computers.  
The output of a digital circuit or deterministic computer program at any time is completely determined by its current inputs and its state.


== Digital logic circuit state ==
Digital logic circuits can be divided into two types: combinational logic, whose output signals are dependent only on its present input signals, and sequential logic, whose outputs are a function of both the current inputs and the past history of inputs. In sequential logic, information from past inputs is stored in electronic memory elements, such as flip-flops. The stored contents of these memory elements, at a given point in time, is collectively referred to as the circuit's state and contains all the information about the past to which the circuit has access.Since each binary memory element, such as a flip-flop, has only two possible states, one or zero, and there is a finite number of memory elements, a digital circuit has only a certain finite number of possible states. If N is the number of binary memory elements in the circuit, the maximum number of states a circuit can have is 2N.


== Program state ==
Similarly, a computer program stores data in variables, which represent storage locations in the computer's memory. The contents of these memory locations, at any given point in the program's execution, is called the program's state.A more specialized definition of state is used for computer programs that operate serially or sequentially on streams of data, such as parsers, firewalls, communication protocols and encryption. Serial programs operate on the incoming data characters or packets sequentially, one at a time. In some of these programs, information about previous data characters or packets received is stored in variables and used to affect the processing of the current character or packet. This is called a stateful protocol and the data carried over from the previous processing cycle is called the state. In others, the program has no information about the previous data stream and starts fresh with each data input; this is called a stateless protocol.
Imperative programming is a programming paradigm (way of designing a programming language) that describes computation in terms of the program state, and of the statements which change the program state. Changes of state are implicit, managed by the program runtime, so that a subroutine has visibility of the changes of state made by other parts of the program, known as side effects.
In declarative programming languages, the program describes the desired results and doesn't specify changes to the state directly.
In functional programming, state is usually represented with temporal logic as explicit variables that represent the program state at each step of a program execution: a state variable is passed as an input parameter of a state-transforming function, which returns the updated state as part of its return value. A pure functional subroutine only has visibility of changes of state represented by the state variables in its scope.


== Finite state machines ==
The output of a sequential circuit or computer program at any time is completely determined by its current inputs and current state. Since each binary memory element has only two possible states, 0 or 1, the total number of different states a circuit can assume is finite, and fixed by the number of memory elements. If there are N binary memory elements, a digital circuit can have at most 2N distinct states. The concept of state is formalized in an abstract mathematical model of computation called a finite state machine, used to design both sequential digital circuits and computer programs.


== Examples ==
An example of an everyday device that has a state is a television set. To change the channel of a TV, the user usually presses a ""channel up"" or ""channel down"" button on the remote control, which sends a coded message to the set. In order to calculate the new channel that the user desires, the digital tuner in the television must have stored in it the number of the current channel it is on. It then adds one or subtracts one from this number to get the number for the new channel, and adjusts the TV to receive that channel. This new number is then stored as the current channel. Similarly, the television also stores a number that controls the level of volume produced by the speaker. Pressing the ""volume up"" or ""volume down"" buttons increments or decrements this number, setting a new level of volume. Both the current channel and current volume numbers are part of the TV's state. They are stored in non-volatile memory, which preserves the information when the TV is turned off, so when it is turned on again the TV will return to its previous station and volume level.
As another example, the state of a microprocessor is the contents of all the memory elements in it: the accumulators, storage registers, data caches, and flags. When computers such as laptops go into a hibernation mode to save energy by shutting down the processor, the state of the processor is stored on the computer's hard disk, so it can be restored when the computer comes out of hibernation, and the processor can take up operations where it left off.


== See also ==
Data (computing)


== References =="
433ebe8967,Garbage collection (computer science),"In computer science, garbage collection (GC) is a form of automatic memory management. The garbage collector attempts to reclaim memory which was allocated by the program, but is no longer referenced; such memory is called garbage. Garbage collection was invented by American computer scientist John McCarthy around 1959 to simplify manual memory management in Lisp.Garbage collection relieves the programmer from doing manual memory management, where the programmer specifies what objects to de-allocate and return to the memory system and when to do so. Other, similar techniques include stack allocation, region inference, and memory ownership, and combinations thereof. Garbage collection may take a significant proportion of a program's total processing time, and affect performance as a result.
Resources other than memory, such as network sockets, database handles, windows, file descriptors, and device descriptors, are not typically handled by garbage collection, but rather by other methods (e.g. destructors). Some such methods de-allocate memory also.


== Overview ==
Many programming languages require garbage collection, either as part of the language specification (e.g., RPL, Java, C#, D, Go, and most scripting languages) or effectively for practical implementation (e.g., formal languages like lambda calculus). These are said to be garbage-collected languages. Other languages, such as C and C++, were designed for use with manual memory management, but have garbage-collected implementations available. Some languages, like Ada, Modula-3, and C++/CLI, allow both garbage collection and manual memory management to co-exist in the same application by using separate heaps for collected and manually managed objects. Still others, like D, are garbage-collected but allow the user to manually delete objects or even disable garbage collection entirely when speed is required.
Although many languages integrate GC into their compiler and runtime system, post-hoc GC systems also exist, such as Automatic Reference Counting (ARC). Some of these post-hoc GC systems do not require recompilation. Post-hoc GC is sometimes called litter collection, to distinguish it from ordinary GC.


=== Advantages ===
GC frees the programmer from manually de-allocating memory. This helps avoid some kinds of errors:

Dangling pointers, which occur when a piece of memory is freed while there are still pointers to it, and one of those pointers is dereferenced. By then the memory may have been reassigned to another use, with unpredictable results.
Double free bugs, which occur when the program tries to free a region of memory that has already been freed, and perhaps already been allocated again.
Certain kinds of memory leaks, in which a program fails to free memory occupied by objects that have become unreachable, which can lead to memory exhaustion.


=== Disadvantages ===
GC uses computing resources to decide which memory to free. Therefore, the penalty for the convenience of not annotating object lifetime manually in the source code is overhead, which can impair program performance. A peer-reviewed paper from 2005 concluded that GC needs five times the memory to compensate for this overhead and to perform as fast as the same program using idealised explicit memory management. The comparison however is made to a program generated by inserting deallocation calls using an oracle, implemented by collecting traces from programs run under a profiler, and the program is only correct for one particular execution of the program. Interaction with memory hierarchy effects can make this overhead intolerable in circumstances that are hard to predict or to detect in routine testing. The impact on performance was given by Apple as a reason for not adopting garbage collection in iOS, despite it being the most desired feature.The moment when the garbage is actually collected can be unpredictable, resulting in stalls (pauses to shift/free memory) scattered throughout a session. Unpredictable stalls can be unacceptable in real-time environments, in transaction processing, or in interactive programs. Incremental, concurrent, and real-time garbage collectors address these problems, with varying trade-offs.


== Strategies ==


=== Tracing ===

Tracing garbage collection is the most common type of garbage collection, so much so that ""garbage collection"" often refers to tracing garbage collection, rather than other methods such as reference counting. The overall strategy consists of determining which objects should be garbage collected by tracing which objects are reachable by a chain of references from certain root objects, and considering the rest as garbage and collecting them. However, there are a large number of algorithms used in implementation, with widely varying complexity and performance characteristics.


=== Reference counting ===

Reference counting garbage collection is where each object has a count of the number of references to it. Garbage is identified by having a reference count of zero. An object's reference count is incremented when a reference to it is created, and decremented when a reference is destroyed. When the count reaches zero, the object's memory is reclaimed.As with manual memory management, and unlike tracing garbage collection, reference counting guarantees that objects are destroyed as soon as their last reference is destroyed, and usually only accesses memory which is either in CPU caches, in objects to be freed, or directly pointed to by those, and thus tends to not have significant negative side effects on CPU cache and virtual memory operation.
There are a number of disadvantages to reference counting; this can generally be solved or mitigated by more sophisticated algorithms:

Cycles
If two or more objects refer to each other, they can create a cycle whereby neither will be collected as their mutual references never let their reference counts become zero. Some garbage collection systems using reference counting (like the one in CPython) use specific cycle-detecting algorithms to deal with this issue. Another strategy is to use weak references for the ""backpointers"" which create cycles. Under reference counting, a weak reference is similar to a weak reference under a tracing garbage collector. It is a special reference object whose existence does not increment the reference count of the referent object. Furthermore, a weak reference is safe in that when the referent object becomes garbage, any weak reference to it lapses, rather than being permitted to remain dangling, meaning that it turns into a predictable value, such as a null reference.Space overhead (reference count)
Reference counting requires space to be allocated for each object to store its reference count. The count may be stored adjacent to the object's memory or in a side table somewhere else, but in either case, every single reference-counted object requires additional storage for its reference count. Memory space with the size of an unsigned pointer is commonly used for this task, meaning that 32 or 64 bits of reference count storage must be allocated for each object. On some systems, it may be possible to mitigate this overhead by using a tagged pointer to store the reference count in unused areas of the object's memory. Often, an architecture does not actually allow programs to access the full range of memory addresses that could be stored in its native pointer size; certain number of high bits in the address is either ignored or required to be zero. If an object reliably has a pointer at a certain location, the reference count can be stored in the unused bits of the pointer. For example, each object in Objective-C has a pointer to its class at the beginning of its memory; on the ARM64 architecture using iOS 7, 19 unused bits of this class pointer are used to store the object's reference count.Speed overhead (increment/decrement)
In naive implementations, each assignment of a reference and each reference falling out of scope often require modifications of one or more reference counters. However, in a common case when a reference is copied from an outer scope variable into an inner scope variable, such that the lifetime of the inner variable is bounded by the lifetime of the outer one, the reference incrementing can be eliminated. The outer variable ""owns"" the reference. In the programming language C++, this technique is readily implemented and demonstrated with the use of const references. Reference counting in C++ is usually implemented using ""smart pointers"" whose constructors, destructors and assignment operators manage the references. A smart pointer can be passed by reference to a function, which avoids the need to copy-construct a new smart pointer (which would increase the reference count on entry into the function and decrease it on exit). Instead the function receives a reference to the smart pointer which is produced inexpensively. The Deutsch-Bobrow method of reference counting capitalizes on the fact that most reference count updates are in fact generated by references stored in local variables. It ignores these references, only counting references in the heap, but before an object with reference count zero can be deleted, the system must verify with a scan of the stack and registers that no other reference to it still exists. A further substantial decrease in the overhead on counter updates can be obtained by update coalescing introduced by Levanoni and Petrank. Consider a pointer that in a given interval of the execution is updated several times. It first points to an object O1, then to an object O2, and so forth until at the end of the interval it points to some object On. A reference counting algorithm would typically execute rc(O1)--, rc(O2)++, rc(O2)--, rc(O3)++, rc(O3)--, ..., rc(On)++. But most of these updates are redundant. In order to have the reference count properly evaluated at the end of the interval it is enough to perform rc(O1)-- and rc(On)++. Levanoni and Petrank measured an elimination of more than 99% of the counter updates in typical Java benchmarks.Requires atomicity
When used in a multithreaded environment, these modifications (increment and decrement) may need to be atomic operations such as compare-and-swap, at least for any objects which are shared, or potentially shared among multiple threads. Atomic operations are expensive on a multiprocessor, and even more expensive if they have to be emulated with software algorithms. It is possible to avoid this issue by adding per-thread or per-CPU reference counts and only accessing the global reference count when the local reference counts become or are no longer zero (or, alternatively, using a binary tree of reference counts, or even giving up deterministic destruction in exchange for not having a global reference count at all), but this adds significant memory overhead and thus tends to be only useful in special cases (it is used, for example, in the reference counting of Linux kernel modules). Update coalescing by Levanoni and Petrank can be used to eliminate all atomic operations from the write-barrier. Counters are never updated by the program threads in the course of program execution. They are only modified by the collector which executes as a single additional thread with no synchronization. This method can be used as a stop-the-world mechanism for parallel programs, and also with a concurrent reference counting collector.Not real-time
Naive implementations of reference counting do not generally provide real-time behavior, because any pointer assignment can potentially cause a number of objects bounded only by total allocated memory size to be recursively freed while the thread is unable to perform other work. It is possible to avoid this issue by delegating the freeing of unreferenced objects to other threads, at the cost of extra overhead.


=== Escape analysis ===

Escape analysis is a compile-time technique that can convert heap allocations to stack allocations, thereby reducing the amount of garbage collection to be done. This analysis determines whether an object allocated inside a function is accessible outside of it. If a function-local allocation is found to be accessible to another function or thread, the allocation is said to ""escape"" and cannot be done on the stack. Otherwise, the object may be allocated directly on the stack and released when the function returns, bypassing the heap and associated memory management costs.


== Availability ==
Generally speaking, higher-level programming languages are more likely to have garbage collection as a standard feature. In some languages lacking built in garbage collection, it can be added through a library, as with the Boehm garbage collector for C and C++.
Most functional programming languages, such as ML, Haskell, and APL, have garbage collection built in. Lisp is especially notable as both the first functional programming language and the first language to introduce garbage collection.Other dynamic languages, such as Ruby and Julia (but not Perl 5 or PHP before version 5.3, which both use reference counting), JavaScript and ECMAScript also tend to use GC. Object-oriented programming languages such as Smalltalk, RPL and Java usually provide integrated garbage collection. Notable exceptions are C++ and Delphi, which have destructors.


=== BASIC ===
BASIC and Logo have often used garbage collection for variable-length data types, such as strings and lists, so as not to burden programmers with memory management details. On the Altair 8800, programs with many string variables and little string space could cause long pauses due to garbage collection. Similarly the Applesoft BASIC interpreter's garbage collection algorithm repeatedly scans the string descriptors for the string having the highest address in order to compact it toward high memory, resulting in 
  
    
      
        O
        (
        
          n
          
            2
          
        
        )
      
    
    {\displaystyle O(n^{2})}
   performance and pauses anywhere from a few seconds to a few minutes. A replacement garbage collector for Applesoft BASIC by Randy Wigginton identifies a group of strings in every pass over the heap, reducing collection time dramatically. BASIC.System, released with ProDOS in 1983, provides a windowing garbage collector for BASIC that is many times faster.


=== Objective-C ===
While the Objective-C traditionally had no garbage collection, with the release of OS X 10.5 in 2007 Apple introduced garbage collection for Objective-C 2.0, using an in-house developed runtime collector.
However, with the 2012 release of OS X 10.8, garbage collection was deprecated in favor of LLVM's automatic reference counter (ARC) that was introduced with OS X 10.7. Furthermore, since May 2015 Apple even forbids the usage of garbage collection for new OS X applications in the App Store. For iOS, garbage collection has never been introduced due to problems in application responsivity and performance; instead, iOS uses ARC.


=== Limited environments ===
Garbage collection is rarely used on embedded or real-time systems because of the usual need for very tight control over the use of limited resources. However, garbage collectors compatible with many limited environments have been developed. The Microsoft .NET Micro Framework, .NET nanoFramework and Java Platform, Micro Edition are embedded software platforms that, like their larger cousins, include garbage collection.


=== Java ===
Garbage collectors available in Java JDKs include:

G1
Parallel
Concurrent mark sweep collector (CMS)
Serial
C4 (Continuously Concurrent Compacting Collector)
Shenandoah
ZGC


=== Compile-time use ===
Compile-time garbage collection is a form of static analysis allowing memory to be reused and reclaimed based on invariants known during compilation.
This form of garbage collection has been studied in the Mercury programming language, and it saw greater usage with the introduction of LLVM's automatic reference counter (ARC) into Apple's ecosystem (iOS and OS X) in 2011.


=== Real-time systems ===
Incremental, concurrent, and real-time garbage collectors have been developed, for example by Henry Baker and by Henry Lieberman.In Baker's algorithm, the allocation is done in either half of a single region of memory. When it becomes half full, a garbage collection is performed which moves the live objects into the other half and the remaining objects are implicitly deallocated. The running program (the 'mutator') has to check that any object it references is in the correct half, and if not move it across, while a background task is finding all of the objects.Generational garbage collection schemes are based on the empirical observation that most objects die young. In generational garbage collection two or more allocation regions (generations) are kept, which are kept separate based on object's age. New objects are created in the ""young"" generation that is regularly collected, and when a generation is full, the objects that are still referenced from older regions are copied into the next oldest generation. Occasionally a full scan is performed.
Some high-level language computer architectures include hardware support for real-time garbage collection.
Most implementations of real-time garbage collectors use tracing. Such real-time garbage collectors meet hard real-time constraints when used with a real-time operating system.


== See also ==
Destructor (computer programming)
Dynamic dead-code elimination
Smart pointer
Virtual memory compression


== References ==


== Further reading ==
Jones, Richard; Hosking, Antony; Moss, J. Eliot B. (2011-08-16). The Garbage Collection Handbook: The Art of Automatic Memory Management. CRC Applied Algorithms and Data Structures Series. Chapman and Hall / CRC Press / Taylor & Francis Ltd. ISBN 978-1-4200-8279-1. (511 pages)
Jones, Richard; Lins, Rafael (1996-07-12). Garbage Collection: Algorithms for Automatic Dynamic Memory Management (1 ed.). Wiley. ISBN 978-0-47194148-4. (404 pages)
Schorr, Herbert; Waite, William M. (August 1967). ""An Efficient Machine-Independent Procedure for Garbage Collection in Various List Structures"" (PDF). Communications of the ACM. 10 (8): 501–506. doi:10.1145/363534.363554. S2CID 5684388. Archived (PDF) from the original on 2021-01-22.
Wilson, Paul R. (1992). ""Uniprocessor Garbage Collection Techniques"". Proceedings of the International Workshop on Memory Management (IWMM 92). Lecture Notes in Computer Science. Springer-Verlag. 637: 1–42. CiteSeerX 10.1.1.47.2438. doi:10.1007/bfb0017182. ISBN 3-540-55940-X.
Wilson, Paul R.; Johnstone, Mark S.; Neely, Michael; Boles, David (1995). ""Dynamic Storage Allocation: A Survey and Critical Review"". Proceedings of the International Workshop on Memory Management (IWMM 95). Lecture Notes in Computer Science (1 ed.). 986: 1–116. CiteSeerX 10.1.1.47.275. doi:10.1007/3-540-60368-9_19. ISBN 978-3-540-60368-9.


== External links ==

The Memory Management Reference
The Very Basics of Garbage Collection
Java SE 6 HotSpot Virtual Machine Garbage Collection Tuning
TinyGC - an independent implementation of the BoehmGC API
Conservative Garbage Collection Implementation for C Language
MeixnerGC - an incremental mark and sweep garbage collector for C++ using smart pointers"
7c99cecb2c,Computer engineering,"Computer engineering (CoE or CpE) is a branch of electrical engineering and computer science that integrates several fields of computer science and electronic engineering required to develop computer hardware and software. Computer engineers require training in electronic engineering, hardware-software integration, software design, and software engineering. It uses the techniques and principles of electrical engineering and computer science, and can encompass areas such as artificial intelligence (AI), robotics, computer networks, computer architecture and operating systems. Computer engineers are involved in many hardware and software aspects of computing, from the design of individual microcontrollers, microprocessors, personal computers, and supercomputers, to circuit design. This field of engineering not only focuses on how computer systems themselves work, yet it also demands them to integrate into the larger picture. Robots are one of the applications of computer engineering.
Computer engineering usually deals with areas including writing software and firmware for embedded microcontrollers, designing VLSI chips, designing analog sensors, designing mixed signal circuit boards, and designing operating systems. Computer engineers are also suited for robotics research, which relies heavily on using digital systems to control and monitor electrical systems like motors, communications, and sensors.
In many institutions of higher learning, computer engineering students are allowed to choose areas of in-depth study in their junior and senior year because the full breadth of knowledge used in the design and application of computers is beyond the scope of an undergraduate degree. Other institutions may require engineering students to complete one or two years of general engineering before declaring computer engineering as their primary focus.


== History ==

Computer engineering began in 1939 when John Vincent Atanasoff and Clifford Berry began developing the world's first electronic digital computer through physics, mathematics, and electrical engineering. John Vincent Atanasoff was once a physics and mathematics teacher for Iowa State University and Clifford Berry a former graduate under electrical engineering and physics. Together, they created the Atanasoff-Berry computer, also known as the ABC which took five years to complete.
While the original ABC was dismantled and discarded in the 1940s a tribute was made to the late inventors, a replica of the ABC was made in 1997 where it took a team of researchers and engineers four years and $350,000 to build.The modern personal computer emerged in the 1970s, after several breakthroughs in semiconductor technology. These include the first working transistor by William Shockley, John Bardeen and Walter Brattain at Bell Labs in 1947, planar process by Jean Hoerni, the monolithic integrated circuit chip by Robert Noyce at Fairchild Semiconductor in 1959, the metal–oxide–semiconductor field-effect transistor (MOSFET, or MOS transistor) by Mohamed Atalla and Dawon Kahng at Bell Labs in 1959, and the single-chip microprocessor (Intel 4004) by Federico Faggin, Marcian Hoff, Masatoshi Shima and Stanley Mazor at Intel in 1971.


=== History of computer engineering education ===
The first computer engineering degree program in the United States was established in 1971 at Case Western Reserve University in Cleveland, Ohio. As of 2015, there were 250 ABET-accredited computer engineering programs in the U.S. In Europe, accreditation of computer engineering schools is done by a variety of agencies part of the EQANIE network. Due to increasing job requirements for engineers who can concurrently design hardware, software, firmware, and manage all forms of computer systems used in industry, some tertiary institutions around the world offer a bachelor's degree generally called computer engineering. Both computer engineering and electronic engineering programs include analog and digital circuit design in their curriculum. As with most engineering disciplines, having a sound knowledge of mathematics and science is necessary for computer engineers.


== Education ==
Computer engineering is referred to as computer science and engineering at some universities. Most entry-level computer engineering jobs require at least a bachelor's degree in computer engineering (or computer science and engineering). Typically one must learn an array of mathematics such as calculus, algebra and trigonometry and some computer science classes. Degrees in electronic or electric engineering also suffice due to the similarity of the two fields. Because hardware engineers commonly work with computer software systems, a strong background in computer programming is necessary. According to BLS, ""a computer engineering major is similar to electrical engineering but with some computer science courses added to the curriculum"". Some large firms or specialized jobs require a master's degree.
It is also important for computer engineers to keep up with rapid advances in technology. Therefore, many continue learning throughout their careers. This can be helpful, especially when it comes to learning new skills or improving existing ones. For example, as the relative cost of fixing a bug increases the further along it is in the software development cycle, there can be greater cost savings attributed to developing and testing for quality code as soon as possible in the process,  particularly before release.


== Profession: Computer engineer ==

A person with a profession in computer engineering is called a computer engineer.


== Applications and practice ==
There are two major focuses in computer engineering: hardware and software.


=== Computer hardware engineering ===

According to the BLS, Job Outlook employment for computer hardware engineers, the expected ten-year growth from 2019 to 2029 for computer hardware engineering was an estimated 2% and a total of 71,100 jobs. (""Slower than average"" in their own words when compared to other occupations)"". This is a decrease from the 2014 to 2024 BLS computer hardware engineering estimate of 3% and  a total of 77,700 jobs. "" and is down from 7% for the 2012 to 2022 BLS estimate and is further down from 9% in the BLS 2010 to 2020 estimate."" Today, computer hardware is somehow equal to electronic and computer engineering (ECE) and has been divided into many subcategories; the most significant is embedded system design.


=== Computer software engineering ===
According to the U.S. Bureau of Labor Statistics (BLS), ""computer applications software engineers and computer systems software engineers are projected to be among the faster than average growing occupations"" The expected ten-year growth as of 2014 for computer software engineering was an estimated seventeen percent and there was a total of 1,114,000 jobs that same year. This is down from the 2012 to 2022 BLS estimate of 22% for software developers. And, further down from the 30% 2010 to 2020 BLS estimate. In addition, growing concerns over cybersecurity add up to put computer software engineering high above the average rate of increase for all fields. However, some of the work will be outsourced in foreign countries. Due to this, job growth will not be as fast as during the last decade, as jobs that would have gone to computer software engineers in the United States would instead go to computer software engineers in countries such as India. In addition, the BLS Job Outlook for Computer Programmers, 2014–24 has an −8% (a decline, in their words), a Job Outlook, 2019-29 a -9% (Decline), and a 10% decline for 2021-2031 for those who program computers (i.e. embedded systems) who are not computer application developers. Furthermore, women in software fields has been declining over the years even faster than other engineering fields.


=== Computer engineering licensing and practice ===
Computer engineering is generally practiced within larger product development firms, and such practice may not be subject to licensing.  However, independent consultants who advertise computer engineering, just like any form of engineering, may be subject to state laws which restrict professional engineer practice to only those who have received the appropriate License.  National Council of Examiners for Engineering and Surveying (NCEES) first offered a Principles and Practice of Engineering Examination for computer engineering in 2003.


== Specialty areas ==
There are many specialty areas in the field of computer engineering.


=== Processor design ===

Processor design process involves choosing an instruction set and a certain execution paradigm (e.g. VLIW or RISC) and results in a microarchitecture, which might be described in e.g. VHDL or Verilog. CPU design is divided into design of the following components: datapaths (such as ALUs and pipelines), control unit: logic which controls the datapaths, memory components such as register files, caches, clock circuitry such as clock drivers, PLLs, clock distribution networks, pad transceiver circuitry, logic gate cell library which is used to implement the logic.


=== Coding, cryptography, and information protection ===

Computer engineers work in coding, cryptography, and information protection to develop new methods for protecting various information, such as digital images and music, fragmentation, copyright infringement and other forms of tampering. Examples include work on wireless communications, multi-antenna systems, optical transmission, and digital watermarking.


=== Communications and wireless networks ===

Those focusing on communications and wireless networks, work advancements in telecommunications systems and networks (especially wireless networks), modulation and error-control coding, and information theory. High-speed network design, interference suppression and modulation, design, and analysis of fault-tolerant system, and storage and transmission schemes are all a part of this specialty.


=== Compilers and operating systems ===

This specialty focuses on compilers and operating systems design and development. Engineers in this field develop new operating system architecture, program analysis techniques, and new techniques to assure quality. Examples of work in this field include post-link-time code transformation algorithm development and new operating system development.


=== Computational science and engineering ===

Computational science and engineering is a relatively new discipline. According to the Sloan Career Cornerstone Center, individuals working in this area, ""computational methods are applied to formulate and solve complex mathematical problems in engineering and the physical and the social sciences. Examples include aircraft design, the plasma processing of nanometer features on semiconductor wafers, VLSI circuit design, radar detection systems, ion transport through biological channels, and much more"".


=== Computer networks, mobile computing, and distributed systems ===

In this specialty, engineers build integrated environments for computing, communications, and information access. Examples include shared-channel wireless networks, adaptive resource management in various systems, and improving the quality of service in mobile and ATM environments. Some other examples include work on wireless network systems and fast Ethernet cluster wired systems.


=== Computer systems: architecture, parallel processing, and dependability ===

Engineers working in computer systems work on research projects that allow for reliable, secure, and high-performance computer systems. Projects such as designing processors for multi-threading and parallel processing are included in this field. Other examples of work in this field include the development of new theories, algorithms, and other tools that add performance to computer systems.Computer architecture includes CPU design, cache hierarchy layout, memory organization, and load balancing.


=== Computer vision and robotics ===

In this specialty, computer engineers focus on developing visual sensing technology to sense an environment, representation of an environment, and manipulation of the environment. The gathered three-dimensional information is then implemented to perform a variety of tasks. These include improved human modeling, image communication, and human-computer interfaces, as well as devices such as special-purpose cameras with versatile vision sensors.


=== Embedded systems ===

Individuals working in this area design technology for enhancing the speed, reliability, and performance of systems. Embedded systems are found in many devices from a small FM radio to the space shuttle. According to the Sloan Cornerstone Career Center, ongoing developments in embedded systems include ""automated vehicles and equipment to conduct search and rescue, automated transportation systems, and human-robot coordination to repair equipment in space."" As of 2018, computer embedded systems specializations include system-on-chip design, architecture of edge computing and the Internet of things.


=== Integrated circuits, VLSI design, testing and CAD ===

This specialty of computer engineering requires adequate knowledge of electronics and electrical systems. Engineers working in this area work on enhancing the speed, reliability, and energy efficiency of next-generation very-large-scale integrated (VLSI) circuits and microsystems. An example of this specialty is work done on reducing the power consumption of VLSI algorithms and architecture.


=== Signal, image and speech processing ===

Computer engineers in this area develop improvements in human-computer interaction, including speech recognition and synthesis, medical and scientific imaging, or communications systems. Other work in this area includes computer vision development such as recognition of human facial features.


=== Quantum computing ===


== See also ==


=== Related fields ===


=== Associations ===
IEEE Computer Society
Association for Computing Machinery


== References ==


== External links ==
 Media related to Computer engineering at Wikimedia Commons"
86ecd2ed72,Assignment (computer science),"In computer programming, an assignment statement sets and/or re-sets the value stored in the storage location(s) denoted by a variable name; in other words, it copies a value into the variable. In most imperative programming languages, the assignment statement (or expression) is a fundamental construct.
Today, the most commonly used notation for this operation is x = expr (originally Superplan 1949–51, popularized by Fortran 1957 and C). The second most commonly used notation is x := expr (originally ALGOL 1958, popularised by Pascal). Many other notations are also in use. In some languages, the symbol used is regarded as an operator (meaning that the assignment statement as a whole returns a value). Other languages define assignment as a statement (meaning that it cannot be used in an expression).
Assignments typically allow a variable to hold different values at different times during its life-span and scope. However, some languages (primarily strictly functional languages) do not allow that kind of ""destructive"" reassignment, as it might imply changes of non-local state. The purpose is to enforce referential transparency, i.e. functions that do not depend on the state of some variable(s), but produce the same results for a given set of parametric inputs at any point in time. Modern programs in other languages also often use similar strategies, although less strict, and only in certain parts, in order to reduce complexity, normally in conjunction with complementing methodologies such as data structuring, structured programming and object orientation.


== Semantics ==
An assignment operation is a process in imperative programming in which different values are associated with a particular variable name as time passes. The program, in such model, operates by changing its state using successive assignment statements. Primitives of imperative programming languages rely on assignment to do iteration. At the lowest level, assignment is implemented using machine operations such as MOVE or STORE.Variables are containers for values. It is possible to put a value into a variable and later replace it with a new one. An assignment operation modifies the current state of the executing program. Consequently, assignment is dependent on the concept of variables. In an assignment:

The expression is evaluated in the current state of the program.
The variable is assigned the computed value, replacing the prior value of that variable.Example: Assuming that a is a numeric variable, the assignment a := 2*a means that the content of the variable a is doubled after the execution of the statement.
An example segment of C code:

In this sample, the variable x is first declared as an int, and is then assigned the value of 10. Notice that the declaration and assignment occur in the same statement. In the second line, y is declared without an assignment. In the third line, x is reassigned the value of 23. Finally, y is assigned the value of 32.4.
For an assignment operation, it is necessary that the value of the expression is well-defined (it is a valid rvalue) and that the variable represents a modifiable entity (it is a valid modifiable (non-const) lvalue). In some languages, typically dynamic ones, it is not necessary to declare a variable prior to assigning it a value. In such languages, a variable is automatically declared the first time it is assigned to, with the scope it is declared in varying by language.


== Single assignment ==

Any assignment that changes an existing value (e.g. x := x + 1) is disallowed in purely functional languages. In functional programming, assignment is discouraged in favor of single assignment, also called initialization. Single assignment is an example of name binding and differs from assignment as described in this article in that it can only be done once, usually when the variable is created; no subsequent reassignment is allowed.
An evaluation of expression does not have a side effect if it does not change an observable state of the machine, and produces same values for same input. Imperative assignment can introduce side effects while destroying and making the old value unavailable while substituting it with a new one, and is referred to as destructive assignment for that reason in LISP and functional programming, similar to destructive updating.
Single assignment is the only form of assignment available in purely functional languages, such as Haskell, which do not have variables in the sense of imperative programming languages but rather named constant values possibly of compound nature with their elements progressively defined on-demand. Purely functional languages can provide an opportunity for computation to be performed in parallel, avoiding the von Neumann bottleneck of sequential one step at a time execution, since values are independent of each other.Impure functional languages provide both single assignment as well as true assignment (though true assignment is typically used with less frequency than in imperative programming languages). For example, in Scheme, both single assignment (with let) and true assignment (with set!) can be used on all variables, and specialized primitives are provided for destructive update inside lists, vectors, strings, etc. In OCaml, only single assignment is allowed for variables, via the let name = value syntax; however destructive update can be used on elements of arrays and strings with separate <- operator, as well as on fields of records and objects that have been explicitly declared mutable (meaning capable of being changed after their initial declaration) by the programmer.
Functional programming languages that use single assignment include Clojure (for data structures, not vars), Erlang (it accepts multiple assignment if the values are equal, in contrast to Haskell), F#, Haskell, JavaScript (for constants), Lava, OCaml, Oz (for dataflow variables, not cells), Racket (for some data structures like lists, not symbols), SASL, Scala (for vals), SISAL, Standard ML. Non-backtracking Prolog code can be considered explicit single-assignment, explicit in a sense that its (named) variables can be in explicitly unassigned state, or be set exactly once. In Haskell, by contrast, there can be no unassigned variables, and every variable can be thought of as being implicitly set, when it is created, to its value (or rather to a computational object that will produce its value on demand).


== Value of an assignment ==
In some programming languages, an assignment statement returns a value, while in others it does not.
In most expression-oriented programming languages (for example, C), the assignment statement returns the assigned value, allowing such idioms as x = y = a, in which the assignment statement y = a returns the value of a, which is then assigned to x. In a statement such as while ((ch = getchar()) != EOF) {…}, the return value of a function is used to control a loop while assigning that same value to a variable.
In other programming languages, Scheme for example, the return value of an assignment is undefined and such idioms are invalid.
In Haskell, there is no variable assignment; but operations similar to assignment (like assigning to a field of an array or a field of a mutable data structure) usually evaluate to the unit type, which is represented as (). This type has only one possible value, therefore containing no information. It is typically the type of an expression that is evaluated purely for its side effects.


== Variant forms of assignment ==
Certain use patterns are very common, and thus often have special syntax to support them. These are primarily syntactic sugar to reduce redundancy in the source code, but also assists readers of the code in understanding the programmer's intent, and provides the compiler with a clue to possible optimization.


=== Augmented assignment ===

The case where the assigned value depends on a previous one is so common that many imperative languages, most notably C and the majority of its descendants, provide special operators called augmented assignment, like *=, so a = 2*a can instead be written as a *= 2. Beyond syntactic sugar, this assists the task of the compiler by making clear that in-place modification of the variable a is possible.


=== Chained assignment ===
A statement like w = x = y = z is called a chained assignment in which the value of z is assigned to multiple variables w, x, and y. Chained assignments are often used to initialize multiple variables, as in
a = b = c = d = f = 0
Not all programming languages support chained assignment. Chained assignments are equivalent to a sequence of assignments, but the evaluation strategy differs between languages. For simple chained assignments, like initializing multiple variables, the evaluation strategy does not matter, but if the targets (l-values) in the assignment are connected in some way, the evaluation strategy affects the result.
In some programming languages (C for example), chained assignments are supported because assignments are expressions, and have values. In this case chain assignment can be implemented by having a right-associative assignment, and assignments happen right-to-left. For example, i = arr[i] = f() is equivalent to arr[i] = f(); i = arr[i]. In C++ they are also available for values of class types by declaring the appropriate return type for the assignment operator.
In Python, assignment statements are not expressions and thus do not have a value. Instead, chained assignments are a series of statements with multiple targets for a single expression. The assignments are executed left-to-right so that i = arr[i] = f() evaluates the expression f(), then assigns the result to the leftmost target, i, and then assigns the same result to the next target, arr[i], using the new value of i. This is essentially equivalent to tmp = f(); i = tmp; arr[i] = tmp though no actual variable is produced for the temporary value.


=== Parallel assignment ===
Some programming languages, such as APL, Common Lisp, Go, JavaScript (since 1.7), PHP, Maple, Lua, occam 2, Perl, Python, REBOL, Ruby, and PowerShell allow several variables to be assigned in parallel, with syntax like:

a, b := 0, 1

which simultaneously assigns 0 to a and 1 to b. This is most often known as parallel assignment; it was introduced in CPL in 1963, under the name simultaneous assignment, and is sometimes called multiple assignment, though this is confusing when used with ""single assignment"", as these are not opposites. If the right-hand side of the assignment is a single variable (e.g. an array or structure), the feature is called unpacking or destructuring assignment:
var list := {0, 1}
a, b := list

The list will be unpacked so that 0 is assigned to a and 1 to b. Furthermore,

a, b := b, a

swaps the values of a and b. In languages without parallel assignment, this would have to be written to use a temporary variable

var t := a
a := b
b := t

since a := b; b := a leaves both a and b with the original value of b.
Some languages, such as Go and Python, combine parallel assignment, tuples, and automatic tuple unpacking to allow multiple return values from a single function, as in this Python example,

while other languages, such as C# and Rust, shown here, require explicit tuple construction and deconstruction with parentheses:

This provides an alternative to the use of output parameters for returning multiple values from a function. This dates to CLU (1974), and CLU helped popularize parallel assignment generally.
C# additionally allows generalized deconstruction assignment with implementation defined by the expression on the right-hand side, as the compiler searches for an appropriate instance or extension Deconstruct method on the expression, which must have output parameters for the variables being assigned to. For example, one such method that would give the class it appears in the same behavior as the return value of f() above would be

In C and C++, the comma operator is similar to parallel assignment in allowing multiple assignments to occur within a single statement, writing a = 1, b = 2 instead of a, b = 1, 2. 
This is primarily used in for loops, and is replaced by parallel assignment in other languages such as Go.
However, the above C++ code does not ensure perfect simultaneity, since the right side of the following code a = b, b = a+1 is evaluated after the left side. In languages such as Python, a, b = b, a+1 will assign the two variables concurrently, using the initial value of a to compute the new b.


== Assignment versus equality ==

The use of the equals sign = as an assignment operator has been frequently criticized, due to the conflict with equals as comparison for equality. This results both in confusion by novices in writing code, and confusion even by experienced programmers in reading code. The use of equals for assignment dates back to Heinz Rutishauser's language Superplan, designed from 1949 to 1951, and was particularly popularized by Fortran:

A notorious example for a bad idea was the choice of the equal sign to denote assignment. It goes back to Fortran in 1957 and has blindly been copied by armies of language designers. Why is it a bad idea? Because it overthrows a century old tradition to let “=” denote a comparison for equality, a predicate which is either true or false. But Fortran made it to mean assignment, the enforcing of equality. In this case, the operands are on unequal footing: The left operand (a variable) is to be made equal to the right operand (an expression). x = y does not mean the same thing as y = x.
Beginning programmers sometimes confuse assignment with the relational operator for equality, as ""="" means equality in mathematics, and is used for assignment in many languages. But assignment alters the value of a variable, while equality testing tests whether two expressions have the same value.
In some languages, such as BASIC, a single equals sign (""="") is used for both the assignment operator and the equality relational operator, with context determining which is meant. Other languages use different symbols for the two operators. For example:

In ALGOL and Pascal, the assignment operator is a colon and an equals sign ("":="") while the equality operator is a single equals (""="").
In C, the assignment operator is a single equals sign (""="") while the equality operator is a pair of equals signs (""=="").
In R, the assignment operator is basically <-, as in x <- value, but a single equals sign can be used in certain contexts.The similarity in the two symbols can lead to errors if the programmer forgets which form (""="", ""=="", "":="") is appropriate, or mistypes ""="" when ""=="" was intended. This is a common programming problem with languages such as C (including one famous attempt to backdoor the Linux kernel), where the assignment operator also returns the value assigned (in the same way that a function returns a value), and can be validly nested inside expressions. If the intention was to compare two values in an if statement, for instance, an assignment is quite likely to return a value interpretable as Boolean true, in which case the then clause will be executed, leading the program to behave unexpectedly. Some language processors (such as gcc) can detect such situations, and warn the programmer of the potential error.


== Notation ==

The two most common representations for the copying assignment are equals sign (=) and colon-equals (:=). Both forms may semantically denote either an assignment statement or an assignment operator (which also has a value), depending on language and/or usage.

Other possibilities include a left arrow or a keyword, though there are other, rarer, variants:

Mathematical pseudo code assignments are generally depicted with a left-arrow.
Some platforms put the expression on the left and the variable on the right:

Some expression-oriented languages, such as Lisp and Tcl, uniformly use prefix (or postfix) syntax for all statements, including assignment.


== See also ==
Assignment operator in C++
Operator (programming)
Name binding
Unification (computing)
Immutable object
Const-correctness
Assignment Problem


== Notes ==


== References =="
5733414bde,Cohesion (computer science),"In computer programming, cohesion refers to the degree to which the elements inside a module belong together. In one sense, it is a measure of the strength of relationship between the methods and data of a class and some unifying purpose or concept served by that class. In another sense, it is a measure of the strength of relationship between the class's methods and data themselves.
Cohesion is an ordinal type of measurement and is usually described as “high cohesion” or “low cohesion”. Modules with high cohesion tend to be preferable, because high cohesion is associated with several desirable traits of software including robustness, reliability, reusability, and understandability. In contrast, low cohesion is associated with undesirable traits such as being difficult to maintain, test, reuse, or even understand.
Cohesion is often contrasted with coupling, a different concept. High cohesion often correlates with loose coupling, and vice versa. The software metrics of coupling and cohesion were invented by Larry Constantine in the late 1960s as part of Structured Design, based on characteristics of “good” programming practices that reduced maintenance and modification costs. Structured Design, cohesion and coupling were published in the article Stevens, Myers & Constantine (1974) and the book Yourdon & Constantine (1979); the latter two subsequently became standard terms in software engineering.


== High cohesion ==
In object-oriented programming, if the methods that serve a class tend to be similar in many aspects, then the class is said to have high cohesion. In a highly cohesive system, code readability and reusability is increased, while complexity is kept manageable.

Cohesion is increased if:

The functionalities embedded in a class, accessed through its methods, have much in common.
Methods carry out a small number of related activities, by avoiding coarsely grained or unrelated sets of data.
Related methods are in the same source file or otherwise grouped together; for example, in separate files but in the same sub-directory/folder.Advantages of high cohesion (or ""strong cohesion"") are:

Reduced module complexity (they are simpler, having fewer operations).
Increased system maintainability, because logical changes in the domain affect fewer modules, and because changes in one module require fewer changes in other modules.
Increased module reusability, because application developers will find the component they need more easily among the cohesive set of operations provided by the module.While in principle a module can have perfect cohesion by only consisting of a single, atomic element – having a single function, for example – in practice complex tasks are not expressible by a single, simple element. Thus a single-element module has an element that either is too complicated, in order to accomplish a task, or is too narrow, and thus tightly coupled to other modules. Thus cohesion is balanced with both unit complexity and coupling.


== Types of cohesion ==
Cohesion is a qualitative measure, meaning that the source code to be measured is examined using a rubric to determine a classification. Cohesion types, from the worst to the best, are as follows:

Coincidental cohesion (worst)
Coincidental cohesion is when parts of a module are grouped arbitrarily; the only relationship between the parts is that they have been grouped together (e.g., a “Utilities” class). Example:
Logical cohesion
Logical cohesion is when parts of a module are grouped because they are logically categorized to do the same thing even though they are different by nature (e.g., grouping all mouse and keyboard input handling routines or bundling all models, views, and controllers in separate folders in an MVC pattern).Temporal cohesion
Temporal cohesion is when parts of a module are grouped by when they are processed - the parts are processed at a particular time in program execution (e.g., a function which is called after catching an exception which closes open files, creates an error log, and notifies the user).Procedural cohesion
Procedural cohesion is when parts of a module are grouped because they always follow a certain sequence of execution (e.g., a function which checks file permissions and then opens the file).Communicational/informational cohesion
Communicational cohesion is when parts of a module are grouped because they operate on the same data (e.g., a module which operates on the same record of information).Sequential cohesion
Sequential cohesion is when parts of a module are grouped because the output from one part is the input to another part like an assembly line (e.g., a function which reads data from a file and processes the data).Functional cohesion (best)
Functional cohesion is when parts of a module are grouped because they all contribute to a single well-defined task of the module (e.g., Lexical analysis of an XML string). Example:
Perfect cohesion (atomic)
Example.
Although cohesion is a ranking type of scale, the ranks do not indicate a steady progression of improved cohesion. Studies by various people including Larry Constantine, Edward Yourdon, and Steve McConnell indicate that the first two types of cohesion are inferior; communicational and sequential cohesion are very good; and functional cohesion is superior.


== See also ==
Coupling (computer science)
List of object-oriented programming terms
Static code analysis


== References ==


== External links ==
Definitions of Cohesion metrics
Cohesion metrics
Measuring Cohesion in Python"
6020aa5b7d,Branch (computer science),"A branch  is an instruction in a computer program that can cause a computer to begin executing a different instruction sequence and thus deviate from its default behavior of executing instructions in order. Branch (or branching, branched) may also refer to the act of switching execution to a different instruction sequence as a result of executing a branch instruction. Branch instructions are used to implement control flow in program loops and conditionals (i.e., executing a particular sequence of instructions only if certain conditions are satisfied).
A branch instruction can be either an unconditional branch, which always results in branching, or a conditional branch, which may or may not cause branching depending on some condition. Also, depending on how it specifies the address of the new instruction sequence (the ""target"" address), a branch instruction is generally classified as direct, indirect or relative, meaning that the instruction contains the target address, or it specifies where the target address is to be found (e.g., a register or memory location), or it specifies the difference between the current and target addresses.


== Implementation ==
Branch instructions can alter the contents of the CPU's Program Counter (or PC) (or Instruction Pointer on Intel microprocessors). The PC maintains the memory address of the next machine instruction to be fetched and executed. Therefore, a branch, if executed, causes the CPU to execute code from a new memory address, changing the program logic according to the algorithm planned by the programmer.
One type of machine level branch is the jump instruction. These may or may not result in the PC being loaded or modified with some new, different value other than what it ordinarily would have been (being incremented past the current instruction to point to the following, next instruction). Jumps typically have unconditional and conditional forms where the latter may be taken or not taken (the PC is modified or not) depending on some condition.
The second type of machine level branch is the call instruction which is used to implement subroutines. Like jump instructions, calls may or may not modify the PC according to condition codes, however, additionally a return address is saved in a secure place in memory (usually in a memory resident data structure called a stack). Upon completion of the subroutine, this return address is restored to the PC, and so program execution resumes with the instruction following the call instruction.
The third type of machine level branch is the return instruction. This ""pops"" a return address off the stack and loads it into the PC register, thus returning control to the calling routine. Return instructions may also be conditionally executed. This description pertains to ordinary practice; however, the machine programmer has considerable powers to manipulate the return address on the stack, and so redirect program execution in any number of different ways.
Depending on the processor, jump and call instructions may alter the contents of the PC register in different ways. An absolute address may be loaded, or the current contents of the PC may have some value (or displacement) added or subtracted from its current value, making the destination address relative to the current place in the program. The source of the displacement value may vary, such as an immediate value embedded within the instruction, or the contents of a processor register or memory location, or the contents of some location added to an index value.
The term branch can also be used when referring to programs in high-level programming languages. In these branches usually take the form of conditional statements of various forms that encapsulate the instruction sequence that will be executed if the conditions are satisfied. Unconditional branch instructions such as GOTO are used to unconditionally jump to a different instruction sequence. If the algorithm requires a conditional branch, the GOTO (or GOSUB subroutine call) is preceded by an IF-THEN statement specifying the condition(s). All high level languages support algorithms that can re-use code as a loop, a control structure that repeats a sequence of instructions until some condition is satisfied that causes the loop to terminate. Loops also qualify as branch instructions. At the machine level, loops are implemented as ordinary conditional jumps that redirect execution to repeating code.
In CPUs with flag registers, an earlier instruction sets a condition in the flag register. The earlier instruction may be arithmetic, or a logic instruction.  It is often close to the branch, though not necessarily the instruction immediately before the branch.  The stored condition is then used in a branch such as jump if overflow-flag set. This temporary information is often stored in a flag register but may also be located elsewhere.  A flag register design is simple in slower, simple computers. In fast computers a flag register can place a bottleneck on speed, because instructions that could otherwise operate in parallel (in several execution units) need to set the flag bits in a particular sequence.
There are also machines (or particular instructions) where the condition may be checked by the jump instruction itself, such as branch <label> if register X negative. In simple computer designs, comparison branches execute more arithmetic and can use more power than flag register branches. In fast computer designs comparison branches can run faster than flag register branches, because comparison branches can access the registers with more parallelism, using the same CPU mechanisms as a calculation.
Some early and simple CPU architectures, still found in microcontrollers, may not implement a conditional jump, but rather only a conditional ""skip the next instruction"" operation. A conditional jump or call is thus implemented as a conditional skip of an unconditional jump or call instruction.


=== Examples ===
Depending on the computer architecture, the assembly language mnemonic for a jump instruction is typically some shortened form of the word jump or the word branch, often along with other informative letters (or an extra parameter) representing the condition. Sometimes other details are included as well, such as the range of the jump (the offset size) or a special addressing mode that should be used to locate the actual effective offset.
This table lists the machine level branch or jump instructions found in several well-known architectures:

* x86, the PDP-11, VAX, and some others, set the carry-flag to signal borrow and clear the carry-flag to signal no borrow. ARM, 6502, the PIC, and some others, do the opposite for subtractive operations. This inverted function of the carry flag for certain instructions is marked by (*), that is, borrow=not carry in some parts of the table, but if not otherwise noted, borrow≡carry. However, carry on additive operations are handled the same way by most architectures.


== Performance problems with branch instructions ==
To achieve high performance, modern processors are pipelined. They consist of multiple parts that each partially process an instruction, feed their results to the next stage in the pipeline, and start working on the next instruction in the program. This design expects instructions to execute in a particular unchanging sequence. Conditional branch instructions make it impossible to know this sequence.  So conditional branches can cause ""stalls"" in which the pipeline has to be restarted on a different part of the program.


== Improving performance by reducing stalls from branches ==
Several techniques improve speed by reducing stalls from conditional branches.


=== Branch prediction hints ===
Historically, branch prediction took statistics, and used the result to optimize code.  A programmer would compile a test version of a program, and run it with test data.  The test code counted how the branches were actually taken. The statistics from the test code were then used by the compiler to optimize the branches of released code. The optimization would arrange that the fastest branch direction (taken or not) would always be the most frequently taken control flow path. To permit this, CPUs must be designed with (or at least have) predictable branch timing. Some CPUs have instruction sets (such as the Power ISA) that were designed with ""branch hints"" so that a compiler can tell a CPU how each branch is to be taken.
The problem with software branch prediction is that it requires a complex software development process.


=== Hardware branch predictors ===
To run any software, hardware branch predictors moved the statistics into the electronics. Branch predictors are parts of a processor that guess the outcome of a conditional branch. Then the processor's logic gambles on the guess by beginning to execute the expected instruction flow. An example of a simple hardware branch prediction scheme is to assume that all backward branches (i.e. to a smaller program counter) are taken (because they are part of a loop), and all forward branches (to a larger program counter) are not taken (because they leave a loop). Better branch predictors are developed and validated statistically by running them in simulation on a variety of test programs.  Good predictors usually count the outcomes of previous executions of a branch. Faster, more expensive computers can then run faster by investing in better branch prediction electronics. In a CPU with hardware branch prediction, branch hints let the compiler's presumably superior branch prediction override the hardware's more simplistic branch prediction.


=== Branch-free code ===
Some logic can be written without branches or with fewer branches. It is often possible to use bitwise operations, conditional moves or other predication instead of branches. In fact, branch-free code is a must for cryptography due to timing attacks.


=== Delay slot ===
Another technique is a branch delay slot. In this approach, one instruction after a branch is always executed. Therefore, the computer can use this instruction to do useful work whether or not its pipeline stalls. This approach was historically popular in RISC computers. In a family of compatible CPUs, it complicates multicycle CPUs (with no pipeline), faster CPUs with longer-than-expected pipelines, and superscalar CPUs (which can execute instructions out of order.)


== See also ==
Branch delay slot
Branch predication
Branch table
Conditional (programming)
Control flow
Indirect branch
Program counter
Subroutine
Spaghetti code


== Notes ==


== References ==


== External links ==
Free IA-32 and x86-64 documentation, provided by Intel
The PDP-11 FAQ
The ARM instruction set"
0981371df7,Semantics (computer science),"In programming language theory, semantics is the rigorous mathematical study of the meaning of programming languages. Semantics assigns computational meaning to valid strings in a programming language syntax.
Semantics describes the processes a computer follows when executing a program in that specific language. This can be shown by describing the relationship between the input and output of a program, or an explanation of how the program will be executed on a certain platform, hence creating a model of computation.


== History ==
In 1967, Robert W. Floyd publishes the paper Assigning meanings to programs; his chief aim is ""a rigorous standard for proofs about computer programs, including proofs of correctness, equivalence, and termination"". Floyd further writes:

A semantic definition of a programming language, in our approach, is founded on a syntactic definition. It must specify which of the phrases in a syntactically correct program represent commands, and what conditions must be imposed on an interpretation in the neighborhood of each command.

In 1969, Tony Hoare publishes a paper on Hoare logic seeded by Floyd's ideas, now sometimes collectively called axiomatic semantics.In the 1970s, the terms operational semantics and denotational semantics emerged.


== Overview ==
The field of formal semantics encompasses all of the following:

The definition of semantic models
The relations between different semantic models
The relations between different approaches to meaning
The relation between computation and the underlying mathematical structures from fields such as logic, set theory, model theory, category theory, etc.It has close links with other areas of computer science such as programming language design, type theory, compilers and interpreters, program verification and model checking.


== Approaches ==
There are many approaches to formal semantics; these belong to three major classes:

Denotational semantics, whereby each phrase in the language is interpreted as a denotation, i.e. a conceptual meaning that can be thought of abstractly.  Such denotations are often mathematical objects inhabiting a mathematical space, but it is not a requirement that they should be so.  As a practical necessity, denotations are described using some form of mathematical notation, which can in turn be formalized as a denotational metalanguage.  For example, denotational semantics of functional languages often translate the language into domain theory. Denotational semantic descriptions can also serve as compositional translations from a programming language into the denotational metalanguage and used as a basis for designing compilers.
Operational semantics, whereby the execution of the language is described directly (rather than by translation).  Operational semantics loosely corresponds to interpretation, although again the ""implementation language"" of the interpreter is generally a mathematical formalism.  Operational semantics may define an abstract machine (such as the SECD machine), and give meaning to phrases by describing the transitions they induce on states of the machine.  Alternatively, as with the pure lambda calculus, operational semantics can be defined via syntactic transformations on phrases of the language itself;
Axiomatic semantics, whereby one gives meaning to phrases by describing the axioms that apply to them.  Axiomatic semantics makes no distinction between a phrase's meaning and the logical formulas that describe it; its meaning is exactly what can be proven about it in some logic.  The canonical example of axiomatic semantics is Hoare logic.Apart from the choice between denotational, operational, or axiomatic approaches, most variations in formal semantic systems arise from the choice of supporting mathematical formalism.


== Variations ==
Some variations of formal semantics include the following:

Action semantics is an approach that tries to modularize denotational semantics, splitting the formalization process in two layers (macro and microsemantics) and predefining three semantic entities (actions, data and yielders) to simplify the specification;
Algebraic semantics is a form of axiomatic semantics based on algebraic laws for describing and reasoning about program semantics in a formal manner. It also supports denotational semantics and operational semantics;
Attribute grammars define systems that systematically compute ""metadata"" (called attributes) for the various cases of the language's syntax.  Attribute grammars can be understood as a denotational semantics where the target language is simply the original language enriched with attribute annotations.  Aside from formal semantics, attribute grammars have also been used for code generation in compilers, and to augment regular or context-free grammars with context-sensitive conditions;
Categorical (or ""functorial"") semantics uses category theory as the core mathematical formalism. A categorical semantics is usually proven to correspond to some axiomatic semantics that gives a syntactic presentation of the categorical structures. Also, denotational semantics are often instances of a general categorical semantics;
Concurrency semantics is a catch-all term for any formal semantics that describes concurrent computations.  Historically important concurrent formalisms have included the actor model and process calculi;
Game semantics uses a metaphor inspired by game theory;
Predicate transformer semantics, developed by Edsger W. Dijkstra, describes the meaning of a program fragment as the function transforming a postcondition to the precondition needed to establish it.


== Describing relationships ==
For a variety of reasons, one might wish to describe the relationships between different formal semantics.  For example:

To prove that a particular operational semantics for a language satisfies the logical formulas of an axiomatic semantics for that language.  Such a proof demonstrates that it is ""sound"" to reason about a particular (operational) interpretation strategy using a particular (axiomatic) proof system.
To prove that operational semantics over a high-level machine is related by a simulation with the semantics over a low-level machine, whereby the low-level abstract machine contains more primitive operations than the high-level abstract machine definition of a given language. Such a proof demonstrates that the low-level machine ""faithfully implements"" the high-level machine.It is also possible to relate multiple semantics through abstractions via the theory of abstract interpretation.


== See also ==
Computational semantics
Formal semantics (logic)
Formal semantics (linguistics)
Ontology
Ontology (information science)
Semantic equivalence
Semantic technology


== References ==


== Further reading ==
Textbooks"
0be417a858,Outline of computer science,"Computer science (also called computing science) is the study of the theoretical foundations of information and computation and their implementation and application in computer systems. One well known subject classification system for computer science is the ACM Computing Classification System devised by the Association for Computing Machinery.
Computer science can be described as all of the following:

Academic discipline
Science
Applied science


== Subfields ==


=== Mathematical foundations ===
Coding theory – Useful in networking, programming, system development, and other areas where computers communicate with each other.
Game theory – Useful in artificial intelligence and cybernetics.
Discrete Mathematics
Graph theory – Foundations for data structures and searching algorithms.
Mathematical logic – Boolean logic and other ways of modeling logical queries; the uses and limitations of formal proof methods
Number theory – Theory of the integers.  Used in cryptography as well as a test domain in artificial intelligence.


=== Algorithms and data structures ===
Algorithms – Sequential and parallel computational procedures for solving a wide range of problems.
Data structures – The organization and manipulation of data.


=== Artificial intelligence ===
Outline of artificial intelligence

Artificial intelligence – The implementation and study of systems that exhibit an autonomous intelligence or behavior of their own.
Automated reasoning – Solving engines, such as used in Prolog, which produce steps to a result given a query on a fact and rule database, and automated theorem provers that aim to prove mathematical theorems with some assistance from a programmer.
Computer vision – Algorithms for identifying three-dimensional objects from a two-dimensional picture.
Soft computing, the use of inexact solutions for otherwise extremely difficult problems:
Machine learning - Development of models that are able to learn and adapt without following explicit instructions, by using algorithms and statistical models to analyse and draw inferences from patterns in data.
Evolutionary computing - Biologically inspired algorithms.
Natural language processing - Building systems and algorithms that analyze, understand, and generate natural (human) languages.
Robotics – Algorithms for controlling the behaviour of robots.


=== Communication and security ===
Networking – Algorithms and protocols for reliably communicating data across different shared or dedicated media, often including error correction.
Computer security – Practical aspects of securing computer systems and computer networks.
Cryptography – Applies results from complexity, probability, algebra and number theory to invent and break codes, and analyze the security of cryptographic protocols.


=== Computer architecture ===
Computer architecture – The design, organization, optimization and verification of a computer system, mostly about CPUs and Memory subsystem (and the bus connecting them).
Operating systems – Systems for managing computer programs and providing the basis of a usable system.


=== Computer graphics ===
Computer graphics – Algorithms both for generating visual images synthetically, and for integrating or altering visual and spatial information sampled from the real world.
Image processing – Determining information from an image through computation.
Information visualization – Methods for representing and displaying abstract data to facilitate human interaction for exploration and understanding.


=== Concurrent, parallel, and distributed systems ===
Parallel computing - The theory and practice of simultaneous computation; data safety in any multitasking or multithreaded environment.
Concurrency (computer science) – Computing using multiple concurrent threads of execution, devising algorithms for solving problems on multiple processors to achieve maximal speed-up compared to sequential execution.
Distributed computing – Computing using multiple computing devices over a network to accomplish a common objective or task and thereby reducing the latency involved in single processor contributions for any task.


=== Databases ===
Outline of databases

Relational databases – the set theoretic and algorithmic foundation of databases.
Structured Storage - non-relational databases such as NoSQL databases.
Data mining – Study of algorithms for searching and processing information in documents and databases; closely related to information retrieval.


=== Programming languages and compilers ===
Compiler theory – Theory of compiler design, based on Automata theory.
Programming language pragmatics – Taxonomy of programming languages, their strength and weaknesses. Various programming paradigms, such as object-oriented programming.
Programming language theory
Formal semantics – rigorous mathematical study of the meaning of programs.
Type theory – Formal analysis of the types of data, and the use of these types to understand properties of programs — especially program safety.


=== Scientific computing ===
Computational science – constructing mathematical models and quantitative analysis techniques and using computers to analyze and solve scientific problems.
Numerical analysis – Approximate numerical solution of mathematical problems such as root-finding, integration, the solution of ordinary differential equations; the approximation of special functions.
Symbolic computation – Manipulation and solution of expressions in symbolic form, also known as Computer algebra.
Computational physics – Numerical simulations of large non-analytic systems
Computational chemistry – Computational modelling of theoretical chemistry in order to determine chemical structures and properties
Bioinformatics and Computational biology – The use of computer science to maintain, analyse, store biological data and to assist in solving biological problems such as Protein folding, function prediction and Phylogeny.
Computational neuroscience – Computational modelling of neurophysiology.


=== Software engineering ===
Outline of software engineering

Formal methods – Mathematical approaches for describing and reasoning about software design.
Software engineering – The principles and practice of designing, developing, and testing programs, as well as proper engineering practices.
Algorithm design – Using ideas from algorithm theory to creatively design solutions to real tasks.
Computer programming – The practice of using a programming language to implement algorithms.
Human–computer interaction – The study and design of computer interfaces that people use.
Reverse engineering – The application of the scientific method to the understanding of arbitrary existing software.


=== Theory of computation ===

Automata theory – Different logical structures for solving problems.
Computability theory – What is calculable with the current models of computers. Proofs developed by Alan Turing and others provide insight into the possibilities of what may be computed and what may not.
List of unsolved problems in computer science
Computational complexity theory – Fundamental bounds (especially time and storage space) on classes of computations.
Quantum computing theory – Explores computational models involving quantum superposition of bits.


== History ==
History of computer science
List of pioneers in computer science


== Professions ==
Programmer (Software developer)
Teacher/Professor
Software engineer
Software architect
Software tester
Hardware engineer
Data analyst
Interaction designer
Network administrator
Data scientist


== Data and data structures ==
Data structure
Data type
Associative array and Hash table
Array
List
Tree
String
Matrix (computer science)
Database


== Programming paradigms ==
Imperative programming/Procedural programming
Functional programming
Logic programming
Object oriented programming
Class
Inheritance
Object


== See also ==
Abstraction
Big O notation
Closure
Compiler
Cognitive science


== External links ==

Outline of computer science at Curlie
ACM report on a recommended computer science curriculum (2008)
Directory of free university lectures in Computer Science
Collection of Computer Science Bibliographies
Photographs of computer scientists (Bertrand Meyer's gallery)"
86b92e6310,AP Computer Science,"In the United States, Advanced Placement Computer Science (commonly shortened to AP Comp Sci) is a suite of Advanced Placement courses and examinations covering areas of computer science. They are offered by the College Board to high school students as an opportunity to earn college credit for college-level courses.  The suite consists of two current classes and one discontinued class.
AP Computer Science was taught in Pascal for the 1984–1998 exams, in C++ for 1999–2003, and in Java since 2004.


== AP Computer Science A ==
AP Computer Science A is a programming class.  The course emphasizes object-oriented programming methodology, especially problem solving and algorithm development, plus an overview of data structures and abstraction. The AP Computer Science A exam tests students on their knowledge of Java.
It is meant to be the equivalent of a first-semester college course in computer science. 
The Microsoft-sponsored program Technology Education and Literacy in Schools (TEALS) aims to increase the number of students taking AP Computer Science classes.


== AP Computer Science AB (discontinued) ==
AP Computer Science AB included all the topics of AP Computer Science A, as well as a more formal and a more in-depth study of algorithms, data structures, and data abstraction. For example, binary trees were studied in AP Computer Science AB but not in AP Computer Science A. The use of recursive data structures and dynamically allocated structures were fundamental to AP Computer Science AB. 
AP Computer Science AB was equivalent to a full-year college course.Due to low numbers of students taking the exam, AP Computer Science AB was discontinued following the May 2009 exam administration.


== AP Computer Science Principles ==
AP Computer Science Principles is an introductory course to computer science, ""with a focus on how computing powers the world"". It is designed as a complement to AP Computer Science A, to emphasize computational thinking and fluency. It is meant to be the equivalent of a first-semester course in computing.


== See also ==
AP Computer Science A
Computer science
Glossary of computer science
Scope (computer science)
Computer graphics (computer science)


== References =="
118cee8d95,Bachelor of Computer Science,"The Bachelor of Computer Science (abbreviated BCompSc or BCS) is a bachelor's degree awarded by some universities for completion of an undergraduate program in computer science. In general, computer science degree programs emphasize the mathematical and theoretical foundations of computing.


== Typical requirements ==
Because computer science is a wide field, courses required to earn a bachelor of computer science degree vary. A typical list of course requirements includes topics such as:
Computer programming
Programming paradigms
Algorithms
Data structures
Logic & Computation
Computer architectureSome schools may place more emphasis on mathematics and require additional courses such as:
Linear algebra
Calculus
Probability theory and statistics
Combinatorics and discrete mathematics
Differential calculus and mathematicsBeyond the basic set of computer science courses, students can typically choose additional courses from a variety of different fields, such as:
Theory of computation
Operating systems
Numerical computation
Compilers, compiler design
Real-time computing
Distributed systems
Computer networking
Data communication
Computer graphics
Artificial intelligence
Human-computer interaction
Information theory
Software testing
Information assuranceSome schools allow students to specialize in a certain area of computer science.


== Related degrees ==
Bachelor of Software Engineering
Bachelor of Science in Information Technology
Bachelor of Computing
Bachelor of Information Technology
Bachelor of Computer Information Systems


== See also ==
Computer science
Computer science and engineering


== References =="
619a440675,Computer science education,"Computer science education  or computing education is the field of teaching and learning the discipline of computer science, and computational thinking. The field of computer science education encompasses a wide range of topics, from basic programming skills to advanced algorithm design and data analysis. It is a rapidly growing field that is essential to preparing students for careers in the technology industry and other fields that require computational skills.Computer science education is essential to preparing students for the 21st century workforce. As technology becomes increasingly integrated into all aspects of society, the demand for skilled computer scientists is growing. According to the Bureau of Labor Statistics, employment of computer and information technology occupations is projected to ""grow 21 percent from 2021 to 2031"", much faster than the average for all occupations.In addition to preparing students for careers in the technology industry, computer science education also promotes computational thinking skills, which are valuable in many fields, including business, healthcare, and education. By learning to think algorithmically and solve problems systematically, students can become more effective problem solvers and critical thinkers.


== Background ==
The history of computer science education can be traced back to the early days of computing, when programming was primarily done by scientists and mathematicians. As computers became more widely used in industry and government, the need for skilled programmers grew, and universities began to offer courses in computer science.
In comparison to  science education and mathematics education, computer science (CS) education is a much younger field. In the history of computing, digital computers were only built from around the 1940s – although computation has been around for centuries since the invention of analog computers.Another differentiator of computer science education is that it has primarily only been taught at university level until recently, with some notable exceptions in Israel, Poland and the United Kingdom with the BBC Micro in the 1980s as part of Computer science education in the United Kingdom. Computer science has been a part of the school curricula from age 14 or age 16 in a few countries for a few decades, but has typically as an elective subject.
Primary and secondary computer science education is relatively new in the United States with many K-12 CS teachers facing obstacles to integrating CS instruction such as professional isolation, limited CS professional development resources, and low levels of CS teaching self-efficacy. According to a 2021 report, only 51% of high schools in the US offer computer science.
Elementary CS teachers in particular have lower CS teaching efficacy and have fewer chances to implement CS into their instruction than their middle and high school peers. Connecting CS teachers to resources and peers using methods such as Virtual Communities of Practice has been shown to help CS and STEM teachers improve their teaching self-efficacy and implement CS topics into student instruction. 


== Curriculum ==
The curriculum for computer science education varies depending on the level of education and country. At the elementary and middle school level, computer science education usually focuses on block or visual programming languages such as Scratch using basic programming concepts, such as loops, conditionals, and variables. At the high school level, students may learn more advanced programming concepts and algorithms, as well as web development, networking, and data analysis.
In college and graduate school, computer science education may include courses in topics such as artificial intelligence, machine learning, data science, and computer graphics. Many computer science programs also offer courses in computer architecture, operating systems, and computer networks.


== Teaching Methods ==
Teaching methods in computer science education vary depending on the level of education and the goals of the program. At the elementary and middle school level, computer science education may focus on interactive games and puzzles to teach programming concepts. In high school and college, computer science education may involve lectures, labs, and hands-on projects that allow students to apply their knowledge to real-world problems.
Online learning platforms and coding bootcamps have also become popular methods of teaching computer science skills. These programs offer self-paced learning and can be accessed from anywhere with an internet connection.


== Computing Education Research ==
Computing education research (CER) or Computer science education research is an interdisciplinary field that focuses on studying the teaching and learning of computer science  . It is a subfield of both computer science and education research, and is concerned with understanding how computer science is taught, learned, and assessed in a variety of settings, such as K-12 schools, colleges and universities, and online learning environments.


=== Background ===
Computer science education research emerged as a field of study in the 1970s, when researchers began to explore the effectiveness of different approaches to teaching computer programming. Since then, the field has grown to encompass a wide range of topics related to computer science education, including curriculum design, assessment, pedagogy, and diversity and inclusion.


=== Topics of Study ===
One of the primary goals of computer science education research is to improve the teaching and learning of computer science. To this end, researchers study a variety of topics, including:


==== Curriculum Design ====
Researchers in computer science education seek to design curricula that are effective and engaging for students. This may involve studying the effectiveness of different programming languages, or developing new pedagogical approaches that promote active learning.


==== Assessment ====
Computer science education researchers are interested in developing effective ways to assess student learning outcomes. This may involve developing new measures of student knowledge or skills, or evaluating the effectiveness of different assessment methods.


==== Pedagogy ====
Researchers in computer science education are interested in exploring different teaching methods and instructional strategies. This may involve studying the effectiveness of lectures, online tutorials, or peer-to-peer learning.


==== Diversity and Inclusion ====
Computer science education researchers are interested in promoting diversity and inclusion in computer science education. This may involve studying the factors that contribute to under representation of certain groups in computer science, and developing interventions to promote inclusivity and equity.


== Research Communities ==
The Association for Computing Machinery (ACM) runs a Special Interest Group (SIG) on Computer science education known as SIGCSE which celebrated its 50th anniversary in 2018, making it one of the oldest and longest running ACM Special Interest Groups. An outcome of computing education research are Parsons problems.


=== Conferences ===
ITiCSE
ICER
CompEd 2
Technical Symposium


== Gender perspectives in computer science education ==
In many countries, there is a significant gender gap in computer science education. In 2015, 15.3% of computer science students graduating from non-doctoral granting institutions in the US were women while at doctoral granting institutions, the figure was 16.6%. The number of female PhD recipients in the US was 19.3% in 2018. In almost everywhere in the world, less than 20% of the computer science graduates are female. This problem mainly arises due to the lack of interests of girls in computing starting from the primary level. Despite numerous efforts by programs specifically designed to increase the ratio of women in this field, no significant improvement has been observed. Furthermore, a declining trend has been noticed in the involvement of women in past decades. The main reason for the failure of these programs is because almost all of them focused on girls in high school or higher levels of education. Researchers argue that by then women have already made up their mind and stereotypes start to form about computer scientists. Computer Science is perceived as a male dominated field, pursued by people who are nerdy and lack social skills. All these characteristics seem to be more damaging for a woman as compared to a man. Therefore, in order to break these stereotypes and to engage more women in computer science, it is crucial that there are special outreach programs designed to develop interest in girls starting at the middle school level and prepare them for a academic track towards the hard sciences.Evidently, there are a few countries in Asia and Africa where these stereotypes do not exist and women are encouraged for a career in science starting at the primary level, thus resulting in a gender gap that is virtually nonexistent. In 2011, women earned half of the computer science degrees in Malaysia. In 2001, 55 percent of computer science graduates in Guyana were women.


== References =="
4e6e30bbae,Node (computer science),"A node is a basic unit of a data structure, such as a linked list or tree data structure. Nodes contain data and also may link to other nodes. Links between nodes are often implemented by pointers.


== Nodes and Trees ==

Nodes are often arranged into tree structures. A node represents the information contained in a single data structure. These nodes may contain a value or condition, or possibly serve as another independent data structure. Nodes are represented by a single parent node. The highest point on a tree structure is called a root node, which does not have a parent node, but serves as the parent or 'grandparent' of all of the nodes below it in the tree. The height of a node is determined by the total number of edges on the path from that node to the furthest leaf node, and the height of the tree is equal to the height of the root node. Node depth is determined by the distance between that particular node and the root node. The root node is said to have a depth of zero. Data can be discovered along these network paths.
An IP address uses this kind of system of nodes to define its location in a network.


=== Definitions ===
Child: A child node is a node extending from another node. For example, a computer with internet access could be considered a child node of a node representing the internet. The inverse relationship is that of a parent node. If node C is a child of node A, then A is the parent node of C.
Degree: the degree of a node is the number of children of the node.
Depth: the depth of node A is the length of the path from A to the root node. The root node is said to have depth 0.
Edge: the connection between nodes.
Forest: a set of trees.
Height: the height of node A is the length of the longest path through children to a leaf node.
Internal node: a node with at least one child.
Leaf node: a node with no children.
Root node: a node distinguished from the rest of the tree nodes. Usually, it is depicted as the highest node of the tree.
Sibling nodes: these are nodes connected to the same parent node.


== Markup languages ==
Another common use of node trees is in web development. In programming, XML is used to communicate information between computer programmers and computers alike. For this reason XML is used to create common communication protocols used in office productivity software, and serves as the base for the development of modern web markup languages like XHTML. Though similar in how it is approached by a programmer, HTML and CSS is typically the language used to develop website text and design. While XML, HTML and XHTML provide the language and expression, the DOM serves as a translator.


=== Node type ===
Different types of nodes in a tree are represented by specific interfaces. In other words, the node type is defined by how it communicates with other nodes. Each node has a node type property, which specifies the type of node, such as sibling or leaf.
For example, if the node type property is the constant properties for a node, this property specifies the type of the node. So if a node type property is the constant node ELEMENT_NODE, one can know that this node object is an object Element. This object uses the Element interface to define all the methods and properties of that particular node.
Different W3C World Wide Web Consortium node types and descriptions:

Document represents the entire document (the root-node of the DOM tree)
DocumentFragment represents a ""lightweight"" Document object, which can hold a portion of a document
DocumentType provides an interface to the entities defined for the document
ProcessingInstruction represents a processing instruction
EntityReference represents an entity reference
Element 	represents an element
Attr represents an attribute
Text represents textual content in an element or attribute
CDATASection represents a CDATA section in a document (text that will NOT be parsed by a parser)
Comment represents a comment
Entity represents an entity
Notation represents a notation declared in the DTD


=== Node object ===
A node object is represented by a single node in a tree. It can be an element node, attribute node, text node, or any type that is described in section ""node type"". All objects can inherit properties and methods for dealing with parent and child nodes, but not all of the objects have parent or child nodes. For example, with text nodes that cannot have child nodes, trying to add child nodes results in a DOM error.
Objects in the DOM tree may be addressed and manipulated by using methods on the objects. The public interface of a DOM is specified in its application programming interface (API). The history of the Document Object Model is intertwined with the history of the ""browser wars"" of the late 1990s between Netscape Navigator and Microsoft Internet Explorer, as well as with that of JavaScript and JScript,  the first scripting languages to be widely implemented in the layout engines of web browsers.


== See also ==
Vertex (graph theory)


== References ==


== External links ==
Data Trees as a Means of Presenting Complex Data Analysis by Sally Knipe
STL-like C++ tree class
Description of tree data structures from ideainfo.8m.com
WormWeb.org: Interactive Visualization of the C. elegans Cell Tree - Visualize the entire cell lineage tree of the nematode C. elegans (javascript)"
a6ce078840,Record (computer science),"In computer science, a record (also called a structure,  struct, or compound data) is a basic data structure. Records in a database or spreadsheet are usually called ""rows"".A record is a collection of fields, possibly of different data types, typically in a fixed number and sequence. The fields of a record may also be called members, particularly in object-oriented programming; fields may also be called elements, though this risks confusion with the elements of a collection.
For example, a date could be stored as a record containing a numeric year field, a month field represented as a string, and a numeric day-of-month field. A personnel record might contain a name, a salary, and a rank. A Circle record might contain a center and a radius—in this instance, the center itself might be represented as a point record containing x and y coordinates.
Records are distinguished from arrays by the fact that their number of fields is determined in the definition of the record, and by the fact the records are a heterogenous data type; not all of the fields must contain the same type of data.A record type is a data type that describes such values and variables. Most modern computer languages allow the programmer to define new record types. The definition includes specifying the data type of each field and an identifier (name or label) by which it can be accessed.  In type theory, product types (with no field names) are generally preferred due to their simplicity, but proper record types are studied in languages such as System F-sub.  Since type-theoretical records may contain first-class function-typed fields in addition to data, they can express many features of object-oriented programming.
Records can exist in any storage medium, including main memory and mass storage devices such as magnetic tapes or hard disks.  Records are a fundamental component of most data structures, especially linked data structures.  Many computer files are organized as arrays of logical records, often grouped into larger physical records or blocks for efficiency.
The parameters of a function or procedure can often be viewed as the fields of a record variable; and the arguments passed to that function can be viewed as a record value that gets assigned to that variable at the time of the call. Also, in the call stack that is often used to implement procedure calls, each entry is an activation record or call frame, containing the procedure parameters and local variables, the return address, and other internal fields.
An object in object-oriented language is essentially a record that contains procedures specialized to handle that record; and object types are an elaboration of record types. Indeed, in most object-oriented languages, records are just special cases of objects, and are known as plain old data structures (PODSs), to contrast with objects that use OO features.
A record can be viewed as the computer analog of a mathematical tuple, although a tuple may or may not be considered a record, and vice versa, depending on conventions and the specific programming language.  In the same vein, a record type can be viewed as the computer language analog of the Cartesian product of two or more mathematical sets, or the implementation of an abstract product type in a specific language.


== Keys ==
A record may have zero or more keys. A key maps an expression to a value, or a set of values, in the record. A primary key is a key this is unique throughout all stored records; only one if this key exists. In other words, no duplicate may exist for any primary key. For example an employee file might contain employee number, name, department, and salary. The employee number will be unique in the organization and would be the primary key. Depending on the storage medium and file organization the employee number might be indexed—that is also stored in a separate file to make lookup faster. The department code is not necessarily unique; it may also be indexed, in which case it would be considered a secondary key, or alternate key. If it is not indexed the entire employee file would have to be scanned to produce a listing of all employees in a specific department. Keys are usually chosen in a way that minimizes the chances of multiple values being feasibly mapped to by one key. For example, the salary field would not normally be considered usable as a key since many employees will likely have the same salary. Indexing is one factor considered when designing a file.


== History ==

The concept of a record can be traced to various types of tables and ledgers used in accounting since remote times.  The modern notion of records in computer science, with fields of well-defined type and size, was already implicit in 19th century mechanical calculators, such as Babbage's Analytical Engine.

The original machine-readable medium used for data (as opposed to control) was punch card used for records in the 1890 United States Census: each punch card was a single record. Compare the journal entry from 1880 and the punch card from 1895. Records were well-established in the first half of the 20th century, when most data processing was done using punched cards. Typically each record of a data file would be recorded in one punched card, with specific columns assigned to specific fields. Generally, a record was the smallest unit that could be read in from external storage (e.g. card reader, tape or disk). The contents of punchcard-style records were originally called ""unit records"" because since punchcards had pre-determined document lengths. When storage systems became more advanced with the use of hard drives and magnetic tape, variable-length records became the standard. A variable-length record is a record in which the size of the record in bytes is approximately equal to the sum of the sizes of its fields. This was not possible to do before more advanced storage hardware was invented because all of the punchcards had to conform to pre-determined document lengths that the computer could read, since at the time the cards had to be physically fed into a machine. 
Most machine language implementations and early assembly languages did not have special syntax for records, but the concept was available (and extensively used) through the use of index registers, indirect addressing, and self-modifying code. Some early computers, such as the IBM 1620, had hardware support for delimiting records and fields, and special instructions for copying such records.
The concept of records and fields was central in some early file sorting and tabulating utilities, such as IBM's Report Program Generator (RPG).
COBOL was the first widespread programming language to support record types, and its record definition facilities were quite sophisticated at the time. The language allows for the definition of nested records with alphanumeric, integer, and fractional fields of arbitrary size and precision, as well as fields that automatically format any value assigned to them (e.g., insertion of currency signs, decimal points, and digit group separators). Each file is associated with a record variable where data is read into or written from. COBOL also provides a MOVE CORRESPONDING statement that assigns corresponding fields of two records according to their names.
The early languages developed for numeric computing, such as FORTRAN (up to FORTRAN IV) and Algol 60, did not have support for record types; but later versions of those languages, such as FORTRAN 77 and Algol 68 did add them. The original Lisp programming language too was lacking records (except for the built-in cons cell), but its S-expressions provided an adequate surrogate. The Pascal programming language was one of the first languages to fully integrate record types with other basic types into a logically consistent type system. The PL/I programming language provided for COBOL-style records. The C programming language initially provided the record concept as a kind of template (struct) that could be laid on top of a memory area, rather than a true record data type.  The latter were provided eventually (by the typedef declaration), but the two concepts are still distinct in the language. Most languages designed after Pascal (such as Ada, Modula, and Java), also supported records.
Although records are not often used in their original context anymore (i.e. being used solely for the purpose of containing data), records influenced  newer object oriented programming languages and relational database management systems. Since records provided more modularity in the way data was stored and handled, they are better suited at representing complex, real-world concepts than the primitive data types provided by default in languages. This influenced later languages such as C++, Python, JavaScript, and Objective-C which address the same modularity concerns of programmers. Objects in these languages are essentially records with the addition of methods and inheritance, which allow programmers to manipulate the way data behaves instead of only the contents of a record. Many programmers regard records as obsolete now since object-oriented languages have features that far surpass what records are capable of. On the other hand, many programmers argue that the low overhead and ability to use records in assembly language make records still relevant when programming with low levels of abstraction. to Today, the most popular languages on the TIOBE index, an indicator of the popularity of programming languages, have been influenced in some way by records due to the fact that they are object oriented. Query languages such as SQL and Object Query Language were also influenced by the concept of records. These languages allow the programmer to store sets of data, which are essentially records, in tables. This data can then be retrieved using a primary key. The tables themselves are also records which may have a foreign key: a key that references data in another table.   


== Operations ==
Declaration of a new record type, including the position, type, and (possibly) name of each field;
Declaration of variables and values as having a given record type;
Construction of a record value from given field values and (sometimes) with given field names;
Selection of a field of a record with an explicit name;
Assignment of a record value to a record variable;
Comparison of two records for equality;
Computation of a standard hash value for the record.The selection of a field from a record value yields a value.
Some languages may provide facilities that enumerate all fields of a record, or at least the fields that are references. This facility is needed to implement certain services such as debuggers, garbage collectors, and serialization. It requires some degree of type polymorphism.
In systems with record subtyping, operations on values of record type may also include:

Adding a new field to a record, setting the value of the new field.
Removing a field from a record.In such settings, a specific record type implies that a specific set of fields are present, but values of that type may contain additional fields. A record with fields x, y, and z would thus belong to the type of records with fields x and y, as would a record with fields x, y, and r. The rationale is that passing an (x,y,z) record to a function that expects an (x,y) record as argument should work, since that function will find all the fields it requires within the record. Many ways of practically implementing records in programming languages would have trouble with allowing such variability, but the matter is a central characteristic of record types in more theoretical contexts.


=== Assignment and comparison ===
Most languages allow assignment between records that have exactly the same record type (including same field types and names, in the same order). Depending on the language, however, two record data types defined separately may be regarded as distinct types even if they have exactly the same fields.
Some languages may also allow assignment between records whose fields have different names, matching each field value with the corresponding field variable by their positions within the record; so that, for example, a complex number with fields called real and imag can be assigned to a 2D point record variable with fields X and Y.  In this alternative, the two operands are still required to have the same sequence of field types.  Some languages may also require that corresponding types have the same size and encoding as well, so that the whole record can be assigned as an uninterpreted bit string.  Other languages may be more flexible in this regard, and require only that each value field can be legally assigned to the corresponding variable field; so that, for example, a short integer field can be assigned to a long integer field, or vice versa.
Other languages (such as COBOL) may match fields and values by their names, rather than positions.
These same possibilities apply to the comparison of two record values for equality.  Some languages may also allow order comparisons ('<'and '>'), using the lexicographic order based on the comparison of individual fields.PL/I allows both of the preceding types of assignment, and also allows structure expressions, such as a = a+1; where ""a"" is a record, or structure in PL/I terminology.


=== Algol 68's distributive field selection ===
In Algol 68, if Pts was an array of records, each with integer fields X and Y, one could write Y of Pts to obtain an array of integers, consisting of the Y fields of all the elements of Pts.  As a result, the statements Y of Pts[3] := 7 and (Y of Pts)[3] := 7 would have the same effect.


=== Pascal's ""with"" statement ===
In the Pascal programming language, the command with R do S would execute the command sequence S as if all the fields of record R had been declared as variables. Similarly to entering a different namespace in an object-oriented language like C#, it is no longer necessary to use the record name as a prefix to access the fields. So, instead of writing Pt.X := 5; Pt.Y := Pt.X + 3 one could write with Pt do begin X := 5; Y := X + 3 end.


== Representation in memory ==
The representation of records in memory varies depending on the programming languages. Usually the fields are stored in consecutive positions in memory, in the same order as they are declared in the record type. This may result in two or more fields stored into the same word of memory; indeed, this feature is often used in systems programming to access specific bits of a word. On the other hand, most compilers will add padding fields, mostly invisible to the programmer, in order to comply with alignment constraints imposed by the machine—say, that a floating point field must occupy a single word.
Some languages may implement a record as an array of addresses pointing to the fields (and, possibly, to their names and/or types). Objects in object-oriented languages are often implemented in rather complicated ways, especially in languages that allow multiple class inheritance.


== Self-defining records ==
A self-defining record is a type of record which contains information to identify the record type and to locate information within the record.  It may contain the offsets of elements; the elements can therefore be stored in any order or may be omitted. The information stored in a self-defining record can be interpreted as metadata for the record, which is similar to what one would expect to find in the UNIX metadata regarding a file, containing information such as the record's creation time and the size of the record in bytes. Alternatively, various elements of the record, each including an element identifier, can simply follow one another in any order.


== See also ==
Block (data storage)
Composite data type
Data hierarchy
Object composition
Passive data structure
Union type


== References =="
1f33a81599,Data (computer science),"In computer science, data (treated as singular, plural, or as a mass noun) is any sequence of one or more symbols; datum is a single symbol of data. Data requires interpretation to become information. Digital data is data that is represented using the binary number system of ones (1) and zeros (0), instead of analog representation. In modern (post-1960) computer systems, all data is digital. 
Data exists in three states: data at rest, data in transit and data in use.  Data within a computer, in most cases, moves as parallel data. Data moving to or from a computer, in most cases, moves as serial data. Data sourced from an analog device, such as a temperature sensor, may be converted to digital using an analog-to-digital converter. Data representing quantities, characters, or symbols on which operations are performed by a computer are stored and recorded on magnetic, optical, electronic, or mechanical recording media, and transmitted in the form of digital electrical or optical signals. Data pass in and out of computers via peripheral devices.
Physical computer memory elements consist of an address and a byte/word of data storage. Digital data are often stored in relational databases, like tables or SQL databases, and can generally be represented as abstract key/value pairs. Data can be organized in many different types of data structures, including arrays, graphs, and objects. Data structures can store data of many different types, including numbers, strings and even other data structures.


== Characteristics ==
Metadata helps translate data to information. Metadata is data about the data. Metadata may be implied, specified or given.  
Data relating to physical events or processes will have a temporal component. This temporal component may be implied. This is the case when a device such as a temperature logger receives data from a temperature sensor. When the temperature is received it is assumed that the data has a temporal reference of now. So the device records the date, time and temperature together.  When the data logger communicates temperatures, it must also report the date and time as metadata for each temperature reading.
Fundamentally, computers follow a sequence of instructions they are given in the form of data.  A set of instructions to perform a given task (or tasks) is called a program. A program is data in the form of coded instructions to control the operation of a computer or other machine.  In the nominal case, the program, as executed by the computer, will consist of machine code.  The elements of storage manipulated by the program, but not actually executed by the central processing unit (CPU), are also data. At its most essential, a single datum is a value stored at a specific location. Therefore, it is possible for computer programs to operate on other computer programs, by manipulating their programmatic data.
To store data bytes in a file, they have to be serialized in a file format. Typically, programs are stored in special file types, different from those used for other data.  Executable files contain programs; all other files are also data files.  However, executable files may also contain data used by the program which is built into the program.  In particular, some executable files have a data segment, which nominally contains constants and initial values for variables, both of which can be considered data.
The line between program and data can become blurry.  An interpreter, for example, is a program.  The input data to an interpreter is itself a program, just not one expressed in native machine language.  In many cases, the interpreted program will be a human-readable text file, which is manipulated with a text editor program. Metaprogramming similarly involves programs manipulating other programs as data.  Programs like compilers, linkers, debuggers, program updaters, virus scanners and such use other programs as their data.
For example, a user might first instruct the operating system to load a word processor program from one file, and then use the running program to open and edit a document stored in another file.  In this example, the document would be considered data.  If the word processor also features a spell checker, then the dictionary (word list) for the spell checker would also be considered data.  The algorithms used by the spell checker to suggest corrections would be either machine code data or text in some interpretable programming language.
In an alternate usage, binary files (which are not human-readable) are sometimes called data as distinguished from human-readable text.The total amount of digital data in 2007 was estimated to be 281 billion gigabytes (281 exabytes).


== Data keys and values, structures and persistence ==
Keys in data provide the context for values.  Regardless of the structure of data, there is always a key component present. Keys in data and data-structures are essential for giving meaning to data values. Without a key that is directly or indirectly associated with a value, or collection of values in a structure, the values become meaningless and cease to be data. That is to say, there has to be a key component linked to a value component in order for it to be considered data.Data can be represented in computers in multiple ways, as per the following examples:


=== RAM ===
Random access memory (RAM) holds data that the CPU has direct access to. A CPU may only manipulate data within its processor registers or memory.  This is as opposed to data storage, where the CPU must direct the transfer of data between the storage device (disk, tape...) and memory. RAM is an array of linear contiguous locations that a processor may read or write by providing an address for the read or write operation. The processor may operate on any location in memory at any time in any order. In RAM the smallest element of data is the binary bit.  The capabilities and limitations of accessing RAM are processor specific. In general main memory is arranged as an array of locations beginning at address 0 (hexadecimal 0).   Each location can store usually 8 or 32 bits depending on the computer architecture.


=== Keys ===
Data keys need not be a direct hardware address in memory. Indirect, abstract and logical keys codes can be stored in association with values to form a data structure.  Data structures have predetermined offsets (or links or paths) from the start of the structure, in which data values are stored. Therefore, the data key consists of the key to the structure plus the offset (or links or paths) into the structure. When such a structure is repeated, storing variations of the data values and the data keys within the same repeating structure, the result can be considered to resemble a table, in which each element of the repeating structure is considered to be a column and each repetition of the structure is considered as a row of the table.  In such an organization of data, the data key is usually a value in one (or a composite of the values in several) of the columns.


=== Organised recurring data structures ===
The tabular view of repeating data structures is only one of many possibilities.  Repeating data structures can be organised hierarchically, such that nodes are linked to each other in a cascade of parent-child relationships.  Values and potentially more complex data-structures are linked to the nodes. Thus the nodal hierarchy provides the key for addressing the data structures associated with the nodes. This representation can be thought of as an inverted tree. E.g. modern computer operating system file systems are a common example; and XML is another.


=== Sorted or ordered data ===
Data has some inherent features when it is sorted on a key. All the values for subsets of the key appear together. When passing sequentially through groups of the data with the same key, or a subset of the key changes, this is referred to in data processing circles as a break, or a control break. It particularly facilitates the aggregation of data values on subsets of a key.


=== Peripheral storage ===
Until the advent of bulk non-volatile memory like flash, persistent data storage was traditionally achieved by writing the data to external block devices like magnetic tape and disk drives. These devices typically seek to a location on the magnetic media and then read or write blocks of data of a predetermined size. In this case, the seek location on the media, is the data key and the blocks are the data values. Early used raw disk data file-systems or disc operating systems reserved contiguous blocks on the disc drive for data files. In those systems, the files could be filled up, running out of data space before all the data had been written to them. Thus much unused data space was reserved unproductively to ensure adequate free space for each file. Later file-systems introduced partitions. They reserved blocks of disc data space for partitions and used the allocated blocks more economically, by dynamically assigning blocks of a partition to a file as needed. To achieve this, the file system had to keep track of which blocks were used or unused by data files in a catalog or file allocation table. Though this made better use of the disc data space, it resulted in fragmentation of files across the disc, and a concomitant performance overhead due additional seek time to read the data. Modern file systems reorganize fragmented files dynamically to optimize file access times. Further developments in file systems resulted in virtualization of disc drives i.e. where a logical drive can be defined as partitions from a number of physical drives.


=== Indexed data ===
Retrieving a small subset of data from a much larger set may imply inefficiently searching through the data sequentially.  Indexes are a way to copy out keys and location addresses from data structures in files, tables and data sets, then organize them using inverted tree structures to reduce the time taken to retrieve a subset of the original data. In order to do this, the key of the subset of data to be retrieved must be known before retrieval begins. The most popular indexes are the B-tree and the dynamic hash key indexing methods.  Indexing is overhead for filing and retrieving data. There are other ways of organizing indexes, e.g. sorting the keys and using a binary search algorithm.


=== Abstraction and indirection ===
Object-oriented programming uses two basic concepts for understanding data and software:The taxonomic rank-structure of classes, which is an example of a hierarchical data structure; and
at run time, the creation of references to in-memory data-structures of objects that have been instantiated from a class library.It is only after instantiation that an object of a specified class exists. After an object's reference is cleared, the object also ceases to exist. The memory locations where the object's data was stored are garbage and are reclassified as unused memory available for reuse.


=== Database data ===
The advent of databases introduced a further layer of abstraction for persistent data storage. Databases use metadata, and a structured query language protocol between client and server systems, communicating over a computer network, using a two phase commit logging system to ensure transactional completeness, when saving data.


=== Parallel distributed data processing ===
Modern scalable and high-performance data persistence technologies, such as Apache Hadoop, rely on massively parallel distributed data processing across many commodity computers on a high bandwidth network. In such systems, the data is distributed across multiple computers and therefore any particular computer in the system must be represented in the key of the data, either directly, or indirectly.  This enables the differentiation between two identical sets of data, each being processed on a different computer at the same time.


== See also ==


== References =="
3a58ce74ee,Computer science (disambiguation),
275f6032fb,Foobar,"The terms foobar (), foo, bar, baz, and others are used as metasyntactic variables and placeholder names in computer programming or computer-related documentation. They have been used to name entities such as variables, functions, and commands whose exact identity is unimportant and serve only to demonstrate a concept.


== History and etymology ==

It is possible that foobar is a playful allusion to the World War II-era military slang FUBAR (Fucked Up Beyond All Recognition).According to an Internet Engineering Task Force RFC, the word FOO originated as a nonsense word with its earliest documented use in the 1930s comic Smokey Stover by Bill Holman. Holman states that he used the word due to having seen it on the bottom of a jade Chinese figurine in San Francisco Chinatown, purportedly signifying ""good luck"". If true, this is presumably related to the Chinese word fu (""福"", sometimes transliterated foo, as in foo dog), which can mean happiness or blessing.The first known use of the terms in print in a programming context appears in a 1965 edition of MIT's Tech Engineering News. The use of foo in a programming context is generally credited to the Tech Model Railroad Club (TMRC) of MIT from circa 1960. In the complex model system, there were scram switches located at numerous places around the room that could be thrown if something undesirable was about to occur, such as a train moving at full power towards an obstruction. Another feature of the system was a digital clock on the dispatch board. When someone hit a scram switch, the clock stopped and the display was replaced with the word ""FOO""; at TMRC the scram switches are, therefore, called ""Foo switches"". Because of this, an entry in the 1959 Dictionary of the TMRC Language went something like this: ""FOO: The first syllable of the misquoted sacred chant phrase 'foo mane padme hum.' Our first obligation is to keep the foo counters turning."" One book describing the MIT train room describes two buttons by the door labeled ""foo"" and ""bar"". These were general-purpose buttons and were often repurposed for whatever fun idea the MIT hackers had at the time, hence the adoption of foo and bar as general-purpose variable names. An entry in the Abridged Dictionary of the TMRC Language states:
Multiflush: stop-all-trains-button. Next best thing to the red door button. Also called FOO. Displays ""FOO"" on the clock when used.
Foobar was used as a variable name in the Fortran code of Colossal Cave Adventure (1977 Crowther and Woods version). The variable FOOBAR was used to contain the player's progress in saying the magic phrase ""Fee Fie Foe Foo"". Intel also used the term foo in their programming documentation in 1978.


== Examples in culture ==
Foo Camp is an annual hacker convention.
BarCamp, an international network of user-generated conferences
During the United States v. Microsoft Corp. trial, some evidence was presented that Microsoft had tried to use the Web Services Interoperability organization (WS-I) as a means to stifle competition, including e-mails in which top executives including Bill Gates referred to the WS-I using the codename ""foo"".
Foobar2000 is an audio player.
Google uses a web tool called ""foobar"" to recruit new employees.
The Foo Bar is a pub in the Leiden University's faculty of Mathematics and Computer Science.


== See also ==
Alice and Bob
Foo fighter
Foo was here
xyzzy
Category:Variable (computer science)
Fu (character)


== References ==


== External links ==

The Jargon File entry on ""foobar"", catb.org
RFC 1639 – FTP Operation Over Big Address Records (FOOBAR)"
a8da3d998e,Thrashing (computer science),"In computer science, thrashing occurs when a computer's virtual memory resources are overused, leading to a constant state of paging and page faults, inhibiting most application-level processing. This causes the performance of the computer to degrade or collapse. The situation can continue indefinitely until either the user closes some running applications or the active processes free up additional virtual memory resources.
After completing initialization, most programs operate on a small number of code and data pages compared to the total memory the program requires. The pages most frequently accessed are called the working set.
When the working set is a small percentage of the system's total number of pages, virtual memory systems work most efficiently and an insignificant amount of computing is spent resolving page faults. As the working set grows, resolving page faults remains manageable until the growth reaches a critical point. Then faults go up dramatically and the time spent resolving them overwhelms time spent on the computing the program was written to do. This condition is referred to as thrashing. Thrashing occurs on a program that works with huge data structures, as its large working set causes continual page faults that drastically slow down the system. Satisfying page faults may require freeing pages that will soon have to be re-read from disk. 
The term is also used for various similar phenomena, particularly movement between other levels of the memory hierarchy, where a process progresses slowly because significant time is being spent acquiring resources.
""Thrashing"" is also used in contexts other than virtual memory systems; for example, to describe cache issues in computing or silly window syndrome in networking.


== Overview ==
Virtual memory works by treating a portion of secondary storage such as a computer hard disk as an additional layer of the cache hierarchy.  Virtual memory is notable for allowing processes to use more memory than is physically present in main memory and for enabling virtual machines.  Operating systems supporting virtual memory assign processes a virtual address space and each process refers to addresses in its execution context by a so-called virtual address.  In order to access data such as code or variables at that address, the process must translate the address to a physical address in a process known as virtual address translation.  In effect, physical main memory becomes a cache for virtual memory which is in general stored on disk in memory pages.
Programs are allocated a certain number of pages as needed by the operating system.  Active memory pages exist in both RAM and on disk.  Inactive pages are removed from the cache and written to disk when the main memory becomes full.
If processes are utilizing all main memory and need additional memory pages, a cascade of severe cache misses known as page faults will occur, often leading to a noticeable lag in operating system responsiveness. This process together with the futile, repetitive page swapping that occurs are known as ""thrashing"". This frequently leads to high, runaway CPU utilization that can grind the system to a halt. In modern computers, thrashing may occur in the paging system (if there is not sufficient physical memory or the disk access time is overly long), or in the I/O communications subsystem (especially in conflicts over internal bus access), etc.
Depending on the configuration and algorithms involved, the throughput and latency of a system may degrade by multiple orders of magnitude.  Thrashing is a state in which the CPU performs 'productive' work less, and 'swapping' more. The overall memory access time may increase since the higher level memory is only as fast as the next lower level in the memory hierarchy. The CPU is busy in swapping pages so much that it can not respond to users' programs and interrupts as much as required. Thrashing occurs when there are too many pages in memory, and each page refers to another page. The real memory shortens in capacity to have all the pages in it, so it uses 'virtual memory'. When each page in execution demands that page that is not currently in real memory (RAM) it places some pages on virtual memory and adjusts the required page on RAM. If the CPU is too busy in doing this task, thrashing occurs.


=== Causes ===
In virtual memory systems, thrashing may be caused by programs or workloads that present insufficient locality of reference: if the working set of a program or a workload cannot be effectively held within physical memory, then constant data swapping, i.e., thrashing, may occur. The term was first used during the tape operating system days to describe the sound the tapes made when data was being rapidly written to and read.
A worst-case scenario of this sort on the IBM System/370 series mainframe computer could be an execute instruction crossing a page boundary that points to a move instruction itself also crossing a page boundary, itself pointing to a source and a target that each cross page boundaries.  The total number of pages thus involved in this particular instruction is eight, and all eight pages must be simultaneously present in memory.  If any one of the eight pages can't be swapped in (for example to make room for any of the other pages), the instruction will fault, and every attempt to restart it will fail until all eight pages can be swapped in.
A system thrashing is often a result of a sudden spike in page demanding from a small number of running programs. Swap-token is a lightweight and dynamic thrashing protection mechanism. The basic idea is to set a token in the system, which is randomly given to a process that has page faults when thrashing happens. The process that has the token is given a privilege to allocate more physical memory pages to build its working set, which is expected to quickly finish its execution and to release the memory pages to other processes. A time stamp is used to handover the token one by one. The first version of swap-token is implemented in Linux. The second version is called preempt swap-token. In this updated swap-token implementation, a priority counter is set for each process to track the number of swap-out pages. The token is always given to the process with a high priority, which has a high number of swap-out pages. The length of the time stamp is not a constant but is determined by the priority: the higher the number of swap-out pages of a process, the longer the time stamp for it will be.


== Other uses ==
Thrashing is best known in the context of memory and storage, but analogous phenomena occur for other resources, including:

Cache thrashingWhere main memory is accessed in a pattern that leads to multiple main memory locations competing for the same cache lines, resulting in excessive cache misses.  This is most problematic for caches that have low associativity.

TLB thrashingWhere the translation lookaside buffer (TLB) acting as a cache for the memory management unit (MMU) which translates virtual addresses to physical addresses is too small for the working set of pages. TLB thrashing can occur even if instruction cache or data cache thrashing are not occurring, because these are cached in different sizes. Instructions and data are cached in small blocks (cache lines), not entire pages, but address lookup is done at the page level. Thus even if the code and data working sets fit into cache, if the working sets are fragmented across many pages, the virtual address working set may not fit into TLB, causing TLB thrashing.

Heap thrashingFrequent garbage collection, due to failure to allocate memory for an object, due to insufficient free memory or insufficient contiguous free memory due to memory fragmentation is referred to as heap thrashing.
Process thrashingA similar phenomenon occurs for processes: when the process working set cannot be coscheduled – so not all interacting processes are scheduled to run at the same time – they experience ""process thrashing"" due to being repeatedly scheduled and unscheduled, progressing only slowly.


== See also ==

Page replacement algorithm – Algorithm for virtual memory implementation
Congestion collapse – Reduced quality of service due to high network trafficPages displaying short descriptions of redirect targets
Resource contention – Conflict over access to a shared resource
Out of memory – State of computer operation where no additional memory can be allocated
Software aging – Tendency of software to fail due to external changes or prolonged operation


== References =="
29206172cb,Statement (computer science),"In computer programming, a statement is a syntactic unit of an imperative programming language that expresses some action to be carried out. A program written in such a language is formed by a sequence of one or more statements. A statement may have internal components (e.g. expressions).
Many programming languages (e.g. Ada, Algol 60, C, Java, Pascal) make a distinction between statements and definitions/declarations. A definition or declaration specifies the data on which a program is to operate, while a statement specifies the actions to be taken with that data.
Statements which cannot contain other statements are simple; those which can contain other statements are compound.The appearance of a statement (and indeed a program) is determined by its syntax or grammar. The meaning of a statement is determined by its semantics.


== Simple statements ==
Simple statements are complete in themselves; these include assignments, subroutine calls, and a few statements which may significantly affect the program flow of control (e.g. goto, return, stop/halt). In some languages, input and output, assertions, and exits are handled by special statements, while other languages use calls to predefined subroutines.

assignment
Fortran: variable = expression
Pascal, Algol 60, Ada: variable := expression;
C, C#, C++, PHP, Java: variable = expression;
call
Fortran: CALL subroutine name(parameters)
C, C++, Java, PHP, Pascal, Ada: subroutine name(parameters);
assertion
C, C++, PHP: assert(relational expression);
Java: assert relational expression;
goto
Fortran: GOTO numbered-label
Algol 60: goto label;
C, C++, PHP, Pascal: goto label;
return
Fortran: RETURN value
C, C++, Java, PHP: return value;
stop/halt/exit
Fortran: STOP number
C, C++: exit(expression)
PHP: exit number;


== Compound statements ==
Compound statements may contain (sequences of) statements, nestable to any reasonable depth, and generally involve tests to decide whether or not to obey or repeat these contained statements.

Notation for the following examples:
<statement> is any single statement (could be simple or compound).
<sequence> is any sequence of zero or more <statements>
Some programming languages provide a general way of grouping statements together, so that any single <statement> can be replaced by a group:Algol 60: begin <sequence> end
Pascal: begin <sequence> end
C, PHP, Java: { <sequence> }Other programming languages have a different special terminator on each kind of compound statement, so that one or more statements are automatically treated as a group:
Ada: if test then <sequence> end if;Many compound statements are loop commands or choice commands. In theory only one of each of these types of commands is required. In practice there are various special cases which occur quite often; these may make a program easier to understand, may make programming easier, and can often be implemented much more efficiently.  There are many subtleties not mentioned here; see the linked articles for details.

count-controlled loop:
Algol 60: for index := 1 step 1 until limit do <statement> ;
Pascal: for index := 1 to limit do <statement> ;
C, Java:  for ( index = 1; index <= limit; index += 1) <statement> ;
Ada: for index in 1..limit loop <sequence> end loop
Fortran 90:condition-controlled loop with test at start of loop:
Algol 60: for index := expression while test do <statement> ;
Pascal: while test do <statement> ;
C, Java: while (test) <statement> ;
Ada: while test loop <sequence> end loop
Fortran 90: 
condition-controlled loop with test at end of loop:
Pascal: repeat <sequence> until test;  { note reversed test}
C, Java: do { <sequence> } while (test) ;
Ada: loop <sequence> exit when test; end loop;
condition-controlled loop with test in the middle of the loop:
C: do { <sequence> if (test) break; <sequence> } while (true) ;
Ada: loop <sequence> exit when test; <sequence> end loop;
if-statement simple situation:
Algol 60:if test then <unconditional statement> ;
Pascal:if test then <statement> ;
C, Java: if (test) <statement> ;
Ada: if test then <sequence> end if;
Fortran 77+: if-statement two-way choice:
Algol 60:if test then <unconditional statement> else <statement> ;
Pascal:if test then <statement> else <statement> ;
C, Java: it (test) <statement> else <statement> ;
Ada: if test then <sequence> else <sequence> end if;
Fortran 77+: 
case/switch statement multi-way choice:
Pascal: case c of 'a': alert(); 'q': quit(); end;
Ada: case c is when 'a' => alert(); when 'q' => quit(); end case;
C, Java: switch (c) { case 'a': alert(); break; case 'q': quit(); break; }
Exception handling:
Ada:  begin protected code except when exception specification => exception handler
Java: try { protected code } catch (exception specification) { exception handler } finally { cleanup }
Python:  try: protected code except exception specification: exception handler else: no exceptions  finally: cleanup


== Syntax ==

Apart from assignments and subroutine calls, most languages start each statement with a special word (e.g. goto, if, while, etc.) as shown in the above examples.  Various methods have been used to describe the form of statements in different languages; the more formal methods tend to be more precise:

Algol 60 used Backus–Naur form (BNF) which set a new level for language grammar specification.
Up until Fortran 77, the language was described in English prose with examples,  From Fortran 90 onwards, the language was described using a variant of BNF.
Cobol used a two-dimensional metalanguage.
Pascal used both syntax diagrams and equivalent BNF.BNF uses recursion to express repetition, so various extensions have been proposed to allow direct indication of repetition.


=== Statements and keywords ===
Some programming language grammars reserve keywords or mark them specially, and do not allow them to be used as identifiers. This often leads to grammars which are easier to parse, requiring less lookahead.


==== No distinguished keywords ====
Fortran and PL/1 do not have reserved keywords, allowing statements like:

in PL/1:
IF IF = THEN THEN ...    (the second IF and the first THEN are variables).
in Fortran:
IF (A) X = 10...              conditional statement (with other variants)
IF (A) = 2               assignment to a subscripted variable named IFAs spaces were optional up to Fortran 95, a typo could completely change the meaning of a statement:DO 10 I = 1,5            start of a loop with I running from 1 to 5
DO 10 I = 1.5            assignment of the value 1.5 to the variable DO10I


==== Flagged words ====

In Algol 60 and Algol 68, special tokens were distinguished explicitly: for publication, in boldface e.g. begin; for programming, with some special marking, e.g., a flag ('begin), quotation marks ('begin'), or underlined (begin on the Elliott 503). This is called ""stropping"".
Tokens that are part of the language syntax thus do not conflict with programmer-defined names.


==== Reserved keywords ====

Certain names are reserved as part of the programming language and can not be used as programmer-defined names.
The majority of the most popular programming languages use reserved keywords. Early examples include FLOW-MATIC (1953) and COBOL (1959). Since 1970 other examples include Ada, C, C++, Java, and Pascal.  The number of reserved words depends on the language: C has about 30 while COBOL has about 400.


== Semantics ==

Semantics is concerned with the meaning of a program. The standards documents for many programming languages use BNF or some equivalent to express the syntax/grammar in a fairly formal and precise way, but the semantics/meaning of the program is generally described using examples and English prose.  This can result in ambiguity.  In some language descriptions the meaning of compound statements is defined by the use of 'simpler' constructions, e.g. a while loop can be defined by a combination of tests, jumps, and labels, using if and goto.
The semantics article describes several mathematical/logical formalisms which have been used to specify  semantics in a precise way; these are generally more complicated than BNF, and no single approach is generally accepted as the way to go.  Some approaches effectively define an interpreter for the language, some use formal logic to reason about a program, some attach affixes to syntactic entities to ensure consistency, etc.


== Expressions ==
A distinction is often made between statements, which are executed, and expressions, which are evaluated. Expressions always evaluate to a value, which statements do not. However, expressions are often used as part of a larger statement.
In most programming languages, a statement can consist little more than an expression, usually by following the expression with a statement terminator (semicolon). In such a case, while the expression evaluates to a value, the complete statement does not (the expression's value is discarded). For instance, in C, C++, C#, and many similar languages, x = y + 1 is an expression that will set x to the value of y plus one, and the whole expression itself will evaluate to the same value that x is set to. However, x = y + 1; (note the semicolon at the end) is a statement that will still set x to the value of y plus one because the expression within the statement is still evaluated, but the result of the expression is discarded, and the statement itself does not evaluate to any value.Expressions can also be contained within other expressions. For instance, the expression x = y + 1 contains the expression y + 1, which in turn contains the values y and 1, which are also technically expressions.
Although the previous examples show assignment expressions, some languages do not implement assignment as an expression, but rather as a statement. A notable example of this is Python, where = is not an operator, but rather just a separator in the assignment statement. Although Python allows multiple assignments as each assignment were an expression, this is simply a special case of the assignment statement built into the language grammar rather than a true expression.


== Extensibility ==
Most languages have a fixed set of statements defined by the language, but there have been experiments with extensible languages that allow the programmer to define new statements.


== See also ==
Comparison of Programming Languages - Statements
Control flow
Expression (contrast)


== References ==


== External links ==
PC ENCYCLOPEDIA: Definition of: program statement"
18fe5af59c,Consensus (computer science),"A fundamental problem in distributed computing and multi-agent systems is to achieve overall system reliability in the presence of a number of faulty processes. This often requires coordinating processes to reach consensus, or agree on some data value that is needed during computation. Example applications of consensus include agreeing on what transactions to commit to a database in which order, state machine replication, and atomic broadcasts. Real-world applications often requiring consensus include cloud computing, clock synchronization, PageRank, opinion formation, smart power grids, state estimation, control of UAVs (and multiple robots/agents in general), load balancing, blockchain, and others.


== Problem description ==
The consensus problem requires agreement among a number of processes (or agents) for a single data value. Some of the processes (agents) may fail or be unreliable in other ways, so consensus protocols must be fault tolerant or resilient. The processes must somehow put forth their candidate values, communicate with one another, and agree on a single consensus value.
The consensus problem is a fundamental problem in control of multi-agent systems. One approach to generating consensus is for all processes (agents) to agree on a majority value. In this context, a majority requires at least one more than half of available votes (where each process is given a vote). However, one or more faulty processes may skew the resultant outcome such that consensus may not be reached or reached incorrectly.
Protocols that solve consensus problems are designed to deal with limited numbers of faulty processes. These protocols must satisfy a number of requirements to be useful. For instance, a trivial protocol could have all processes output binary value 1. This is not useful and thus the requirement is modified such that the output must somehow depend on the input. That is, the output value of a consensus protocol must
be the input value of some process. Another requirement is that a process may decide upon an output value only once and this decision is irrevocable. A process is called correct in an execution if it does not experience a failure. A consensus protocol tolerating halting failures must satisfy the following properties.
Termination
Eventually, every correct process decides some value.
Integrity
If all the correct processes proposed the same value 
  
    
      
        v
      
    
    {\displaystyle v}
  , then any correct process must decide 
  
    
      
        v
      
    
    {\displaystyle v}
  .
Agreement
Every correct process must agree on the same value.Variations on the definition of integrity may be appropriate, according to the application. For example, a weaker type of integrity would be for the decision value to equal a value that some correct process proposed – not necessarily all of them. There is also a condition known as validity in the literature which refers to the property that a message sent by a process must be delivered.A protocol that can correctly guarantee consensus amongst n processes of which at most t fail is said to be t-resilient.
In evaluating the performance of consensus protocols two factors of interest are running time and message complexity. Running time is given in Big O notation in the number of rounds of message exchange as a function of some input parameters (typically the number of processes and/or the size of the input domain). Message complexity refers to the amount of message traffic that is generated by the protocol. Other factors may include memory usage and the size of messages.


== Models of computation ==
Varying models of computation may define a ""consensus problem"". Some models may deal with fully connected graphs, while others may deal with rings and trees. In some models message authentication is allowed, whereas in others processes are completely anonymous. Shared memory models in which processes communicate by accessing objects in shared memory are also an important area of research.


=== Communication channels with direct or transferable authentication ===
In most models of communication protocol participants communicate through authenticated channels. This means that messages are not anonymous, and receivers know the source of every message they receive.
Some models assume a stronger, transferable form of authentication, where each message is signed by the sender, so that a receiver knows not just the immediate source of every message, but the participant that initially created the message.
This stronger type of authentication is achieved by digital signatures, and when this stronger form of authentication is available, protocols can tolerate a larger number of faults.The two different authentication models are often called oral communication and written communication models. In an oral communication model, the immediate source of information is known, whereas in stronger, written communication models, every step along the receiver learns not just the immediate source of the message, but the communication history of the message.


=== Inputs and outputs of consensus ===
In the most traditional single-value consensus protocols such as Paxos, cooperating nodes agree on a single value such as an integer, which may be of variable size so as to encode useful metadata such as a transaction committed to a database.
A special case of the single-value consensus problem, called binary consensus, restricts the input, and hence the output domain, to a single binary digit {0,1}. While not highly useful by themselves, binary consensus protocols are often useful as building blocks in more general consensus protocols, especially for asynchronous consensus.
In multi-valued consensus protocols such as Multi-Paxos and Raft, the goal is to agree on not just a single value but a series of values over time, forming a progressively-growing history. While multi-valued consensus may be achieved naively by running multiple iterations of a single-valued consensus protocol in succession, many optimizations and other considerations such as reconfiguration support can make multi-valued consensus protocols more efficient in practice.


=== Crash and Byzantine failures ===

There are two types of failures a process may undergo, a crash failure or a Byzantine failure. A crash failure occurs when a process abruptly stops and does not resume. Byzantine failures are failures in which absolutely no conditions are imposed. For example, they may occur as a result of the malicious actions of an adversary. A process that experiences a Byzantine failure may send contradictory or conflicting data to other processes, or it may sleep and then resume activity after a lengthy delay. Of the two types of failures, Byzantine failures are far more disruptive.
Thus, a consensus protocol tolerating Byzantine failures must be resilient to every possible error that can occur.
A stronger version of consensus tolerating Byzantine failures is given by strengthening the Integrity constraint:

Integrity
If a correct process decides 
  
    
      
        v
      
    
    {\displaystyle v}
  , then 
  
    
      
        v
      
    
    {\displaystyle v}
   must have been proposed by some correct process.


=== Asynchronous and synchronous systems ===
The consensus problem may be considered in the case of asynchronous or synchronous systems. While real world communications are often inherently asynchronous, it is more practical and often easier to model synchronous systems, given that asynchronous systems naturally involve more issues than synchronous ones.
In synchronous systems, it is assumed that all communications proceed in rounds. In one round, a process may send all the messages it requires, while receiving all messages from other processes. In this manner, no message from one round may influence any messages sent within the same round.


==== The FLP impossibility result for asynchronous deterministic consensus ====
In a fully asynchronous message-passing distributed system, in which at least one process may have a crash failure, it has been proven in the famous 1985 FLP impossibility result by Fischer, Lynch and Paterson that a deterministic algorithm for achieving consensus is impossible. This impossibility result derives from worst-case scheduling scenarios, which are unlikely to occur in practice except in adversarial situations such as an intelligent denial-of-service attacker in the network. In most normal situations, process scheduling has a degree of natural randomness.In an asynchronous model, some forms of failures can be handled by a synchronous consensus protocol. For instance, the loss of a communication link may be modeled as a process which has suffered a Byzantine failure.
Randomized consensus algorithms can circumvent the FLP impossibility result by achieving both safety and liveness with overwhelming probability, even under worst-case scheduling scenarios such as an intelligent denial-of-service attacker in the network.


=== Permissioned versus permissionless consensus ===
Consensus algorithms traditionally assume that the set of participating nodes is fixed and given at the outset: that is, that some prior (manual or automatic) configuration process has permissioned a particular known group of participants who can authenticate each other as members of the group.  In the absence of such a well-defined, closed group with authenticated members, a Sybil attack against an open consensus group can defeat even a Byzantine consensus algorithm, simply by creating enough virtual participants to overwhelm the fault tolerance threshold.
A permissionless consensus protocol, in contrast, allows anyone in the network to join dynamically and participate without prior permission, but instead imposes a different form of artificial cost or barrier to entry to mitigate the Sybil attack threat.  Bitcoin introduced the first permissionless consensus protocol using proof of work and a difficulty adjustment function, in which participants compete to solve cryptographic hash puzzles, and probabilistically earn the right to commit blocks and earn associated rewards in proportion to their invested computational effort.  Motivated in part by the high energy cost of this approach, subsequent permissionless consensus protocols have proposed or adopted other alternative participation rules for Sybil attack protection, such as proof of stake, proof of space, and proof of authority.


== Equivalency of agreement problems ==
Three agreement problems of interest are as follows.


=== Terminating Reliable Broadcast ===

A collection of 
  
    
      
        n
      
    
    {\displaystyle n}
   processes, numbered from 
  
    
      
        0
      
    
    {\displaystyle 0}
   to 
  
    
      
        n
        −
        1
        ,
      
    
    {\displaystyle n-1,}
   communicate by sending messages to one another. Process 
  
    
      
        0
      
    
    {\displaystyle 0}
   must transmit a value 
  
    
      
        v
      
    
    {\displaystyle v}
   to all processes such that:

if process 
  
    
      
        0
      
    
    {\displaystyle 0}
   is correct, then every correct process receives 
  
    
      
        v
      
    
    {\displaystyle v}
  
for any two correct processes, each process receives the same value.It is also known as The General's Problem.


=== Consensus ===
Formal requirements for a consensus protocol may include:

Agreement: All correct processes must agree on the same value.
Weak validity: For each correct process, its output must be the input of some correct process.
Strong validity: If all correct processes receive the same input value, then they must all output that value.
Termination: All processes must eventually decide on an output value


=== Weak Interactive Consistency ===
For n processes in a partially synchronous system (the system alternates between good and bad periods of synchrony), each process chooses a private value. The processes communicate with each other by rounds to determine a public value and generate a
consensus vector with the following requirements:
if a correct process sends 
  
    
      
        v
      
    
    {\displaystyle v}
  , then all correct processes receive either 
  
    
      
        v
      
    
    {\displaystyle v}
   or nothing (integrity property)
all messages sent in a round by a correct process are received in the same round by all correct processes (consistency property).It can be shown that variations of these problems are equivalent in that the solution for a problem in one type of model may be the solution for another problem in another type of model. For example, a solution to the Weak Byzantine General problem in a synchronous authenticated message passing model leads to a solution for Weak Interactive Consistency. An interactive consistency algorithm can solve the consensus problem by having each process choose the majority value in its consensus vector as its consensus value.


== Solvability results for some agreement problems ==
There is a t-resilient anonymous synchronous protocol which solves the Byzantine Generals problem, if 
  
    
      
        
          
            
              t
              n
            
          
        
        <
        
          
            
              1
              3
            
          
        
      
    
    {\displaystyle {\tfrac {t}{n}}<{\tfrac {1}{3}}}
    and the Weak Byzantine Generals case where 
  
    
      
        t
      
    
    {\displaystyle t}
   is the number of failures and 
  
    
      
        n
      
    
    {\displaystyle n}
   is the number of processes.
For systems with 
  
    
      
        n
      
    
    {\displaystyle n}
   processors, of which 
  
    
      
        f
      
    
    {\displaystyle f}
   are Byzantine, it has been shown that there exists no algorithm that solves the consensus problem for 
  
    
      
        n
        ≤
        3
        f
      
    
    {\displaystyle n\leq 3f}
   in the oral-messages model. The proof is constructed by first showing the impossibility for the three-node case 
  
    
      
        n
        =
        3
      
    
    {\displaystyle n=3}
   and using this result to argue about partitions of processors.  In the written-messages model there are protocols that can tolerate 
  
    
      
        n
        =
        f
        +
        1
      
    
    {\displaystyle n=f+1}
  .In a fully asynchronous system there is no consensus solution that can tolerate one or more crash failures even when only requiring the non triviality property. This result is sometimes called the FLP impossibility proof named after the authors Michael J. Fischer, Nancy Lynch, and Mike Paterson who were awarded a Dijkstra Prize for this significant work. The FLP result has been mechanically verified to hold even under fairness assumptions.   However, FLP does not state that consensus can never be reached: merely that under the model's assumptions, no algorithm can always reach consensus in bounded time. In practice it is highly unlikely to occur.


== Some consensus protocols ==
The Paxos consensus algorithm by Leslie Lamport, and variants of it such as Raft, are used pervasively in widely deployed distributed and cloud computing systems.  These algorithms are typically synchronous, dependent on an elected leader to make progress, and tolerate only crashes and not Byzantine failures.
An example of a polynomial time binary consensus protocol that tolerates Byzantine failures is the Phase King algorithm by Garay and Berman. The algorithm solves consensus in a synchronous message passing model with n processes and up to f failures, provided n > 4f.
In the phase king algorithm, there are f + 1 phases, with 2 rounds per phase.
Each process keeps track of its preferred output (initially equal to the process's own input value).  In the first round of each phase each process broadcasts its own preferred value to all other processes. It then receives the values from all processes and determines which value is the majority value and its count. In the second round of the phase, the process whose id matches the current phase number is designated the king of the phase. The king broadcasts the majority value it observed in the first round and serves as a tie breaker.  Each process then updates its preferred value as follows.  If the count of the majority value the process observed in the first round is greater than n/2 + f, the process changes its preference to that majority value; otherwise it uses the phase king's value. At the end of f + 1 phases the processes output their preferred values.
Google has implemented a distributed lock service library called Chubby.  Chubby maintains lock information in small files which are stored in a replicated database to achieve high availability in the face of failures. The database is implemented on top of a fault-tolerant log layer which is based on the Paxos consensus algorithm. In this scheme, Chubby clients communicate with the Paxos master in order to access/update the replicated log; i.e., read/write to the files.Many peer-to-peer online Real-time strategy games use a modified Lockstep protocol as a consensus protocol in order to manage game state between players in a game.  Each game action results in a game state delta broadcast to all other players in the game along with a hash of the total game state.  Each player validates the change by applying the delta to their own game state and comparing the game state hashes.  If the hashes do not agree then a vote is cast, and those players whose game state is in the minority are disconnected and removed from the game (known as a desync.)
Another well-known approach is called MSR-type algorithms which have been used widely from computer science to control theory.


=== Permissionless consensus protocols ===
Bitcoin uses proof of work, a difficulty adjustment function and a reorganization function to achieve permissionless consensus in its open peer-to-peer network. To extend Bitcoin's blockchain or distributed ledger, miners attempt to solve a cryptographic puzzle, where probability of finding a solution is proportional to the computational effort expended in hashes per second. The node that first solves such a puzzle has their proposed version of the next block of transactions added to the ledger and eventually accepted by all other nodes. As any node in the network can attempt to solve the proof-of-work problem, a Sybil attack is infeasible in principle unless the attacker has over 50% of the computational resources of the network.
Other cryptocurrencies (i.e. NEO, STRATIS, ...) use proof of stake, in which nodes compete to append blocks and earn associated rewards in proportion to stake, or existing cryptocurrency allocated and locked or staked for some time period. One advantage of a 'proof of stake' over a 'proof of work' system, is the high energy consumption demanded by the latter. As an example, Bitcoin mining (2018) is estimated to consume non-renewable energy sources at an amount similar to the entire nations of Czech Republic or Jordan.Some cryptocurrencies, such as Ripple, use a system of validating nodes to validate the ledger.
This system used by Ripple, called Ripple Protocol Consensus Algorithm (RPCA), works in rounds: 
Step 1: every server compiles a list of valid candidate transactions;
Step 2: each server amalgamates all candidates coming from its Unique Nodes List (UNL) and votes on their veracity;
Step 3: transactions passing the minimum threshold are passed to the next round;
Step 4: the final round requires 80% agreementOther participation rules used in permissionless consensus protocols to impose barriers to entry and resist sybil attacks include proof of authority, proof of space, proof of burn, or proof of elapsed time.
Contrasting with the above permissionless participation rules, all of which reward participants in proportion to amount of investment in some action or resource, proof of personhood protocols aim to give each real human participant exactly one unit of voting power in permissionless consensus, regardless of economic investment.  Proposed approaches to achieving one-per-person distribution of consensus power for proof of personhood include physical pseudonym parties, social networks, pseudonymized government-issued identities, and biometrics.


== Consensus number ==
To solve the consensus problem in a shared-memory system, concurrent objects must be introduced. A concurrent object, or shared object, is a data structure which helps concurrent processes communicate to reach an agreement. Traditional implementations using critical sections face the risk of crashing if some process dies inside the critical section or sleeps for an intolerably long time. Researchers defined wait-freedom as the guarantee that the algorithm completes in a finite number of steps.
The consensus number of a concurrent object is defined to be the maximum number of processes in the system which can reach consensus by the given object in a wait-free implementation. Objects with a consensus number of 
  
    
      
        n
      
    
    {\displaystyle n}
   can implement any object with a consensus number of 
  
    
      
        n
      
    
    {\displaystyle n}
   or lower, but cannot implement any objects with a higher consensus number. The consensus numbers form what is called Herlihy's hierarchy of synchronization objects.
According to the hierarchy, read/write registers cannot solve consensus even in a 2-process system. Data structures like stacks and queues can only solve consensus between two processes. However, some concurrent objects are universal (notated in the table with 
  
    
      
        ∞
      
    
    {\displaystyle \infty }
  ), which means they can solve consensus among any number of processes and they can simulate any other objects through an operation sequence.


== See also ==
Uniform consensus
Quantum Byzantine agreement
Byzantine fault tolerance


== References ==


== Further reading ==
Herlihy, M.; Shavit, N. (1999). ""The topological structure of asynchronous computability"". Journal of the ACM. 46 (6): 858. CiteSeerX 10.1.1.78.1455. doi:10.1145/331524.331529. S2CID 5797174.
Saks, M.; Zaharoglou, F. (2000). ""Wait-Free k-Set Agreement is Impossible: The Topology of Public Knowledge"". SIAM Journal on Computing. 29 (5): 1449–1483. doi:10.1137/S0097539796307698.
Bashir, Imran. ""Blockchain Consensus."" Blockchain Consensus - An Introduction to Classical, Blockchain, and Quantum Consensus Protocols. ISBN 978-1-4842-8178-9 Apress, Berkeley, CA, 2022. doi:10.1007/978-1-4842-8179-6"
9983fa7947,Robustness (computer science),"In computer science, robustness is the ability of a computer system to cope with errors during execution and cope with erroneous input. Robustness can encompass many areas of computer science, such as robust programming, robust machine learning, and Robust Security Network. Formal techniques, such as fuzz testing, are essential to showing robustness since this type of testing involves invalid or unexpected inputs. Alternatively, fault injection can be used to test robustness. Various commercial products perform robustness testing of software analysis.


== Introduction ==
In general, building robust systems that encompass every point of possible failure is difficult because of the vast quantity of possible inputs and input combinations. Since all inputs and input combinations would require too much time to test, developers cannot run through all cases exhaustively. Instead, the developer will try to generalize such cases. For example, imagine inputting some integer values. Some selected inputs might consist of a negative number, zero, and a positive number. When using these numbers to test software in this way, the developer generalizes the set of all reals into three numbers. This is a more efficient and manageable method, but more prone to failure. Generalizing test cases is an example of just one technique to deal with failure—specifically, failure due to invalid user input. Systems generally may also fail due to other reasons as well, such as disconnecting from a network.
Regardless, complex systems should still handle any errors encountered gracefully. There are many examples of such successful systems. Some of the most robust systems are evolvable and can be easily adapted to new situations.


== Challenges ==
Programs and software are tools focused on a very specific task, and thus aren't generalized and flexible. However, observations in systems such as the internet or biological systems demonstrate adaptation to their environments. One of the ways biological systems adapt to environments is through the use of redundancy. Many organs are redundant in humans. The kidney is one such example. Humans generally only need one kidney, but having a second kidney allows room for failure. This same principle may be taken to apply to software, but there are some challenges.
When applying the principle of redundancy to computer science, blindly adding code is not suggested. Blindly adding code introduces more errors, makes the system more complex, and renders it harder to understand. Code that doesn't provide any reinforcement to the already existing code is unwanted. The new code must instead possess equivalent functionality, so that if a function is broken, another providing the same function can replace it, using manual or automated software diversity. To do so, the new code must know how and when to accommodate the failure point. This means more logic needs to be added to the system. But as a system adds more logic, components, and increases in size, it becomes more complex. Thus, when making a more redundant system, the system also becomes more complex and developers must consider balancing redundancy with complexity.
Currently, computer science practices do not focus on building robust systems. Rather, they tend to focus on scalability and efficiency. One of the main reasons why there is no focus on robustness today is because it is hard to do in a general way.


== Areas ==


=== Robust programming ===
Robust programming is a style of programming that focuses on handling unexpected termination and unexpected actions. It requires code to handle these terminations and actions gracefully by displaying accurate and unambiguous error messages. These error messages allow the user to more easily debug the program.


==== Principles ====
Paranoia
When building software, the programmer assumes users are out to break their code. The programmer also assumes that their own written code may fail or work incorrectly.Stupidity
The programmer assumes users will try incorrect, bogus and malformed inputs. As a consequence, the programmer returns to the user an unambiguous, intuitive error message that does not require looking up error codes. The error message should try to be as accurate as possible without being misleading to the user, so that the problem can be fixed with ease.Dangerous implements
Users should not gain access to libraries, data structures, or pointers to data structures. This information should be hidden from the user so that the user doesn't accidentally modify them and introduce a bug in the code. When such interfaces are correctly built, users use them without finding loopholes to modify the interface. The interface should already be correctly implemented, so the user does not need to make modifications. The user therefore focuses solely on their own code.Can't happen
Very often, code is modified and may introduce a possibility that an ""impossible"" case occurs. Impossible cases are therefore assumed to be highly unlikely instead. The developer thinks about how to handle the case that is highly unlikely, and implements the handling accordingly.


=== Robust machine learning ===
Robust machine learning typically refers to the robustness of machine learning algorithms. For a machine learning algorithm to be considered robust, either the testing error has to be consistent with the training error, or the performance is stable after adding some noise to the dataset. Recently, consistently with their rise in popularity, there has been an increasing interest in the robustness of neural networks. This is particularly due their vulnerability to adverserial attacks.


=== Robust network design ===
Robust network design is the study of network design in the face of variable or uncertain demands. In a sense, robustness in network design is broad just like robustness in software design because of the vast possibilities of changes or inputs.


=== Robust algorithms ===
There exists algorithms that tolerate errors in the input.


== See also ==
Defensive programming
Non-functional requirement


== References =="
370d2bfa7b,Logic in computer science,"Logic in computer science covers the overlap between the field of logic and that of computer science. The topic can essentially be divided into three main areas:

Theoretical foundations and analysis
Use of computer technology to aid logicians
Use of concepts from logic for computer applications


== Theoretical foundations and analysis ==
Logic plays a fundamental role in computer science.  Some of the key areas of logic that are particularly significant are computability theory (formerly called recursion theory), modal logic and category theory. The theory of computation is based on concepts defined by logicians and mathematicians such as Alonzo Church and Alan Turing.  Church first showed the existence of algorithmically unsolvable problems using his notion of lambda-definability.  Turing gave the first compelling analysis of what can be called a mechanical procedure and Kurt Gödel asserted that he found Turing's analysis ""perfect.""
In addition some other major areas of theoretical overlap between logic and computer science are:

Gödel's incompleteness theorem proves that any logical system powerful enough to characterize arithmetic will contain statements that can neither be proved nor disproved within that system.  This has direct application to theoretical issues relating to the feasibility of proving the completeness and correctness of software.
The frame problem is a basic problem that must be overcome when using first-order logic to represent the goals and state of an artificial intelligence agent.
The Curry–Howard correspondence is a relation between logical systems and software. This theory established a precise correspondence between proofs and programs.  In particular it showed that terms in the simply-typed lambda-calculus correspond to proofs of intuitionistic propositional logic.
Category theory represents a view of mathematics that emphasizes the relations between structures.  It is intimately tied to many aspects of computer science: type systems for programming languages, the theory of transition systems, models of programming languages and the theory of programming language semantics.


== Computers to assist logicians ==
One of the first applications to use the term artificial intelligence was the Logic Theorist system developed by Allen Newell, J. C. Shaw, and Herbert Simon in 1956. One of the things that a logician does is to take a set of statements in logic and deduce the conclusions (additional statements) that must be true by the laws of logic. For example, If given a logical system that states ""All humans are mortal"" and ""Socrates is human"" a valid conclusion is ""Socrates is mortal"".  Of course this is a trivial example. In actual logical systems the statements can be numerous and complex. It was realized early on that this kind of analysis could be significantly aided by the use of computers. The Logic Theorist validated the theoretical work of Bertrand Russell and Alfred North Whitehead in their influential work on mathematical logic called Principia Mathematica. In addition, subsequent systems have been utilized by logicians to validate and discover new logical theorems and proofs.


== Logic applications for computers ==
There has always been a strong influence from mathematical logic on the field of artificial intelligence (AI). From the beginning of the field it was realized that technology to automate logical inferences could have great potential to solve problems and draw conclusions from facts. Ron Brachman has described first-order logic (FOL) as the metric by which all AI knowledge representation formalisms should be evaluated. There is no more general or powerful known method for describing and analyzing information than FOL. The reason FOL itself is simply not used as a computer language is that it is actually too expressive, in the sense that FOL can easily express statements that no computer, no matter how powerful, could ever solve. For this reason every form of knowledge representation is in some sense a trade off between expressivity and computability. The more expressive the language is, the closer it is to FOL, the more likely it is to be slower and prone to an infinite loop.For example, IF THEN rules used in expert systems approximate to a very limited subset of FOL. Rather than arbitrary formulas with the full range of logical operators the starting point is simply what logicians refer to as modus ponens. As a result, rule-based systems can support high-performance computation, especially if they take advantage of optimization algorithms and compilation.Another major area of research for logical theory was software engineering. Research projects such as the Knowledge Based Software Assistant and Programmer's Apprentice programs applied logical theory to validate the correctness of software specifications. They also used them to transform the specifications into efficient code on diverse platforms and to prove the equivalence between the implementation and the specification.  This formal transformation driven approach is often far more effortful than traditional software development. However, in specific domains with appropriate formalisms and reusable templates the approach has proven viable for commercial products. The appropriate domains are usually those such as weapons systems, security systems, and real time financial systems where failure of the system has excessively high human or financial cost. An example of such a domain is Very Large Scale Integrated (VLSI) design—the process for designing the chips used for the CPUs and other critical components of digital devices. An error in a chip is catastrophic. Unlike software, chips can't be patched or updated. As a result, there is commercial justification for using formal methods to prove that the implementation corresponds to the specification.Another important application of logic to computer technology has been in the area of frame languages and automatic classifiers. Frame languages such as KL-ONE have a rigid semantics. Definitions in KL-ONE can be directly mapped to set theory and the predicate calculus. This allows specialized theorem provers called classifiers to analyze the various declarations between sets, subsets, and relations in a given model. In this way the model can be validated and any inconsistent definitions flagged. The classifier can also infer new information, for example define new sets based on existing information and change the definition of existing sets based on new data. The level of flexibility is ideal for handling the ever changing world of the Internet. Classifier technology is built on top of languages such as the Web Ontology Language to allow a logical semantic level on to the existing Internet. This layer of is called the Semantic web.Temporal logic is used for reasoning in concurrent systems.


== See also ==
Automated reasoning
Computational logic
Logic programming


== References ==


== Further reading ==
Ben-Ari, Mordechai (2012). Mathematical Logic for Computer Science (3rd ed.). Springer-Verlag. ISBN 978-1447141280.
Harrison, John (2009). Handbook of Practical Logic and Automated Reasoning (1st ed.). Cambridge University Press. ISBN 978-0521899574.
Huth, Michael; Ryan, Mark (2004). Logic in Computer Science: Modelling and Reasoning about Systems (2nd ed.). Cambridge University Press. ISBN 978-0521543101.
Burris, Stanley N. (1997). Logic for Mathematics and Computer Science (1st ed.). Prentice Hall. ISBN 978-0132859745.


== External links ==
Article on Logic and Artificial Intelligence at the Stanford Encyclopedia of Philosophy.
IEEE Symposium on Logic in Computer Science (LICS)
Alwen Tiu, Introduction to logic video recording of a lecture at ANU Logic Summer School '09 (aimed mostly at computer scientists)"
cbbeb5f1f2,History of computer science,"The history of computer science began long before the modern discipline of computer science, usually appearing in forms like mathematics or physics. Developments in previous centuries alluded to the discipline that we now know as computer science. This progression, from mechanical inventions and mathematical theories towards modern computer concepts and machines, led to the development of a major academic field, massive technological advancement across the Western world, and the basis of a massive worldwide trade and culture.


== Prehistory ==

The earliest known tool for use in computation was the abacus, developed in the period between 2700 and 2300 BCE in Sumer. The Sumerians' abacus consisted of a table of successive columns which delimited the successive orders of magnitude of their sexagesimal number system.: 11  Its original style of usage was by lines drawn in sand with pebbles. Abaci of a more modern design are still used as calculation tools today, such as the Chinese abacus.In the 5th century BC in ancient India, the grammarian Pāṇini formulated the grammar of Sanskrit in 3959 rules known as the Ashtadhyayi which was highly systematized and technical. Panini used metarules, transformations and recursions.The Antikythera mechanism is believed to be an early mechanical analog computer.  It was designed to calculate astronomical positions. It was discovered in 1901 in the Antikythera wreck off the Greek island of Antikythera, between Kythera and Crete, and has been dated to circa 100 BC.Mechanical analog computer devices appeared again a thousand years later in the medieval Islamic world and were developed by Muslim astronomers, such as the mechanical geared astrolabe by Abū Rayhān al-Bīrūnī, and the torquetum by Jabir ibn Aflah. According to Simon Singh, Muslim mathematicians also made important advances in cryptography, such as the development of cryptanalysis and frequency analysis by Alkindus. Programmable machines were also invented by Muslim engineers, such as the automatic flute player by the Banū Mūsā brothers, and Al-Jazari's programmable castle clock, which is considered to be the first programmable analog computer. Technological artifacts of similar complexity appeared in 14th century Europe, with mechanical astronomical clocks.When John Napier discovered logarithms for computational purposes in the early 17th century, there followed a period of considerable progress by inventors and scientists in making calculating tools. In 1623 Wilhelm Schickard designed a calculating machine, but abandoned the project, when the prototype he had started building was destroyed by a fire in 1624. Around 1640, Blaise Pascal, a leading French mathematician, constructed a mechanical adding device based on a design described by Greek mathematician Hero of Alexandria. Then in 1672 Gottfried Wilhelm Leibniz invented the Stepped Reckoner which he completed in 1694.In 1837 Charles Babbage first described his Analytical Engine which is accepted as the first design for a modern computer. The analytical engine had expandable memory, an arithmetic unit, and logic processing capabilities able to interpret a programming language with loops and conditional branching. Although never built, the design has been studied extensively and is understood to be Turing equivalent. The analytical engine would have had a memory capacity of less than 1 kilobyte of memory and a clock speed of less than 10 Hertz.Considerable advancement in mathematics and electronics theory was required before the first modern computers could be designed.


== Binary logic ==


=== Gottfried Wilhelm Leibniz ===

 
In 1702, Gottfried Wilhelm Leibniz developed logic in a formal, mathematical sense with his writings on the binary numeral system. Leibniz simplified the binary system and articulated logical properties such as conjunction, disjunction, negation, identity, inclusion, and the empty set. He anticipated Lagrangian interpolation and algorithmic information theory. His calculus ratiocinator anticipated aspects of the universal Turing machine. In 1961, Norbert Wiener suggested that Leibniz should be considered the patron saint of cybernetics. Wiener is quoted with ""Indeed, the general idea of a computing machine is nothing but a mechanization of Leibniz's Calculus Ratiocinator."" But it took more than a century before George Boole published his Boolean algebra in 1854 with a complete system that allowed computational processes to be mathematically modeled.By this time, the first mechanical devices driven by a binary pattern had been invented. The industrial revolution had driven forward the mechanization of many tasks, and this included weaving. Punched cards controlled Joseph Marie Jacquard's loom in 1801, where a hole punched in the card indicated a binary one and an unpunched spot indicated a binary zero. Jacquard's loom was far from being a computer, but it did illustrate that machines could be driven by binary systems.


== Emergence of a discipline ==


=== Charles Babbage and Ada Lovelace ===

Charles Babbage is often regarded as one of the first pioneers of computing. Beginning in the 1810s, Babbage had a vision of mechanically computing numbers and tables. Putting this into reality, Babbage designed a calculator to compute numbers up to 8 decimal points long. Continuing with the success of this idea, Babbage worked to develop a machine that could compute numbers with up to 20 decimal places. By the 1830s, Babbage had devised a plan to develop a machine that could use punched cards to perform arithmetical operations. The machine would store numbers in memory units, and there would be a form of sequential control.  This means that one operation would be carried out before another in such a way that the machine would produce an answer and not fail. This machine was to be known as the “Analytical Engine”, which was the first true representation of what is the modern computer.

Ada Lovelace (Augusta Ada Byron) is credited as the pioneer of computer programming and is regarded as a mathematical genius. Lovelace began working with Charles Babbage as an assistant while Babbage was working on his ""Analytical Engine"", the first mechanical computer. During her work with Babbage, Ada Lovelace became the designer of the first computer algorithm, which had the ability to compute Bernoulli numbers, although this is arguable as Charles was the first to design the difference engine and consequently its corresponding difference based algorithms, making him the first computer algorithm designer.  Moreover, Lovelace's work with Babbage resulted in her prediction of future computers to not only perform mathematical calculations, but also manipulate symbols, mathematical or not. While she was never able to see the results of her work, as the ""Analytical Engine"" was not created in her lifetime, her efforts in later years, beginning in the 1840s, did not go unnoticed.


=== Contributions to Babbage's Analytical Engine during the first half of the 20th century ===
Following Babbage, although at first unaware of his earlier work, was Percy Ludgate, a clerk to a corn merchant in Dublin, Ireland. He independently designed a programmable mechanical computer, which he described in a work that was published in 1909. Two other inventors, Leonardo Torres y Quevedo and Vannevar Bush, also did follow on research based on Babbage's work. In his Essays on Automatics (1913) Torres y Quevedo designed a Babbage type of calculating machine that used electromechanical parts which included floating point number representations and built a prototype in 1920. Bush's paper Instrumental Analysis (1936) discussed using existing IBM punch card machines to implement Babbage's design. In the same year he started the Rapid Arithmetical Machine project to investigate the problems of constructing an electronic digital computer.


=== Charles Sanders Peirce and electrical switching circuits ===

In an 1886 letter, Charles Sanders Peirce described how logical operations could be carried out by electrical switching circuits. During 1880–81 he showed that NOR gates alone (or alternatively NAND gates alone) can be used to reproduce the functions of all the other logic gates, but this work on it was unpublished until 1933. The first published proof was by Henry M. Sheffer in 1913, so the NAND logical operation is sometimes called Sheffer stroke; the logical NOR is sometimes called Peirce's arrow. Consequently, these gates are sometimes called universal logic gates.Eventually, vacuum tubes replaced relays for logic operations. Lee De Forest's modification, in 1907, of the Fleming valve can be used as a logic gate. Ludwig Wittgenstein introduced a version of the 16-row truth table as proposition 5.101 of Tractatus Logico-Philosophicus (1921). Walther Bothe, inventor of the coincidence circuit, got part of the 1954 Nobel Prize in physics, for the first modern electronic AND gate in 1924. Konrad Zuse designed and built electromechanical logic gates for his computer Z1 (from 1935 to 1938).
Up to and during the 1930s, electrical engineers were able to build electronic circuits to solve mathematical and logic problems, but most did so in an ad hoc manner, lacking any theoretical rigor.  This changed with switching circuit theory in the 1930s. From 1934 to 1936, Akira Nakashima, Claude Shannon, and Viktor Shetakov published a series of papers showing that the two-valued Boolean algebra, can describe the operation of switching circuits. This concept, of utilizing the properties of electrical switches to do logic, is the basic concept that underlies all electronic digital computers. Switching circuit theory provided the mathematical foundations and tools for digital system design in almost all areas of modern technology.While taking an undergraduate philosophy class, Shannon had been exposed to Boole's work, and recognized that it could be used to arrange electromechanical relays (then used in telephone routing switches) to solve logic problems. His thesis became the foundation of practical digital circuit design when it became widely known among the electrical engineering community during and after World War II.


=== Alan Turing and the Turing machine ===

Before the 1920s, computers (sometimes computors) were human clerks that performed computations. They were usually under the lead of a physicist. Many thousands of computers were employed in commerce, government, and research establishments. Many of these clerks who served as human computers were women. Some performed astronomical calculations for calendars, others ballistic tables for the military.After the 1920s, the expression computing machine referred to any machine that performed the work of a human computer, especially those in accordance with effective methods of the Church-Turing thesis. The thesis states that a mathematical method is effective if it could be set out as a list of instructions able to be followed by a human clerk with paper and pencil, for as long as necessary, and without ingenuity or insight.
Machines that computed with continuous values became known as the analog kind. They used machinery that represented continuous numeric quantities, like the angle of a shaft rotation or difference in electrical potential.
Digital machinery, in contrast to analog, were able to render a state of a numeric value and store each individual digit. Digital machinery used difference engines or relays before the invention of faster memory devices.
The phrase computing machine gradually gave way, after the late 1940s, to just computer as the onset of electronic digital machinery became common. These computers were able to perform the calculations that were performed by the previous human clerks.
Since the values stored by digital machines were not bound to physical properties like analog devices, a logical computer, based on digital equipment, was able to do anything that could be described ""purely mechanical."" The theoretical Turing Machine, created by Alan Turing, is a hypothetical device theorized in order to study the properties of such hardware.
The mathematical foundations of modern computer science began to be laid by Kurt Gödel with his incompleteness theorem (1931). In this theorem, he showed that there were limits to what could be proved and disproved within a formal system. This led to work by Gödel and others to define and describe these formal systems, including concepts such as mu-recursive functions and lambda-definable functions.In 1936  Alan Turing and Alonzo Church independently, and also together, introduced the formalization of an algorithm, with limits on what can be computed, and a ""purely mechanical"" model for computing. This became the Church–Turing thesis, a hypothesis about the nature of mechanical calculation devices, such as electronic computers. The thesis states that any calculation that is possible can be performed by an algorithm running on a computer, provided that sufficient time and storage space are available.In 1936, Alan Turing also published his seminal work on the Turing machines, an abstract digital computing machine which is now simply referred to as the Universal Turing machine. This machine invented the principle of the modern computer and was the birthplace of the stored program concept that almost all modern day computers use. These hypothetical machines were designed to formally determine, mathematically, what can be computed, taking into account limitations on computing ability. If a Turing machine can complete the task, it is considered Turing computable.The Los Alamos physicist Stanley Frankel, has described John von Neumann's view of the fundamental importance of Turing's 1936 paper, in a letter:
 I know that in or about 1943 or ‘44 von Neumann was well aware of the fundamental importance of Turing's paper of 1936… Von Neumann introduced me to that paper and at his urging I studied it with care. Many people have acclaimed von Neumann as the ""father of the computer"" (in a modern sense of the term) but I am sure that he would never have made that mistake himself. He might well be called the midwife, perhaps, but he firmly emphasized to me, and to others I am sure, that the fundamental conception is owing to Turing...


=== Early computer hardware ===
The world's first electronic digital computer, the Atanasoff–Berry computer, was built on the Iowa State campus from 1939 through 1942 by John V. Atanasoff, a professor of physics and mathematics, and Clifford Berry, an engineering graduate student.
In 1941, Konrad Zuse developed the world's first functional program-controlled computer, the Z3. In 1998, it was shown to be Turing-complete in principle. Zuse also developed the S2 computing machine, considered the first process control computer. He founded one of the earliest computer businesses in 1941, producing the Z4, which became the world's first commercial computer.  In 1946, he designed the first high-level programming language, Plankalkül.In 1948, the Manchester Baby was completed; it was the world's first electronic digital computer that ran programs stored in its memory, like almost all modern computers. The influence on Max Newman of Turing's seminal 1936 paper on the Turing Machines and of his logico-mathematical contributions to the project, were both crucial to the successful development of the Baby.In 1950, Britain's National Physical Laboratory completed Pilot ACE, a small scale programmable computer, based on Turing's philosophy. With an operating speed of 1 MHz, the Pilot Model ACE was for some time the fastest computer in the world. Turing's design for ACE had much in common with today's RISC architectures and it called for a high-speed memory of roughly the same capacity as an early Macintosh computer, which was enormous by the standards of his day. Had Turing's ACE been built as planned and in full, it would have been in a different league from the other early computers.

The first actual computer bug was a moth. It was stuck in between the relays on the Harvard Mark II.
While the invention of the term 'bug' is often but erroneously attributed to Grace Hopper, a future rear admiral in the U.S. Navy, who supposedly logged the ""bug"" on September 9, 1945, most other accounts conflict at least with these details. According to these accounts, the actual date was September 9, 1947 when operators filed this 'incident' — along with the insect and the notation ""First actual case of bug being found"" (see software bug for details).


=== Shannon and information theory ===
Claude Shannon went on to found the field of information theory with his 1948 paper titled A Mathematical Theory of Communication, which applied probability theory to the problem of how to best encode the information a sender wants to transmit.  This work is one of the theoretical foundations for many areas of study, including data compression and cryptography.


=== Wiener and cybernetics ===
From experiments with anti-aircraft systems that interpreted radar images to detect enemy planes, Norbert Wiener coined the term cybernetics from the Greek word for ""steersman."" He published ""Cybernetics"" in 1948, which influenced artificial intelligence. Wiener also compared computation, computing machinery, memory devices, and other cognitive similarities with his analysis of brain waves.


=== John von Neumann and the von Neumann architecture ===

In 1946, a model for computer architecture was introduced and became known as Von Neumann architecture. Since 1950, the von Neumann model provided uniformity in subsequent computer designs. The von Neumann architecture was considered innovative as it introduced an idea of allowing machine instructions and data to share memory space.  The von Neumann model is composed of three major parts, the arithmetic logic unit (ALU), the memory, and the instruction processing unit (IPU). In von Neumann machine design, the IPU passes addresses to memory, and memory, in turn, is routed either back to the IPU if an instruction is being fetched or to the ALU if data is being fetched.Von Neumann's machine design uses a RISC (Reduced instruction set computing) architecture, which means the instruction set uses a total of 21 instructions to perform all tasks. (This is in contrast to CISC, complex instruction set computing, instruction sets which have more instructions from which to choose.)  With von Neumann architecture, main memory along with the accumulator (the register that holds the result of logical operations) are the two memories that are addressed. Operations can be carried out as simple arithmetic (these are performed by the ALU and include addition, subtraction, multiplication and division), conditional branches (these are more commonly seen now as if statements or while loops. The branches serve as go to statements), and logical moves between the different components of the machine, i.e., a move from the accumulator to memory or vice versa. Von Neumann architecture accepts fractions and instructions as data types. Finally, as the von Neumann architecture is a simple one, its register management is also simple. The architecture uses a set of seven registers to manipulate and interpret fetched data and instructions. These registers include the ""IR"" (instruction register), ""IBR"" (instruction buffer register), ""MQ"" (multiplier quotient register), ""MAR"" (memory address register), and ""MDR"" (memory data register).""  The architecture also uses a program counter (""PC"") to keep track of where in the program the machine is.


=== John McCarthy, Marvin Minsky and artificial intelligence ===

The term artificial intelligence was credited by John McCarthy to explain the research that they were doing for a proposal for the Dartmouth Summer Research. The naming of artificial intelligence also led to the birth of a new field in computer science. On August 31, 1955, a research project was proposed consisting of John McCarthy, Marvin L. Minsky, Nathaniel Rochester, and Claude E. Shannon. The official project began in 1956 that consisted of several significant parts they felt would help them better understand artificial intelligence's makeup.McCarthy and his colleagues' ideas behind automatic computers was while a machine is capable of completing a task, then the same should be confirmed with a computer by compiling a program to perform the desired results. They also discovered that the human brain was too complex to replicate, not by the machine itself but by the program. The knowledge to produce a program that sophisticated was not there yet.The concept behind this was looking at how humans understand our own language and structure of how we form sentences, giving different meaning and rule sets and comparing them to a machine process. The way computers can understand is at a hardware level. This language is written in binary (1s and 0's). This has to be written in a specific format that gives the computer the ruleset to run a particular hardware piece.Minsky's process determined how these artificial neural networks could be arranged to have similar qualities to the human brain. However, he could only produce partial results and needed to further the research into this idea.McCarthy and Shannon's idea behind this theory was to develop a way to use complex problems to determine and measure the machine's efficiency through mathematical theory and computations. However, they were only to receive partial test results.The idea behind self-improvement is how a machine would use self-modifying code to make itself smarter. This would allow for a machine to grow in intelligence and increase calculation speeds. The group believed they could study this if a machine could improve upon the process of completing a task in the abstractions part of their research.The group thought that research in this category could be broken down into smaller groups. This would consist of sensory and other forms of information about artificial intelligence. Abstractions in computer science can refer to mathematics and programming language.Their idea of computational creativity is how the program or a machine can be seen in having similar ways of human thinking. They wanted to see if a machine could take a piece of incomplete information and improve upon it to fill in the missing details as the human mind can do. If this machine could do this; they needed to think of how did the machine determine the outcome.


== See also ==
Computer museum
List of computer term etymologies, the origins of computer science words
List of pioneers in computer science
History of computing
History of computing hardware
History of software
History of personal computers
Timeline of algorithms
Timeline of women in computing
Timeline of computing 2020–present


== References ==


=== Sources ===
Evans, Claire L. (2018). Broad Band: The Untold Story of the Women Who Made the Internet. New York: Portfolio/Penguin. ISBN 9780735211759.
Grier, David Alan (2013). When Computers Were Human. Princeton: Princeton University Press. ISBN 9781400849369 – via Project MUSE.


== Further reading ==
Tedre, Matti (2014). The Science of Computing: Shaping a Discipline. Taylor and Francis / CRC Press. ISBN 978-1-4822-1769-8.
Kak, Subhash : Computing Science in Ancient India; Munshiram Manoharlal Publishers Pvt. Ltd (2001)
The Development of Computer Science: A Sociocultural Perspective Matti Tedre's Ph.D. Thesis, University of Joensuu (2006)
Ceruzzi, Paul E. (1998). A History of a Modern Computing. The MIT Press. ISBN 978-0-262-03255-1.
Copeland, B. Jack. ""The Modern History of Computing"".  In Zalta, Edward N. (ed.). Stanford Encyclopedia of Philosophy.


== External links ==

Computer History Museum
Computers: From the Past to the Present
The First ""Computer Bug"" at the Naval History and Heritage Command Photo Archives.
Bitsavers, an effort to capture, salvage, and archive historical computer software and manuals from minicomputers and mainframes of the 1950s, 1960s, 1970s, and 1980s
Oral history interviews"
2144a217f6,Persistence (computer science),"In computer science, persistence refers to the characteristic of state of a system that outlives (persists more than) the process that created it. This is achieved in practice by storing the state as data in computer data storage. Programs have to transfer data to and from storage devices and have to provide mappings from the native programming-language data structures to the storage device data structures.Picture editing programs or word processors, for example, achieve state persistence by saving their documents to files.


== Orthogonal or transparent persistence ==
Persistence is said to be ""orthogonal"" or ""transparent"" when it is implemented as an intrinsic property of the execution environment of a program. An orthogonal persistence environment does not require any specific actions by programs running in it to retrieve or save their state.
Non-orthogonal persistence requires data to be written and read to and from storage using specific instructions in a program, resulting in the use of persist as a transitive verb: On completion, the program persists the data.
The advantage of orthogonal persistence environments is simpler and less error-prone programs.The term ""persistent"" was first introduced by Atkinson and Morrison in the sense of orthogonal persistence: they used an adjective rather than a verb to emphasize persistence as a property of the data, as distinct from an imperative action performed by a program. The use of the transitive verb ""persist"" (describing an action performed by a program) is a back-formation.  


=== Adoption ===
Orthogonal persistence is widely adopted in operating systems for hibernation and in platform virtualization systems such as VMware and VirtualBox for state saving.
Research prototype languages such as PS-algol, Napier88, Fibonacci and pJama, successfully demonstrated the concepts along with the advantages to programmers.


== Persistence techniques ==


=== System images ===

Using system images is the simplest persistence strategy. Notebook hibernation is an example of orthogonal persistence using a system image because it does not require any actions by the programs running on the machine. An example of non-orthogonal persistence using a system image is a simple text editing program executing specific instructions to save an entire document to a file.
Shortcomings: Requires enough RAM to hold the entire system state. State changes made to a system after its last image was saved are lost in the case of a system failure or shutdown. Saving an image for every single change would be too time-consuming for most systems, so images are not used as the single persistence technique for critical systems.


=== Journals ===

Using journals is the second simplest persistence technique. Journaling is the process of storing events in a log before each one is applied to a system. Such logs are called journals.
On startup, the journal is read and each event is reapplied to the system, avoiding data loss in the case of system failure or shutdown.
The entire ""Undo/Redo"" history of user commands in a picture editing program, for example, when written to a file, constitutes a journal capable of recovering the state of an edited picture at any point in time.
Journals are used by journaling file systems, prevalent systems and database management systems where they are also called ""transaction logs"" or ""redo logs"".
Shortcomings: When journals are used exclusively, the entire (potentially large) history of all system events must be reapplied on every system startup. As a result, journals are often combined with other persistence techniques.


=== Dirty writes ===
This technique is the writing to storage of only those portions of system state that have been modified (are dirty) since their last write. Sophisticated document editing applications, for example, will use dirty writes to save only those portions of a document that were actually changed since the last save.
Shortcomings: This technique requires state changes to be intercepted within a program. This is achieved in a non-transparent way by requiring specific storage-API calls or in a transparent way with automatic program transformation. This results in code that is slower than native code and more complicated to debug.


== Persistence layers ==
Any software layer that makes it easier for a program to persist its state is generically called a persistence layer. Most persistence layers will not achieve persistence directly but will use an underlying database management system.


== System prevalence ==

System prevalence is a technique that combines system images and transaction journals, mentioned above, to overcome their limitations.
Shortcomings: A prevalent system must have enough RAM to hold the entire system state.


== Database management systems (DBMSs) ==

DBMSs use a combination of the dirty writes and transaction journaling techniques mentioned above. They provide not only persistence but also other services such as queries, auditing and access control.


== Persistent operating systems ==
Persistent operating systems are operating systems that remain persistent even after a crash or unexpected shutdown. Operating systems that employ this ability include

KeyKOS
EROS, the successor to KeyKOS
CapROS, revisions of EROS
Coyotos, successor to EROS
Multics with its single-level store
Phantom
IBM System/38
IBM i
Grasshopper OS [1]
Lua OS
tahrpuppy-6.0.5


== See also ==
Persistent data
Persistent data structure
Persistent identifier
Persistent memory
Copy-on-write
CRUD
Java Data Objects
Java Persistence API
System prevalence
Orthogonality
Service Data Object
Snapshot (computer storage)


== References =="
b0b63eb7fa,Correctness (computer science),"In theoretical computer science, an algorithm is correct with respect to a specification if it behaves as specified. Best explored is functional correctness, which refers to the input-output behavior of the algorithm (i.e., for each input it produces an output satisfying the specification).Within the latter notion, partial correctness, requiring that if an answer is returned it will be correct, is distinguished from total correctness, which additionally requires that an answer is eventually returned, i.e. the algorithm terminates. Correspondingly, to prove a program's total correctness, it is sufficient to prove its partial correctness, and its termination.  The latter kind of proof (termination proof) can never be fully automated, since the halting problem is undecidable.

For example, successively searching through integers 1, 2, 3, … to see if we can find an example of some phenomenon—say an odd perfect number—it is quite easy to write a partially correct program (see box). But to say this program is totally correct would be to assert something currently not known in number theory.
A proof would have to be a mathematical proof, assuming both the algorithm and specification are given formally. In particular it is not expected to be a correctness assertion for a given program implementing the algorithm on a given machine. That would involve such considerations as limitations on computer memory.
A deep result in proof theory, the Curry–Howard correspondence, states that a proof of functional correctness in constructive logic corresponds to a certain program in the lambda calculus. Converting a proof in this way is called program extraction.
Hoare logic is a specific formal system for reasoning rigorously about the correctness of computer programs. It uses axiomatic techniques to define programming language semantics and argue about the correctness of programs through assertions known as Hoare triples.
Software testing is any activity aimed at evaluating an attribute or capability of a program or system and determining that it meets its required results. Although crucial to software quality and widely deployed by programmers and testers, software testing still remains an art, due to limited understanding of the principles of software. The difficulty in software testing stems from the complexity of software: we can not completely test a program with moderate complexity. Testing is more than just debugging. The purpose of testing can be quality assurance, verification and validation, or reliability estimation. Testing can be used as a generic metric as well. Correctness testing and reliability testing are two major areas of testing. Software testing is a trade-off between budget, time and quality.


== See also ==
Formal verification
Design by contract
Program analysis
Model checking
Compiler correctness
Program derivation


== Notes ==


== References ==
""Human Language Technology. Challenges for Computer Science and Linguistics."" Google Books. N.p., n.d. Web. 10 April 2017.
""Security in Computing and Communications."" Google Books. N.p., n.d. Web. 10 April 2017.
""The Halting Problem of Alan Turing - A Most Merry and Illustrated Explanation."" The Halting Problem of Alan Turing - A Most Merry and Illustrated Explanation. N.p., n.d. Web. 10 April 2017.
Turner, Raymond, and Nicola Angius. ""The Philosophy of Computer Science."" Stanford Encyclopedia of Philosophy. Stanford University, 20 August 2013. Web. 10 April 2017.
Dijkstra, E. W. ""Program Correctness"". U of Texas at Austin, Departments of Mathematics and Computer Sciences, Automatic Theorem Proving Project, 1970. Web."
17ede7c4e2,Reference (computer science),"In computer programming, a reference is a value that enables a program to indirectly access a particular data, such as a variable's value or a record, in the computer's memory or in some other storage device.  The reference is said to refer to the datum, and accessing the datum is called dereferencing the reference. A reference is distinct from the datum itself.
A reference is an abstract data type and may be implemented in many ways. Typically, a reference refers to data stored in memory on a given system, and its internal value is the memory address of the data, i.e. a reference is implemented as a pointer. For this reason a reference is often said to ""point to"" the data. Other implementations include an offset (difference) between the datum's address and some fixed ""base"" address, an index, unique key, or identifier used in a lookup operation into an array or table, an operating system handle, a physical address on a storage device, or a network address such as a URL.


== Formal representation ==
A reference R is a value that admits one operation, dereference(R), which yields a value. Usually the reference is typed so that it returns values of a specific type, e.g.:

Often the reference also admits an assignment operation store(R, x), meaning it is an abstract variable.


== Use ==
References are widely used in programming, especially to efficiently pass large or mutable data as arguments to procedures, or to share such data among various uses.  In particular, a reference may point to a variable or record that contains references to other data.  This idea is the basis of indirect addressing and of many linked data structures, such as linked lists. References increase flexibility in where objects can be stored, how they are allocated, and how they are passed between areas of code. As long as one can access a reference to the data, one can access the data through it, and the data itself need not be moved. They also make sharing of data between different code areas easier; each keeps a reference to it.
References can cause significant complexity in a program, partially due to the possibility of dangling and wild references and partially because the topology of data with references is a directed graph, whose analysis can be quite complicated. Nonetheless, references are still simpler to analyze than pointers due to the absence of pointer arithmetic.
The mechanism of references, if varying in implementation, is a fundamental programming language feature common to nearly all modern programming languages. Even some languages that support no direct use of references have some internal or implicit use. For example, the call by reference calling convention can be implemented with either explicit or implicit use of references.


== Examples ==
Pointers are the most primitive type of reference. Due to their intimate relationship with the underlying hardware, they are one of the most powerful and efficient types of references. However, also due to this relationship, pointers require a strong understanding by the programmer of the details of memory architecture. Because pointers store a memory location's address, instead of a value directly, inappropriate use of pointers can lead to undefined behavior in a program, particularly due to dangling pointers or wild pointers. Smart pointers are opaque data structures that act like pointers but can only be accessed through particular methods.
A handle is an abstract reference, and may be represented in various ways. A common example are file handles (the FILE data structure in the C standard I/O library), used to abstract file content. It usually represents both the file itself, as when requesting a lock on the file, and a specific position within the file's content, as when reading a file.
In distributed computing, the reference may contain more than an address or identifier; it may also include an embedded specification of the network protocols used to locate and access the referenced object, the way information is encoded or serialized. Thus, for example, a WSDL description of a remote web service can be viewed as a form of reference; it includes a complete specification of how to locate and bind to a particular web service. A reference to a live distributed object is another example: it is a complete specification for how to construct a small software component called a proxy that will subsequently engage in a peer-to-peer interaction, and through which the local machine may gain access to data that is replicated or exists only as a weakly consistent message stream. In all these cases, the reference includes the full set of instructions, or a recipe, for how to access the data; in this sense, it serves the same purpose as an identifier or address in memory.
If we have a set of keys K and a set of data objects D, any well-defined (single-valued) function from K to D ∪ {null} defines a type of reference, where null is the image of a key not referring to anything meaningful.
An alternative representation of such a function is a directed graph called a reachability graph. Here, each datum is represented by a vertex and there is an edge from u to v if the datum in u refers to the datum in v. The maximum out-degree is one. These graphs are valuable in garbage collection, where they can be used to separate accessible from inaccessible objects.


== External and internal storage ==
In many data structures, large, complex objects are composed of smaller objects. These objects are typically stored in one of two ways:

With internal storage, the contents of the smaller object are stored inside the larger object.
With external storage, the smaller objects are allocated in their own location, and the larger object only stores references to them.Internal storage is usually more efficient, because there is a space cost for the references and dynamic allocation metadata, and a time cost associated with dereferencing a reference and with allocating the memory for the smaller objects. Internal storage also enhances locality of reference by keeping different parts of the same large object close together in memory. However, there are a variety of situations in which external storage is preferred:

If the data structure is recursive, meaning it may contain itself. This cannot be represented in the internal way.
If the larger object is being stored in an area with limited space, such as the stack, then we can prevent running out of storage by storing large component objects in another memory region and referring to them using references.
If the smaller objects may vary in size, it is often inconvenient or expensive to resize the larger object so that it can still contain them.
References are often easier to work with and adapt better to new requirements.Some languages, such as Java, Smalltalk, Python, and Scheme, do not support internal storage.  In these languages, all objects are uniformly accessed through references.


== Language support ==


=== Assembly ===
In assembly language, it is typical to express references using either raw memory addresses or indexes into tables. These work, but are somewhat tricky to use, because an address tells you nothing about the value it points to, not even how large it is or how to interpret it; such information is encoded in the program logic. The result is that misinterpretations can occur in incorrect programs, causing bewildering errors.


=== Lisp ===
One of the earliest opaque references was that of the Lisp language cons cell, which is simply a record containing two references to other Lisp objects, including possibly other cons cells. This simple structure is most commonly used to build singly linked lists, but can also be used to build simple binary trees and so-called ""dotted lists"", which terminate not with a null reference but a value.


=== C/C++ ===

The pointer is still one of the most popular types of references today. It is similar to the assembly representation of a raw address, except that it carries a static datatype which can be used at compile-time to ensure that the data it refers to is not misinterpreted. However, because C has a weak type system which can be violated using casts (explicit conversions between various pointer types and between pointer types and integers), misinterpretation is still possible, if more difficult. Its successor C++ tried to increase type safety of pointers with new cast operators, a reference type &, and smart pointers in its standard library, but still retained the ability to circumvent these safety mechanisms for compatibility.


=== Fortran ===
Fortran does not have an explicit representation of references, but does use them implicitly in its call-by-reference calling semantics. A Fortran reference is best thought of as an alias of another object, such as a scalar variable or a row or column of an array. There is no syntax to dereference the reference or manipulate the contents of the referent directly. Fortran references can be null. As in other languages, these references facilitate the processing of dynamic structures, such as linked lists, queues, and trees.


=== Object-oriented languages ===
A number of object-oriented languages languages such as Eiffel, Java, C#, and Visual Basic have adopted a much more opaque type of reference, usually referred to as simply a reference. These references have types like C pointers indicating how to interpret the data they reference, but they are typesafe in that they cannot be interpreted as a raw address and unsafe conversions are not permitted. References are extensively used to access and assign objects. References are also used in function/method calls or message passing, and reference counts are frequently used to perform garbage collection of unused objects.


=== Functional languages ===
In Standard ML, OCaml, and many other functional languages, most values are persistent: they cannot be modified by assignment. Assignable ""reference cells"" provide mutable variables, data that can be modified. Such reference cells can hold any value, and so are given the polymorphic type α ref, where α is to be replaced with the type of value pointed to. These mutable references can be pointed to different objects over their lifetime. For example, this permits building of circular data structures. The reference cell is functionally equivalent to a mutable array of length 1.
To preserve safety and efficient implementations, references cannot be type-cast in ML, nor can pointer arithmetic be performed. It is important to note that in the functional paradigm, many structures that would be represented using pointers in a language like C are represented using other facilities, such as the powerful algebraic datatype mechanism. The programmer is then able to enjoy certain properties (such as the guarantee of  immutability) while programming, even though the compiler often uses machine pointers ""under the hood"".


=== Perl/PHP ===
Perl supports hard references, which function similarly to those in other languages, and symbolic references, which are just string values that contain the names of variables. When a value that is not a hard reference is dereferenced, Perl considers it to be a symbolic reference and gives the variable with the name given by the value. PHP has a similar feature in the form of its $$var syntax.


== See also ==
Reference type
Abstraction (computer science)
Autovivification
Bounded pointer
Linked data
Magic cookie
Variable (programming)
Weak reference


== References ==


== External links ==

Pointer Fun With Binky Introduction to pointers in a 3-minute educational video – Stanford Computer Science Education Library"
e88681766d,Computing,"Computing is any goal-oriented activity requiring, benefiting from, or creating computing machinery. It includes the study and experimentation of algorithmic processes, and development of both hardware and software. Computing has scientific, engineering, mathematical, technological and social aspects. Major computing disciplines include computer engineering, computer science, cybersecurity, data science, information systems, information technology and software engineering.The term computing is also synonymous with counting and calculating. In earlier times, it was used in reference to the action performed by mechanical computing machines, and before that, to human computers.


== History ==

The history of computing is longer than the history of computing hardware and includes the history of methods intended for pen and paper (or for chalk and slate) with or without the aid of tables. Computing is intimately tied to the representation of numbers, though mathematical concepts necessary for computing existed before numeral systems. The earliest known tool for use in computation is the abacus, and it is thought to have been invented in Babylon circa between 2700–2300 BC. Abaci, of a more modern design, are still used as calculation tools today.
The first recorded proposal for using digital electronics in computing was the 1931 paper ""The Use of Thyratrons for High Speed Automatic Counting of Physical Phenomena"" by C. E. Wynn-Williams. Claude Shannon's 1938 paper ""A Symbolic Analysis of Relay and Switching Circuits"" then introduced the idea of using electronics for Boolean algebraic operations.
The concept of a field-effect transistor was proposed by Julius Edgar Lilienfeld in 1925. John Bardeen and Walter Brattain, while working under William Shockley at Bell Labs, built the first working transistor, the point-contact transistor, in 1947. In 1953, the University of Manchester built the first transistorized computer, the Manchester Baby. However, early junction transistors were relatively bulky devices that were difficult to mass-produce, which limited them to a number of specialised applications. The metal–oxide–silicon field-effect transistor (MOSFET, or MOS transistor) was invented by Mohamed Atalla and Dawon Kahng at Bell Labs in 1959.  The MOSFET made it possible to build high-density integrated circuits, leading to what is known as the computer revolution or microcomputer revolution.


== Computer ==

A computer is a machine that manipulates data according to a set of instructions called a computer program. The program has an executable form that the computer can use directly to execute the instructions. The same program in its human-readable source code form, enables a programmer to study and develop a sequence of steps known as an algorithm. Because the instructions can be carried out in different types of computers, a single set of source instructions converts to machine instructions according to the CPU type.The execution process carries out the instructions in a computer program. Instructions express the computations performed by the computer. They trigger sequences of simple actions on the executing machine. Those actions produce effects according to the semantics of the instructions.


=== Computer hardware ===

Computer hardware includes the physical parts of a computer, including central processing unit, memory and input/output. Computational logic and computer architecture are key topics in the field of computer hardware.


=== Computer software ===

Computer software, or just software, is a collection of computer programs and related data, which provides instructions to a computer. Software refers to one or more computer programs and data held in the storage of the computer. It is a set of programs, procedures, algorithms, as well as its documentation concerned with the operation of a data processing system. Program software performs the function of the program it implements, either by directly providing instructions to the computer hardware or by serving as input to another piece of software. The term was coined to contrast with the old term hardware (meaning physical devices). In contrast to hardware, software is intangible.Software is also sometimes used in a more narrow sense, meaning application software only.


==== System software ====

System software, or systems software, is computer software designed to operate and control computer hardware, and to provide a platform for running application software. System software includes operating systems, utility software, device drivers, window systems, and firmware. Frequently used development tools such as compilers, linkers, and debuggers are classified as system software. System software and middleware manage and integrate a computer's capabilities, but typically do not directly apply them in the performance of tasks that benefit the user, unlike application software.


==== Application software ====

Application software, also known as an application or an app, is computer software designed to help the user perform specific tasks. Examples include enterprise software, accounting software, office suites, graphics software and media players. Many application programs deal principally with documents. Apps may be bundled with the computer and its system software, or may be published separately. Some users are satisfied with the bundled apps and need never install additional applications. The system software manages the hardware and serves the application, which in turn serves the user. 
Application software applies the power of a particular computing platform or system software to a particular purpose. Some apps, such as Microsoft Office, are developed in multiple versions for several different platforms; others have narrower requirements and are generally referred to by the platform they run on. For example, a geography application for Windows or an Android application for education or Linux gaming. Applications that run only on one platform and increase the desirability of that platform due to the popularity of the application, known as killer applications.


=== Computer network ===

A computer network, often simply referred to as a network, is a collection of hardware components and computers interconnected by communication channels that allow sharing of resources and information. When at least one process in one device is able to send or receive data to or from at least one process residing in a remote device, the two devices are said to be in a network. Networks may be classified according to a wide variety of characteristics such as the medium used to transport the data, communications protocol used, scale, topology, and organizational scope.
Communications protocols define the rules and data formats for exchanging information in a computer network, and provide the basis for network programming. One well-known communications protocol is Ethernet, a hardware and link layer standard that is ubiquitous in local area networks. Another common protocol is the Internet Protocol Suite, which defines a set of protocols for internetworking, i.e. for data communication between multiple networks, host-to-host data transfer, and application-specific data transmission formats.Computer networking is sometimes considered a sub-discipline of electrical engineering, telecommunications, computer science, information technology or computer engineering, since it relies upon the theoretical and practical application of these disciplines.


==== Internet ====

The Internet is a global system of interconnected computer networks that use the standard Internet Protocol Suite (TCP/IP) to serve billions of users. This includes millions of private, public, academic, business, and government networks, ranging in scope from local to global. These networks are linked by a broad array of electronic, wireless and optical networking technologies. The Internet carries an extensive range of information resources and services, such as the inter-linked hypertext documents of the World Wide Web and the infrastructure to support email.


=== Computer programming ===

Computer programming is the process of writing, testing, debugging, and maintaining the source code and documentation of computer programs. This source code is written in a programming language, which is an artificial language that is often more restrictive than natural languages, but easily translated by the computer. Programming is used to invoke some desired behavior (customization) from the machine.Writing high-quality source code requires knowledge of both the computer science domain and the domain in which the application will be used. The highest-quality software is thus often developed by a team of domain experts, each a specialist in some area of development. However, the term programmer may apply to a range of program quality, from hacker to open source contributor to professional. It is also possible for a single programmer to do most or all of the computer programming needed to generate the proof of concept to launch a new killer application.


==== Computer programmer ====

A programmer, computer programmer, or coder is a person who writes computer software. The term computer programmer can refer to a specialist in one area of computer programming or to a generalist who writes code for many kinds of software. One who practices or professes a formal approach to programming may also be known as a programmer analyst. A programmer's primary computer language (C, C++, Java, Lisp, Python etc.) is often prefixed to the above titles, and those who work in a web environment often prefix their titles with Web. The term programmer can be used to refer to a software developer, software engineer, computer scientist, or software analyst. However, members of these professions typically possess other software engineering skills, beyond programming.


=== Computer industry ===

The computer industry is made up of businesses involved in developing computer software, designing computer hardware and computer networking infrastructures, manufacturing computer components and providing information technology services, including system administration and maintenance.The software industry includes businesses engaged in development, maintenance and publication of software. The industry also includes software services, such as training, documentation, and consulting.


== Sub-disciplines of computing ==


=== Computer engineering ===

Computer engineering is a discipline that integrates several fields of electrical engineering and computer science required to develop computer hardware and software. Computer engineers usually have training in electronic engineering (or electrical engineering), software design, and hardware-software integration, rather than just software engineering or electronic engineering. Computer engineers are involved in many hardware and software aspects of computing, from the design of individual microprocessors, personal computers, and supercomputers, to circuit design. This field of engineering includes not only the design of hardware within its own domain, but also the interactions between hardware and the context in which it operates.


=== Software engineering ===

Software engineering (SE) is the application of a systematic, disciplined and quantifiable approach to the design, development, operation, and maintenance of software, and the study of these approaches. That is, the application of engineering to software. It is the act of using insights to conceive, model and scale a solution to a problem. The first reference to the term is the 1968 NATO Software Engineering Conference, and was intended to provoke thought regarding the perceived software crisis at the time. Software development, a widely-used and more generic term, does not necessarily subsume the engineering paradigm. The generally accepted concepts of Software Engineering as an engineering discipline have been specified in the Guide to the Software Engineering Body of Knowledge (SWEBOK). The SWEBOK has become an internationally accepted standard in ISO/IEC TR 19759:2015.


=== Computer science ===

Computer science or computing science (abbreviated CS or Comp Sci) is the scientific and practical approach to computation and its applications. A computer scientist specializes in the theory of computation and the design of computational systems.Its subfields can be divided into practical techniques for its implementation and application in computer systems, and purely theoretical areas. Some, such as computational complexity theory, which studies fundamental properties of computational problems, are highly abstract, while others, such as computer graphics, emphasize real-world applications. Others focus on the challenges in implementing computations. For example, programming language theory studies approaches to the description of computations, while the study of computer programming investigates the use of programming languages and complex systems. The field of human–computer interaction focuses on the challenges in making computers and computations useful, usable, and universally accessible to humans.


=== Cybersecurity ===
The field of cybersecurity pertains to the protection of computer systems and networks. This includes information and data privacy, preventing disruption of IT services and prevention of theft of and damage to hardware, software and data.


=== Data science ===
Data science is a field that uses scientific and computing tools to extract information and insights from data, driven by the increasing volume and availability of data. Data mining, big data, statistics and machine learning are all interwoven with data science.


=== Information systems ===

Information systems (IS) is the study of complementary networks of hardware and software (see information technology) that people and organizations use to collect, filter, process, create, and distribute data. The ACM's Computing Careers describes IS as: 

""A majority of IS [degree] programs are located in business schools; however, they may have different names such as management information systems, computer information systems, or business information systems. All IS degrees combine business and computing topics, but the emphasis between technical and organizational issues varies among programs. For example, programs differ substantially in the amount of programming required.""

The study of IS bridges business and computer science, using the theoretical foundations of information and computation to study various business models and related algorithmic processes within a computer science discipline.  The field of Computer Information Systems (CIS) studies computers and algorithmic processes, including their principles, their software and hardware designs, their applications, and their impact on society while IS emphasizes functionality over design.


=== Information technology ===

Information technology (IT) is the application of computers and telecommunications equipment to store, retrieve, transmit and manipulate data, often in the context of a business or other enterprise. The term is commonly used as a synonym for computers and computer networks, but also encompasses other information distribution technologies such as television and telephones. Several industries are associated with information technology, including computer hardware, software, electronics, semiconductors, internet, telecom equipment, e-commerce and computer services.


== Research and emerging technologies ==

DNA-based computing and quantum computing are areas of active research for both computing hardware and software, such as the development of quantum algorithms. Potential infrastructure for future technologies includes DNA origami on photolithography and quantum antennae for transferring information between ion traps. By 2011, researchers had entangled 14 qubits. Fast digital circuits, including those based on Josephson junctions and rapid single flux quantum technology, are becoming more nearly realizable with the discovery of nanoscale superconductors.Fiber-optic and photonic (optical) devices, which already have been used to transport data over long distances, are starting to be used by data centers, along with CPU and semiconductor memory components. This allows the separation of RAM from CPU by optical interconnects. IBM has created an integrated circuit with both electronic and optical information processing in one chip. This is denoted CMOS-integrated nanophotonics (CINP). One benefit of optical interconnects is that motherboards, which formerly required a certain kind of system on a chip (SoC), can now move formerly dedicated memory and network controllers off the motherboards, spreading the controllers out onto the rack. This allows standardization of backplane interconnects and motherboards for multiple types of SoCs, which allows more timely upgrades of CPUs.Another field of research is spintronics. Spintronics can provide computing power and storage, without heat buildup. Some research is being done on hybrid chips, which combine photonics and spintronics. There is also research ongoing on combining plasmonics, photonics, and electronics.


=== Cloud computing ===
Cloud computing is a model that allows for the use of computing resources, such as servers or applications, without the need for interaction between the owner of these resources and the end user. It is typically offered as a service, making it an example of Software as a Service, Platforms as a Service, and Infrastructure as a Service, depending on the functionality offered. Key characteristics include on-demand access, broad network access, and the capability of rapid scaling. It allows individual users or small business to benefit from economies of scale.
One area of interest in this field is its potential to support energy efficiency. Allowing thousands of instances of computation to occur on one single machine instead of thousands of individual machines could help save energy. It could also ease the transition to renewable energy source, since it would suffice to power one server farm with renewable energy, rather than millions of homes and offices.However, this centralized computing model poses several challenges, especially in security and privacy. Current legislation does not sufficiently protect users from companies mishandling their data on company servers. This suggests potential for further legislative regulations on cloud computing and tech companies.


=== Quantum computing ===
Quantum computing is an area of research that brings together the disciplines of computer science, information theory, and quantum physics. While the idea of information as part of physics is relatively new, there appears to be a strong tie between information theory and quantum mechanics. Whereas traditional computing operates on a binary system of ones and zeros, quantum computing uses qubits. Qubits are capable of being in a superposition, i.e. in both states of one and zero, simultaneously. Thus, the value of the qubit is not between 1 and 0, but changes depending on when it is measured. This trait of qubits is known as quantum entanglement, and is the core idea of quantum computing that allows quantum computers to do large scale computations. Quantum computing is often used for scientific research in cases where traditional computers do not have the computing power to do the necessary calculations, such in molecular modeling. Large molecules and their reactions are far too complex for traditional computers to calculate, but the computational power of quantum computers could provide a tool to perform such calculations.


== See also ==
Computational thinking
Creative computing
Electronic data processing
Enthusiast computing
Index of history of computing articles
Instruction set architecture
Lehmer sieve
List of computer term etymologies
Mobile computing
Scientific computing


== References ==


== External links ==

FOLDOC: the Free On-Line Dictionary Of Computing"
cf46759de8,Marshalling (computer science),"In computer science, marshalling or marshaling (US spelling) is the process of transforming the memory representation of an object into a data format suitable for storage or transmission. It is typically used when data must be moved between different parts of a computer program or from one program to another. 
Marshalling can be somewhat similar to or synonymous with serialization. Marshalling is describing an intent or process to transfer some object from a client to server. The intent of marshalling is to have the same object that is present in one running program be present in another running program; that is, an object on the client should be transferred to the server. Serialization does not necessarily have this same intent, since it is only concerned about transforming data, for example, into a stream of bytes. Marshalling and serialization might be done differently, but some form of serialization is usually used to do marshalling.It simplifies complex communications, because it uses composite objects in order to communicate instead of primitive objects. The inverse process of marshalling is called unmarshalling (or demarshalling, similar to deserialization). An unmarshalling interface takes a serialized object and transforms it into an internal data structure.
The accurate definition of marshalling differs across programming languages such as Python, Java, and .NET, and in some contexts, is used interchangeably with serialization.


== Comparison with serialization ==
To ""serialize"" an object means to convert its state into a byte stream in such a way that the byte stream can be converted back into a copy of the object.
The term ""marshal"" is used for a specific type of ""serialization"" in the Python standard library – storing internal python objects:

The marshal module exists mainly to support reading and writing the “pseudo-compiled” code for Python modules of .pyc files. 
…

If you’re serializing and de-serializing Python objects, use the pickle module instead
In the Java-related RFC 2713, marshalling is used when serialising objects for remote invocation. An object that is marshalled records the state of the original object and it contains the codebase (codebase here refers to a list of URLs where the object code can be loaded from, and not source code). Hence, in order to convert the object state and codebase(s), unmarshalling must be done. The unmarshaller interface automatically converts the marshalled data containing codebase(s) into an executable Java object in JAXB. Any object that can be deserialized can be unmarshalled. However, the converse need not be true.

To ""marshal"" an object means to record its state and codebase(s) in such a way that when the marshalled object is ""unmarshalled,"" a copy of the original object is obtained, possibly by automatically loading the class definitions of the object.  You can marshal any object that is serializable or remote (that is, implements the java.rmi.Remote interface).  Marshalling is like serialization, except marshalling also records codebases. Marshalling is different from serialization in that marshalling treats remote objects specially.
…

Any object whose methods can be invoked [on an object in another Java virtual machine] must implement the java.rmi.Remote interface.  When such an object is invoked, its arguments are marshalled and sent from the local virtual machine to the remote one, where the arguments are unmarshalled and used.
In Microsoft .NET, marshalling is also used to refer to serialization when using remote calls:

When you marshal an object by value, a copy of the object is created and serialized to the server. Any method calls made on that object are done on the server


== Usage ==
Marshalling is used within implementations of different remote procedure call (RPC) mechanisms, where it is necessary to transport data between processes and/or between threads. In Microsoft's Component Object Model (COM), interface pointers must be marshalled when crossing COM apartment boundaries. In the .NET Framework, the conversion between an unmanaged type and a CLR type, as in the P/Invoke process, is also an example of an action that requires marshalling to take place.Additionally, marshalling is used extensively within scripts and applications that use the XPCOM technologies provided within the Mozilla application framework. The Mozilla Firefox browser is a popular application built with this framework, that additionally allows scripting languages to use XPCOM through XPConnect (Cross-Platform Connect).


=== Example ===
In the Microsoft Windows family of operating systems the entire set of device drivers for Direct3D are kernel-mode drivers. The user-mode portion of the API is handled by the DirectX runtime provided by Microsoft.
This is an issue because calling kernel-mode operations from user-mode requires performing a system call, and this inevitably forces the CPU to switch to ""kernel mode"". This is a slow operation, taking on the order of microseconds to complete. During this time, the CPU is unable to perform any operations. As such, minimizing the number of times this switching operation must be performed would optimize performance to a substantive degree.
Linux OpenGL drivers are split in two: a kernel-driver and a user-space driver. The user-space driver does all the translation of OpenGL commands into machine code to be submitted to the GPU. To reduce the number of system calls, the user-space driver implements marshalling. If the GPU's command buffer is full of rendering data, the API could simply store the requested rendering call in a temporary buffer and, when the command buffer is close to being empty, it can perform a switch to kernel-mode and add a number of stored commands all at once.


== Formats ==
XML is one means of transferring data between systems. Microsoft, for example, uses it as the basis of the file formats of the various components (Word, Excel, Access, PowerPoint, etc.) of the Microsoft Office suite (see Office Open XML). While this typically results in a verbose wire format, XML's fully-bracketed ""start-tag"", ""end-tag"" syntax allows provision of more accurate diagnostics and easier recovery from transmission or disk errors. In addition, because the tags occur repeatedly, one can use standard compression methods to shrink the content—all the Office file formats are created by zipping the raw XML. Alternative formats such as JSON (JavaScript Object Notation) are more concise, but correspondingly less robust for error recovery. 
Once the data is transferred to a program or an application, it needs to be converted back to an object for usage. Hence, unmarshalling is generally used in the receiver end of the implementations of Remote Method Invocation (RMI) and Remote procedure call (RPC) mechanisms to unmarshal transmitted objects in an executable form.


=== JAXB ===
JAXB or Java Architecture for XML Binding is the most common framework used by developers to marshal and unmarshal Java objects. JAXB provides for the interconversion between fundamental data types supported by Java and standard XML schema data types.


=== XmlSerializer ===
XmlSerializer is the framework used by C# developers to marshal and unmarshal C# objects. One of the advantages of C# over Java is that C# natively supports marshalling due to the inclusion of XmlSerializer class. Java, on the other hand requires a non-native glue code in the form of JAXB to support marshalling.


=== XML and executable representation ===
An example of unmarshalling is the conversion of an XML representation of an object to the default representation of the object in any programming language. Consider the following class.
XML representation of Student object:
Executable representation of Student object:
Unmarshalling converts the XML representation of Code Snippet 1 to the default executable Java representation of Code Snippet 2.


== Unmarshalling in Java ==


=== Unmarshaller in JAXB ===
The process of unmarshalling XML data into an executable Java object is taken care of by the in-built Unmarshaller class. The unmarshal methods defined in the Unmarshaller class are overloaded to accept XML from different types of input such as a File, FileInputStream, or URL. For example:


=== Unmarshalling XML Data ===
Unmarshal methods can deserialize an entire XML document or a small part of it. When the XML root element is globally declared, these methods utilize the JAXBContext's mapping of XML root elements to JAXB mapped classes to initiate the unmarshalling. If the mappings are not sufficient and the root elements are declared locally, the unmarshal methods use declaredType methods for the unmarshalling process. These two approaches can be understood below.


==== Unmarshal a global XML root element ====
The unmarshal method uses JAXBContext to unmarshal the XML data, when the root element is globally declared. The JAXBContext object always maintains a mapping of the globally declared XML element and its name to a JAXB mapped class. If the XML element name or its @xsi:type attribute matches the JAXB mapped class, the unmarshal method transforms the XML data using the appropriate JAXB mapped class. However, if the XML element name has no match, the unmarshal process will abort and throw an UnmarshalException. This can be avoided by using the unmarshal by declaredType methods.


==== Unmarshal a local XML root element ====
When the root element is not declared globally, the application assists the unmarshaller by application-provided mapping using declaredType parameters. By an order of precedence, even if the root name has a mapping to an appropriate JAXB class, the declaredType overrides the mapping. However, if the @xsi:type attribute of the XML data has a mapping to an appropriate JAXB class, then this takes precedence over declaredType parameter. The unmarshal methods by declaredType parameters always return a JAXBElement<declaredType> instance. The properties of this JAXBElement instance are set as follows:


== See also ==

Free and open-source graphics device driver#Software architecture
Component Object Model
CORBA
Pickle (Python)
Protocol Buffers
Java Architecture for XML Binding


== References =="
93b6540b0f,Session (computer science),"In computer science and networking in particular, a session is a time-delimited two-way link, a practical (relatively high) layer in the TCP/IP protocol enabling interactive expression and information exchange between two or more communication devices or ends – be they computers, automated systems, or live active users (see login session). A session is established at a certain point in time, and then ‘torn down’ - brought to an end - at some later point. An established communication session may involve more than one message in each direction. A session is typically stateful, meaning that at least one of the communicating parties needs to hold current state information and save information about the session history to be able to communicate, as opposed to stateless communication, where the communication consists of independent requests with responses.
An established session is the basic requirement to perform a connection-oriented communication. A session also is the basic step to transmit in connectionless communication modes. However, any unidirectional transmission does not define a session.Communication Transport may be implemented as part of protocols and services at the application layer, at the session layer or at the transport layer in the OSI model.

Application layer examples:
HTTP sessions, which allow associating information with individual visitors
A telnet remote login session
Session layer example:
A Session Initiation Protocol (SIP) based Internet phone call
Transport layer example:
A TCP session, which is synonymous to a TCP virtual circuit, a TCP connection, or an established TCP socket.In the case of transport protocols that do not implement a formal session layer (e.g., UDP) or where sessions at the application layer are generally very short-lived (e.g., HTTP), sessions are maintained by a higher level program using a method defined in the data being exchanged.  For example, an HTTP exchange between a browser and a remote host may include an HTTP cookie which identifies state, such as a unique session ID, information about the user's preferences or authorization level.
HTTP/1.0 was thought to only allow a single request and response during one Web/HTTP Session. Protocol version HTTP/1.1 improved this by completing the Common Gateway Interface (CGI), making it easier to maintain the Web Session and supporting HTTP cookies and file uploads.
Most client-server sessions are maintained by the transport layer - a single connection for a single session. However each transaction phase of a Web/HTTP session creates a separate connection. Maintaining session continuity between phases requires a session ID. The session ID is embedded within the <A HREF> or <FORM> links of dynamic web pages so that it is passed back to the CGI. CGI then uses the session ID to ensure session continuity between transaction phases. One advantage of one connection-per-phase is that it works well over low bandwidth (modem) connections.


== Software implementation ==
TCP sessions are typically implemented in software using child processes and/or multithreading, where a new process or thread is created when the computer establishes or joins a session. HTTP sessions are typically not implemented using one thread per session, but by means of a database with information about the state of each session. The advantage with multiple processes or threads is relaxed complexity of the software, since each thread is an instance with its own history and encapsulated variables. The disadvantage is large overhead in terms of system resources, and that the session may be interrupted if the system is restarted.
When a client may connect to any server in a cluster of servers, a special problem is encountered in maintaining consistency when the servers must maintain session state.  The client must either be directed to the same server for the duration of the session, or the servers must transmit server-side session information via a shared file system or database.  Otherwise, the client may reconnect to a different server than the one it started the session with, which will cause problems when the new server does not have access to the stored state of the old one.


== Server-side web sessions ==
Server-side sessions are handy and efficient, but can become difficult to handle in conjunction with load-balancing/high-availability systems and are not usable at all in some embedded systems with no storage. The load-balancing problem can be solved by using shared storage or by applying forced peering between each client and a single server in the cluster, although this can compromise system efficiency and load distribution.
A method of using server-side sessions in systems without mass-storage is to reserve a portion of RAM for storage of session data. This method is applicable for servers with a limited number of clients (e.g. router or access point with infrequent or disallowed access to more than one client at a time).


== Client-side web sessions ==
Client-side sessions use cookies and cryptographic techniques to maintain state without storing as much data on the server. When presenting a dynamic web page, the server sends the current state data to the client (web browser) in the form of a cookie. The client saves the cookie in memory or on disk. With each successive request, the client sends the cookie back to the server, and the server uses the data to ""remember"" the state of the application for that specific client and generate an appropriate response.
This mechanism may work well in some contexts; however, data stored on the client is vulnerable to tampering by the user or by software that has access to the client computer. To use client-side sessions where confidentiality and integrity are required, the following must be guaranteed:

Confidentiality: Nothing apart from the server should be able to interpret session data.
Data integrity: Nothing apart from the server should manipulate session data (accidentally or maliciously).
Authenticity: Nothing apart from the server should be able to initiate valid sessions.To accomplish this, the server needs to encrypt the session data before sending it to the client, and modification of such information by any other party should be prevented via cryptographic means.
Transmitting state back and forth with every request is only practical when the size of the cookie is small. In essence, client-side sessions trade server disk space for the extra bandwidth that each web request will require. Moreover, web browsers limit the number and size of cookies that may be stored by a web site. To improve efficiency and allow for more session data, the server may compress the data before creating the cookie, decompressing it later when the cookie is returned by the client.


== HTTP session token ==
A session token is a unique identifier that is generated and sent from a server to a client to identify the current interaction session. The client usually stores and sends the token as an HTTP cookie and/or sends it as a parameter in GET or POST queries. The reason to use session tokens is that the client only has to handle the identifier—all session data is stored on the server (usually in a database, to which the client does not have direct access) linked to that identifier. Examples of the names that some programming languages use when naming their HTTP cookie include JSESSIONID (JSP), PHPSESSID (PHP), CGISESSID (CGI), and ASPSESSIONID (ASP).


== Session management ==
In human–computer interaction, session management is the process of keeping track of a user's activity across sessions of interaction with the computer system.
Typical session management tasks in a desktop environment include keeping track of which applications are open and which documents each application has opened, so that the same state can be restored when the user logs out and logs in later. For a website, session management might involve requiring the user to re-login if the session has expired (i.e., a certain time limit has passed without user activity). It is also used to store information on the server-side between HTTP requests.


=== Desktop session management ===
A desktop session manager is a program that can save and restore desktop sessions. A desktop session is all the windows currently running and their current content. Session management on Linux-based systems is provided by X session manager. On Microsoft Windows systems, session management is provided by the Session Manager Subsystem (smss.exe); user session functionality can be extended by third-party applications like twinsplay.


=== Browser session management ===
Session management is particularly useful in a web browser where a user can save all open pages and settings and restore them at a later date or on a different  computer (see data portability).
To help recover from a system or application crash, pages and settings can also be restored on next run. Google Chrome, Mozilla Firefox, Internet Explorer, OmniWeb and Opera are examples of web browsers that support session management. Session management is often managed through the application of cookies.


=== Web server session management ===
Hypertext Transfer Protocol (HTTP) is stateless. Session management is the technique used by the web developer to make the stateless HTTP protocol support session state. For example, once a user has been authenticated to the web server, the user's next HTTP request (GET or POST) should not cause the web server to ask for the user's account and password again. For a discussion of the methods used to accomplish this see HTTP cookie and Session ID
In situations where multiple web servers must share knowledge of session state (as is typical in a cluster environment) session information must be shared between the cluster nodes that are running web server software. Methods for sharing session state between nodes in a cluster include: multicasting session information to member nodes (see JGroups for one example of this technique), sharing session information with a partner node using distributed shared memory or memory virtualization, sharing session information between nodes using network sockets, storing session information on a shared file system such as a distributed file system or a global file system, or storing the session information outside the cluster in a database.
If session information is considered transient, volatile data that is not required for non-repudiation of transactions and does not contain data that is subject to compliance auditing (in the U.S. for example, see the Health Insurance Portability and Accountability Act and the Sarbanes–Oxley Act for examples of two laws that necessitate compliance auditing) then any method of storing session information can be used.  However, if session information is subject to audit compliance, consideration should be given to the method used for session storage, replication, and clustering.
In a service-oriented architecture, Simple Object Access Protocol or  SOAP messages constructed with Extensible Markup Language (XML) messages can be used by consumer applications to cause web servers to create sessions.


=== Session management over SMS ===
Just as HTTP is a stateless protocol, so is SMS.  As SMS became interoperable across rival networks in 1999, and text messaging started its ascent towards becoming a ubiquitous global form of communication, various enterprises became interested in using the SMS channel for commercial purposes.  Initial services did not require session management since they were only one-way communications (for example, in 2000, the first mobile news service was delivered via SMS in Finland).  Today, these applications are referred to as application-to-peer (A2P) messaging as distinct from peer-to-peer (P2P) messaging.  The development of interactive enterprise applications required session management, but because SMS is a stateless protocol as defined by the GSM standards, early implementations were controlled client-side by having the end-users enter commands and service identifiers manually.


== See also ==
HTTPS
REST
Session ID
Sessionization
Session fixation
Session poisoning


== References ==


== External links ==
Sessions by Doug Lea"
57ef767578,AP Computer Science A,"Advanced Placement (AP) Computer Science A (also known as AP CompSci, AP CompSci A, APCS, APCSA, AP Computer Science Applications, or AP Java) is an AP Computer Science course and examination offered by the College Board to high school students as an opportunity to earn college credit for a college-level computer science course. AP Computer Science A is meant to be the equivalent of a first-semester course in computer science. The AP exam currently tests students on their knowledge of Java.
AP Computer Science AB, which was equal to a full year, was discontinued following the May 2009 exam administration.


== Course ==
AP Computer Science emphasizes object-oriented programming methodology with an emphasis on problem solving and algorithm development. It also includes the study of data structures and abstraction, but these topics were not covered to the extent that they were covered in AP Computer Science AB. The Microsoft-sponsored program Technology Education and Literacy in Schools (TEALS) aims to increase the number of students taking AP Computer Science classes.The units of the exam are as follows:


== Case studies and labs ==
Historically, the AP exam used several programs in its free-response section to test students' knowledge of object-oriented programs without requiring them to develop an entire environment. These programs were called Case Studies.
This practice was discontinued as of the 2014–15 school year and replaced with optional labs that teach concepts.


=== Case studies (discontinued) ===
Case studies were used in AP Computer Science curriculum starting in 1994.


==== Big Integer case study (1994-1999) ====
The Big Integer case study was in use prior to 2000. It was replaced by the Marine Biology case study.


==== Marine Biology case study (2000-2007) ====
The Marine Biology Case Study (MBCS) was a program written in C++ until 2003, then in Java, for use with the A and AB examinations. It served as an example of object-oriented programming (OOP) embedded in a more complicated design project than most students had worked with before.
The case study was designed to allow the College Board to quickly test a student's knowledge of object oriented programming ideas such as inheritance and encapsulation while requiring students to understand how objects such as ""the environment"", ""the fish"", and the simulation's control module interact with each other without having to develop the entire environment independently, which would be quite time-consuming. The case study also gives all students taking the AP Computer Science exams with a common experience from which to draw additional test questions.
On each of the exams, at least one free-response question was derived from the case study. There were also five multiple-choice questions that are derived from the case study.
This case study was discontinued from 2007, and was replaced by GridWorld.


==== GridWorld case study (2008-2014) ====
GridWorld is a computer program case study written in Java that was used with the AP Computer Science program from 2008 to 2014. It serves as an example of object-oriented programming (OOP). GridWorld succeeded the Marine Biology Simulation Case Study, which was used from 2000–2007. The GridWorld framework was designed and implemented by Cay Horstmann, based on the Marine Biology Simulation Case Study. The narrative was produced by Chris Nevison and Barbara Cloud Wells, Colgate University.
The GridWorld Case Study was used as a substitute for writing a single large program as a culminating project. Due to obvious time restraints during the exam, the GridWorld Case Study was provided by the College Board  to students prior to the exam. Students were expected to be familiar with the classes and interfaces (and how they interact) before taking the exam. The case study was divided into five sections, the last of which was only tested on the AB exam. Roughly five multiple-choice questions in Section I were devoted to the GridWorld Case Study, and it was the topic of one free response question in Section II.
GridWorld has been discontinued and replaced with a set of labs for the 2014–2015 school year.

Actors
The GridWorld Case Study employs an Actor class to construct objects in the grid.  The Actor class manages the object's color, direction, location, what the object does in the simulation, and how the object interacts with other objects.
Actors are broken down into the classes ""Flower"", ""Rock"", ""Bug"", and ""Critter"", which inherit the Actor class and often override certain methods (most notably the Act method).  Flowers can't move, and when forced to Act, they become darker.  Flowers are dropped by Bugs and eaten by Critters.  Rocks are also immobile and aren't dropped or eaten.  Bugs move directly ahead of themselves, unless blocked by a rock or another bug, in which case the Bug will make a 45 degree turn and try again.  They drop flowers in every space they occupy, eat flowers that are directly on their space of grid, and are consumed by Critters.  Critters move in a random direction to a space that isn't occupied by a Rock or other Critter and consume Flowers and Bugs.
Extensions
The Case Study also includes several extensions of the above classes. ""BoxBug"" extends ""Bug"" and moves in a box shape if its route is not blocked. ""ChameleonCritter"" extends ""Critter"" and does not eat other Actors, instead changing its color to match the color one of its neighbors. ""Crab Critter"" moves left or right and only eats Actors in front of it, but otherwise extends the ""Critter"" class.
Students often create their own extensions of the Actor class. Some common examples of student created extensions are Warden organisms and SimCity-like structures, in which objects of certain types create objects of other types based on their neighbors (much like Conway's Game of Life). Students have even created versions of the games Pac-Man, Fire Emblem, and Tetris.
Known issues
The version that is available at the College Board website, GridWorld 1.00, contains a bug (not to be confused with the Actor subclass Bug) that causes a SecurityException to be thrown when it is deployed as an applet. This was fixed in the ""unofficial code"" release on the GridWorld website. Also, after setting the environment to an invalid BoundedGrid, it will cause a NullPointerException.


=== Labs ===
Instead of the discontinued case studies, the College Board created three new labs that instructors are invited to use, but they are optional and are not tested on the exam. There are no questions on the specific content of the labs on the AP exam, but there are questions that test the concepts developed in the labs. The three labs are:
The Magpie Lab
The Elevens Lab
The Picture Lab


== Exam ==


=== History ===
The AP exam in Computer Science was first offered in 1984.
Before 1999, the AP exam tested students on their knowledge of Pascal. From 1999 to 2003, the exam tested students on their knowledge of C++ instead. Since 2003, the AP Computer Science exam has tested students on their knowledge of computer science through Java.


=== Format ===
The exam is composed of two sections, formerly consisting of the following times:

Section I: Multiple Choice [1 hour and 15 minutes for 40 multiple-choice questions]
Section II: Free-Response [1 hour and 45 minutes for 4 problems involving extended reasoning]As of 2015, however, the Multiple Choice section was extended by 15 minutes while the Free-Response section was reduced by 15 minutes for the following:

Section I: Multiple Choice [1 hour and 30 minutes for 40 multiple-choice questions]
Section II: Free-Response [1 hour and 30 minutes for 4 problems involving extended reasoning]


=== Grade distributions ===
In the 2014 administration, 39,278 students took the exam. The mean score was a 2.96 with a standard deviation of 1.55. The grade distributions since 2003 were:


== AP Computer Science AB ==


=== Course ===
The discontinued AP Computer Science AB course included all the topics of AP Computer Science A, as well as a more formal and a more in-depth study of algorithms, data structures, and data abstraction. For example, binary trees were studied in AP Computer Science AB but not in AP Computer Science A. The use of recursive data structures and dynamically allocated structures were fundamental to AP Computer Science AB. Due to low numbers of students taking the AP Computer Science AB exam, it was discontinued after the 2008–2009 year.


=== Grade distributions for AP Computer Science AB ===
The AP Computer Science AB Examination was discontinued as of May 2009. The grade distributions from 2003 to 2009 are shown below:


== See also ==
Computer science
Glossary of computer science


== References ==


== External links ==
College Board: AP Computer Science A"
c5ca633e69,MIT Computer Science and Artificial Intelligence Laboratory,"Computer Science and Artificial Intelligence Laboratory (CSAIL) is a research institute at the Massachusetts Institute of Technology (MIT) formed by the 2003 merger of the Laboratory for Computer Science (LCS) and the Artificial Intelligence Laboratory (AI Lab). Housed within the Ray and Maria Stata Center, CSAIL is the largest on-campus laboratory as measured by research scope and membership. It is part of the Schwarzman College of Computing but is also overseen by the MIT Vice President of Research.


== Research activities ==
CSAIL's research activities are organized around a number of semi-autonomous research groups, each of which is headed by one or more professors or research scientists. These groups are divided up into seven general areas of research:

Artificial intelligence
Computational biology
Graphics and vision
Language and learning
Theory of computation
Robotics
Systems (includes computer architecture, databases, distributed systems, networks and networked systems, operating systems, programming methodology, and software engineering, among others)In addition, CSAIL hosts the World Wide Web Consortium (W3C).


== History ==
Computing Research at MIT began with Vannevar Bush's research into a differential analyzer and Claude Shannon's electronic Boolean algebra in the 1930s, the wartime MIT Radiation Laboratory, the post-war Project Whirlwind and Research Laboratory of Electronics (RLE), and MIT Lincoln Laboratory's SAGE in the early 1950s. At MIT, research in the field of artificial intelligence began in late 1950s.


=== Project MAC ===
On July 1, 1963, Project MAC (the Project on Mathematics and Computation, later backronymed to Multiple Access Computer, Machine Aided Cognitions, or Man and Computer) was launched with a $2 million grant from the Defense Advanced Research Projects Agency (DARPA). Project MAC's original director was Robert Fano of MIT's Research Laboratory of Electronics (RLE). Fano decided to call MAC a ""project"" rather than a ""laboratory"" for reasons of internal MIT politics – if MAC had been called a laboratory, then it would have been more difficult to raid other MIT departments for research staff. The program manager responsible for the DARPA grant was J. C. R. Licklider, who had previously been at MIT conducting research in RLE, and would later succeed Fano as director of Project MAC.
Project MAC would become famous for groundbreaking research in operating systems, artificial intelligence, and the theory of computation. Its contemporaries included Project Genie at Berkeley, the Stanford Artificial Intelligence Laboratory, and (somewhat later) University of Southern California's (USC's) Information Sciences Institute.
An ""AI Group"" including Marvin Minsky (the director), John McCarthy (inventor of Lisp), and a talented community of computer programmers were incorporated into Project MAC. They were interested principally in the problems of vision, mechanical motion and manipulation, and language, which they view as the keys to more intelligent machines. In the 1960s and 1970s the AI Group developed a time-sharing operating system called Incompatible Timesharing System (ITS) which ran on PDP-6 and later PDP-10 computers.The early Project MAC community included Fano, Minsky, Licklider, Fernando J. Corbató, and a community of computer programmers and enthusiasts among others who drew their inspiration from former colleague John McCarthy. These founders envisioned the creation of a computer utility whose computational power would be as reliable as an electric utility. To this end, Corbató brought the first computer time-sharing system, Compatible Time-Sharing System (CTSS), with him from the MIT Computation Center, using the DARPA funding to purchase an IBM 7094 for research use. One of the early focuses of Project MAC would be the development of a successor to CTSS, Multics, which was to be the first high availability computer system, developed as a part of an industry consortium including General Electric and Bell Laboratories.
In 1966, Scientific American featured Project MAC in the September thematic issue devoted to computer science, that was later published in book form. At the time, the system was described as having approximately 100 TTY terminals, mostly on campus but with a few in private homes. Only 30 users could be logged in at the same time. The project enlisted students in various classes to use the terminals simultaneously in problem solving, simulations, and multi-terminal communications as tests for the multi-access computing software being developed.


=== AI Lab and LCS ===
In the late 1960s, Minsky's artificial intelligence group was seeking more space, and was unable to get satisfaction from project director Licklider. Minsky found that although Project MAC as a single entity could not get the additional space he wanted, he could split off to form his own laboratory and then be entitled to more office space. As a result, the MIT AI Lab was formed in 1970, and many of Minsky's AI colleagues left Project MAC to join him in the new laboratory, while most of the remaining members went on to form the Laboratory for Computer Science. Talented programmers such as Richard Stallman, who used TECO to develop EMACS, flourished in the AI Lab during this time.
Those researchers who did not join the smaller AI Lab formed the Laboratory for Computer Science and continued their research into operating systems, programming languages, distributed systems, and the theory of computation. Two professors, Hal Abelson and Gerald Jay Sussman, chose to remain neutral — their group was referred to variously as Switzerland and Project MAC for the next 30 years.Among much else, the AI Lab led to the invention of Lisp machines and their attempted commercialization by two companies in the 1980s: Symbolics and Lisp Machines Inc. This divided the AI Lab into ""camps"" which resulted in a hiring away of many of the talented programmers. The incident inspired Richard Stallman's later work on the GNU Project. ""Nobody had envisioned that the AI lab's hacker group would be wiped out, but it was."" ... ""That is the basis for the free software movement — the experience I had, the life that I've lived at the MIT AI lab — to be working on human knowledge, and not be standing in the way of anybody's further using and further disseminating human knowledge"".


=== CSAIL ===
On the fortieth anniversary of Project MAC's establishment, July 1, 2003, LCS was merged with the AI Lab to form the MIT Computer Science and Artificial Intelligence Laboratory, or CSAIL. This merger created the largest laboratory (over 600 personnel) on the MIT campus and was regarded as a reuniting of the diversified elements of Project MAC.In 2018, CSAIL launched a five-year collaboration program with IFlytek, a company sanctioned the following year for allegedly using its technology for surveillance and human rights abuses in Xinjiang. In October 2019, MIT announced that it would review its partnerships with sanctioned firms such as iFlyTek and SenseTime. In April 2020, the agreement with iFlyTek was terminated.CSAIL moved from the School of Engineering to the newly formed Schwarzman College of Computing by February 2020.


== Offices ==
From 1963 to 2004, Project MAC, LCS, the AI Lab, and CSAIL had their offices at 545 Technology Square, taking over more and more floors of the building over the years. In 2004, CSAIL moved to the new Ray and Maria Stata Center, which was built specifically to house it and other departments.


== Outreach activities ==
The IMARA (from Swahili word for ""power"") group sponsors a variety of outreach programs that bridge the global digital divide. Its aim is to find and implement long-term, sustainable solutions which will increase the availability of educational technology and resources to domestic and international communities. These projects are run under the aegis of CSAIL and staffed by MIT volunteers who give training, install and donate computer setups in greater Boston, Massachusetts, Kenya, Native American Indian tribal reservations in the American Southwest such as the Navajo Nation, the Middle East, and Fiji Islands. The CommuniTech project strives to empower under-served communities through sustainable technology and education and does this through the MIT Used Computer Factory (UCF), providing refurbished computers to under-served families, and through the Families Accessing Computer Technology (FACT) classes, it trains those families to become familiar and comfortable with computer technology.


== Notable researchers ==
(Including members and alumni of CSAIL's predecessor laboratories)

MacArthur Fellows Tim Berners-Lee, Erik Demaine, Dina Katabi, Daniela L. Rus, Regina Barzilay, Peter Shor, Richard Stallman, and Joshua Tenenbaum
Turing Award recipients Leonard M. Adleman, Fernando J. Corbató, Shafi Goldwasser, Butler W. Lampson, John McCarthy, Silvio Micali, Marvin Minsky, Ronald L. Rivest, Adi Shamir, Barbara Liskov, Michael Stonebraker, and Tim Berners-Lee
IJCAI Computers and Thought Award recipients Terry Winograd, Patrick Winston, David Marr, Gerald Jay Sussman, Rodney Brooks
Rolf Nevanlinna Prize recipients Madhu Sudan, Peter Shor, Constantinos Daskalakis
Gödel Prize recipients Shafi Goldwasser (two-time recipient), Silvio Micali, Maurice Herlihy, Charles Rackoff, Johan Håstad, Peter Shor, and Madhu Sudan
Grace Murray Hopper Award recipients Robert Metcalfe, Shafi Goldwasser, Guy L. Steele, Jr., Richard Stallman, and W. Daniel Hillis
Textbook authors Harold Abelson and Gerald Jay Sussman, Richard Stallman, Thomas H. Cormen, Charles E. Leiserson, Patrick Winston, Ronald L. Rivest, Barbara Liskov, John Guttag, Jerome H. Saltzer, Frans Kaashoek, Clifford Stein, and Nancy Lynch
David D. Clark, former chief protocol architect for the Internet; co-author with Jerome H. Saltzer (also a CSAIL member) and David P. Reed of the influential paper ""End-to-End Arguments in Systems Design""
Eric Grimson, expert on computer vision and its applications to medicine, appointed Chancellor of MIT March 2011
Bob Frankston, co-developer of VisiCalc, the first computer spreadsheet
Seymour Papert, inventor of the Logo programming language
Joseph Weizenbaum, creator of the ELIZA computer-simulated therapist


=== Notable alumni ===
Robert Metcalfe, who later invented Ethernet at Xerox PARC and later founded 3Com
Mark Raibert, who created the robot company Boston Dynamics
Drew Houston, co-founder of Dropbox
Colin Angle and Helen Greiner who, with previous CSAIL director Rodney Brooks, founded iRobot
Jeremy Wertheimer, who developed ITA Software used by travel websites like Kayak and Orbitz
Max Krohn, co-founder of OkCupid


== Directors ==
Directors of Project MACRobert Fano, 1963–1968
J. C. R. Licklider, 1968–1971
Edward Fredkin, 1971–1974
Michael Dertouzos, 1974–1975Directors of the Artificial Intelligence LaboratoryMarvin Minsky, 1970–1972
Patrick Winston, 1972–1997
Rodney Brooks, 1997–2003Directors of the Laboratory for Computer ScienceMichael Dertouzos, 1975–2001
Victor Zue, 2001–2003Directors of CSAILRodney Brooks, 2003–2007
Victor Zue, 2007–2011
Anant Agarwal, 2011–2012
Daniela L. Rus, 2012–


== CSAIL Alliances ==
CSAIL Alliances is the industry connection arm of MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL). CSAIL Alliances offers companies programs to connect with the research, faculty, students, and startups of CSAIL by providing organizations with opportunities to learn about the research, engage with students, explore collaborations with researchers, and join research initiatives such as FinTech at CSAIL, MIT Future of Data, and Machine Learning Applications. 


== See also ==


== References ==


== Further reading ==
""A Marriage of Convenience: The Founding of the MIT Artificial Intelligence Laboratory"" (PDF)., Chious et al. — includes important information on the Incompatible Timesharing System
Weizenbaum. Rebel at Work: a documentary film with and about Joseph Weizenbaum
Garfinkel, Simson (1999).  Abelson, Hall (ed.). Architects of the Information Society: Thirty-Five Years of the Laboratory for Computer Science at MIT. Cambridge, Massachusetts: MIT Press. ISBN 0-262-07196-7.


== External links ==
Official website of CSAIL, successor of the AI Lab
""A Marriage of Convenience: The Founding of the MIT Artificial Intelligence Laboratory"", Chious et al. — includes important information on the Incompatible Timesharing System."
4e84dfe9c1,Concurrency (computer science),"In computer science, concurrency is the ability of different parts or units of a program, algorithm, or problem to be executed out-of-order or in partial order, without affecting the outcome.  This allows for parallel execution of the concurrent units, which can significantly improve overall speed of the execution in multi-processor and multi-core systems. In more technical terms, concurrency refers to the decomposability of a program, algorithm, or problem into order-independent or partially-ordered components or units of computation.According to Rob Pike, concurrency is the composition of independently executing computations, and concurrency is not parallelism: concurrency is about dealing with lots of things at once but parallelism is about doing lots of things at once. Concurrency is about structure, parallelism is about execution, concurrency provides a way to structure a solution to solve a problem that may (but not necessarily) be parallelizable.A number of mathematical models have been developed for general concurrent computation including Petri nets, process calculi, the parallel random-access machine model, the actor model and the Reo Coordination Language.


== History ==
As Leslie Lamport (2015) notes, ""While concurrent program execution had been considered for years, the computer science of concurrency began with Edsger Dijkstra's seminal 1965 paper that introduced the mutual exclusion problem. ... The ensuing decades have seen a huge growth of interest in concurrency—particularly in distributed systems. Looking back at the origins of the field, what stands out is the fundamental role played by Edsger Dijkstra"".


== Issues ==
Because computations in a concurrent system can interact with each other while being executed, the number of possible execution paths in the system can be extremely large, and the resulting outcome can be indeterminate. Concurrent use of shared resources can be a source of indeterminacy leading to issues such as deadlocks, and resource starvation.Design of concurrent systems often entails finding reliable techniques for coordinating their execution, data exchange, memory allocation, and execution scheduling to minimize response time and maximise throughput.


== Theory ==
Concurrency theory has been an active field of research in theoretical computer science.  One of the first proposals was  Carl Adam Petri's seminal work on Petri nets in the early 1960s. In the years since, a wide variety of formalisms have been developed for modeling and reasoning about concurrency.


=== Models ===
A number of formalisms for modeling and understanding concurrent systems have been developed, including:
The parallel random-access machine
The actor model
Computational bridging models such as the bulk synchronous parallel (BSP) model
Petri nets
Process calculi
Calculus of communicating systems (CCS)
Communicating sequential processes (CSP) model
π-calculus
Tuple spaces, e.g., Linda
Simple Concurrent Object-Oriented Programming (SCOOP)
Reo Coordination Language
Trace monoidsSome of these models of concurrency are primarily intended to support reasoning and specification, while others can be used through the entire development cycle, including design, implementation, proof, testing and simulation of concurrent systems. Some of these are based on message passing, while others have different mechanisms for concurrency.
The proliferation of different models of concurrency has motivated some researchers to develop ways to unify these different theoretical models. For example, Lee and Sangiovanni-Vincentelli have demonstrated that a so-called ""tagged-signal"" model can be used to provide a common framework for defining the denotational semantics of a variety of different models of concurrency, while Nielsen, Sassone, and Winskel have demonstrated that category theory can be used to provide a similar unified understanding of different models.The Concurrency Representation Theorem in the actor model provides a fairly general way to represent concurrent systems that are closed in the sense that they do not receive communications from outside. (Other concurrency systems, e.g., process calculi can be modeled in the actor model using a two-phase commit protocol.) The mathematical denotation denoted by a closed system S is constructed increasingly better approximations from an initial behavior called ⊥S using a behavior approximating function progressionS to construct a denotation (meaning ) for S as follows:
DenoteS ≡ ⊔i∈ω progressionSi(⊥S)In this way, S can be mathematically characterized in terms of all its possible behaviors.


=== Logics ===
Various types of temporal logic can be used to help reason about concurrent systems. Some of these logics, such as linear temporal logic and computation tree logic, allow assertions to be made about the sequences of states that a concurrent system can pass through. Others, such as action computational tree logic, Hennessy–Milner logic, and Lamport's temporal logic of actions, build their assertions from sequences of actions (changes in state). The principal application of these logics is in writing specifications for concurrent systems.


== Practice ==
Concurrent programming encompasses programming languages and algorithms used to implement concurrent systems.  Concurrent programming is usually considered to be more general than parallel programming because it can involve arbitrary and dynamic patterns of communication and interaction, whereas parallel systems generally have a predefined and well-structured communications pattern. The base goals of concurrent programming include correctness, performance and robustness. Concurrent systems such as Operating systems and Database management systems are generally designed to operate indefinitely, including automatic recovery from failure, and not terminate unexpectedly (see Concurrency control). Some concurrent systems implement a form of transparent concurrency, in which concurrent computational entities may compete for and share a single resource, but the complexities of this competition and sharing are shielded from the programmer.
Because they use shared resources, concurrent systems in general require the inclusion of some kind of arbiter somewhere in their implementation (often in the underlying hardware), to control access to those resources. The use of arbiters introduces the possibility of indeterminacy in concurrent computation which has major implications for practice including correctness and performance.  For example, arbitration introduces unbounded nondeterminism which raises issues with model checking because it causes explosion in the state space and can even cause models to have an infinite number of states.
Some concurrent programming models include coprocesses and deterministic concurrency. In these models, threads of control explicitly yield their timeslices, either to the system or to another process.


== See also ==
Chu space
Client–server network nodes
Clojure
Cluster nodes
Concurrency control
Concurrent computing
Concurrent object-oriented programming
Concurrency pattern
Construction and Analysis of Distributed Processes (CADP)
D (programming language)
Distributed system
Elixir (programming language)
Erlang (programming language)
Go (programming language)
Gordon Pask
International Conference on Concurrency Theory (CONCUR)
OpenMP
Parallel computing
Partitioned global address space
Processes
Ptolemy Project
Rust (programming language)
Sheaf (mathematics)
Threads
X10 (programming language)
Structured concurrency


== References ==


== Further reading ==
Lynch, Nancy A. (1996). Distributed Algorithms. Morgan Kaufmann. ISBN 978-1-55860-348-6.
Tanenbaum, Andrew S.; Van Steen, Maarten (2002). Distributed Systems: Principles and Paradigms. Prentice Hall. ISBN 978-0-13-088893-8.
Kurki-Suonio, Reino (2005). A Practical Theory of Reactive Systems. Springer. ISBN 978-3-540-23342-8.
Garg, Vijay K. (2002). Elements of Distributed Computing. Wiley-IEEE Press. ISBN 978-0-471-03600-5.
Magee, Jeff; Kramer, Jeff (2006). Concurrency: State Models and Java Programming. Wiley. ISBN 978-0-470-09355-9.
Distefano, S., & Bruneo, D. (2015). Quantitative assessments of distributed systems: Methodologies and techniques (1st ed.). Somerset: John Wiley & Sons Inc.ISBN 9781119131144
Bhattacharyya, S. S. (2013;2014;). Handbook of signal processing systems (Second;2;2nd 2013; ed.). New York, NY: Springer.10.1007/978-1-4614-6859-2 ISBN 9781461468592
Wolter, K. (2012;2014;). Resilience assessment and evaluation of computing systems (1. Aufl.;1; ed.). London;Berlin;: Springer. ISBN 9783642290329


== External links ==
Process Algebra Diary - Prof. Luca Aceto's blog on Concurrency Theory
Concurrent Systems at The WWW Virtual Library
Concurrency patterns presentation given at scaleconf"
b414c73d4a,National University of Computer and Emerging Sciences,"The National University of Computer and Emerging Sciences (Initials: NUCES) (Urdu: قومی جامعہ برائے کمپیوٹر و علومِ ظہوری سائنس), also commonly known as ""Foundation for Advancement of Science and Technology"" (FAST), (Urdu: دانش گاہِ اساسی برائے ارتقائے سائنس و علومِ فنون) is a private research university with multiple campuses in different cities of Pakistan.


== Overview ==
The university is the first multi-campus university in Pakistan, having five modern campuses based in different cities. These campuses are located in Chiniot-Faisalabad, Islamabad, Karachi, Lahore and Peshawar, providing a standard educational environment and recreational facilities to 11,000 students, out of which 500 are faculty members and a quarter is covered by female students. Founded as Federally Chartered University, it was inaugurated by President Pervez Musharraf in July 2000. It is consistently ranked among the leading institutions of higher education in the country and ranked top in computer sciences and information technology by the Higher Education Commission of Pakistan in 2020. Its engineering programs are accredited with Pakistan Engineering Council. FAST is a not-for-profit educational institution charging subsidized fees from its students. Besides this, FAST offers different financial assistance programs for deserving students in the form of loans.


== History ==
The Foundation of Advancement of Science and Technology was founded and established by Bank of Credit and Commerce International financier. Hasan Abidi, founder of BCCI, provided a large financial capital for the university to promote research in computer sciences and emerging technologies during 1980s. Later this foundation established the National University of Computer and Emerging Sciences which was inaugurated by Former President and Chief of Army Staff General Pervez Musharraf in 2000. It is privileged to be the first private sector university, having multiple campuses set up under the Federal Charter granted by Ordinance No.XXIII of 2000, dated July 1, 2000.
Established in 1980, the sponsoring body of FAST university was registered by Government of Pakistan as a charitable institution. FAST was a pioneer in Pakistan's IT sector development by offering the country's first undergraduate computer science curriculum, with its headquarters at Islamabad.


== Campuses ==
National University of Computer and Emerging Sciences is a premier university in Pakistan, with a multi-campus setup and its central administration based in Islamabad. The university operates five campuses in Islamabad, Karachi, Lahore, Peshawar, and Faisalabad, making it the first of its kind in the country.


=== Islamabad Campus ===
The FAST National University Islamabad campus, situated at A.K Brohi Road, H-11/4, serves as the university's main hub.
This campus provides state-of-the-art lecture halls and classrooms, extensive libraries and research centers, student housing, dining and recreational facilities, athletic fields, student clubs and organizations, and more. Additionally, the campus provides a range of support services, such as health and wellness resources, academic advising, and career guidance.
At the heart of these offerings is the Career Services Office, which provides students and alumni with a variety of career development support, including workshops, seminars, career counseling, mock interviews, and recruitment drives for internships and jobs. The campus also hosts an annual job fair and provides opportunities for alumni engagement through events such as alumni talks and the annual homecoming.


=== Karachi Campus ===
The FAST National University Karachi campus has two branches: the main campus, located on the National Highway, and the city campus, located in Block-6 PECHS.
At the Karachi campus, students have access to state-of-the-art labs, well-equipped to support their studies in a variety of technical fields. They are also able to take advantage of a variety of study and research resources through libraries.
In addition to its academic facilities, the Karachi campus offers a range of recreational and wellness services, including sports facilities and a gym. Additionally, the campus provides transportation services to support the mobility of its students.


=== Lahore Campus ===
The FAST National University Lahore campus is situated in Faisal Town and spans 12.5 acres of land.
At the Lahore campus, students have access to a variety of indoor and outdoor sporting facilities, including football, volleyball, badminton, cricket, basketball, lawn tennis, table tennis, and jogging. Swimming, rowing, and athletics are also available through off-campus arrangements.
In addition to its athletic facilities, the Lahore campus provides students with purpose-built classrooms equipped with cutting-edge technology, as well as a range of computing and engineering laboratories. The campus also houses an auditorium, a seminar hall, a cafeteria, and separate common rooms for boys and girls. The offices of various student groups can also be found on the campus.
The Lahore campus library is a standout feature of the university, as it is the second library in Pakistan with its library catalog accessible through the Library of Congress Gateway. The library holds over 21,000 books and 57 international journals and magazines.


=== Peshawar Campus ===
The Peshawar campus of the FAST National University is for students seeking an education in technical fields. It is located in the heart of the city.
At the Peshawar campus, students can pursue degree programs in Computer Science, Electrical Engineering, and Business Administration, taught by a dedicated and highly qualified faculty.


=== Chiniot-Faisalabad Campus ===
The Faisalabad campus of the FAST National University is the fifth and newest addition to the university's network of campuses. It is located on 22 acres of land on the Faisalabad-Chiniot Road, approximately nine kilometers from the Faisalabad Motorway interchange.
The Faisalabad campus offers degree programs in Computer Science, Electrical Engineering, and Business Administration.


== Academic Profile ==
FAST university offers undergraduate, post-graduate and doctoral programs in business and sciences, at their campuses. The availability of bachelor programs depend on the campuses.


=== Undergraduate Studies ===
The undergraduate courses are offered by university in different disciplines for bachelor's in sciences and business, leading to a bachelor's degree.


==== Faculty of Computing ====
Dean: Jawwad Shamsi
Degrees offered:

BS (Artificial Intelligence)
BS (Computer Science)
BS (Cyber Security)
BS (Data Science)
BS (Software Engineering)


==== Faculty of Engineering ====
Dean: Dr Saima Zafar
Degrees offered:

BS (Civil Engineering)
BS (Electrical Engineering)
BS (Internet of Things)
BS (Robotics)


==== Faculty of Management Sciences ====
Dean: M. Ayub Siddiqui
Degrees offered:

BBA (4 years)
BS (Accounting and Finance) (4 years)
BS (Business Analytics) (4 years)


=== Graduate Studies ===
The university offers post graduate studies for different disciplines for master's in sciences and business, leading to a master's degree.


==== Faculty of Computing ====
Dean: Jawwad Shamsi
Degrees offered:

MS (Artificial intelligence}
MS (Computer Networks & Security
MS (Computer Science)
MS (Data Science)
MS (Software Engineering)
MS (Software Project Management)


==== Faculty of Engineering ====
Dean: S.M Sajid
Degrees offered:

MS (Civil Engineering)
MS (Electrical Engineering)


==== Faculty of Management Sciences ====
Dean: M. Ayub Siddiqui
Degrees offered:

MBA (2 years)
MS (Accounting and Finance) (2 years)
MS (Management Sciences) (2 years)


==== Faculty of Science & Humanities ====
Dean: Dr.Summaira Sarfraz
Degrees offered:

MS (Applied in linguistics)
MS (Mathematics)


=== Doctor of philosophy ===
Degrees offered:

PhD (Civil Engineering)
PhD (Computer Science)
PhD (Electrical Engineering)
PhD (Management Sciences)
PhD (Mathematics)
PhD (Software Engineering)


== Notable alumni ==
Farhan Saeed - singer, actor
Fawad Khan – singer, actor
Hania Amir – actress, model, singer
Mir Zafar Ali – visual effects artist who won an Academy Award for the animated film Frozen (2013)
Osman Khalid Butt – actor
Xulfi – musician, singer, music producer, song composer


== Research labs ==
FAST-National university encourages the growth of research in university. It has its research labs in four campuses, Islamabad, Lahore, Peshawar and Karachi. It is further accredited as one of the leading research institutions of computer science in the country. 


== References ==


== External links ==
Official website
Karachi Campus
Islamabad Campus
Lahore Campus
Peshawar Campus
Faisalabad CampusFAST University Merit List 2023
{{Fast University Jobs 2023}}"
6f352dc98f,Side effect (computer science),"In computer science, an operation, function or expression is said to have a side effect if it modifies some state variable value(s) outside its local environment, which is to say if it has any observable effect other than its primary effect of returning a value to the invoker of the operation. Example side effects include modifying a non-local variable, modifying a static local variable, modifying a mutable argument passed by reference, performing I/O or calling other functions with side-effects. In the presence of side effects, a program's behaviour may depend on history; that is, the order of evaluation matters. Understanding and debugging a function with side effects requires knowledge about the context and its possible histories.Side effects play an important role in the design and analysis of programming languages. The degree to which side effects are used depends on the programming paradigm. For example, imperative programming is commonly used to produce side effects, to update a system's state. By contrast, declarative programming is commonly used to report on the state of system, without side effects. 
Functional programming aims to minimize or eliminate side effects. The lack of side effects makes it easier to do formal verification of a program. The functional language Haskell eliminates side effects such as I/O and other stateful computations by replacing them with monadic actions. Functional languages such as Standard ML, Scheme and Scala do not restrict side effects, but it is customary for programmers to avoid them.Assembly language programmers must be aware of hidden side effects—instructions that modify parts of the processor state which are not mentioned in the instruction's mnemonic. A classic example of a hidden side effect is an arithmetic instruction that implicitly modifies condition codes (a hidden side effect) while it explicitly modifies a register (the intended effect). One potential drawback of an instruction set with hidden side effects is that, if many instructions have side effects on a single piece of state, like condition codes, then the logic required to update that state sequentially may become a performance bottleneck. The problem is particularly acute on some processors designed with pipelining (since 1990) or with out-of-order execution. Such a processor may require additional control circuitry to detect hidden side effects and stall the pipeline if the next instruction depends on the results of those effects.


== Referential transparency ==

Absence of side effects is a necessary, but not sufficient, condition for referential transparency. Referential transparency means that an expression (such as a function call) can be replaced with its value. This requires that the expression is pure, that is to say the expression must be deterministic (always give the same value for the same input) and side-effect free.


== Temporal side effects ==
Side effects caused by the time taken for an operation to execute are usually ignored when discussing side effects and referential transparency. There are some cases, such as with hardware timing or testing, where operations are inserted specifically for their temporal side effects e.g. sleep(5000) or for (int i = 0; i < 10000; ++i) {}. These instructions do not change state other than taking an amount of time to complete.


== Idempotence ==

A subroutine with side effects is idempotent if multiple applications of the subroutine have the same effect on the system state as a single application, in other words if the function from the system state space to itself associated with the subroutine is idempotent in the mathematical sense. For instance, consider the following Python program:

setx is idempotent because the second application of setx to 3 has the same effect on the system state as the first application: x was already set to 3 after the first application, and it is still set to 3 after the second application.
A pure function is idempotent if it is idempotent in the mathematical sense. For instance, consider the following Python program:

abs is idempotent because the second application of abs to the return value of the first application to -3 returns the same value as the first application to -3.


== Example ==
One common demonstration of side effect behavior is that of the assignment operator in C. The assignment a = b is an expression that evaluates to the same value as the expression b, with the side effect of storing the R-value of b into the L-value of a. This allows multiple assignment:

Because the operator right associates, this is equivalent to

This presents a potential hangup for novice programmers who may confuse

with


== See also ==
Action at a distance (computer programming)
Don't-care term
Sequence point
Side-channel attack
Undefined behaviour
Unspecified behaviour


== References =="
2502fc5b78,Covariance and contravariance (computer science),"Many programming language type systems support subtyping. For instance, if the type Cat is a subtype of Animal, then an expression of type Cat should be substitutable wherever an expression of type Animal is used.
Variance refers to how subtyping between more complex types relates to subtyping between their components. For example, how should a list of Cats relate to a list of Animals? Or how should a function that returns Cat relate to a function that returns Animal?
Depending on the variance of the type constructor, the subtyping relation of the simple types may be either preserved, reversed, or ignored for the respective complex types. In the OCaml programming language, for example, ""list of Cat"" is a subtype of ""list of Animal"" because the list type constructor is covariant. This means that the subtyping relation of the simple types are preserved for the complex types.
On the other hand, ""function from Animal to String"" is a subtype of ""function from Cat to String"" because the function type constructor is contravariant in the parameter type. Here, the subtyping relation of the simple types is reversed for the complex types.
In other words, covariance is the quality of being different by being more specific (Cat is covariant to Animal) while contravariance is the quality of being different by being more general (Animal is contravariant to Cat).
A programming language designer will consider variance when devising typing rules for language features such as arrays, inheritance, and generic datatypes. By making type constructors covariant or contravariant instead of invariant, more programs will be accepted as well-typed. On the other hand, programmers often find contravariance unintuitive, and accurately tracking variance to avoid runtime type errors can lead to complex typing rules.
In order to keep the type system simple and allow useful programs, a language may treat a type constructor as invariant even if it would be safe to consider it variant, or treat it as covariant even though that could violate type safety.


== Formal definition ==
Suppose A and B are types, and T<U> denotes application of a type constructor T with type argument U.
Within the type system of a programming language, a typing rule for a type constructor I is:

covariant if it preserves the ordering of types (≤), which orders types from more specific to more generic: If A ≤ B, then  I<A> ≤ I<B>;
contravariant if it reverses this ordering: If A ≤ B, then  I<B> ≤ I<A>;
bivariant if both of these apply (i.e., if A ≤ B, then  I<A> ≡ I<B>);
variant if covariant, contravariant or bivariant;
invariant or nonvariant if not variant.The article considers how this applies to some common type constructors.


=== C# examples ===
For example, in C#, if  Cat is a subtype of Animal, then:

IEnumerable<Cat> is a subtype of IEnumerable<Animal>. The subtyping is preserved because IEnumerable<T> is covariant on T.
Action<Animal> is a subtype of Action<Cat>. The subtyping is reversed because Action<T> is contravariant on T.
Neither IList<Cat> nor IList<Animal> is a subtype of the other, because IList<T> is invariant on T.The variance of a C# generic interface is declared by placing the out (covariant) or in (contravariant) attribute on (zero or more of) its type parameters. For each so-marked type parameter, the compiler conclusively verifies, with any violation being fatal, that such use is globally consistent. The above interfaces are declared as IEnumerable<out T>, Action<in T>, and IList<T>. Types with more than one type parameter may specify different variances on each type parameter. For example, the delegate type Func<in T, out TResult> represents a function with a contravariant input parameter of type T and a covariant return value of type TResult.The typing rules for interface variance ensure type safety. For example, an Action<T> represents a first-class function expecting an argument of type T, and a function that can handle any type of animal can always be used instead of one that can only handle cats.


== Arrays ==
Read-only data types (sources) can be covariant; write-only data types (sinks) can be contravariant. Mutable data types which act as both sources and sinks should be invariant. To illustrate this general phenomenon, consider the array type.  For the type Animal we can make the type Animal[], which is an ""array of animals"".  For the purposes of this example, this array supports both reading and writing elements.
We have the option to treat this as either:

covariant: a Cat[] is an Animal[];
contravariant: an Animal[] is a Cat[];
invariant: an Animal[] is not a Cat[] and a Cat[] is not an Animal[].If we wish to avoid type errors, then only the third choice is safe. Clearly, not every Animal[] can be treated as if it were a Cat[], since a client reading from the array will expect a Cat, but an Animal[] may contain e.g. a Dog. So the contravariant rule is not safe.
Conversely, a Cat[] cannot be treated as an Animal[]. It should always be possible to put a Dog into an Animal[]. With covariant arrays this cannot be guaranteed to be safe, since the backing store might actually be an array of cats. So the covariant rule is also not safe—the array constructor should be invariant. Note that this is only an issue for mutable arrays; the covariant rule is safe for immutable (read-only) arrays.
Likewise, the contravariant rule would be safe for write-only arrays.


=== Covariant arrays in Java and C# ===
Early versions of Java and C# did not include generics, also termed parametric polymorphism. In such a setting, making arrays invariant rules out useful polymorphic programs.
For example, consider writing a function to shuffle an array, or a function that tests two arrays for equality using the Object.equals method on the elements. The implementation does not depend on the exact type of element stored in the array, so it should be possible to write a single function that works on all types of arrays. It is easy to implement functions of type:

However, if array types were treated as invariant, it would only be possible to call these functions on an array of exactly the type Object[]. One could not, for example, shuffle an array of strings.
Therefore, both Java and C# treat array types covariantly.
For instance, in Java String[] is a subtype of Object[], and in C# string[] is a subtype of object[].
As discussed above, covariant arrays lead to problems with writes into the array. Java and C# deal with this by marking each array object with a type when it is created. Each time a value is stored into an array, the execution environment will check that the run-time type of the value is equal to the run-time type of the array. If there is a mismatch, an ArrayStoreException (Java) or ArrayTypeMismatchException (C#) is thrown:

In the above example, one can read from the array (b) safely. It is only trying to write to the array that can lead to trouble.
One drawback to this approach is that it leaves the possibility of a run-time error that a stricter type system could have caught at compile-time. Also, it hurts performance because each write into an array requires an additional run-time check.
With the addition of generics, Java and C# now offer ways to write this kind of polymorphic function without relying on covariance. The array comparison and shuffling functions can be given the parameterized types

Alternatively, to enforce that a C# method accesses a collection in a read-only way, one can use the interface  IEnumerable<object> instead of passing it an array object[].


== Function types ==
Languages with first-class functions have function types like ""a function expecting a Cat and returning an Animal"" (written Cat -> Animal in OCaml syntax or Func<Cat,Animal> in C# syntax).
Those languages also need to specify when one function type is a subtype of another—that is, when it is safe to use a function of one type in a context that expects a function of a different type. 
It is safe to substitute a function f for a function g if f accepts a more general type of argument and returns a more specific type than g. For example, functions of type Animal -> Cat,  Cat -> Cat, and Animal -> Animal can be used wherever a Cat -> Animal was expected. (One can compare this to the robustness principle of communication: ""be liberal in what you accept and conservative in what you produce."") The general rule is:

  
    
      
        (
        
          P
          
            1
          
        
        →
        
          R
          
            1
          
        
        )
        ≤
        (
        
          P
          
            2
          
        
        →
        
          R
          
            2
          
        
        )
      
    
    {\displaystyle (P_{1}\rightarrow R_{1})\leq (P_{2}\rightarrow R_{2})}
   if 
  
    
      
        
          P
          
            1
          
        
        ≥
        
          P
          
            2
          
        
      
    
    {\displaystyle P_{1}\geq P_{2}}
   and 
  
    
      
        
          R
          
            1
          
        
        ≤
        
          R
          
            2
          
        
      
    
    {\displaystyle R_{1}\leq R_{2}}
  .Using inference rule notation the same rule can be written as:

  
    
      
        
          
            
              
                P
                
                  1
                
              
              ≥
              
                P
                
                  2
                
              
              
              
                R
                
                  1
                
              
              ≤
              
                R
                
                  2
                
              
            
            
              (
              
                P
                
                  1
                
              
              →
              
                R
                
                  1
                
              
              )
              ≤
              (
              
                P
                
                  2
                
              
              →
              
                R
                
                  2
                
              
              )
            
          
        
      
    
    {\displaystyle {\frac {P_{1}\geq P_{2}\quad R_{1}\leq R_{2}}{(P_{1}\rightarrow R_{1})\leq (P_{2}\rightarrow R_{2})}}}
  In other words, the → type constructor is contravariant in the parameter (input) type and covariant in the return (output) type. This rule was first stated formally by John C. Reynolds, and further popularized in a paper by Luca Cardelli.When dealing with functions that take functions as arguments, this rule can be applied several times. For example, by applying the rule twice, we see that 
  
    
      
        (
        (
        
          P
          
            1
          
        
        →
        R
        )
        →
        R
        )
        ≤
        (
        (
        
          P
          
            2
          
        
        →
        R
        )
        →
        R
        )
      
    
    {\displaystyle ((P_{1}\to R)\to R)\leq ((P_{2}\to R)\to R)}
   if 
  
    
      
        
          P
          
            1
          
        
        ≤
        
          P
          
            2
          
        
      
    
    {\displaystyle P_{1}\leq P_{2}}
  . In other words, the type 
  
    
      
        (
        (
        A
        →
        B
        )
        →
        C
        )
      
    
    {\displaystyle ((A\to B)\to C)}
   is covariant in the position of 
  
    
      
        A
      
    
    {\displaystyle A}
  . For complicated types it can be confusing to mentally trace why a given type specialization is or isn't type-safe, but it is easy to calculate which positions are co- and contravariant: a position is covariant if it is on the left side of an even number of arrows applying to it.


== Inheritance in object-oriented languages ==
When a subclass overrides a method in a superclass, the compiler must check that the overriding method has the right type. While some languages require that the type exactly matches the type in the superclass (invariance), it is also type safe to allow the overriding method to have a ""better"" type. By the usual subtyping rule for function types, this means that the overriding method should return a more specific type (return type covariance), and accept a more general argument (parameter type contravariance). In UML notation, the possibilities are as follows (where Class B is the subclass that extends Class A which is the superclass):

Variance and method overriding: overview
		
		
		
		
		
For a concrete example, suppose we are writing a class to model an animal shelter. We assume that Cat is a subclass of Animal, and that we have a base class (using Java syntax)

Now the question is: if we subclass AnimalShelter, what types are we allowed to give to getAnimalForAdoption and putAnimal?


=== Covariant method return type ===
In a language which allows covariant return types, a derived class can override the getAnimalForAdoption method to return a more specific type:

Among mainstream OO languages, Java, C++ and C# (as of version 9.0 ) support covariant return types. Adding the covariant return type was one of the first modifications of the C++ language approved by the standards committee in 1998. Scala and D  also support covariant return types.


=== Contravariant method parameter type ===
Similarly, it is type safe to allow an overriding method to accept a more general argument than the method in the base class:

Only a few object-oriented languages actually allow this (for example, Python when typechecked with mypy). C++, Java and most other languages that support overloading and/or shadowing would interpret this as a method with an overloaded or shadowed name.
However, Sather supported both covariance and contravariance. Calling convention for overridden methods are covariant with out parameters and return values, and contravariant with normal parameters (with the mode in).


=== Covariant method parameter type ===
A couple of mainstream languages, Eiffel and Dart allow the parameters of an overriding method to have a more specific type than the method in the superclass (parameter type covariance). Thus, the following Dart code would type check, with putAnimal overriding the method in the base class:

This is not type safe. By up-casting a CatShelter to an AnimalShelter, one can try to place a dog in a cat shelter. That does not meet CatShelter parameter restrictions, and will result in a runtime error. The lack of type safety (known as the ""catcall problem"" in the Eiffel community, where ""cat"" or ""CAT"" is a Changed Availability or Type) has been a long-standing issue. Over the years, various combinations of global static analysis, local static analysis, and new language features  have been proposed to remedy it, and these have been implemented in some Eiffel compilers.
Despite the type safety problem, the Eiffel designers consider covariant parameter types crucial for modeling real world requirements. The cat shelter illustrates a common phenomenon: it is a kind of animal shelter but has additional restrictions, and it seems reasonable to use inheritance and restricted parameter types to model this. In proposing this use of inheritance, the Eiffel designers reject the Liskov substitution principle, which states that objects of subclasses should always be less restricted than objects of their superclass.
One other instance of a mainstream language allowing covariance in method parameters is PHP in regards to class constructors. In the following example, the __construct() method is accepted, despite the method parameter being covariant to the parent's method parameter. Were this method anything other than __construct(), an error would occur:

Another example where covariant parameters seem helpful is so-called binary methods, i.e. methods where the parameter is expected to be of the same type as the object the method is called on. An example is the compareTo method: a.compareTo(b) checks whether a comes before or after b in some ordering, but the way to compare, say, two rational numbers will be different from the way to compare two strings. Other common examples of binary methods include equality tests, arithmetic operations, and set operations like subset and union.
In older versions of Java, the comparison method was specified as an interface Comparable:

The drawback of this is that the method is specified to take an argument of type Object. A typical implementation would first down-cast this argument (throwing an error if it is not of the expected type):

In a language with covariant parameters, the argument to compareTo could be directly given the desired type RationalNumber, hiding the typecast. (Of course, this would still give a runtime error if compareTo was then called on e.g. a String.)


=== Avoiding the need for covariant parameter types ===
Other language features can provide the apparent benefits of covariant parameters while preserving Liskov substitutability.
In a language with generics (a.k.a. parametric polymorphism) and bounded quantification, the previous examples can be written in a type-safe way. Instead of defining AnimalShelter, we define a parameterized class Shelter<T>. (One drawback of this is that the implementer of the base class needs to foresee which types will need to be specialized in the subclasses.)

Similarly, in recent versions of Java the Comparable interface has been parameterized, which allows the downcast to be omitted in a type-safe way:

Another language feature that can help is multiple dispatch. One reason that binary methods are awkward to write is that in a call like a.compareTo(b), selecting the correct implementation of compareTo really depends on the runtime type of both a and b, but in a conventional OO language only the runtime type of a is taken into account. In a language with Common Lisp Object System (CLOS)-style multiple dispatch, the comparison method could be written as a generic function where both arguments are used for method selection.
Giuseppe Castagna observed that in a typed language with multiple dispatch, a generic function can have some parameters which control dispatch and some ""left-over"" parameters which do not. Because the method selection rule chooses the most specific applicable method, if a method overrides another method, then the overriding method will have more specific types for the controlling parameters. On the other hand, to ensure type safety the language still must require the left-over parameters to be at least as general. Using the previous terminology, types used for runtime method selection are covariant while types not used for runtime method selection of the method are contravariant. Conventional single-dispatch languages like Java also obey this rule: only one argument is used for method selection (the receiver object, passed along to a method as the hidden argument this), and indeed the type of this is more specialized inside overriding methods than in the superclass.
Castagna suggests that examples where covariant parameter types are superior (particularly, binary methods) should be handled using multiple dispatch; which is naturally covariant.
However, most programming languages do not support multiple dispatch.


=== Summary of variance and inheritance ===
The following table summarizes the rules for overriding methods in the languages discussed above.


== Generic types ==
In programming languages that support generics (a.k.a. parametric polymorphism), the programmer can extend the type system with new constructors. For example, a C# interface like IList<T> makes it possible to construct new types like IList<Animal> or IList<Cat>. The question then arises what the variance of these type constructors should be.
There are two main approaches. In languages with declaration-site variance annotations (e.g., C#), the programmer annotates the definition of a generic type with the intended variance of its type parameters. With use-site variance annotations (e.g., Java), the programmer instead annotates the places where a generic type is instantiated.


=== Declaration-site variance annotations ===
The most popular languages with declaration-site variance annotations are C# and Kotlin (using the keywords out and in), and Scala and OCaml (using the keywords + and -). C# only allows variance annotations for interface types, while Kotlin, Scala and OCaml allow them for both interface types and concrete data types.


==== Interfaces ====
In C#, each type parameter of a generic interface can be marked covariant (out), contravariant (in), or invariant (no annotation). For example, we can define an interface IEnumerator<T> of read-only iterators, and declare it to be covariant (out) in its type parameter.

With this declaration, IEnumerator will be treated as covariant in its type parameter, e.g. IEnumerator<Cat> is a subtype of IEnumerator<Animal>.
The type checker enforces that each method declaration in an interface only mentions the type parameters in a way consistent with the in/out annotations. That is, a parameter that was declared covariant must not occur in any contravariant positions (where a position is contravariant if it occurs under an odd number of contravariant type constructors). The precise rule is that the return types of all methods in the interface must be valid covariantly and all the method parameter types must be valid contravariantly, where valid S-ly is defined as follows:

Non-generic types (classes, structs, enums, etc.) are valid both co- and contravariantly.
A type parameter T is valid covariantly if it was not marked in, and valid contravariantly if it was not marked out.
An array type A[] is valid S-ly if A is. (This is because C# has covariant arrays.)
A generic type G<A1, A2, ..., An> is valid S-ly if for each parameter Ai,
Ai is valid S-ly, and the ith parameter to G is declared covariant, or
Ai is valid (not S)-ly, and the ith parameter to G is declared contravariant, or
Ai is valid both covariantly and contravariantly, and the ith parameter to G is declared invariant.As an example of how these rules apply, consider the IList<T> interface. 

The parameter type T of Insert must be valid contravariantly, i.e. the type parameter T must not be tagged out. Similarly, the result type IEnumerator<T> of GetEnumerator must be valid covariantly, i.e. (since IEnumerator is a covariant interface) the type T must be valid covariantly, i.e. the type parameter T must not be tagged in. This shows that the interface IList is not allowed to be marked either co- or contravariant.
In the common case of a generic data structure such as IList, these restrictions mean that an out parameter can only be used for methods getting data out of the structure, and an in parameter can only be used for methods putting data into the structure, hence the choice of keywords.


==== Data ====
C# allows variance annotations on the parameters of interfaces, but not the parameters of classes. Because fields in C# classes are always mutable, variantly parameterized classes in C# would not be very useful. But languages which emphasize immutable data can make good use of covariant data types. For example, in all of Scala, Kotlin and OCaml the immutable list type is covariant: List[Cat] is a subtype of List[Animal].
Scala's rules for checking variance annotations are essentially the same as C#'s. However, there are some idioms that apply to immutable datastructures in particular. They are illustrated by the following (excerpt from the) definition of the List[A] class.

First, class members that have a variant type must be immutable. Here, head has the type A, which was declared covariant (+), and indeed head was declared as a method (def). Trying to declare it as a mutable field (var) would be rejected as type error.
Second, even if a data structure is immutable, it will often have methods where the parameter type occurs contravariantly. For example, consider the method :: which adds an element to the front of a list. (The implementation works by creating a new object of the similarly named class ::, the class of nonempty lists.) The most obvious type to give it would be

However, this would be a type error, because the covariant parameter A appears in a contravariant position (as a function parameter). But there is a trick to get around this problem. We give :: a more general type, which allows adding an element of any type B 
as long as B is a supertype of A. Note that this relies on List being covariant, since 
this  has type List[A] and we treat it as having type List[B].  At first glance it may not be obvious that the generalized type is sound, but if the programmer starts out with the simpler type declaration, the type errors will point out the place that  needs to be generalized.


==== Inferring variance ====
It is possible to design a type system where the compiler automatically infers the best possible variance annotations for all datatype parameters. However, the analysis can get complex for several reasons. First, the analysis is nonlocal since the variance of an interface I depends on the variance of all interfaces that I mentions. Second, in order to get unique best solutions the type system must allow bivariant parameters (which are simultaneously co- and contravariant). And finally, the variance of type parameters should arguably be a deliberate choice by the designer of an interface, not something that just happens.
For these reasons most languages do very little variance inference. C# and Scala do not infer any variance annotations at all. OCaml can infer the variance of parameterized concrete datatypes, but the programmer must explicitly specify the variance of abstract types (interfaces).
For example, consider an OCaml datatype T which wraps a function

The compiler will automatically infer that T is contravariant in the first parameter, and covariant in the second. The programmer can also provide explicit annotations, which the compiler will check are satisfied. Thus the following declaration is equivalent to the previous one:

Explicit annotations in OCaml become useful when specifying interfaces. For example, the standard library interface Map.S for association tables include an annotation saying that the map type constructor is covariant in the result type.

This ensures that e.g. cat IntMap.t is a subtype of animal IntMap.t.


=== Use-site variance annotations (wildcards) ===
One drawback of the declaration-site approach is that many interface types must be made invariant. For example, we saw above that IList needed to be invariant, because it contained both Insert and GetEnumerator. In order to expose more variance, the API designer could provide additional interfaces which provide subsets of the available methods (e.g. an ""insert-only list"" which only provides Insert). However this quickly becomes unwieldy.
Use-site variance means the desired variance is indicated with an annotation at the specific site in the code where the type will be used. This gives users of a class more opportunities for subtyping without requiring the designer of the class to define multiple interfaces with different variance. Instead, at the point a generic type is instantiated to an actual parameterized type, the programmer can indicate that only a subset of its methods will be used. In effect, each definition of a generic class also makes available interfaces for the covariant and contravariant parts of that class.
Java provides use-site variance annotations through wildcards, a restricted form of bounded existential types. A parameterized type can be instantiated by a wildcard ? together with an upper or lower bound, e.g. List<? extends Animal> or List<? super Animal>. An unbounded wildcard like List<?> is equivalent to List<? extends Object>. Such a type represents List<X> for some unknown type X which satisfies the bound. For example, if l has type List<? extends Animal>, then the type checker will accept

because the type X is known to be a subtype of Animal, but

will be rejected as a type error since an Animal is not necessarily an X. In general, given some interface I<T>, a reference to an I<? extends T> forbids using  methods from the interface where T occurs contravariantly in the type of the method. Conversely, if l had type List<? super Animal> one could call l.add but not l.get.

While non-wildcard parameterized types in Java are invariant (e.g. there is no subtyping relationship between List<Cat> and List<Animal>), wildcard types can be made more specific by specifying a tighter bound. For example, List<? extends Cat> is a subtype of List<? extends Animal>. This shows that wildcard types are covariant in their upper bounds (and also contravariant in their lower bounds). In total, given a wildcard type like C<? extends T>, there are three ways to form a subtype: by specializing the class C, by specifying a tighter bound T, or by replacing the wildcard ? with a specific type (see figure).
By applying two of the above three forms of subtyping, it becomes possible to, for example, pass an argument of type List<Cat> to a method expecting a List<? extends Animal>. This is the kind of expressiveness that results from covariant interface types. The type List<? extends Animal> acts as an interface type containing only the covariant methods of List<T>, but the implementer of List<T> did not have to define it ahead of time.
In the common case of a generic data structure IList, covariant parameters are used for methods getting data out of the structure, and contravariant parameters for methods putting data into the structure. The mnemonic for Producer Extends, Consumer Super (PECS), from the book Effective Java by Joshua Bloch gives an easy way to remember when to use covariance and contravariance.
Wildcards are flexible, but there is a drawback. While use-site variance means that API designers need not consider variance of type parameters to interfaces, they must often instead use more complicated method signatures. A common example involves the Comparable interface. Suppose we want to write a function that finds the biggest element in a collection. The elements need to implement the compareTo method, so a first try might be

However, this type is not general enough—one can find the max of a Collection<Calendar>, but not a Collection<GregorianCalendar>. The problem is that GregorianCalendar does not implement Comparable<GregorianCalendar>, but instead the (better) interface Comparable<Calendar>. In Java, unlike in C#, Comparable<Calendar> is not considered a subtype of Comparable<GregorianCalendar>. Instead the type of max has to be modified:

The bounded wildcard ? super T conveys the information that max calls only contravariant methods from the Comparable interface. This particular example is frustrating because all the methods in Comparable are contravariant, so that condition is trivially true. A declaration-site system could handle this example with less clutter by annotating only the definition of Comparable.


=== Comparing declaration-site and use-site annotations ===
Use-site variance annotations provide additional flexibility, allowing more programs to type check. However, they have been criticized for the complexity they add to the language, leading to complicated type signatures and error messages.
One way to assess whether the extra flexibility is useful is to see if it is used in existing programs. A survey of a large set of Java libraries found that 39% of wildcard annotations could have been directly replaced by declaration-site annotations. Thus the remaining 61% is an indication of places where Java benefits from having the use-site system available.
In a declaration-site language, libraries must either expose less variance, or define more interfaces. For example, the Scala Collections library defines three separate interfaces for classes which employ covariance: a covariant base interface containing common methods, an invariant mutable version which adds side-effecting methods, and a covariant immutable version which may specialize the inherited implementations to exploit structural sharing. This design works well with declaration-site annotations, but the large number of interfaces carry a complexity cost for clients of the library. And modifying the library interface may not be an option—in particular, one goal when adding generics to Java was to maintain binary backwards compatibility.
On the other hand, Java wildcards are themselves complex. In a conference presentation Joshua Bloch criticized them as being too hard to understand and use, stating that when adding support for closures ""we simply cannot afford another wildcards"". Early versions of Scala used use-site variance annotations but programmers found them difficult to use in practice, while declaration-site annotations were found to be very helpful when designing classes. Later versions of Scala added Java-style existential types and wildcards; however, according to Martin Odersky, if there were no need for interoperability with Java then these would probably not have been included.Ross Tate argues that part of the complexity of Java wildcards is due to the decision to encode use-site variance using a form of existential types. The original proposals used special-purpose syntax for variance annotations, writing List<+Animal> instead of Java's more verbose List<? extends Animal>.
Since wildcards are a form of existential types they can be used for more things than just variance. A type like List<?> (""a list of unknown type"") lets objects be passed to methods or stored in fields without exactly specifying their type parameters. This is particularly valuable for classes such as Class where most of the methods do not mention the type parameter.
However, type inference for existential types is a difficult problem. For the compiler implementer, Java wildcards raise issues with type checker termination, type argument inference, and ambiguous programs. In general it is undecidable whether a Java program using generics is well-typed or not, so any type checker will have to go into an infinite loop or time out for some programs. For the programmer, it leads to complicated type error messages. Java type checks wildcard types by replacing the wildcards with fresh type variables (so-called capture conversion). This can make error messages harder to read, because they refer to type variables that the programmer did not directly write. For example, trying to add a Cat to a List<? extends Animal> will give an error like

method List.add (capture#1) is not applicable
  (actual argument Cat cannot be converted to capture#1 by method invocation conversion)
where capture#1 is a fresh type-variable:
  capture#1 extends Animal from capture of ? extends Animal

Since both declaration-site and use-site annotations can be useful, some type systems provide both.


== Etymology ==
These terms come from the notion of covariant and contravariant functors in category theory. Consider the category 
  
    
      
        C
      
    
    {\displaystyle C}
   whose objects are types and whose morphisms represent the subtype relationship  ≤. (This is an example of how any partially ordered set can be considered as a category.) Then for example the function type constructor takes two types p and r and creates a new type p → r; so it takes objects in 
  
    
      
        
          C
          
            2
          
        
      
    
    {\displaystyle C^{2}}
   to objects in 
  
    
      
        C
      
    
    {\displaystyle C}
  . By the subtyping rule for function types this operation reverses ≤ for the first parameter and preserves it for the second, so it is a contravariant functor in the first parameter and a covariant functor in the second.


== See also ==
Polymorphism (computer science)
Inheritance (computer science)
Liskov substitution principle


== References ==


== External links ==
Fabulous Adventures in Coding: An article series about implementation concerns surrounding co/contravariance in C#
Contra Vs Co Variance (note this article is not updated about C++)
Closures for the Java 7 Programming Language (v0.5)
The theory behind covariance and contravariance in C# 4"
0408f8b30f,Instance (computer science),"In a computer system, any time a new context is created based on some model, it is said that the model has been instantiated. In practice, this instance usually has a data structure in common with other instances, but the values stored in the instances are separate. Changing the values in one instance will then not interfere with the values of some other instance. A computer instance can be software state or hardware which can run a block code, for example a CPU, GPU or a virtual machine.


== Computer graphics ==
In computer graphics, a polygonal model can be instantiated in order to be drawn several times in different locations in a scene.
This is a technique that can be used to improve the performance of rendering, since the work needed to display each instance overlaps.


== Object-oriented programming ==
In object-oriented programming (OOP), an instance is a concrete occurrence of any object, existing usually during the runtime of a computer program. Formally, ""instance"" is synonymous with ""object"" as they are each a particular value (realization), and these may be called an instance object; ""instance"" emphasizes the distinct identity of the object. The creation of an instance is called instantiation.
An object may be varied in a number of ways. Each realized variation of that object is an instance of its class. That is, it is a member of a given class that has specified values rather than variables. In a non-programming context, you could think of ""dog"" as a type and your particular dog as an instance of that class.In class-based programming, objects are created as instances of classes by subroutines called constructors, and destroyed by destructors. An object is an instance of a class as it can access to all data types(primitive as well as non primitive), and methods etc, of a class. Therefore, objects may be called a class instances or class objects. Object instantiation is known as construction. Not all classes can be instantiated –  abstract classes cannot be instantiated, while classes that can be instantiated are called concrete classes. In prototype-based programming, instantiation is instead done by copying (cloning) a prototype instance.


== Operating systems ==
In the context of POSIX-oriented operating systems, the term ""(program) instance"" typically refers to any executing process instantiated from that  program (via system calls, e.g. fork() and exec()); that is, each executing process in the OS is an instance of some program which it has been instantiated from.


== References =="
fe29567b72,Boxing (computer science),"In computer science, boxing (a.k.a. wrapping) is the transformation of placing a primitive type within an object so that the value can be used as a reference. Unboxing is the reverse transformation of extracting the primitive value from its wrapper object. Autoboxing is the term for automatically applying boxing and/or unboxing transformations as needed.


== Boxing ==
Boxing's most prominent use is in Java where there is a distinction between reference and value types for reasons such as runtime efficiency and syntax and semantic issues. In Java, a LinkedList can only store values of type Object. One might desire to have a LinkedList of int, but this is not directly possible. Instead Java defines primitive wrapper classes corresponding to each primitive type: Integer and int, Character and char, Float and float, etc. One can then define a LinkedList using the boxed type Integer and insert int values into the list by boxing them as Integer objects. (Using generic parameterized types introduced in J2SE 5.0, this type is represented as LinkedList<Integer>.)
On the other hand, C# has no primitive wrapper classes, but allows boxing of any value type, returning a generic Object reference. In Objective-C, any primitive value can be prefixed by a @ to make an NSNumber out of it (e.g. @123 or @(123)). This allows for adding them in any of the standard collections, such as an NSArray.
Haskell has little or no notion of reference type, but still uses the term ""boxed"" for the runtime system's uniform pointer-to-tagged union representation.The boxed object is always a copy of the value object, and is usually immutable. Unboxing the object also returns a copy of the stored value. Repeated boxing and unboxing of objects can have a severe performance impact, because boxing dynamically allocates new objects and unboxing (if the boxed value is no longer used) then makes them eligible for garbage collection. However, modern garbage collectors such as the default Java HotSpot garbage collector can more efficiently collect short-lived objects, so if the boxed objects are short-lived, the performance impact may not be severe.
In some languages, there is a direct equivalence between an unboxed primitive type and a reference to an immutable, boxed object type. In fact, it is possible to substitute all the primitive types in a program with boxed object types. Whereas assignment from one primitive to another will copy its value, assignment from one reference to a boxed object to another will copy the reference value to refer to the same object as the first reference. However, this will not cause any problems, because the objects are immutable, so there is semantically no real difference between two references to the same object or to different objects (unless you look at physical equality). For all operations other than assignment, such as arithmetic, comparison, and logical operators, one can unbox the boxed type, perform the operation, and re-box the result as needed. Thus, it is possible to not store primitive types at all.


== Autoboxing ==
Autoboxing is the term for getting a reference type out of a value type just through type conversion (either implicit or explicit). The compiler automatically supplies the extra source code that creates the object.
For example, in versions of Java prior to J2SE 5.0, the following code did not compile:

Compilers prior to 5.0 would not accept the last line. Integer are reference objects, on the surface no different from List, Object, and so forth. To convert from an int to an Integer, one had to ""manually"" instantiate the Integer object. As of J2SE 5.0, the compiler will accept the last line, and automatically transform it so that an Integer object is created to store the value 9. This means that, from J2SE 5.0 on, something like Integer c = a + b, where a and b are Integer themselves, will compile now - a and b are unboxed, the integer values summed up, and the result is autoboxed into a new Integer, which is finally stored inside variable c. The equality operators cannot be used this way, because the equality operators are already defined for reference types, for equality of the references; to test for equality of the value in a boxed type, one must still manually unbox them and compare the primitives, or use the Objects.equals method.
Another example: J2SE 5.0 allows the programmer to treat a collection (such as a LinkedList) as if it contained int values instead of Integer objects. This does not contradict what was said above: the collection still only contains references to dynamic objects, and it cannot list primitive types. It cannot be a LinkedList<int>, but it must be a LinkedList<Integer> instead. However, the compiler automatically transforms the code so that the list will ""silently"" receive objects, while the source code only mentions primitive values. For example, the programmer can now write list.add(3) and think as if the int 3 were added to the list; but, the compiler will have actually transformed the line into list.add(new Integer(3)).


=== Automatic unboxing ===
With automatic unboxing the compiler automatically supplies the extra source code that retrieves the value out of that object, either by invoking some method on that object, or by other means.
For example, in versions of Java prior to J2SE 5.0, the following code did not compile:

C# doesn't support automatic unboxing in the same meaning as Java, because it doesn't have a separate set of primitive types and object types. All types that have both primitive and object version in Java, are automatically implemented by the C# compiler as either primitive (value) types or object (reference) types.
In both languages, automatic boxing does not downcast automatically, i.e. the following code won't compile:
C#:

Java:


== Type helpers ==
Modern Object Pascal has yet another way to perform operations on simple types, close to boxing, called type helpers in FreePascal or record helpers in Delphi and FreePascal in Delphi mode.
The dialects mentioned are Object Pascal compile-to-native languages, and so miss some of the features that C# and Java can implement. Notably run-time type inference on strongly typed variables.
But the feature is related to boxing.
It allows the programmer to use constructs like


== References =="
2cdad583f8,Input (computer science),"In computer science, the general meaning of input is to provide or give something to the computer, in other words, when a computer or device is receiving a command or signal from outer sources, the event is referred to as input to the device.
Some computer devices can also be categorized as input devices  because we use these devices to send instructions to the computer, some common examples of computer input devices are:

Mouse
Keyboard
Touchscreen
Microphone
Webcam
Softcam
Touchpad
Trackpad
Image scanner
TrackballAlso some internal components of computer are input components to other components, like the power-on button of a computer is an input component for the processor or the power supply, because it takes user input and sends it to other components for further processing.
In many computer languages the keyword ""input"" is used as a special keyword or function, such as in Visual Basic or Python. The command ""input"" is used to give the machine the data it has to process.


== See also ==
Input method
Input device
Input/output


== References =="
389ff88cce,Reification (computer science),"Reification is the process by which an abstract idea about a computer program is turned into an explicit data model or other object created in a programming language. A computable/addressable object—a resource—is created in a system as a proxy for a non computable/addressable object. By means of reification, something that was previously implicit, unexpressed, and possibly inexpressible is explicitly formulated and made available to conceptual (logical or computational) manipulation. Informally, reification is often referred to as ""making something a first-class citizen"" within the scope of a particular system. Some aspect of a system can be reified at language design time, which is related to reflection in programming languages. It can be applied as a stepwise refinement at system design time. Reification is one of the most frequently used techniques of conceptual analysis and knowledge representation.


== Reflective programming languages ==
In the context of programming languages, reification is the process by which a user program or any aspect of a programming language that was implicit in the translated program and the run-time system, are  expressed in the language itself. This process makes it available to the program, which can inspect all these aspects as ordinary data. In reflective languages, reification data is causally connected to the related reified aspect such that a modification to one of them affects the other. Therefore, the reification data is always a faithful representation of the related reified aspect. Reification data is often said to be made a first class object. Reification, at least partially, has been experienced in many languages to date: in early Lisp dialects and in current  Prolog dialects, programs have been treated as data, although the causal connection has often been left to the responsibility of the programmer. In Smalltalk-80, the compiler from the source text to bytecode has been part of the run-time system since the very first implementations of the language.
The C programming language reifies the low-level detail of memory addresses.Many programming language designs encapsulate the details of memory allocation in the compiler and the run-time system. In the design of the C programming language, the memory address is reified and is available for direct manipulation by other language constructs. For example, the following code may be used when implementing a memory-mapped device driver. The buffer pointer is a proxy for the memory address 0xB8000000.
Functional programming languages based on lambda-calculus reify the concept of a procedure abstraction and procedure application in the form of the Lambda expression.
The Scheme programming language reifies continuations (approximately, the call stack).
In C#, reification is used to make parametric polymorphism implemented in the form of generics as a first-class feature of the language.
In the Java programming language, there exist ""reifiable types"" that are ""completely available at run time"" (i.e. their information is not erased during compilation).
REBOL reifies code as data and vice versa.
Many languages, such as Lisp, JavaScript, and Curl, provide an eval or evaluate procedure that effectively reifies the language interpreter.
The Logtalk framework for Prolog offers a means to explore reification in the context of logic programming.
Smalltalk and Actor languages permit the reification of blocks and messages, which are equivalent of lambda expressions in Lisp, and thisContext in Smallltalk, which is a reification of the current executing block.
Homoiconic languages reify the syntax of the language itself in the form of an abstract syntax tree, typically together with eval.


== Data reification vs. data refinement ==
Data reification (stepwise refinement) involves finding a more concrete representation of the abstract data types used in a formal specification.
Data reification is the terminology of the Vienna Development Method (VDM) that most other people would call data refinement. An example is taking a step towards an implementation by replacing a data representation without a counterpart in the intended implementation language, such as sets, by one that does have a counterpart (such as maps with fixed domains that can be implemented by arrays), or at least one that is closer to having a counterpart, such as sequences. The VDM community prefers the word ""reification"" over ""refinement"", as the process has more to do with concretising an idea than with refining it.For similar usages, see Reification (linguistics).


== In conceptual modeling ==
Reification is widely used in conceptual modeling. Reifying a relationship means viewing it as an entity. The purpose of reifying a relationship is to make it explicit, when additional information needs to be added to it. Consider the relationship type IsMemberOf(member:Person, Committee). An instance of IsMemberOf is a relationship that represents the fact that a person is a member of a committee. The figure below shows an example population of IsMemberOf relationship in tabular form. Person P1 is a member of committees C1 and C2. Person P2 is a member of committee C1 only. 
The same fact, however, could also be viewed as an entity. Viewing a relationship as an entity, one can say that the entity reifies the relationship. This is called reification of a relationship. Like any other entity, it must be an instance of an entity type. In the present example, the entity type has been named Membership. For each instance of IsMemberOf, there is one and only one instance of Membership, and vice versa. Now, it becomes possible to add more information to the original relationship. As an example, we can express the fact that ""person p1 was nominated to be the member of committee c1 by person p2"". Reified relationship Membership can be used as the source of a new relationship IsNominatedBy(Membership, Person).
For related usages see Reification (knowledge representation).


== In Unified Modeling Language (UML) ==
 UML provides an association class construct for defining reified relationship types. The association class is a single model element that is both a kind of association and a kind of a class. The association and the entity type that reifies are both the same model element. Note that attributes cannot be reified.


== On Semantic Web ==


=== RDF and OWL ===
In Semantic Web languages, such as Resource Description Framework (RDF) and Web Ontology Language (OWL), a statement is a binary relation. It is used to link two individuals or an individual and a value. Applications sometimes need to describe other RDF statements, for instance, to record information like when statements were made, or who made them, which is sometimes called ""provenance"" information. As an example, we may want to represent properties of a relation, such as our certainty about it, severity or strength of a relation, relevance of a relation, and so on.
The example from the conceptual modeling section describes a particular person with URIref person:p1, who is a member of the committee:c1. The RDF triple from that description is

Consider to store two further facts: (i) to record who nominated this particular person to this committee (a statement about the membership itself), and (ii) to record who added the fact to the database (a statement about the statement).
The first case is a case of classical reification like above in UML: reify the membership and store its attributes and roles etc.:

Additionally, RDF provides a built-in vocabulary intended for describing RDF statements. A description of a statement using this vocabulary is called a reification of the statement. The RDF reification vocabulary consists of the type rdf:Statement, and the properties rdf:subject, rdf:predicate, and rdf:object.Using the reification vocabulary, a reification of the statement about the person's membership would be given by assigning the statement a URIref such as committee:membership12345 so that describing statements can be written as follows:

These statements say that the resource identified by the URIref committee:membership12345Stat is an RDF statement, that the subject of the statement refers to the resource identified by person:p1, the predicate of the statement refers to the resource identified by committee:isMemberOf, and the object of the statement refers to the resource committee:c1. Assuming that the original statement is actually identified by committee:membership12345, it should be clear by comparing the original statement with the reification that the reification actually does describe it. The conventional use of the RDF reification vocabulary always involves describing a statement using four statements in this pattern. Therefore, they are sometimes referred to as the ""reification quad"".Using reification according to this convention, we could record the fact that person:p3 added the statement to the
database by

It is important to note that in the conventional use of reification, the subject of the reification triples is assumed to identify a particular instance  of a triple in a particular RDF document, rather than some arbitrary triple having the same subject, predicate, and object. This particular convention is used because reification is intended for expressing properties such as dates of composition and source information, as in the examples given already, and these properties need to be applied to specific instances of triples. 
Note that the described triple (subject predicate object) itself is not implied by such a reification quad (and it is not necessary that it actually exists in the database). This allows also to use this mechanism to express which triples do not hold.
The power of the reification vocabulary in RDF is restricted by the lack of a built-in means for assigning URIrefs to statements, so in order to express ""provenance"" information of this kind in RDF, one has to use some mechanism (outside of RDF) to assign URIs to individual RDF statements, then make further statements about those individual statements, using their URIs to identify them.


=== In Topic Maps ===
In an XML Topic Map (XTM), only a topic can have a name or play a role in an association. One may use an association to make an assertion about a topic, but one cannot directly make assertions about that assertion. However, it is possible to create a topic that reifies a non-topic construct in a map, thus enabling the association to be named and treated as a topic itself.


=== n-ary relations ===
In Semantic Web languages, such as RDF and OWL, a property is a binary relation used to link two individuals or an individual and a value. However, in some cases, the natural and convenient way to represent certain concepts is to use relations to link an individual to more than just one individual or value. These relations are called n-ary relations. Examples are representing relations among multiple individuals, such as a committee, a person who is a committee member and another person who has nominated the first person to become the committee member, or a buyer, a seller, and an object that was bought when describing a purchase of a book.
A more general approach to reification is to create an explicit new class and n new properties to represent an n-ary relation, making an instance of the relation linking the n individuals an instance of this class. This approach can also be used to represent provenance information and other properties for an individual relation instance.


=== Vs. quotation ===
It is also important to note that the reification described here is not the same as ""quotation"" found in other languages. Instead, the reification describes the relationship between a particular instance of a triple and the resources the triple refers to. The reification can be read intuitively as saying ""this RDF triple talks about these things"", rather than (as in quotation) ""this RDF triple has this form."" For instance, in the reification example used in this section, the triple:

describing the rdf:subject of the original statement says that the subject of the statement is the resource (the person) identified by the URIref person:p1. It does not state that the subject of the statement is the URIref itself (i.e., a string beginning with certain characters), as quotation would.


== See also ==

Denotational semantics
Formal semantics of programming languages
Meta-circular evaluator
Metamodeling
Metaobject
Metaprogramming
Normalization by evaluation
Operational semantics
Reflection (computer science)
Resource Description Framework
Self-interpreter
Topic Maps


== References =="
d7cad0da35,Expression (computer science),"In computer science, an expression is a syntactic entity in a programming language that may be evaluated to determine its value. It is a combination of one or more constants, variables, functions, and operators that the programming language interprets (according to its particular rules of precedence and of association) and computes to produce (""to return"", in a stateful environment) another value. This process, for mathematical expressions, is called evaluation.
In simple settings, the resulting value is usually one of various primitive types, such as numerical, string, boolean, complex data type or other types.
Expression is often contrasted with statement—a syntactic entity that has no value (an instruction).


== Examples ==
For example, 2 + 3 is both an arithmetic and programming expression, which evaluates to 5. A variable is an expression because it denotes a value in memory, so y + 6 is also an expression. An example of a relational expression is 4 ≠ 4, which evaluates to false.


== Void as a result type ==
In C and most C-derived languages, a call to a function with a void return type is a valid expression, of type void.
Values of type void cannot be used, so the value of such an expression is always thrown away.


== Side effects and elimination ==
In many programming languages a function, and hence an expression containing a function, may have side effects. An expression with side effects does not normally have the property of referential transparency. In many languages (e.g. C++), expressions may be ended with a semicolon (;) to turn the expression into an expression statement.  This asks the implementation to evaluate the expression for its side-effects only and to disregard the result of the expression (e.g. x+1;) unless it is a part of an expression statement that induces side-effects (e.g. y=x+1; or func1(func2());).


=== Caveats ===
Note that the formal notion of a side effect is a change to the abstract state of the running program.
Another class of side effects are changes to the concrete state of the computational system, such as loading data into cache memories.  Languages that are often described as ""side effect–free"" will generally still have concrete side effects that can be exploited, for example, in side-channel attacks.
Furthermore, the elapsed time evaluating an expression (even one with no other apparent side effects), is sometimes essential to the correct operation of a system, as behaviour in time is easily visible from outside the evaluation environment by other parts of the system with which it interacts, and might even be regarded as the primary effect such as when performing benchmark testing.
It depends on the particular programming language specification whether an expression with no abstract side effects can legally be eliminated from the execution path by the processing environment in which the expression is evaluated.


== See also ==
Statement (computer science) (contrast)
Boolean expression
Expression (mathematics)
Evaluation strategy


== References ==


== External links ==
This article is based on material taken from Expression at the Free On-line Dictionary of Computing  prior to 1 November 2008 and incorporated under the ""relicensing"" terms of the GFDL, version 1.3 or later."
0957e6b9c8,Precision (computer science),"In computer science, the precision of a numerical quantity is a measure of the detail in which the quantity is expressed.  This is usually measured in bits, but sometimes in decimal digits. It is related to precision in mathematics, which describes the number of digits that are used to express a value.
Some of the standardized precision formats are 

Half-precision floating-point format
Single-precision floating-point format
Double-precision floating-point format
Quadruple-precision floating-point format
Octuple-precision floating-point formatOf these, octuple-precision format is rarely used. The single- and double-precision formats are most widely used and supported on nearly all platforms. The use of half-precision format has been increasing especially in the field of machine learning since many machine learning algorithms are inherently error-tolerant.


== Rounding error ==

Precision is often the source of rounding errors in computation. The number of bits used to store a number will often cause some loss of accuracy. An example would be to store ""sin(0.1)"" in IEEE single precision floating point standard. The error is then often magnified as subsequent computations are made using the data (although it can also be reduced).


== See also ==
Arbitrary-precision arithmetic
Extended precision
IEEE754 (IEEE floating point standard)
Integer (computer science)
Significant figures
Truncation
Approximate computing


== References =="
924645b3e3,Computer,"A computer is a machine that can be programmed to carry out sequences of arithmetic or logical operations (computation) automatically. Modern digital electronic computers can perform generic sets of operations known as programs. These programs enable computers to perform a wide range of tasks. A computer system is a nominally complete computer that includes the hardware, operating system (main software), and peripheral equipment needed and used for full operation. This term may also refer to a group of computers that are linked and function together, such as a computer network or computer cluster.
A broad range of industrial and consumer products use computers as control systems. Simple special-purpose devices like microwave ovens and remote controls are included, as are factory devices like industrial robots and computer-aided design, as well as general-purpose devices like personal computers and mobile devices like smartphones. Computers power the Internet, which links billions of other computers and users.
Early computers were meant to be used only for calculations. Simple manual instruments like the abacus have aided people in doing calculations since ancient times. Early in the Industrial Revolution, some mechanical devices were built to automate long, tedious tasks, such as guiding patterns for looms. More sophisticated electrical machines did specialized analog calculations in the early 20th century. The first digital electronic calculating machines were developed during World War II. The first semiconductor transistors in the late 1940s were followed by the silicon-based MOSFET (MOS transistor) and monolithic integrated circuit  chip technologies in the late 1950s, leading to the microprocessor and the microcomputer revolution in the 1970s. The speed, power and versatility of computers have been increasing dramatically ever since then, with transistor counts increasing at a rapid pace (as predicted by Moore's law), leading to the Digital Revolution during the late 20th to early 21st centuries.
Conventionally, a modern computer consists of at least one processing element, typically a central processing unit (CPU) in the form of a microprocessor, along with some type of computer memory, typically semiconductor memory chips. The processing element carries out arithmetic and logical operations, and a sequencing and control unit can change the order of operations in response to stored information. Peripheral devices include input devices (keyboards, mice, joystick, etc.), output devices (monitor screens, printers, etc.), and input/output devices that perform both functions (e.g., the 2000s-era touchscreen). Peripheral devices allow information to be retrieved from an external source and they enable the result of operations to be saved and retrieved.


== Etymology ==

According to the Oxford English Dictionary, the first known use of computer was in a 1613 book called The Yong Mans Gleanings by the English writer Richard Brathwait: ""I haue  [sic] read the truest computer of Times, and the best Arithmetician that euer  [sic] breathed, and he reduceth thy dayes into a short number."" This usage of the term referred to a human computer, a person who carried out calculations or computations. The word continued with the same meaning until the middle of the 20th century. During the latter part of this period women were often hired as computers because they could be paid less than their male counterparts. By 1943, most human computers were women.The Online Etymology Dictionary gives the first attested use of computer in the 1640s, meaning 'one who calculates'; this is an ""agent noun from compute (v.)"". The Online Etymology Dictionary states that the use of the term to mean ""'calculating machine' (of any type) is from 1897.""  The Online Etymology Dictionary indicates that the ""modern use"" of the term, to mean 'programmable digital electronic computer' dates from ""1945 under this name; [in a] theoretical [sense] from 1937, as Turing machine"".


== History ==


=== Pre-20th century ===

Devices have been used to aid computation for thousands of years, mostly using one-to-one correspondence with fingers. The earliest counting device was most likely a form of tally stick. Later record keeping aids throughout the Fertile Crescent included calculi (clay spheres, cones, etc.) which represented counts of items, likely livestock or grains, sealed in hollow unbaked clay containers. The use of counting rods is one example.

The abacus was initially used for arithmetic tasks. The Roman abacus was developed from devices used in Babylonia as early as 2400 BC. Since then, many other forms of reckoning boards or tables have been invented. In a medieval European counting house, a checkered cloth would be placed on a table, and markers moved around on it according to certain rules, as an aid to calculating sums of money.

The Antikythera mechanism is believed to be the earliest known mechanical analog computer, according to Derek J. de Solla Price. It was designed to calculate astronomical positions. It was discovered in 1901 in the Antikythera wreck off the Greek island of Antikythera, between Kythera and Crete, and has been dated to approximately c. 100 BC. Devices of comparable complexity to the Antikythera mechanism would not reappear until the fourteenth century.Many mechanical aids to calculation and measurement were constructed for astronomical and navigation use. The planisphere was a star chart invented by Abū Rayhān al-Bīrūnī in the early 11th century. The astrolabe was invented in the Hellenistic world in either the 1st or 2nd centuries BC and is often attributed to Hipparchus. A combination of the planisphere and dioptra, the astrolabe was effectively an analog computer capable of working out several different kinds of problems in spherical astronomy. An astrolabe incorporating a mechanical calendar computer and gear-wheels was invented by Abi Bakr of Isfahan, Persia in 1235. Abū Rayhān al-Bīrūnī invented the first mechanical geared lunisolar calendar astrolabe, an early fixed-wired knowledge processing machine with a gear train and gear-wheels, c. 1000 AD.
The sector, a calculating instrument used for solving problems in proportion, trigonometry, multiplication and division, and for various functions, such as squares and cube roots, was developed in the late 16th century and found application in gunnery, surveying and navigation.
The planimeter was a manual instrument to calculate the area of a closed figure by tracing over it with a mechanical linkage.

The slide rule was invented around 1620–1630 by the English clergyman William Oughtred, shortly after the publication of the concept of the logarithm. It is a hand-operated analog computer for doing multiplication and division. As slide rule development progressed, added scales provided reciprocals, squares and square roots, cubes and cube roots, as well as transcendental functions such as logarithms and exponentials, circular and hyperbolic trigonometry and other functions. Slide rules with special scales are still used for quick performance of routine calculations, such as the E6B circular slide rule used for time and distance calculations on light aircraft.
In the 1770s, Pierre Jaquet-Droz, a Swiss watchmaker, built a mechanical doll (automaton) that could write holding a quill pen. By switching the number and order of its internal wheels different letters, and hence different messages, could be produced. In effect, it could be mechanically ""programmed"" to read instructions. Along with two other complex machines, the doll is at the Musée d'Art et d'Histoire of Neuchâtel, Switzerland, and still operates.In 1831–1835, mathematician and engineer Giovanni Plana devised a Perpetual Calendar machine, which, through a system of pulleys and cylinders and over, could predict the perpetual calendar for every year from AD 0 (that is, 1 BC) to AD 4000, keeping track of leap years and varying day length. The tide-predicting machine invented by the Scottish scientist Sir William Thomson in 1872 was of great utility to navigation in shallow waters. It used a system of pulleys and wires to automatically calculate predicted tide levels for a set period at a particular location.
The differential analyser, a mechanical analog computer designed to solve differential equations by integration, used wheel-and-disc mechanisms to perform the integration. In 1876, Sir William Thomson had already discussed the possible construction of such calculators, but he had been stymied by the limited output torque of the ball-and-disk integrators. In a differential analyzer, the output of one integrator drove the input of the next integrator, or a graphing output. The torque amplifier was the advance that allowed these machines to work. Starting in the 1920s, Vannevar Bush and others developed mechanical differential analyzers.


=== First computer ===

Charles Babbage, an English mechanical engineer and polymath, originated the concept of a programmable computer. Considered the ""father of the computer"", he conceptualized and invented the first mechanical computer in the early 19th century. After working on his revolutionary difference engine, designed to aid in navigational calculations, in 1833 he realized that a much more general design, an Analytical Engine, was possible. The input of programs and data was to be provided to the machine via punched cards, a method being used at the time to direct mechanical looms such as the Jacquard loom. For output, the machine would have a printer, a curve plotter and a bell. The machine would also be able to punch numbers onto cards to be read in later. The Engine incorporated an arithmetic logic unit, control flow in the form of conditional branching and loops, and integrated memory, making it the first design for a general-purpose computer that could be described in modern terms as Turing-complete.The machine was about a century ahead of its time. All the parts for his machine had to be made by hand – this was a major problem for a device with thousands of parts. Eventually, the project was dissolved with the decision of the British Government to cease funding. Babbage's failure to complete the analytical engine can be chiefly attributed to political and financial difficulties as well as his desire to develop an increasingly sophisticated computer and to move ahead faster than anyone else could follow. Nevertheless, his son, Henry Babbage, completed a simplified version of the analytical engine's computing unit (the mill) in 1888. He gave a successful demonstration of its use in computing tables in 1906.


=== Analog computers ===

During the first half of the 20th century, many scientific computing needs were met by increasingly sophisticated analog computers, which used a direct mechanical or electrical model of the problem as a basis for computation. However, these were not programmable and generally lacked the versatility and accuracy of modern digital computers. The first modern analog computer was a tide-predicting machine, invented by Sir William Thomson (later to become Lord Kelvin) in 1872. The differential analyser, a mechanical analog computer designed to solve differential equations by integration using wheel-and-disc mechanisms, was conceptualized in 1876 by James Thomson, the elder brother of the more famous Sir William Thomson.The art of mechanical analog computing reached its zenith with the differential analyzer, built by H. L. Hazen and Vannevar Bush at MIT starting in 1927. This built on the mechanical integrators of James Thomson and the torque amplifiers invented by H. W. Nieman. A dozen of these devices were built before their obsolescence became obvious. By the 1950s, the success of digital electronic computers had spelled the end for most analog computing machines, but analog computers remained in use during the 1950s in some specialized applications such as education (slide rule) and aircraft (control systems).


=== Digital computers ===


==== Electromechanical ====
By 1938, the United States Navy had developed an electromechanical analog computer small enough to use aboard a submarine. This was the Torpedo Data Computer, which used trigonometry to solve the problem of firing a torpedo at a moving target. During World War II similar devices were developed in other countries as well.

Early digital computers were electromechanical; electric switches drove mechanical relays to perform the calculation. These devices had a low operating speed and were eventually superseded by much faster all-electric computers, originally using vacuum tubes. The Z2, created by German engineer Konrad Zuse in 1939 in Berlin, was one of the earliest examples of an electromechanical relay computer.

In 1941, Zuse followed his earlier machine up with the Z3, the world's first working electromechanical programmable, fully automatic digital computer. The Z3 was built with 2000 relays, implementing a 22 bit word length that operated at a clock frequency of about 5–10 Hz. Program code was supplied on punched film while data could be stored in 64 words of memory or supplied from the keyboard. It was quite similar to modern machines in some respects, pioneering numerous advances such as floating-point numbers. Rather than the harder-to-implement decimal system (used in Charles Babbage's earlier design), using a binary system meant that Zuse's machines were easier to build and potentially more reliable, given the technologies available at that time. The Z3 was not itself a universal computer but could be extended to be Turing complete.Zuse's next computer, the Z4, became the world's first commercial computer; after initial delay due to the Second World War, it was completed in 1950 and delivered to the ETH Zurich. The computer was manufactured by Zuse's own company, Zuse KG, which was founded in 1941 as the first company with the sole purpose of developing computers in Berlin.


==== Vacuum tubes and digital electronic circuits ====

Purely electronic circuit elements soon replaced their mechanical and electromechanical equivalents, at the same time that digital calculation replaced analog. The engineer Tommy Flowers, working at the Post Office Research Station in London in the 1930s, began to explore the possible use of electronics for the telephone exchange. Experimental equipment that he built in 1934 went into operation five years later, converting a portion of the telephone exchange network into an electronic data processing system, using thousands of vacuum tubes. In the US, John Vincent Atanasoff and Clifford E. Berry of Iowa State University developed and tested the Atanasoff–Berry Computer (ABC) in 1942, the first ""automatic electronic digital computer"". This design was also all-electronic and used about 300 vacuum tubes, with capacitors fixed in a mechanically rotating drum for memory.

During World War II, the British code-breakers at Bletchley Park achieved a number of successes at breaking encrypted German military communications. The German encryption machine, Enigma, was first attacked with the help of the electro-mechanical bombes which were often run by women. To crack the more sophisticated German Lorenz SZ 40/42 machine, used for high-level Army communications, Max Newman and his colleagues commissioned Flowers to build the Colossus. He spent eleven months from early February 1943 designing and building the first Colossus. After a functional test in December 1943, Colossus was shipped to Bletchley Park, where it was delivered on 18 January 1944 and attacked its first message on 5 February.Colossus was the world's first electronic digital programmable computer. It used a large number of valves (vacuum tubes). It had paper-tape input and was capable of being configured to perform a variety of boolean logical operations on its data, but it was not Turing-complete. Nine Mk II Colossi were built (The Mk I was converted to a Mk II making ten machines in total). Colossus Mark I contained 1,500 thermionic valves (tubes), but Mark II with 2,400 valves, was both five times faster and simpler to operate than Mark I, greatly speeding the decoding process.

The ENIAC (Electronic Numerical Integrator and Computer) was the first electronic programmable computer built in the U.S. Although the ENIAC was similar to the Colossus, it was much faster, more flexible, and it was Turing-complete. Like the Colossus, a ""program"" on the ENIAC was defined by the states of its patch cables and switches, a far cry from the stored program electronic machines that came later. Once a program was written, it had to be mechanically set into the machine with manual resetting of plugs and switches. The programmers of the ENIAC were six women, often known collectively as the ""ENIAC girls"".It combined the high speed of electronics with the ability to be programmed for many complex problems. It could add or subtract 5000 times a second, a thousand times faster than any other machine. It also had modules to multiply, divide, and square root. High speed memory was limited to 20 words (about 80 bytes). Built under the direction of John Mauchly and J. Presper Eckert at the University of Pennsylvania, ENIAC's development and construction lasted from 1943 to full operation at the end of 1945. The machine was huge, weighing 30 tons, using 200 kilowatts of electric power and contained over 18,000 vacuum tubes, 1,500 relays, and hundreds of thousands of resistors, capacitors, and inductors.


=== Modern computers ===


==== Concept of modern computer ====
The principle of the modern computer was proposed by Alan Turing in his seminal 1936 paper, On Computable Numbers. Turing proposed a simple device that he called ""Universal Computing machine"" and that is now known as a universal Turing machine. He proved that such a machine is capable of computing anything that is computable by executing instructions (program) stored on tape, allowing the machine to be programmable. The fundamental concept of Turing's design is the stored program, where all the instructions for computing are stored in memory. Von Neumann acknowledged that the central concept of the modern computer was due to this paper. Turing machines are to this day a central object of study in theory of computation. Except for the limitations imposed by their finite memory stores, modern computers are said to be Turing-complete, which is to say, they have algorithm execution capability equivalent to a universal Turing machine.


==== Stored programs ====

Early computing machines had fixed programs. Changing its function required the re-wiring and re-structuring of the machine. With the proposal of the stored-program computer this changed. A stored-program computer includes by design an instruction set and can store in memory a set of instructions (a program) that details the computation. The theoretical basis for the stored-program computer was laid out by Alan Turing in his 1936 paper. In 1945, Turing joined the National Physical Laboratory and began work on developing an electronic stored-program digital computer. His 1945 report ""Proposed Electronic Calculator"" was the first specification for such a device. John von Neumann at the University of Pennsylvania also circulated his First Draft of a Report on the EDVAC in 1945.The Manchester Baby was the world's first stored-program computer. It was built at the University of Manchester in England by Frederic C. Williams, Tom Kilburn and Geoff Tootill, and ran its first program on 21 June 1948. It was designed as a testbed for the Williams tube, the first random-access digital storage device. Although the computer was described as ""small and primitive"" by a 1998 retrospective, it was the first working machine to contain all of the elements essential to a modern electronic computer. As soon as the Baby had demonstrated the feasibility of its design, a project began at the university to develop it into a practically useful computer, the Manchester Mark 1.
The Mark 1 in turn quickly became the prototype for the Ferranti Mark 1, the world's first commercially available general-purpose computer. Built by Ferranti, it was delivered to the University of Manchester in February 1951. At least seven of these later machines were delivered between 1953 and 1957, one of them to Shell labs in Amsterdam. In October 1947 the directors of British catering company J. Lyons & Company decided to take an active role in promoting the commercial development of computers. Lyons's LEO I computer, modelled closely on the Cambridge EDSAC of 1949, became operational in April 1951 and ran the world's first routine office computer job.
Grace Hopper was the first to develop a compiler for a programming language.


==== Transistors ====

The concept of a field-effect transistor was proposed by Julius Edgar Lilienfeld in 1925. John Bardeen and Walter Brattain, while working under William Shockley at Bell Labs, built the first working transistor, the point-contact transistor, in 1947, which was followed by Shockley's bipolar junction transistor in 1948. From 1955 onwards, transistors replaced vacuum tubes in computer designs, giving rise to the ""second generation"" of computers. Compared to vacuum tubes, transistors have many advantages: they are smaller, and require less power than vacuum tubes, so give off less heat. Junction transistors were much more reliable than vacuum tubes and had longer, indefinite, service life. Transistorized computers could contain tens of thousands of binary logic circuits in a relatively compact space. However, early junction transistors were relatively bulky devices that were difficult to manufacture on a mass-production basis, which limited them to a number of specialised applications.At the University of Manchester, a team under the leadership of Tom Kilburn designed and built a machine using the newly developed transistors instead of valves. Their first transistorised computer and the first in the world, was operational by 1953, and a second version was completed there in April 1955. However, the machine did make use of valves to generate its 125 kHz clock waveforms and in the circuitry to read and write on its magnetic drum memory, so it was not the first completely transistorized computer. That distinction goes to the Harwell CADET of 1955, built by the electronics division of the Atomic Energy Research Establishment at Harwell.

The metal–oxide–silicon field-effect transistor (MOSFET), also known as the MOS transistor, was invented by Mohamed M. Atalla and Dawon Kahng at Bell Labs in 1959. It was the first truly compact transistor that could be miniaturised and mass-produced for a wide range of uses. With its high scalability, and much lower power consumption and higher density than bipolar junction transistors, the MOSFET made it possible to build high-density integrated circuits. In addition to data processing, it also enabled the practical use of MOS transistors as memory cell storage elements, leading to the development of MOS semiconductor memory, which replaced earlier magnetic-core memory in computers. The MOSFET led to the microcomputer revolution, and became the driving force behind the computer revolution. The MOSFET is the most widely used transistor in computers, and is the fundamental building block of digital electronics.


==== Integrated circuits ====

The next great advance in computing power came with the advent of the integrated circuit (IC).
The idea of the integrated circuit was first conceived by a radar scientist working for the Royal Radar Establishment of the Ministry of Defence, Geoffrey W.A. Dummer. Dummer presented the first public description of an integrated circuit at the Symposium on Progress in Quality Electronic Components in Washington, D.C. on 7 May 1952.The first working ICs were invented by Jack Kilby at Texas Instruments and Robert Noyce at Fairchild Semiconductor. Kilby recorded his initial ideas concerning the integrated circuit in July 1958, successfully demonstrating the first working integrated example on 12 September 1958. In his patent application of 6 February 1959, Kilby described his new device as ""a body of semiconductor material ... wherein all the components of the electronic circuit are completely integrated"". However, Kilby's invention was a hybrid integrated circuit (hybrid IC), rather than a monolithic integrated circuit (IC) chip. Kilby's IC had external wire connections, which made it difficult to mass-produce.Noyce also came up with his own idea of an integrated circuit half a year later than Kilby. Noyce's invention was the first true monolithic IC chip. His chip solved many practical problems that Kilby's had not. Produced at Fairchild Semiconductor, it was made of silicon, whereas Kilby's chip was made of germanium. Noyce's monolithic IC was fabricated using the planar process, developed by his colleague Jean Hoerni in early 1959. In turn, the planar process was based on Mohamed M. Atalla's work on semiconductor surface passivation by silicon dioxide in the late 1950s.Modern monolithic ICs are predominantly MOS (metal–oxide–semiconductor) integrated circuits, built from MOSFETs (MOS transistors). The earliest experimental MOS IC to be fabricated was a 16-transistor chip built by Fred Heiman and Steven Hofstein at RCA in 1962. General Microelectronics later introduced the first commercial MOS IC in 1964, developed by Robert Norman. Following the development of the self-aligned gate (silicon-gate) MOS transistor by Robert Kerwin, Donald Klein and John Sarace at Bell Labs in 1967, the first silicon-gate MOS IC with self-aligned gates was developed by Federico Faggin at Fairchild Semiconductor in 1968. The MOSFET has since become the most critical device component in modern ICs.The development of the MOS integrated circuit led to the invention of the microprocessor, and heralded an explosion in the commercial and personal use of computers. While the subject of exactly which device was the first microprocessor is contentious, partly due to lack of agreement on the exact definition of the term ""microprocessor"", it is largely undisputed that the first single-chip microprocessor was the Intel 4004, designed and realized by Federico Faggin with his silicon-gate MOS IC technology, along with Ted Hoff, Masatoshi Shima and Stanley Mazor at Intel. In the early 1970s, MOS IC technology enabled the integration of more than 10,000 transistors on a single chip.System on a Chip (SoCs) are complete computers on a microchip (or chip) the size of a coin. They may or may not have integrated RAM and flash memory. If not integrated, the RAM is usually placed directly above (known as Package on package) or below (on the opposite side of the circuit board) the SoC, and the flash memory is usually placed right next to the SoC, this all done to improve data transfer speeds, as the data signals don't have to travel long distances. Since ENIAC in 1945, computers have advanced enormously, with modern SoCs (Such as the Snapdragon 865) being the size of a coin while also being hundreds of thousands of times more powerful than ENIAC, integrating billions of transistors, and consuming only a few watts of power.


=== Mobile computers ===
The first mobile computers were heavy and ran from mains power. The 50 lb (23 kg) IBM 5100 was an early example. Later portables such as the Osborne 1 and Compaq Portable were considerably lighter but still needed to be plugged in. The first laptops, such as the Grid Compass, removed this requirement by incorporating batteries – and with the continued miniaturization of computing resources and advancements in portable battery life, portable computers grew in popularity in the 2000s. The same developments allowed manufacturers to integrate computing resources into cellular mobile phones by the early 2000s.
These smartphones and tablets run on a variety of operating systems and recently became the dominant computing device on the market. These are powered by System on a Chip (SoCs), which are complete computers on a microchip the size of a coin.


== Types ==

Computers can be classified in a number of different ways, including:


=== By architecture ===
Analog computer
Digital computer
Hybrid computer
Harvard architecture
Von Neumann architecture
Complex instruction set computer
Reduced instruction set computer


=== By size, form-factor and purpose ===
Supercomputer
Mainframe computer
Minicomputer (term no longer used), Midrange computer
Server
Rackmount server
Blade server
Tower server
Personal computer
Workstation
Microcomputer (term no longer used)Home computer (term fallen into disuse)
Desktop computer
Tower desktop
Slimline desktop
Multimedia computer (non-linear editing system computers, video editing PCs and the like, this term is no longer used)
Gaming computer
All-in-one PC
Nettop (Small form factor PCs, Mini PCs)
Home theater PC
Keyboard computer
Portable computer
Thin client
Internet appliance
Laptop
Desktop replacement computer
Gaming laptop
Rugged laptop
2-in-1 PC
Ultrabook
Chromebook
Subnotebook
Netbook
Mobile computers:
Tablet computer
Smartphone
Ultra-mobile PC
Pocket PC
Palmtop PC
Handheld PC
Wearable computer
Smartwatch
Smartglasses
Single-board computer
Plug computer
Stick PC
Programmable logic controller
Computer-on-module
System on module
System in a package
System-on-chip (Also known as an Application Processor or AP if it lacks circuitry such as radio circuitry)
Microcontroller


== Hardware ==

The term hardware covers all of those parts of a computer that are tangible physical objects. Circuits, computer chips, graphic cards, sound cards, memory (RAM), motherboard, displays, power supplies, cables, keyboards, printers and ""mice"" input devices are all hardware.


=== History of computing hardware ===


=== Other hardware topics ===
A general-purpose computer has four main components: the arithmetic logic unit (ALU), the control unit, the memory, and the input and output devices (collectively termed I/O). These parts are interconnected by buses, often made of groups of wires. Inside each of these parts are thousands to trillions of small electrical circuits which can be turned off or on by means of an electronic switch. Each circuit represents a bit (binary digit) of information so that when the circuit is on it represents a ""1"", and when off it represents a ""0"" (in positive logic representation). The circuits are arranged in logic gates so that one or more of the circuits may control the state of one or more of the other circuits.


=== Input devices ===
When unprocessed data is sent to the computer with the help of input devices, the data is processed and sent to output devices. The input devices may be hand-operated or automated. The act of processing is mainly regulated by the CPU. Some examples of input devices are:

Computer keyboard
Digital camera
Digital video
Graphics tablet
Image scanner
Joystick
Microphone
Mouse
Overlay keyboard
Real-time clock
Trackball
Touchscreen
Light pen


=== Output devices ===
The means through which computer gives output are known as output devices. Some examples of output devices are:

Computer monitor
Printer
PC speaker
Projector
Sound card
Video card


=== Control unit ===

The control unit (often called a control system or central controller) manages the computer's various components; it reads and interprets (decodes) the program instructions, transforming them into control signals that activate other parts of the computer. Control systems in advanced computers may change the order of execution of some instructions to improve performance.
A key component common to all CPUs is the program counter, a special memory cell (a register) that keeps track of which location in memory the next instruction is to be read from.The control system's function is as follows— this is a simplified description, and some of these steps may be performed concurrently or in a different order depending on the type of CPU:

Read the code for the next instruction from the cell indicated by the program counter.
Decode the numerical code for the instruction into a set of commands or signals for each of the other systems.
Increment the program counter so it points to the next instruction.
Read whatever data the instruction requires from cells in memory (or perhaps from an input device). The location of this required data is typically stored within the instruction code.
Provide the necessary data to an ALU or register.
If the instruction requires an ALU or specialized hardware to complete, instruct the hardware to perform the requested operation.
Write the result from the ALU back to a memory location or to a register or perhaps an output device.
Jump back to step (1).Since the program counter is (conceptually) just another set of memory cells, it can be changed by calculations done in the ALU. Adding 100 to the program counter would cause the next instruction to be read from a place 100 locations further down the program. Instructions that modify the program counter are often known as ""jumps"" and allow for loops (instructions that are repeated by the computer) and often conditional instruction execution (both examples of control flow).
The sequence of operations that the control unit goes through to process an instruction is in itself like a short computer program, and indeed, in some more complex CPU designs, there is another yet smaller computer called a microsequencer, which runs a microcode program that causes all of these events to happen.


=== Central processing unit (CPU) ===

The control unit, ALU, and registers are collectively known as a central processing unit (CPU). Early CPUs were composed of many separate components. Since the 1970s, CPUs have typically been constructed on a single MOS integrated circuit chip called a microprocessor.


=== Arithmetic logic unit (ALU) ===

The ALU is capable of performing two classes of operations: arithmetic and logic. The set of arithmetic operations that a particular ALU supports may be limited to addition and subtraction, or might include multiplication, division, trigonometry functions such as sine, cosine, etc., and square roots. Some can operate only on whole numbers (integers) while others use floating point to represent real numbers, albeit with limited precision. However, any computer that is capable of performing just the simplest operations can be programmed to break down the more complex operations into simple steps that it can perform. Therefore, any computer can be programmed to perform any arithmetic operation—although it will take more time to do so if its ALU does not directly support the operation. An ALU may also compare numbers and return Boolean truth values (true or false) depending on whether one is equal to, greater than or less than the other (""is 64 greater than 65?""). Logic operations involve Boolean logic: AND, OR, XOR, and NOT. These can be useful for creating complicated conditional statements and processing Boolean logic.
Superscalar computers may contain multiple ALUs, allowing them to process several instructions simultaneously. Graphics processors and computers with SIMD and MIMD features often contain ALUs that can perform arithmetic on vectors and matrices.


=== Memory ===

A computer's memory can be viewed as a list of cells into which numbers can be placed or read. Each cell has a numbered ""address"" and can store a single number. The computer can be instructed to ""put the number 123 into the cell numbered 1357"" or to ""add the number that is in cell 1357 to the number that is in cell 2468 and put the answer into cell 1595."" The information stored in memory may represent practically anything. Letters, numbers, even computer instructions can be placed into memory with equal ease. Since the CPU does not differentiate between different types of information, it is the software's responsibility to give significance to what the memory sees as nothing but a series of numbers.
In almost all modern computers, each memory cell is set up to store binary numbers in groups of eight bits (called a byte). Each byte is able to represent 256 different numbers (28 = 256); either from 0 to 255 or −128 to +127. To store larger numbers, several consecutive bytes may be used (typically, two, four or eight). When negative numbers are required, they are usually stored in two's complement notation. Other arrangements are possible, but are usually not seen outside of specialized applications or historical contexts. A computer can store any kind of information in memory if it can be represented numerically. Modern computers have billions or even trillions of bytes of memory.
The CPU contains a special set of memory cells called registers that can be read and written to much more rapidly than the main memory area. There are typically between two and one hundred registers depending on the type of CPU. Registers are used for the most frequently needed data items to avoid having to access main memory every time data is needed. As data is constantly being worked on, reducing the need to access main memory (which is often slow compared to the ALU and control units) greatly increases the computer's speed.
Computer main memory comes in two principal varieties:

random-access memory or RAM
read-only memory or ROMRAM can be read and written to anytime the CPU commands it, but ROM is preloaded with data and software that never changes, therefore the CPU can only read from it. ROM is typically used to store the computer's initial start-up instructions. In general, the contents of RAM are erased when the power to the computer is turned off, but ROM retains its data indefinitely. In a PC, the ROM contains a specialized program called the BIOS that orchestrates loading the computer's operating system from the hard disk drive into RAM whenever the computer is turned on or reset. In embedded computers, which frequently do not have disk drives, all of the required software may be stored in ROM. Software stored in ROM is often called firmware, because it is notionally more like hardware than software. Flash memory blurs the distinction between ROM and RAM, as it retains its data when turned off but is also rewritable. It is typically much slower than conventional ROM and RAM however, so its use is restricted to applications where high speed is unnecessary.In more sophisticated computers there may be one or more RAM cache memories, which are slower than registers but faster than main memory. Generally computers with this sort of cache are designed to move frequently needed data into the cache automatically, often without the need for any intervention on the programmer's part.


=== Input/output (I/O) ===

I/O is the means by which a computer exchanges information with the outside world. Devices that provide input or output to the computer are called peripherals. On a typical personal computer, peripherals include input devices like the keyboard and mouse, and output devices such as the display and printer. Hard disk drives, floppy disk drives and optical disc drives serve as both input and output devices. Computer networking is another form of I/O.
I/O devices are often complex computers in their own right, with their own CPU and memory. A graphics processing unit might contain fifty or more tiny computers that perform the calculations necessary to display 3D graphics. Modern desktop computers contain many smaller computers that assist the main CPU in performing I/O. A 2016-era flat screen display contains its own computer circuitry.


=== Multitasking ===

While a computer may be viewed as running one gigantic program stored in its main memory, in some systems it is necessary to give the appearance of running several programs simultaneously. This is achieved by multitasking i.e. having the computer switch rapidly between running each program in turn. One means by which this is done is with a special signal called an interrupt, which can periodically cause the computer to stop executing instructions where it was and do something else instead. By remembering where it was executing prior to the interrupt, the computer can return to that task later. If several programs are running ""at the same time"". then the interrupt generator might be causing several hundred interrupts per second, causing a program switch each time. Since modern computers typically execute instructions several orders of magnitude faster than human perception, it may appear that many programs are running at the same time even though only one is ever executing in any given instant. This method of multitasking is sometimes termed ""time-sharing"" since each program is allocated a ""slice"" of time in turn.Before the era of inexpensive computers, the principal use for multitasking was to allow many people to share the same computer. Seemingly, multitasking would cause a computer that is switching between several programs to run more slowly, in direct proportion to the number of programs it is running, but most programs spend much of their time waiting for slow input/output devices to complete their tasks. If a program is waiting for the user to click on the mouse or press a key on the keyboard, then it will not take a ""time slice"" until the event it is waiting for has occurred. This frees up time for other programs to execute so that many programs may be run simultaneously without unacceptable speed loss.


=== Multiprocessing ===

Some computers are designed to distribute their work across several CPUs in a multiprocessing configuration, a technique once employed in only large and powerful machines such as supercomputers, mainframe computers and servers. Multiprocessor and multi-core (multiple CPUs on a single integrated circuit) personal and laptop computers are now widely available, and are being increasingly used in lower-end markets as a result.
Supercomputers in particular often have highly unique architectures that differ significantly from the basic stored-program architecture and from general-purpose computers. They often feature thousands of CPUs, customized high-speed interconnects, and specialized computing hardware. Such designs tend to be useful for only specialized tasks due to the large scale of program organization required to use most of the available resources at once. Supercomputers usually see usage in large-scale simulation, graphics rendering, and cryptography applications, as well as with other so-called ""embarrassingly parallel"" tasks.


== Software ==

Software refers to parts of the computer which do not have a material form, such as programs, data, protocols, etc. Software is that part of a computer system that consists of encoded information or computer instructions, in contrast to the physical hardware from which the system is built. Computer software includes computer programs, libraries and related non-executable data, such as online documentation or digital media. It is often divided into system software and application software Computer hardware and software require each other and neither can be realistically used on its own. When software is stored in hardware that cannot easily be modified, such as with BIOS ROM in an IBM PC compatible computer, it is sometimes called ""firmware"".


=== Languages ===
There are thousands of different programming languages—some intended for general purpose, others useful for only highly specialized applications.


=== Programs ===
The defining feature of modern computers which distinguishes them from all other machines is that they can be programmed. That is to say that some type of instructions (the program) can be given to the computer, and it will process them. Modern computers based on the von Neumann architecture often have machine code in the form of an imperative programming language. In practical terms, a computer program may be just a few instructions or extend to many millions of instructions, as do the programs for word processors and web browsers for example. A typical modern computer can execute billions of instructions per second (gigaflops) and rarely makes a mistake over many years of operation. Large computer programs consisting of several million instructions may take teams of programmers years to write, and due to the complexity of the task almost certainly contain errors.


==== Stored program architecture ====

This section applies to most common RAM machine–based computers.
In most cases, computer instructions are simple: add one number to another, move some data from one location to another, send a message to some external device, etc. These instructions are read from the computer's memory and are generally carried out (executed) in the order they were given. However, there are usually specialized instructions to tell the computer to jump ahead or backwards to some other place in the program and to carry on executing from there. These are called ""jump"" instructions (or branches). Furthermore, jump instructions may be made to happen conditionally so that different sequences of instructions may be used depending on the result of some previous calculation or some external event. Many computers directly support subroutines by providing a type of jump that ""remembers"" the location it jumped from and another instruction to return to the instruction following that jump instruction.
Program execution might be likened to reading a book. While a person will normally read each word and line in sequence, they may at times jump back to an earlier place in the text or skip sections that are not of interest. Similarly, a computer may sometimes go back and repeat the instructions in some section of the program over and over again until some internal condition is met. This is called the flow of control within the program and it is what allows the computer to perform tasks repeatedly without human intervention.
Comparatively, a person using a pocket calculator can perform a basic arithmetic operation such as adding two numbers with just a few button presses. But to add together all of the numbers from 1 to 1,000 would take thousands of button presses and a lot of time, with a near certainty of making a mistake. On the other hand, a computer may be programmed to do this with just a few simple instructions. The following example is written in the MIPS assembly language:

Once told to run this program, the computer will perform the repetitive addition task without further human intervention. It will almost never make a mistake and a modern PC can complete the task in a fraction of a second.


==== Machine code ====
In most computers, individual instructions are stored as machine code with each instruction being given a unique number (its operation code or opcode for short). The command to add two numbers together would have one opcode; the command to multiply them would have a different opcode, and so on. The simplest computers are able to perform any of a handful of different instructions; the more complex computers have several hundred to choose from, each with a unique numerical code. Since the computer's memory is able to store numbers, it can also store the instruction codes. This leads to the important fact that entire programs (which are just lists of these instructions) can be represented as lists of numbers and can themselves be manipulated inside the computer in the same way as numeric data. The fundamental concept of storing programs in the computer's memory alongside the data they operate on is the crux of the von Neumann, or stored program, architecture. In some cases, a computer might store some or all of its program in memory that is kept separate from the data it operates on. This is called the Harvard architecture after the Harvard Mark I computer. Modern von Neumann computers display some traits of the Harvard architecture in their designs, such as in CPU caches.
While it is possible to write computer programs as long lists of numbers (machine language) and while this technique was used with many early computers, it is extremely tedious and potentially error-prone to do so in practice, especially for complicated programs. Instead, each basic instruction can be given a short name that is indicative of its function and easy to remember – a mnemonic such as ADD, SUB, MULT or JUMP. These mnemonics are collectively known as a computer's assembly language. Converting programs written in assembly language into something the computer can actually understand (machine language) is usually done by a computer program called an assembler.


==== Programming language ====

Programming languages provide various ways of specifying programs for computers to run. Unlike natural languages, programming languages are designed to permit no ambiguity and to be concise. They are purely written languages and are often difficult to read aloud. They are generally either translated into machine code by a compiler or an assembler before being run, or translated directly at run time by an interpreter. Sometimes programs are executed by a hybrid method of the two techniques.


===== Low-level languages =====

Machine languages and the assembly languages that represent them (collectively termed low-level programming languages) are generally unique to the particular architecture of a computer's central processing unit (CPU). For instance, an ARM architecture CPU (such as may be found in a smartphone or a hand-held videogame) cannot understand the machine language of an x86 CPU that might be in a PC. Historically a significant number of other cpu architectures were created and saw extensive use, notably including the MOS Technology 6502 and 6510 in addition to the Zilog Z80.


===== High-level languages =====

Although considerably easier than in machine language, writing long programs in assembly language is often difficult and is also error prone. Therefore, most practical programs are written in more abstract high-level programming languages that are able to express the needs of the programmer more conveniently (and thereby help reduce programmer error). High level languages are usually ""compiled"" into machine language (or sometimes into assembly language and then into machine language) using another computer program called a compiler. High level languages are less related to the workings of the target computer than assembly language, and more related to the language and structure of the problem(s) to be solved by the final program. It is therefore often possible to use different compilers to translate the same high level language program into the machine language of many different types of computer. This is part of the means by which software like video games may be made available for different computer architectures such as personal computers and various video game consoles.


==== Program design ====
Program design of small programs is relatively simple and involves the analysis of the problem, collection of inputs, using the programming constructs within languages, devising or using established procedures and algorithms, providing data for output devices and solutions to the problem as applicable. As problems become larger and more complex, features such as subprograms, modules, formal documentation, and new paradigms such as object-oriented programming are encountered. Large programs involving thousands of line of code and more require formal software methodologies. The task of developing large software systems presents a significant intellectual challenge. Producing software with an acceptably high reliability within a predictable schedule and budget has historically been difficult; the academic and professional discipline of software engineering concentrates specifically on this challenge.


==== Bugs ====

Errors in computer programs are called ""bugs"". They may be benign and not affect the usefulness of the program, or have only subtle effects. However, in some cases they may cause the program or the entire system to ""hang"", becoming unresponsive to input such as mouse clicks or keystrokes, to completely fail, or to crash. Otherwise benign bugs may sometimes be harnessed for malicious intent by an unscrupulous user writing an exploit, code designed to take advantage of a bug and disrupt a computer's proper execution. Bugs are usually not the fault of the computer. Since computers merely execute the instructions they are given, bugs are nearly always the result of programmer error or an oversight made in the program's design. Admiral Grace Hopper, an American computer scientist and developer of the first compiler, is credited for having first used the term ""bugs"" in computing after a dead moth was found shorting a relay in the Harvard Mark II computer in September 1947.


== Networking and the Internet ==

Computers have been used to coordinate information between multiple locations since the 1950s. The U.S. military's SAGE system was the first large-scale example of such a system, which led to a number of special-purpose commercial systems such as Sabre. In the 1970s, computer engineers at research institutions throughout the United States began to link their computers together using telecommunications technology. The effort was funded by ARPA (now DARPA), and the computer network that resulted was called the ARPANET. The technologies that made the Arpanet possible spread and evolved.
In time, the network spread beyond academic and military institutions and became known as the Internet. The emergence of networking involved a redefinition of the nature and boundaries of the computer. Computer operating systems and applications were modified to include the ability to define and access the resources of other computers on the network, such as peripheral devices, stored information, and the like, as extensions of the resources of an individual computer. Initially these facilities were available primarily to people working in high-tech environments, but in the 1990s the spread of applications like e-mail and the World Wide Web, combined with the development of cheap, fast networking technologies like Ethernet and ADSL saw computer networking become almost ubiquitous. In fact, the number of computers that are networked is growing phenomenally. A very large proportion of personal computers regularly connect to the Internet to communicate and receive information. ""Wireless"" networking, often utilizing mobile phone networks, has meant networking is becoming increasingly ubiquitous even in mobile computing environments.


== Unconventional computers ==

A computer does not need to be electronic, nor even have a processor, nor RAM, nor even a hard disk. While popular usage of the word ""computer"" is synonymous with a personal electronic computer, a typical modern definition of a computer is: ""A device that computes, especially a programmable [usually] electronic machine that performs high-speed mathematical or logical operations or that assembles, stores, correlates, or otherwise processes information."" According to this definition, any device that processes information qualifies as a computer.


== Future ==
There is active research to make computers out of many promising new types of technology, such as optical computers, DNA computers, neural computers, and quantum computers. Most computers are universal, and are able to calculate any computable function, and are limited only by their memory capacity and operating speed. However different designs of computers can give very different performance for particular problems; for example quantum computers can potentially break some modern encryption algorithms (by quantum factoring) very quickly.


=== Computer architecture paradigms ===
There are many types of computer architectures:

Quantum computer vs. Chemical computer
Scalar processor vs. Vector processor
Non-Uniform Memory Access (NUMA) computers
Register machine vs. Stack machine
Harvard architecture vs. von Neumann architecture
Cellular architectureOf all these abstract machines, a quantum computer holds the most promise for revolutionizing computing. Logic gates are a common abstraction which can apply to most of the above digital or analog paradigms. The ability to store and execute lists of instructions called programs makes computers extremely versatile, distinguishing them from calculators. The Church–Turing thesis is a mathematical statement of this versatility: any computer with a minimum capability (being Turing-complete) is, in principle, capable of performing the same tasks that any other computer can perform. Therefore, any type of computer (netbook, supercomputer, cellular automaton, etc.) is able to perform the same computational tasks, given enough time and storage capacity.


=== Artificial intelligence ===
A computer will solve problems in exactly the way it is programmed to, without regard to efficiency, alternative solutions, possible shortcuts, or possible errors in the code. Computer programs that learn and adapt are part of the emerging field of artificial intelligence and machine learning. Artificial intelligence based products generally fall into two major categories: rule-based systems and pattern recognition systems. Rule-based systems attempt to represent the rules used by human experts and tend to be expensive to develop. Pattern-based systems use data about a problem to generate conclusions. Examples of pattern-based systems include voice recognition, font recognition, translation and the emerging field of on-line marketing.


== Professions and organizations ==
As the use of computers has spread throughout society, there are an increasing number of careers involving computers.

The need for computers to work well together and to be able to exchange information has spawned the need for many standards organizations, clubs and societies of both a formal and informal nature.


== See also ==


== Notes ==


== References ==


== Sources ==


== External links ==
 Media related to Computers at Wikimedia Commons
 Wikiversity has a quiz on this article
Warhol & The Computer (by Chris Garcia) at CHM"
21e8d9df35,Kernel (operating system),"The kernel is a computer program at the core of a computer's operating system and generally has complete control over everything in the system. It is the portion of the operating system code that is always resident in memory and facilitates interactions between hardware and software components. A full kernel controls all hardware resources (e.g. I/O, memory, cryptography) via device drivers, arbitrates conflicts between processes concerning such resources, and optimizes the utilization of common resources e.g. CPU & cache usage, file systems, and network sockets. On most systems, the kernel is one of the first programs loaded on startup (after the bootloader). It handles the rest of startup as well as memory, peripherals, and input/output (I/O) requests from software, translating them into data-processing instructions for the central processing unit.
The critical code of the kernel is usually loaded into a separate area of memory, which is protected from access by application software or other less critical parts of the operating system. The kernel performs its tasks, such as running processes, managing hardware devices such as the hard disk, and handling interrupts, in this protected kernel space. In contrast, application programs such as browsers, word processors, or audio or video players  use a separate area of memory, user space. This separation prevents user data and kernel data from interfering with each other and causing instability and slowness, as well as preventing malfunctioning applications from affecting other applications or crashing the entire operating system. Even in systems where the kernel is included in application address spaces, memory protection is used to prevent unauthorized applications from modifying the kernel.
The kernel's interface is a low-level abstraction layer. When a process requests a service from the kernel, it must invoke a system call, usually through a wrapper function.
There are different kernel architecture designs. Monolithic kernels run entirely in a single address space with the CPU executing in supervisor mode, mainly for speed. Microkernels run most but not all of their services in user space, like user processes do, mainly for resilience and modularity. MINIX 3 is a notable example of microkernel design. Instead, the Linux kernel is monolithic, although it is also modular, for it can insert and remove loadable kernel modules at runtime.
This central component of a computer system is responsible for executing programs. The kernel takes responsibility for deciding at any time which of the many running programs should be allocated to the processor or processors.


== Random-access memory ==
Random-access memory (RAM) is used to store both program instructions and data. Typically, both need to be present in memory in order for a program to execute. Often multiple programs will want access to memory, frequently demanding more memory than the computer has available. The kernel is responsible for deciding which memory each process can use, and determining what to do when not enough memory is available.


== Input/output devices ==
I/O devices include such peripherals as keyboards, mice, disk drives, printers, USB devices, network adapters, and display devices. The kernel allocates requests from applications to perform I/O to an appropriate device and provides convenient methods for using the device (typically abstracted to the point where the application does not need to know implementation details of the device).


== Resource management ==
Key aspects necessary in resource management are defining the execution domain (address space) and the protection mechanism used to mediate access to the resources within a domain. Kernels also provide methods for synchronization and inter-process communication (IPC). These implementations may be located within the kernel itself or the kernel can also rely on other processes it is running. Although the kernel must provide IPC in order to provide access to the facilities provided by each other, kernels must also provide running programs with a method to make requests to access these facilities. The kernel is also responsible for context switching between processes or threads.


== Memory management ==

The kernel has full access to the system's memory and must allow processes to safely access this memory as they require it. Often the first step in doing this is virtual addressing, usually achieved by paging and/or segmentation. Virtual addressing allows the kernel to make a given physical address appear to be another address, the virtual address. Virtual address spaces may be different for different processes; the memory that one process accesses at a particular (virtual) address may be different memory from what another process accesses at the same address. This allows every program to behave as if it is the only one (apart from the kernel) running and thus prevents applications from crashing each other.On many systems, a program's virtual address may refer to data which is not currently in memory. The layer of indirection provided by virtual addressing allows the operating system to use other data stores, like a hard drive, to store what would otherwise have to remain in main memory (RAM). As a result, operating systems can allow programs to use more memory than the system has physically available. When a program needs data which is not currently in RAM, the CPU signals to the kernel that this has happened, and the kernel responds by writing the contents of an inactive memory block to disk (if necessary) and replacing it with the data requested by the program. The program can then be resumed from the point where it was stopped. This scheme is generally known as demand paging.
Virtual addressing also allows creation of virtual partitions of memory in two disjointed areas, one being reserved for the kernel (kernel space) and the other for the applications (user space). The applications are not permitted by the processor to address kernel memory, thus preventing an application from damaging the running kernel. This fundamental partition of memory space has contributed much to the current designs of actual general-purpose kernels and is almost universal in such systems, although some research kernels (e.g., Singularity) take other approaches.


== Device management ==
To perform useful functions, processes need access to the peripherals connected to the computer, which are controlled by the kernel through device drivers. A device driver is a computer program encapsulating, monitoring and controlling a hardware device (via its Hardware/Software Interface (HSI)) on behalf of the OS. It provides the operating system with an API, procedures and information about how to control and communicate with a certain piece of hardware. Device drivers are an important and vital dependency for all OS and their applications. The design goal of a driver is abstraction; the function of the driver is to translate the OS-mandated abstract function calls (programming calls) into device-specific calls. In theory, a device should work correctly with a suitable driver. Device drivers are used for e.g. video cards, sound cards, printers, scanners, modems, and Network cards.
At the hardware level, common abstractions of device drivers include:

Interfacing directly
Using a high-level interface (Video BIOS)
Using a lower-level device driver (file drivers using disk drivers)
Simulating work with hardware, while doing something entirely differentAnd at the software level, device driver abstractions include:

Allowing the operating system direct access to hardware resources
Only implementing primitives
Implementing an interface for non-driver software such as TWAIN
Implementing a language (often a high-level language such as PostScript)For example, to show the user something on the screen, an application would make a request to the kernel, which would forward the request to its display driver, which is then responsible for actually plotting the character/pixel.A kernel must maintain a list of available devices. This list may be known in advance (e.g., on an embedded system where the kernel will be rewritten if the available hardware changes), configured by the user (typical on older PCs and on systems that are not designed for personal use) or detected by the operating system at run time (normally called plug and play). In plug-and-play systems, a device manager first performs a scan on different peripheral buses, such as Peripheral Component Interconnect (PCI) or Universal Serial Bus (USB), to detect installed devices, then searches for the appropriate drivers.
As device management is a very OS-specific topic, these drivers are handled differently by each kind of kernel design, but in every case, the kernel has to provide the I/O to allow drivers to physically access their devices through some port or memory location. Important decisions have to be made when designing the device management system, as in some designs accesses may involve context switches, making the operation very CPU-intensive and easily causing a significant performance overhead.


== System calls ==

In computing, a system call is how a process requests a service from an operating system's kernel that it does not normally have permission to run. System calls provide the interface between a process and the operating system. Most operations interacting with the system require permissions not available to a user-level process, e.g., I/O performed with a device present on the system, or any form of communication with other processes requires the use of system calls.
A system call is a mechanism that is used by the application program to request a service from the operating system. They use a machine-code instruction that causes the processor to change mode. An example would be from supervisor mode to protected mode. This is where the operating system performs actions like accessing hardware devices or the memory management unit. Generally the operating system provides a library that sits between the operating system and normal user programs. Usually it is a C library such as Glibc or Windows API. The library handles the low-level details of passing information to the kernel and switching to supervisor mode. System calls include close, open, read, wait and write.
To actually perform useful work, a process must be able to access the services provided by the kernel. This is implemented differently by each kernel, but most provide a C library or an API, which in turn invokes the related kernel functions.The method of invoking the kernel function varies from kernel to kernel. If memory isolation is in use, it is impossible for a user process to call the kernel directly, because that would be a violation of the processor's access control rules. A few possibilities are:

Using a software-simulated interrupt. This method is available on most hardware, and is therefore very common.
Using a call gate. A call gate is a special address stored by the kernel in a list in kernel memory at a location known to the processor. When the processor detects a call to that address, it instead redirects to the target location without causing an access violation. This requires hardware support, but the hardware for it is quite common.
Using a special system call instruction. This technique requires special hardware support, which common architectures (notably, x86) may lack. System call instructions have been added to recent models of x86 processors, however, and some operating systems for PCs make use of them when available.
Using a memory-based queue. An application that makes large numbers of requests but does not need to wait for the result of each may add details of requests to an area of memory that the kernel periodically scans to find requests.


== Kernel design decisions ==


=== Protection ===
An important consideration in the design of a kernel is the support it provides for protection from faults (fault tolerance) and from malicious behaviours (security). These two aspects are usually not clearly distinguished, and the adoption of this distinction in the kernel design leads to the rejection of a hierarchical structure for protection.The mechanisms or policies provided by the kernel can be classified according to several criteria, including: static (enforced at compile time) or dynamic (enforced at run time); pre-emptive or post-detection; according to the protection principles they satisfy (e.g., Denning); whether they are hardware supported or language based;  whether they are more an open mechanism or a binding policy; and many more.
Support for hierarchical protection domains is typically implemented using CPU modes.
Many kernels provide implementation of ""capabilities"", i.e., objects that are provided to user code which allow limited access to an underlying object managed by the kernel. A common example is file handling: a file is a representation of information stored on a permanent storage device. The kernel may be able to perform many different operations, including read, write, delete or execute, but a user-level application may only be permitted to perform some of these operations (e.g., it may only be allowed to read the file).  A common implementation of this is for the kernel to provide an object to the application (typically so called a ""file handle"") which the application may then invoke operations on, the validity of which the kernel checks at the time the operation is requested. Such a system may be extended to cover all objects that the kernel manages, and indeed to objects provided by other user applications.
An efficient and simple way to provide hardware support of capabilities is to delegate to the memory management unit (MMU) the responsibility of checking access-rights for every memory access, a mechanism called capability-based addressing. Most commercial computer architectures lack such MMU support for capabilities.
An alternative approach is to simulate capabilities using commonly supported hierarchical domains. In this approach, each protected object must reside in an address space that the application does not have access to; the kernel also maintains a list of capabilities in such memory. When an application needs to access an object protected by a capability, it performs a system call and the kernel then checks whether the application's capability grants it permission to perform the requested action, and if it is permitted performs the access for it (either directly, or by delegating the request to another user-level process). The performance cost of address space switching limits the practicality of this approach in systems with complex interactions between objects, but it is used in current operating systems for objects that are not accessed frequently or which are not expected to perform quickly.If the firmware does not support protection mechanisms, it is possible to simulate protection at a higher level, for example by simulating capabilities by manipulating page tables, but there are performance implications. Lack of hardware support may not be an issue, however, for systems that choose to use language-based protection.An important kernel design decision is the choice of the abstraction levels where the security mechanisms and policies should be implemented. Kernel security mechanisms play a critical role in supporting security at higher levels.One approach is to use firmware and kernel support for fault tolerance (see above), and build the security policy for malicious behavior on top of that (adding features such as cryptography mechanisms where necessary), delegating some responsibility to the compiler. Approaches that delegate enforcement of security policy to the compiler and/or the application level are often called language-based security.
The lack of many critical security mechanisms in current mainstream operating systems impedes the implementation of adequate security policies at the application abstraction level. In fact, a common misconception in computer security is that any security policy can be implemented in an application regardless of kernel support.According to Mars Research Group developers, a lack of isolation is one of the main factors undermining kernel security. They propose their driver isolation framework for protection, primarily in the Linux kernel.


==== Hardware- or language-based protection ====
Typical computer systems today use hardware-enforced rules about what programs are allowed to access what data. The processor monitors the execution and stops a program that violates a rule, such as a user process that tries to write to kernel memory. In systems that lack support for capabilities, processes are isolated from each other by using separate address spaces. Calls from user processes into the kernel are regulated by requiring them to use one of the above-described system call methods.
An alternative approach is to use language-based protection. In a language-based protection system, the kernel will only allow code to execute that has been produced by a trusted language compiler. The language may then be designed such that it is impossible for the programmer to instruct it to do something that will violate a security requirement.Advantages of this approach include:

No need for separate address spaces. Switching between address spaces is a slow operation that causes a great deal of overhead, and a lot of optimization work is currently performed in order to prevent unnecessary switches in current operating systems. Switching is completely unnecessary in a language-based protection system, as all code can safely operate in the same address space.
Flexibility. Any protection scheme that can be designed to be expressed via a programming language can be implemented using this method. Changes to the protection scheme (e.g. from a hierarchical system to a capability-based one) do not require new hardware.Disadvantages include:

Longer application startup time. Applications must be verified when they are started to ensure they have been compiled by the correct compiler, or may need recompiling either from source code or from bytecode.
Inflexible type systems. On traditional systems, applications frequently perform operations that are not type safe. Such operations cannot be permitted in a language-based protection system, which means that applications may need to be rewritten and may, in some cases, lose performance.Examples of systems with language-based protection include JX and Microsoft's Singularity.


=== Process cooperation ===
Edsger Dijkstra proved that from a logical point of view, atomic lock and unlock operations operating on binary semaphores are sufficient primitives to express any functionality of process cooperation. However this approach is generally held to be lacking in terms of safety and efficiency, whereas a message passing approach is more flexible.  A number of other approaches (either lower- or higher-level) are available as well, with many modern kernels providing support for systems such as shared memory and remote procedure calls.


=== I/O device management ===
The idea of a kernel where I/O devices are handled uniformly with other processes, as parallel co-operating processes, was first proposed and implemented by Brinch Hansen (although similar ideas were suggested in 1967). In Hansen's description of this, the ""common"" processes are called internal processes, while the I/O devices are called external processes.Similar to physical memory, allowing applications direct access to controller ports and registers can cause the controller to malfunction, or system to crash. With this, depending on the complexity of the device, some devices can get surprisingly complex to program, and use several different controllers. Because of this, providing a more abstract interface to manage the device is important. This interface is normally done by a device driver or hardware abstraction layer. Frequently, applications will require access to these devices. The kernel must maintain the list of these devices by querying the system for them in some way. This can be done through the BIOS, or through one of the various system buses (such as PCI/PCIE, or USB). Using an example of a video driver, when an application requests an operation on a device, such as displaying a character, the kernel needs to send this request to the current active video driver. The video driver, in turn, needs to carry out this request. This is an example of inter-process communication (IPC).


== Kernel-wide design approaches ==
The above listed tasks and features can be provided in many ways that differ from each other in design and implementation.
The principle of separation of mechanism and policy is the substantial difference between the philosophy of micro and monolithic kernels. Here a mechanism is the support that allows the implementation of many different policies, while a policy is a particular ""mode of operation"". Example:  

Mechanism: User login attempts are routed to an authorization server
Policy: Authorization server requires a password which is verified against stored passwords in a databaseBecause the mechanism and policy are separated, the policy can be easily changed to e.g. require the use of a security token.
In minimal microkernel just some very basic policies are included, and its mechanisms allows what is running on top of the kernel (the remaining part of the operating system and the other applications) to decide which policies to adopt (as memory management, high level process scheduling, file system management, etc.). A monolithic kernel instead tends to include many policies, therefore restricting the rest of the system to rely on them.
Per Brinch Hansen presented arguments in favour of separation of mechanism and policy. The failure to properly fulfill this separation is one of the major causes of the lack of substantial innovation in existing operating systems, a problem common in computer architecture. The monolithic design is induced by the ""kernel mode""/""user mode"" architectural approach to protection (technically called hierarchical protection domains), which is common in conventional commercial systems; in fact, every module needing protection is therefore preferably included into the kernel. This link between monolithic design and ""privileged mode"" can be reconducted to the key issue of mechanism-policy separation; in fact the ""privileged mode"" architectural approach melds together the protection mechanism with the security policies, while the major alternative architectural approach, capability-based addressing, clearly distinguishes between the two, leading naturally to a microkernel design (see Separation of protection and security).
While monolithic kernels execute all of their code in the same address space (kernel space), microkernels try to run most of their services in user space, aiming to improve maintainability and modularity of the codebase. Most kernels do not fit exactly into one of these categories, but are rather found in between these two designs. These are called hybrid kernels. More exotic designs such as nanokernels and exokernels are available, but are seldom used for production systems. The Xen hypervisor, for example, is an exokernel.


=== Monolithic kernels ===

In a monolithic kernel, all OS services run along with the main kernel thread, thus also residing in the same memory area. This approach provides rich and powerful hardware access. UNIX developer Ken Thompson stated that ""it is in [his] opinion easier to implement a
monolithic kernel"". The main disadvantages of monolithic kernels are the dependencies between system components –  a bug in a device driver might crash the entire system –  and the fact that large kernels can become very difficult to maintain; Thompson also stated that ""It is also easier for [a monolithic kernel] to turn into a mess in a hurry as it is modified.""Monolithic kernels, which have traditionally been used by Unix-like operating systems, contain all the operating system core functions and the device drivers. A monolithic kernel is one single program that contains all of the code necessary to perform every kernel-related task. Every part which is to be accessed by most programs which cannot be put in a library is in the kernel space: Device drivers, scheduler, memory handling, file systems, and network stacks. Many system calls are provided to applications, to allow them to access all those services. A monolithic kernel, while initially loaded with subsystems that may not be needed, can be tuned to a point where it is as fast as or faster than the one that was specifically designed for the hardware, although more relevant in a general sense.
Modern monolithic kernels, such as the Linux kernel, the FreeBSD kernel, the AIX kernel, the HP-UX kernel, and the Solaris kernel, all of which fall into the category of Unix-like operating systems, support loadable kernel modules, allowing modules to be loaded into the kernel at runtime, permitting easy extension of the kernel's capabilities as required, while helping to minimize the amount of code running in kernel space.
Most work in the monolithic kernel is done via system calls. These are interfaces, usually kept in a tabular structure, that access some subsystem within the kernel such as disk operations. Essentially calls are made within programs and a checked copy of the request is passed through the system call. Hence, not far to travel at all. The monolithic Linux kernel can be made extremely small not only because of its ability to dynamically load modules but also because of its ease of customization. In fact, there are some versions that are small enough to fit together with a large number of utilities and other programs on a
single floppy disk and still provide a fully functional operating system (one of the most popular of which is muLinux). This ability to miniaturize its kernel has also led to a rapid growth in the use of Linux in embedded systems.
These types of kernels consist of the core functions of the operating system and the device drivers with the ability to load modules at runtime. They provide rich and powerful abstractions of the underlying hardware. They provide a small set of simple hardware abstractions and use applications called servers to provide more functionality. This particular approach defines a high-level virtual interface over the hardware, with a set of system calls to implement operating system services such as process management, concurrency and memory management in several modules that run in supervisor mode.
This design has several flaws and limitations:

Coding in kernel can be challenging, in part because one cannot use common libraries (like a full-featured libc), and because one needs to use a source-level debugger like gdb.  Rebooting the computer is often required. This is not just a problem of convenience to the developers. When debugging is harder, and as difficulties become stronger, it becomes more likely that code will be ""buggier"".
Bugs in one part of the kernel have strong side effects; since every function in the kernel has all the privileges, a bug in one function can corrupt data structure of another, totally unrelated part of the kernel, or of any running program.
Kernels often become very large and difficult to maintain.
Even if the modules servicing these operations are separate from the whole, the code integration is tight and difficult to do correctly.
Since the modules run in the same address space, a bug can bring down the entire system.


=== Microkernels ===

Microkernel (also abbreviated μK or uK) is the term describing an approach to operating system design by which the functionality of the system is moved out of the traditional ""kernel"", into a set of ""servers"" that communicate through a ""minimal"" kernel, leaving as little as possible in ""system space"" and as much as possible in ""user space"". A microkernel that is designed for a specific platform or device is only ever going to have what it needs to operate. The microkernel approach consists of defining a simple abstraction over the hardware, with a set of primitives or system calls to implement minimal OS services such as memory management, multitasking, and inter-process communication. Other services, including those normally provided by the kernel, such as networking, are implemented in user-space programs, referred to as servers. Microkernels are easier to maintain than monolithic kernels, but the large number of system calls and context switches might slow down the system because they typically generate more overhead than plain function calls.
Only parts which really require being in a privileged mode are in kernel space: IPC (Inter-Process Communication), basic scheduler, or scheduling primitives, basic memory handling, basic I/O primitives. Many critical parts are now running in user space: The complete scheduler, memory handling, file systems, and network stacks. Micro kernels were invented as a reaction to traditional ""monolithic"" kernel design, whereby all system functionality was put in a one static program running in a special ""system"" mode of the processor. In the microkernel, only the most fundamental of tasks are performed such as being able to access some (not necessarily all) of the hardware, manage memory and coordinate message passing between the processes. Some systems that use micro kernels are QNX and the HURD. In the case of QNX and Hurd user sessions can be entire snapshots of the system itself or views as it is referred to. The very essence of the microkernel architecture illustrates some of its advantages:

Easier to maintain
Patches can be tested in a separate instance, and then swapped in to take over a production instance.
Rapid development time and new software can be tested without having to reboot the kernel.
More persistence in general, if one instance goes haywire, it is often possible to substitute it with an operational mirror.Most microkernels use a message passing system to handle requests from one server to another. The message passing system generally operates on a port basis with the microkernel. As an example, if a request for more memory is sent, a port is opened with the microkernel and the request sent through. Once within the microkernel, the steps are similar to system calls. The rationale was that it would bring modularity in the system architecture, which would entail a cleaner system, easier to debug or dynamically modify, customizable to users' needs, and more performing. They are part of the operating systems like GNU Hurd, MINIX, MkLinux, QNX and Redox OS.  Although microkernels are very small by themselves, in combination with all their required auxiliary code they are, in fact, often larger than monolithic kernels. Advocates of monolithic kernels also point out that the two-tiered structure of microkernel systems, in which most of the operating system does not interact directly with the hardware, creates a not-insignificant cost in terms of system efficiency. These types of kernels normally provide only the minimal services such as defining memory address spaces, inter-process communication (IPC) and the process management. The other functions such as running the hardware processes are not handled directly by microkernels. Proponents of micro kernels point out those monolithic kernels have the disadvantage that an error in the kernel can cause the entire system to crash. However, with a microkernel, if a kernel process crashes, it is still possible to prevent a crash of the system as a whole by merely restarting the service that caused the error.
Other services provided by the kernel such as networking are implemented in user-space programs referred to as servers. Servers allow the operating system to be modified by simply starting and stopping programs. For a machine without networking support, for instance, the networking server is not started. The task of moving in and out of the kernel to move data between the various applications and servers creates overhead which is detrimental to the efficiency of micro kernels in comparison with monolithic kernels.
Disadvantages in the microkernel exist however. Some are:

Larger running memory footprint
More software for interfacing is required, there is a potential for performance loss.
Messaging bugs can be harder to fix due to the longer trip they have to take versus the one off copy in a monolithic kernel.
Process management in general can be very complicated.The disadvantages for microkernels are extremely context-based. As an example, they work well for small single-purpose (and critical) systems because if not many processes need to run, then the complications of process management are effectively mitigated.
A microkernel allows the implementation of the remaining part of the operating system as a normal application program written in a high-level language, and the use of different operating systems on top of the same unchanged kernel. It is also possible to dynamically switch among operating systems and to have more than one active simultaneously.


=== Monolithic kernels vs. microkernels ===
As the computer kernel grows, so grows the size and vulnerability of its trusted computing base; and, besides reducing security, there is the problem of enlarging the memory footprint. This is mitigated to some degree by perfecting the virtual memory system, but not all computer architectures have virtual memory support. To reduce the kernel's footprint, extensive editing has to be performed to carefully remove unneeded code, which can be very difficult with non-obvious interdependencies between parts of a kernel with millions of lines of code.
By the early 1990s, due to the various shortcomings of monolithic kernels versus microkernels, monolithic kernels were considered obsolete by virtually all operating system researchers. As a result, the design of Linux as a monolithic kernel rather than a microkernel was the topic of a famous debate between Linus Torvalds and Andrew Tanenbaum. There is merit on both sides of the argument presented in the Tanenbaum–Torvalds debate.


==== Performance ====
Monolithic kernels are designed to have all of their code in the same address space (kernel space), which some developers argue is necessary to increase the performance of the system. Some developers also maintain that monolithic systems are extremely efficient if well written. The monolithic model tends to be more efficient through the use of shared kernel memory, rather than the slower IPC system of microkernel designs, which is typically based on message passing.The performance of microkernels was poor in both the 1980s and early 1990s. However, studies that empirically measured the performance of these microkernels did not analyze the reasons of such inefficiency. The explanations of this data were left to ""folklore"", with the assumption that they were due to the increased frequency of switches from ""kernel-mode"" to ""user-mode"", to the increased frequency of inter-process communication and to the increased frequency of context switches.In fact, as guessed in 1995, the reasons for the poor performance of microkernels might as well have been: (1) an actual inefficiency of the whole microkernel approach, (2) the particular concepts implemented in those microkernels, and (3) the particular implementation of those concepts. Therefore it remained to be studied if the solution to build an efficient microkernel was, unlike previous attempts, to apply the correct construction techniques.On the other end, the hierarchical protection domains architecture that leads to the design of a monolithic kernel has a significant performance drawback each time there's an interaction between different levels of protection (i.e., when a process has to manipulate a data structure both in ""user mode"" and ""supervisor mode""), since this requires message copying by value.


=== Hybrid (or modular) kernels ===

Hybrid kernels are used in most commercial operating systems such as Microsoft Windows NT 3.1, NT 3.5, NT 3.51, NT 4.0, 2000, XP, Vista, 7, 8, 8.1 and 10. Apple's own macOS uses a hybrid kernel called XNU which is based upon code from OSF/1's Mach kernel (OSFMK 7.3) and FreeBSD's monolithic kernel. They are similar to micro kernels, except they include some additional code in kernel-space to increase performance. These kernels represent a compromise that was implemented by some developers to accommodate the major advantages of both monolithic and micro kernels. These types of kernels are extensions of micro kernels with some properties of monolithic kernels. Unlike monolithic kernels, these types of kernels are unable to load modules at runtime on their own. Hybrid kernels are micro kernels that have some ""non-essential"" code in kernel-space in order for the code to run more quickly than it would were it to be in user-space. Hybrid kernels are a compromise between the monolithic and microkernel designs. This implies running some services (such as the network stack or the filesystem) in kernel space to reduce the performance overhead of a traditional microkernel, but still running kernel code (such as device drivers) as servers in user space.
Many traditionally monolithic kernels are now at least adding (or else using) the module capability. The most well known of these kernels is the Linux kernel. The modular kernel essentially can have parts of it that are built into the core kernel binary or binaries that load into memory on demand. It is important to note that a code tainted module has the potential to destabilize a running kernel. Many people become confused on this point when discussing micro kernels. It is possible to write a driver for a microkernel in a completely separate memory space and test it before ""going"" live. When a kernel module is loaded, it accesses the monolithic portion's memory space by adding to it what it needs, therefore, opening the doorway to possible pollution. A few advantages to the modular (or) Hybrid kernel are:

Faster development time for drivers that can operate from within modules. No reboot required for testing (provided the kernel is not destabilized).
On demand capability versus spending time recompiling a whole kernel for things like new drivers or subsystems.
Faster integration of third party technology (related to development but pertinent unto itself nonetheless).Modules, generally, communicate with the kernel using a module interface of some sort. The interface is generalized (although particular to a given operating system) so it is not always possible to use modules. Often the device drivers may need more flexibility than the module interface affords. Essentially, it is two system calls and often the safety checks that only have to be done once in the monolithic kernel now may be done twice. Some of the disadvantages of the modular approach are:

With more interfaces to pass through, the possibility of increased bugs exists (which implies more security holes).
Maintaining modules can be confusing for some administrators when dealing with problems like symbol differences.


=== Nanokernels ===

A nanokernel delegates virtually all services –  including even the most basic ones like interrupt controllers or the timer –  to device drivers to make the kernel memory requirement even smaller than a traditional microkernel.


=== Exokernels ===

Exokernels are a still-experimental approach to operating system design. They differ from other types of kernels in limiting their functionality to the protection and multiplexing of the raw hardware, providing no hardware abstractions on top of which to develop applications. This separation of hardware protection from hardware management enables application developers to determine how to make the most efficient use of the available hardware for each specific program.
Exokernels in themselves are extremely small. However, they are accompanied by library operating systems (see also unikernel), providing application developers with the functionalities of a conventional operating system. This comes down to every user writing their own rest-of-the kernel from near scratch, which is a very-risky, complex and quite a daunting assignment - particularly in a time-constrained production-oriented environment, which is why exokernels have never caught on. A major advantage of exokernel-based systems is that they can incorporate multiple library operating systems, each exporting a different API, for example one for high level UI development and one for real-time control.


=== Multikernels ===

A multikernel operating system treats a multi-core machine as a network of independent cores, as if it were a distributed system. It does not assume shared memory but rather implements inter-process communications as message passing. Barrelfish was the first operating system to be described as a multikernel.


== History of kernel development ==


=== Early operating system kernels ===

Strictly speaking, an operating system (and thus, a kernel) is not required to run a computer. Programs can be directly loaded and executed on the ""bare metal"" machine, provided that the authors of those programs are willing to work without any hardware abstraction or operating system support. Most early computers operated this way during the 1950s and early 1960s, which were reset and reloaded between the execution of different programs. Eventually, small ancillary programs such as program loaders and debuggers were left in memory between runs, or loaded from ROM. As these were developed, they formed the basis of what became early operating system kernels. The ""bare metal"" approach is still used today on some video game consoles and embedded systems, but in general, newer computers use modern operating systems and kernels.
In 1969, the RC 4000 Multiprogramming System introduced the system design philosophy of a small nucleus ""upon which operating systems for different purposes could be built in an orderly manner"", what would be called the microkernel approach.


=== Time-sharing operating systems ===

In the decade preceding Unix, computers had grown enormously in power –  to the point where computer operators were looking for new ways to get people to use their spare time on their machines. One of the major developments during this era was time-sharing, whereby a number of users would get small slices of computer time, at a rate at which it appeared they were each connected to their own, slower, machine.The development of time-sharing systems led to a number of problems. One was that users, particularly at universities where the systems were being developed, seemed to want to hack the system to get more CPU time. For this reason, security and access control became a major focus of the Multics project in 1965. Another ongoing issue was properly handling computing resources: users spent most of their time staring at the terminal and thinking about what to input instead of actually using the resources of the computer, and a time-sharing system should give the CPU time to an active user during these periods. Finally, the systems typically offered a memory hierarchy several layers deep, and partitioning this expensive resource led to major developments in virtual memory systems.


=== Amiga ===

The Commodore Amiga was released in 1985, and was among the first –  and certainly most successful –  home computers to feature  an advanced kernel architecture. The AmigaOS kernel's executive component, exec.library, uses a microkernel message-passing design, but there are other kernel components, like graphics.library, that have direct access to the hardware. There is no memory protection, and the kernel is almost always running in user mode. Only special actions are executed in kernel mode, and user-mode applications can ask the operating system to execute their code in kernel mode.


=== Unix ===

During the design phase of Unix, programmers decided to model every high-level device as a file, because they believed the purpose of computation was data transformation.For instance, printers were represented as a ""file"" at a known location –  when data was copied to the file, it printed out. Other systems, to provide a similar functionality, tended to virtualize devices at a lower level –  that is, both devices and files would be instances of some lower level concept. Virtualizing the system at the file level allowed users to manipulate the entire system using their existing file management utilities and concepts, dramatically simplifying operation. As an extension of the same paradigm, Unix allows programmers to manipulate files using a series of small programs, using the concept of pipes, which allowed users to complete operations in stages, feeding a file through a chain of single-purpose tools. Although the end result was the same, using smaller programs in this way dramatically increased flexibility as well as ease of development and use, allowing the user to modify their workflow by adding or removing a program from the chain.
In the Unix model, the operating system consists of two parts: first, the huge collection of utility programs that drive most operations; second, the kernel that runs the programs. Under Unix, from a programming standpoint, the distinction between the two is fairly thin; the kernel is a program, running in supervisor mode, that acts as a program loader and supervisor for the small utility programs making up the rest of the system, and to provide locking and I/O services for these programs; beyond that, the kernel didn't intervene at all in user space.
Over the years the computing model changed, and Unix's treatment of everything as a file or byte stream no longer was as universally applicable as it was before. Although a terminal could be treated as a file or a byte stream, which is printed to or read from, the same did not seem to be true for a graphical user interface. Networking posed another problem. Even if network communication can be compared to file access, the low-level packet-oriented architecture dealt with discrete chunks of data and not with whole files. As the capability of computers grew, Unix became increasingly cluttered with code. It is also because the modularity of the Unix kernel is extensively scalable. While kernels might have had 100,000 lines of code in the seventies and eighties, kernels like Linux, of modern Unix successors like GNU, have more than 13 million lines.Modern Unix-derivatives are generally based on module-loading monolithic kernels. Examples of this are the Linux kernel in the many distributions of GNU, IBM AIX, as well as the Berkeley Software Distribution variant kernels such as FreeBSD, DragonFly BSD, OpenBSD, NetBSD, and macOS. Apart from these alternatives, amateur developers maintain an active operating system development community, populated by self-written hobby kernels which mostly end up sharing many features with Linux, FreeBSD, DragonflyBSD, OpenBSD or NetBSD kernels and/or being compatible with them.


=== Classic Mac OS and macOS ===

Apple first launched its classic Mac OS in 1984, bundled with its Macintosh personal computer. Apple moved to a nanokernel design in Mac OS 8.6. Against this, the modern macOS (originally named Mac OS X) is based on Darwin, which uses a hybrid kernel called XNU, which was created by combining the 4.3BSD kernel and the Mach kernel.


=== Microsoft Windows ===

Microsoft Windows was first released in 1985 as an add-on to MS-DOS.  Because of its dependence on another operating system, initial releases of Windows, prior to Windows 95, were considered an operating environment (not to be confused with an operating system).  This product line continued to evolve through the 1980s and 1990s, with the Windows 9x series adding 32-bit addressing and pre-emptive multitasking; but ended with the release of Windows Me in 2000.
Microsoft also developed Windows NT, an operating system with a very similar interface, but intended for high-end and business users. This line started with the release of Windows NT 3.1 in 1993, and was introduced to general users with the release of Windows XP in October 2001—replacing Windows 9x with a completely different, much more sophisticated operating system. This is the line that continues with Windows 11.
The architecture of Windows NT's kernel is considered a hybrid kernel because the kernel itself contains tasks such as the Window Manager and the IPC Managers, with a client/server layered subsystem model. It was designed as a modified microkernel, as the Windows NT kernel was influenced by the Mach microkernel but does not meet all of the criteria of a pure microkernel.


=== IBM Supervisor ===
Supervisory program or supervisor is a computer program, usually part of an operating system, that controls the execution of other routines and regulates work scheduling, input/output operations, error actions, and similar functions and regulates the flow of work in a data processing system.
Historically, this term was essentially associated with IBM's line of mainframe operating systems starting with OS/360. In other operating systems, the supervisor is generally called the kernel.
In the 1970s, IBM further abstracted the supervisor state from the hardware, resulting in a hypervisor that enabled full virtualization, i.e. the capacity to run multiple operating systems on the same machine totally independently from each other. Hence the first such system was called Virtual Machine or VM.


=== Development of microkernels ===
Although Mach, developed by Richard Rashid at Carnegie Mellon University, is the best-known general-purpose microkernel, other microkernels have been developed with more specific aims. The L4 microkernel family (mainly the L3 and the L4 kernel) was created to demonstrate that microkernels are not necessarily slow. Newer implementations such as Fiasco and Pistachio are able to run Linux next to other L4 processes in separate address spaces.Additionally, QNX is a microkernel which is principally used in embedded systems, and the open-source software MINIX, while originally created for educational purposes, is now focused on being a highly reliable and self-healing microkernel OS.


== See also ==
Comparison of operating system kernels
Inter-process communication
Operating system
Virtual memory


== Notes ==


== References ==


== Sources ==


== Further reading ==
Andrew S. Tanenbaum, Albert S. Woodhull, Operating Systems: Design and Implementation (Third edition);
Andrew S. Tanenbaum, Herbert Bos, Modern Operating Systems (Fourth edition);
Daniel P. Bovet, Marco Cesati, Understanding the Linux Kernel (Third edition);
David A. Patterson, John L. Hennessy, Computer Organization and Design (Sixth edition), Morgan Kaufmann (ISBN 978-0-12-820109-1);
B.S. Chalk, A.T. Carter, R.W. Hind, Computer Organisation and Architecture: An Introduction (Second edition), Palgrave Macmillan (ISBN 978-1-4039-0164-4).


== External links ==

Detailed comparison between most popular operating system kernels"
5e864d9b9f,Object (computer science),"In computer science, an object can be a variable, a data structure, a function, or a method. As regions of memory, they contain value and are referenced by identifiers.
In the object-oriented programming paradigm, object can be a combination of variables, functions, and data structures; in particular in class-based variations of the paradigm it refers to a particular instance of a class.
In the relational model of database management, an object can be a table or column, or an association between data and a database entity (such as relating a person's age to a specific person).


== Object-based languages ==

An important distinction in programming languages is the difference between an object-oriented language and an object-based language. A language is usually considered object-based if it includes the basic capabilities for an object: identity, properties, and attributes. A language is considered object-oriented if it is object-based and also has the capability of polymorphism, inheritance, encapsulation, and, possibly, composition. Polymorphism refers to the ability to overload the name of a function with multiple behaviors based on which object(s) are passed to it. Conventional message passing discriminates only on the first object and considers that to be ""sending a message"" to that object. However, some object-oriented programming languages such as Flavors and the Common Lisp Object System (CLOS) enable discriminating on more than the first parameter of the function. Inheritance is the ability to subclass an object class, to create a new class that is a subclass of an existing one and inherits all the data constraints and behaviors of its parents but also adds new and/or changes one or more of them.


== Object-oriented programming ==

Object-oriented programming is an approach to designing modular reusable software systems. The object-oriented approach is an evolution of good design practices that go back to the very beginning of computer programming. Object-orientation is simply the logical extension of older techniques such as structured programming and abstract data types. An object is an abstract data type with the addition of polymorphism and inheritance.
Rather than structure programs as code and data, an object-oriented system integrates the two using the concept of an ""object"". An object has state (data) and behavior (code). Objects can correspond to things found in the real world. So for example, a graphics program will have objects such as circle, square, menu. An online shopping system will have objects such as shopping cart, customer, product. The shopping system will support behaviors such as place order, make payment, and offer discount. The objects are designed as class hierarchies. So for example with the shopping system there might be high level classes such as electronics product, kitchen product, and book. There may be further refinements for example under electronic products: CD Player, DVD player, etc. These classes and subclasses correspond to sets and subsets in mathematical logic.


== Specialized objects ==
An important concept for objects is the design pattern. A design pattern provides a reusable template to address a common problem. The following object descriptions are examples of some of the most common design patterns for objects.
Function object: an object with a single method (in C++, this method would be the function operator, ""operator()"") that acts much like a function (like a C/C++ pointer to a function).
Immutable object: an object set up with a fixed state at creation time and which does not change afterward.
First-class object: an object that can be used without restriction.
Container object: an object that can contain other objects.
Factory object: an object whose purpose is to create other objects.
Metaobject: an object from which other objects can be created (compare with a class, which is not necessarily an object).
Prototype object: a specialized metaobject from which other objects can be created by copying
God object: an object that knows or does too much (it is an example of an anti-pattern).
Singleton object: an object that is the only instance of its class during the lifetime of the program.
Filter object: an object that receives a stream of data as its input and transforms it into the object's output. Often the input and output streams are streams of characters, but these also may be streams of arbitrary objects. These are generally used in wrappers since they conceal the existing implementation with the abstraction required at the developer side.


== Distributed objects ==

The object-oriented approach is not just a programming model. It can be used equally well as an interface definition language for distributed systems. The objects in a distributed computing model tend to be larger grained, longer lasting, and more service-oriented than programming objects.
A standard method to package distributed objects is via an Interface Definition Language (IDL). An IDL shields the client of all of the details of the distributed server object. Details such as which computer the object resides on, what programming language it uses, what operating system, and other platform-specific issues. The IDL is also usually part of a distributed environment that provides services such as transactions and persistence to all objects in a uniform manner. Two of the most popular standards for distributed objects are the Object Management Group's CORBA standard and Microsoft's DCOM.In addition to distributed objects, a number of other extensions to the basic concept of an object have been proposed to enable distributed computing:

Protocol objects are components of a protocol stack that enclose network communication within an object-oriented interface.
Replicated objects are groups of distributed objects (called replicas) that run a distributed multi-party protocol to achieve high consistency between their internal states, and that respond to requests in a coordinated way. Examples include fault-tolerant CORBA objects.
Live distributed objects (or simply live objects) generalize the replicated object concept to groups of replicas that might internally use any distributed protocol, perhaps resulting in only a weak consistency between their local states.Some of these extensions, such as distributed objects and protocol objects, are domain-specific terms for special types of ""ordinary"" objects used in a certain context (such as remote method invocation or protocol composition). Others, such as replicated objects and live distributed objects, are more non-standard, in that they abandon the usual case that an object resides in a single location at a time, and apply the concept to groups of entities (replicas) that might span across multiple locations, might have only weakly consistent state, and whose membership might dynamically change.


== The Semantic Web ==
The Semantic Web is essentially a distributed-objects framework. Two key technologies in the Semantic Web are the Web Ontology Language (OWL) and the Resource Description Framework (RDF). RDF provides the capability to define basic objects—names, properties, attributes, relations—that are accessible via the Internet. OWL adds a richer object model, based on set theory, that provides additional modeling capabilities such as multiple inheritance.
OWL objects are not like standard large-grained distributed objects accessed via an Interface Definition Language. Such an approach would not be appropriate for the Internet because the Internet is constantly evolving and standardization on one set of interfaces is difficult to achieve. OWL objects tend to be similar to the kinds of objects used to define application domain models in programming languages such as Java and C++.
However, there are important distinctions between OWL objects and traditional object-oriented programming objects. Traditional objects get compiled into static hierarchies usually with single inheritance, but OWL objects are dynamic. An OWL object can change its structure at run time and can become an instance of new or different classes.
Another critical difference is the way the model treats information that is currently not in the system. Programming objects and most database systems use the ""closed-world assumption"". If a fact is not known to the system that fact is assumed to be false. Semantic Web objects use the open-world assumption, a statement is only considered false if there is actual relevant information that it is false, otherwise it is assumed to be unknown, neither true nor false.
OWL objects are actually most like objects in artificial intelligence frame languages such as KL-ONE and Loom.
The following table contrasts traditional objects from Object-Oriented programming languages such as Java or C++ with Semantic Web Objects:


== See also ==
Object lifetime – In programming, time between an object's creation and destruction
Object copying – Technique in object-oriented programming
Software design pattern – Reusable solution to a commonly occurring software problem
Business object – Entity within a multi-tiered software application
Actor model – Model of concurrent computation


== References ==


== External links ==
What Is an Object? from The Java Tutorials"
f220811f56,Decomposition (computer science),"Decomposition in computer science, also known as factoring, is breaking a complex problem or system into parts that are easier to conceive, understand, program, and maintain.


== Overview ==
There are different types of decomposition defined in computer sciences:

In structured programming, algorithmic decomposition breaks a process down into well-defined steps.
Structured analysis breaks down a software system from the system context level to system functions and data entities as described by Tom DeMarco.
Object-oriented decomposition, on the other hand, breaks a large system down into progressively smaller classes or objects that are responsible for some part of the problem domain.
According to Booch, algorithmic decomposition is a necessary part of object-oriented analysis and design, but object-oriented systems start with and emphasize decomposition into objects.More generally, functional decomposition in computer science is a technique for mastering the complexity of the function of a model. A functional model of a system is thereby replaced by a series of functional models of subsystems.


== Decomposition topics ==


=== Decomposition paradigm ===
A decomposition  paradigm in computer programming is a strategy for organizing a program as a number of parts, and it usually implies a specific way to organize a program text. Usually the aim of using a decomposition paradigm is to optimize some metric related to program complexity, for example the modularity of the program or its maintainability.
Most decomposition paradigms suggest breaking down a program into parts so as to minimize the static dependencies among those parts, and to maximize the cohesiveness of each part. Some popular decomposition paradigms are the procedural, modules, abstract data type and object oriented ones.
The concept of decomposition paradigm is entirely independent and different from that of model of computation, but the two are often confused, most often in the cases of the functional model of computation being confused with procedural decomposition, and of the actor model of computation being confused with object oriented decomposition.


=== Decomposition diagram ===

		
		
		
A decomposition diagram shows a complex, process, organization, data subject area, or other type of object broken down into lower level, more detailed components. For example, decomposition diagrams may represent organizational structure or functional decomposition into processes. Decomposition diagrams  provide a logical hierarchical decomposition of a system.


== See also ==
Code refactoring
Component-based software engineering
Dynamization
Duplicate code
Event partitioning
How to Solve It
Integrated Enterprise Modeling
Personal information management
Readability
Subroutine


== References ==


== External links ==

Object Oriented Analysis and Design
On the Criteria To Be Used in Decomposing Systems into Modules"
338fd7de88,Concern (computer science),"In computer science, a concern is a particular set of information that has an effect on the code of a computer program. A concern can be as general as the details of database interaction or as specific as performing a primitive calculation, depending on the level of conversation between developers and the program being discussed. IBM uses the term concern space to describe the sectioning of conceptual information.


== Overview ==
Usually the code can be separated into logical sections, each addressing separate concerns, and so it hides the need for a given section to know particular information addressed by a different section. This leads to a modular program. Edsger W. Dijkstra coined the term ""separation of concerns"" to describe the mentality behind this modularization, which allows the programmer to reduce the complexity of the system being designed. Two different concerns that intermingle in the same section of code are called ""highly coupled"". Sometimes the chosen module divisions do not allow for one concern to be completely separated from another, resulting in cross-cutting concerns. The various programming paradigms address the issue of cross-cutting concerns to different degrees. Data logging is a common cross-cutting concern, being used in many other parts of the program other than the particular module(s) that actually log the data. Since changes to the logging code can affect other sections, it could introduce bugs in the operation of the program.
Paradigms that specifically address the issue of concern separation:

Object-oriented programming, describing concerns as objects
Functional programming, describing concerns as functions
Aspect-oriented software development, treating concerns and their interaction as constructs of their own standing


== See also ==
Cross-cutting concern
Separation of concerns
Issue (computers), a unit of work to accomplish an improvement in a data system


== References ==


== External links ==
Concerns in Rails, by DHH, the Rails creator"
02f06ae0c2,Starvation (computer science),"In computer science, resource starvation is a problem encountered in concurrent computing where a process is perpetually denied necessary resources to process its work. Starvation may be caused by errors in a scheduling or mutual exclusion algorithm, but can also be caused by resource leaks, and can be intentionally caused via a denial-of-service attack such as a fork bomb.
When starvation is impossible in a concurrent algorithm, the algorithm is called starvation-free, lockout-freed or said to have finite bypass. This property is an instance of liveness, and is one of the two requirements for any mutual exclusion algorithm; the other being correctness. The name ""finite bypass"" means that any process (concurrent part) of the algorithm is bypassed at most a finite number times before being allowed access to the shared resource.


== Scheduling ==
Starvation is usually caused by an overly simplistic scheduling algorithm. For example, if a (poorly designed) multi-tasking system always switches between the first two tasks while a third never gets to run, then the third task is being starved of CPU time. The scheduling algorithm, which is part of the kernel, is supposed to allocate resources equitably; that is, the algorithm should allocate resources so that no process perpetually lacks necessary resources.
Many operating system schedulers employ the concept of process priority. A high priority process A will run before a low priority process B. If the high priority process (process A) blocks and never yields, the low priority process (B) will (in some systems) never be scheduled—it will experience starvation. If there is an even higher priority process X, which is dependent on a result from process B, then process X might never finish, even though it is the most important process in the system. This condition is called a priority inversion.  Modern scheduling algorithms normally contain code to guarantee that all processes will receive a minimum amount of each important resource (most often CPU time) in order to prevent any process from being subjected to starvation.
In computer networks, especially wireless networks, scheduling algorithms may suffer from scheduling starvation. An example is maximum throughput scheduling.
Starvation is normally caused by deadlock in that it causes a process to freeze. Two or more processes become deadlocked when each of them is doing nothing while waiting for a resource occupied by another program in the same set. On the other hand, a process is in starvation when it is waiting for a resource that is continuously given to other processes. Starvation-freedom is a stronger guarantee than the absence of deadlock: a mutual exclusion algorithm that must choose to allow one of two processes into a critical section and picks one arbitrarily is deadlock-free, but not starvation-free.A possible solution to starvation is to use a scheduling algorithm with priority queue that also uses the aging technique. Aging is a technique of gradually increasing the priority of processes that wait in the system for a long time.


== See also ==
Dining philosophers problem


== References =="
e6eb671e81,List of unsolved problems in computer science,"This article is a list of notable unsolved problems in computer science. A problem in computer science is considered unsolved when no solution is known, or when experts in the field disagree about proposed solutions.


== Computational complexity ==

P versus NP problem
What is the relationship between BQP and NP?
NC = P problem
NP = co-NP problem
P = BPP problem
P = PSPACE problem
L = NL problem
PH = PSPACE problem
L = P problem
L = RL problem
Unique games conjecture
Is the exponential time hypothesis true?
Is the strong exponential time hypothesis (SETH) true?
Do one-way functions exist?
Is public-key cryptography possible?
Log-rank conjecture


== Polynomial versus nondeterministic-polynomial time for specific algorithmic problems ==

Can integer factorization be done in polynomial time on a classical (non-quantum) computer?
Can the discrete logarithm be computed in polynomial time on a classical (non-quantum) computer?
Can the shortest vector of a lattice be computed in polynomial time on a classical or quantum computer?
Can clustered planar drawings be found in polynomial time?
Can the graph isomorphism problem be solved in polynomial time?
Can leaf powers and k-leaf powers be recognized in polynomial time?
Can parity games be solved in polynomial time?
Can the rotation distance between two binary trees be computed in polynomial time?
Can graphs of bounded clique-width be recognized in polynomial time?
Can one find a simple closed quasigeodesic on a convex polyhedron in polynomial time?
Can a simultaneous embedding with fixed edges for two given graphs be found in polynomial time?


== Other algorithmic problems ==
The dynamic optimality conjecture: do splay trees have a bounded competitive ratio?
Is there a k-competitive online algorithm for the k-server problem?
Can a depth-first search tree be constructed in NC?
Can the fast Fourier transform be computed in o(n log n) time?
What is the fastest algorithm for multiplication of two n-digit numbers?
What is the lowest possible average-case time complexity of Shellsort with a deterministic, fixed gap sequence?
Can 3SUM be solved in strongly sub-quadratic time, that is, in time O(n2−ϵ) for some ϵ>0?
Can the edit distance between two strings of length n be computed in strongly sub-quadratic time?  (This is only possible if the strong exponential time hypothesis is false.)
Can X + Y sorting be done in o(n2 log n) time?
What is the fastest algorithm for matrix multiplication?
Can all-pairs shortest paths be computed in strongly sub-cubic time, that is, in time O(V3−ϵ) for some ϵ>0?
Can the Schwartz–Zippel lemma for polynomial identity testing be derandomized?
Does linear programming admit a strongly polynomial-time algorithm?  (This is problem #9 in Smale's list of problems.)
How many queries are required for envy-free cake-cutting?
What is the algorithmic complexity of the minimum spanning tree problem? Equivalently, what is the decision tree complexity of the MST problem? The optimal algorithm to compute MSTs is known, but it relies on decision trees, so its complexity is unknown.
Gilbert–Pollack conjecture on the Steiner ratio of the Euclidean plane


== Programming language theory ==

POPLmark
Barendregt–Geuvers–Klop conjecture


== Other problems ==
Aanderaa–Karp–Rosenberg conjecture
Černý Conjecture
Generalized star-height problem
Separating words problem


== References ==


== External links ==
Open problems around exact algorithms by Gerhard J. Woeginger, Discrete Applied Mathematics 156 (2008) 397–405.
The RTA list of open problems – open problems in rewriting.
The TLCA List of Open Problems – open problems in area typed lambda calculus."
73372aa250,Circuit (computer science),"In theoretical computer science, a circuit is a model of computation in which input values proceed through a sequence of gates, each of which computes a function. Circuits of this kind provide a generalization of Boolean circuits and a mathematical model for digital logic circuits. Circuits are defined by the gates they contain and the values the gates can produce.  For example, the values in a Boolean circuit are boolean values, and the circuit includes conjunction, disjunction, and negation gates.  The values in an integer circuit are sets of integers and the gates compute set union, set intersection, and set complement, as well as the arithmetic operations addition and multiplication.


== Formal definition ==
A circuit is a triple 
  
    
      
        (
        M
        ,
        L
        ,
        G
        )
      
    
    {\displaystyle (M,L,G)}
  , where

  
    
      
        M
      
    
    {\displaystyle M}
   is a set of values,

  
    
      
        L
      
    
    {\displaystyle L}
   is a set of gate labels, each of which is a function from 
  
    
      
        
          M
          
            i
          
        
      
    
    {\displaystyle M^{i}}
   to 
  
    
      
        M
      
    
    {\displaystyle M}
   for some non-negative integer 
  
    
      
        i
      
    
    {\displaystyle i}
   (where 
  
    
      
        i
      
    
    {\displaystyle i}
   represents the number of inputs to the gate), and

  
    
      
        G
      
    
    {\displaystyle G}
   is a labelled directed acyclic graph with labels from 
  
    
      
        L
      
    
    {\displaystyle L}
  .The vertices of the graph are called gates. For each gate 
  
    
      
        g
      
    
    {\displaystyle g}
   of in-degree 
  
    
      
        i
      
    
    {\displaystyle i}
  , the gate 
  
    
      
        g
      
    
    {\displaystyle g}
   can be labeled by an element 
  
    
      
        ℓ
      
    
    {\displaystyle \ell }
   of 
  
    
      
        L
      
    
    {\displaystyle L}
   if and only if 
  
    
      
        ℓ
      
    
    {\displaystyle \ell }
   is defined on 
  
    
      
        
          M
          
            i
          
        
        .
      
    
    {\displaystyle M^{i}.}
  


=== Terminology ===
The gates of in-degree 0 are called inputs or leaves. The gates of out-degree 0 are called outputs. If there is an edge from gate 
  
    
      
        g
      
    
    {\displaystyle g}
   to gate 
  
    
      
        h
      
    
    {\displaystyle h}
   in the graph 
  
    
      
        G
      
    
    {\displaystyle G}
   then 
  
    
      
        h
      
    
    {\displaystyle h}
   is called a child of 
  
    
      
        g
      
    
    {\displaystyle g}
  . We suppose there is an order on the vertices of the graph, so we can speak of the 
  
    
      
        k
      
    
    {\displaystyle k}
  th child of a gate when 
  
    
      
        k
      
    
    {\displaystyle k}
   is less than the out-degree of the gate.
The size of a circuit is the number of nodes of a circuit. The depth of a gate 
  
    
      
        g
      
    
    {\displaystyle g}
   is the length of the longest path in 
  
    
      
        G
      
    
    {\displaystyle G}
   beginning at 
  
    
      
        g
      
    
    {\displaystyle g}
   up to an output gate. In particular, the gates of out-degree 0 are the only gates of depth 1. The depth of a circuit is the maximum depth of any gate. 
Level 
  
    
      
        i
      
    
    {\displaystyle i}
   is the set of all gates of depth 
  
    
      
        i
      
    
    {\displaystyle i}
  . A levelled circuit is a circuit in which the edges to gates of depth 
  
    
      
        i
      
    
    {\displaystyle i}
   comes only from gates of depth 
  
    
      
        i
        +
        1
      
    
    {\displaystyle i+1}
   or from the inputs. In other words, edges only exist between adjacent levels of the circuit. The width of a levelled circuit is the maximum size of any level.


=== Evaluation ===
The exact value 
  
    
      
        V
        (
        g
        )
      
    
    {\displaystyle V(g)}
   of a gate 
  
    
      
        g
      
    
    {\displaystyle g}
   with in-degree 
  
    
      
        i
      
    
    {\displaystyle i}
   and label 
  
    
      
        l
      
    
    {\displaystyle l}
   is defined recursively for all gates 
  
    
      
        g
      
    
    {\displaystyle g}
  .

  
    
      
        V
        (
        g
        )
        =
        
          
            {
            
              
                
                  l
                
                
                  
                    if 
                  
                  g
                  
                     is an input
                  
                
              
              
                
                  l
                  (
                  V
                  (
                  
                    g
                    
                      1
                    
                  
                  )
                  ,
                  …
                  ,
                  V
                  (
                  
                    g
                    
                      i
                    
                  
                  )
                  )
                
                
                  
                    otherwise,
                  
                
              
            
            
          
        
      
    
    {\displaystyle V(g)={\begin{cases}l&{\text{if }}g{\text{ is an input}}\\l(V(g_{1}),\dotsc ,V(g_{i}))&{\text{otherwise,}}\end{cases}}}
  where each 
  
    
      
        
          g
          
            j
          
        
      
    
    {\displaystyle g_{j}}
   is a parent of 
  
    
      
        g
      
    
    {\displaystyle g}
  .
The value of the circuit is the value of each of the output gates.


== Circuits as functions ==
The labels of the leaves can also be variables which take values in 
  
    
      
        M
      
    
    {\displaystyle M}
  . If there are 
  
    
      
        n
      
    
    {\displaystyle n}
   leaves, then the circuit can be seen as a function from  
  
    
      
        
          M
          
            n
          
        
      
    
    {\displaystyle M^{n}}
   to 
  
    
      
        M
      
    
    {\displaystyle M}
  . It is then usual to consider a family of circuits 
  
    
      
        (
        
          C
          
            n
          
        
        
          )
          
            n
            ∈
            
              N
            
          
        
      
    
    {\displaystyle (C_{n})_{n\in \mathbb {N} }}
  , a sequence of circuits indexed by the integers where the circuit 
  
    
      
        
          C
          
            n
          
        
      
    
    {\displaystyle C_{n}}
   has 
  
    
      
        n
      
    
    {\displaystyle n}
   variables. Families of circuits can thus be seen as functions from 
  
    
      
        
          M
          
            ∗
          
        
      
    
    {\displaystyle M^{*}}
   to 
  
    
      
        M
      
    
    {\displaystyle M}
  .
The notions of size, depth and width can be naturally extended to families of functions, becoming functions from 
  
    
      
        
          N
        
      
    
    {\displaystyle \mathbb {N} }
   to 
  
    
      
        
          N
        
      
    
    {\displaystyle \mathbb {N} }
  ; for example, 
  
    
      
        s
        i
        z
        e
        (
        n
        )
      
    
    {\displaystyle size(n)}
   is the size of the  
  
    
      
        n
      
    
    {\displaystyle n}
  th circuit of the family.


== Complexity and algorithmic problems ==
Computing the output of a given Boolean circuit on a specific input is a P-complete problem. If the input is an integer circuit, however, it is unknown whether this problem is decidable.
Circuit complexity attempts to classify Boolean functions with respect to the size or depth of circuits that can compute them.


== See also ==
Arithmetic circuit complexity
Boolean circuit
Circuit complexity
Circuits over sets of natural numbers
The complexity classes NC, AC and TC
Quantum circuit and BQP


== References ==
Vollmer, Heribert (1999). Introduction to Circuit Complexity. Berlin: Springer. ISBN 978-3-540-64310-4.
Yang, Ke (2001). ""Integer Circuit Evaluation Is PSPACE-Complete"". Journal of Computer and System Sciences. 63 (2, September 2001): 288–303. doi:10.1006/jcss.2001.1768. ISSN 0022-0000."
28ce9605f7,Zipping (computer science),"In computer science, zipping is a function which maps a tuple of sequences into a sequence of tuples.  This name zip derives from the action of a zipper in that it interleaves two formerly disjoint sequences.  The inverse function is unzip.


== Example ==
Given the three words cat, fish and be where |cat| is 3, |fish| is 4 and |be| is 2. Let 
  
    
      
        ℓ
      
    
    {\displaystyle \ell }
   denote the length of the longest word which is fish; 
  
    
      
        ℓ
        =
        4
      
    
    {\displaystyle \ell =4}
  . The zip of cat, fish, be is then 4 tuples of elements:

  
    
      
        (
        c
        ,
        f
        ,
        b
        )
        (
        a
        ,
        i
        ,
        e
        )
        (
        t
        ,
        s
        ,
        #
        )
        (
        #
        ,
        h
        ,
        #
        )
      
    
    {\displaystyle (c,f,b)(a,i,e)(t,s,\#)(\#,h,\#)}
  where # is a symbol not in the original alphabet. In Haskell this truncates to the shortest sequence 
  
    
      
        
          
            ℓ
            _
          
        
      
    
    {\displaystyle {\underline {\ell }}}
  , where 
  
    
      
        
          
            ℓ
            _
          
        
        =
        2
      
    
    {\displaystyle {\underline {\ell }}=2}
  :


== Definition ==
Let Σ be an alphabet, # a symbol not in Σ.
Let x1x2... x|x|, y1y2... y|y|, z1z2... z|z|, ... be n words (i.e. finite sequences) of elements of Σ. Let 
  
    
      
        ℓ
      
    
    {\displaystyle \ell }
   denote the length of the longest word, i.e. the maximum of |x|, |y|, |z|, ... .
The zip of these words is a finite sequence of n-tuples of elements of (Σ ∪ {#}), i.e. an element of 
  
    
      
        (
        (
        Σ
        ∪
        {
        #
        }
        
          )
          
            n
          
        
        
          )
          
            ∗
          
        
      
    
    {\displaystyle ((\Sigma \cup \{\#\})^{n})^{*}}
  :

  
    
      
        (
        
          x
          
            1
          
        
        ,
        
          y
          
            1
          
        
        ,
        …
        )
        (
        
          x
          
            2
          
        
        ,
        
          y
          
            2
          
        
        ,
        …
        )
        …
        (
        
          x
          
            ℓ
          
        
        ,
        
          y
          
            ℓ
          
        
        ,
        …
        )
      
    
    {\displaystyle (x_{1},y_{1},\ldots )(x_{2},y_{2},\ldots )\ldots (x_{\ell },y_{\ell },\ldots )}
  ,where for any index i > |w|, the wi is #.
The zip of x, y, z, ... is denoted zip(x, y, z, ...) or x ⋆ y ⋆ z ⋆ ...
The inverse to zip is sometimes denoted unzip.
A variation of the zip operation is defined by:

  
    
      
        (
        
          x
          
            1
          
        
        ,
        
          y
          
            1
          
        
        ,
        …
        )
        (
        
          x
          
            2
          
        
        ,
        
          y
          
            2
          
        
        ,
        …
        )
        …
        (
        
          x
          
            
              ℓ
              _
            
          
        
        ,
        
          y
          
            
              ℓ
              _
            
          
        
        ,
        …
        )
      
    
    {\displaystyle (x_{1},y_{1},\ldots )(x_{2},y_{2},\ldots )\ldots (x_{\underline {\ell }},y_{\underline {\ell }},\ldots )}
  where 
  
    
      
        
          
            ℓ
            _
          
        
      
    
    {\displaystyle {\underline {\ell }}}
   is the minimum length of the input words.  It avoids the use of an adjoined element 
  
    
      
        #
      
    
    {\displaystyle \#}
  , but destroys information about elements of the input sequences beyond 
  
    
      
        
          
            ℓ
            _
          
        
      
    
    {\displaystyle {\underline {\ell }}}
  .


== In programming languages ==
Zip functions are often available in programming languages, often referred to as zip. In Lisp-dialects one can simply map the desired function over the desired lists, map is variadic in Lisp so it can take an arbitrary number of lists as argument. An example from Clojure:

In Common Lisp:

Languages such as Python provide a zip() function, older version (Python 2.*) allowed mapping None over lists to get a similar effect. zip() in conjunction with the * operator unzips a list:

Haskell has a method of zipping sequences but requires a specific function for each arity (zip for two sequences, zip3 for three etc.), similarly the functions unzip and unzip3 are available for unzipping:


== Language comparison ==
List of languages by support of zip:


== See also ==
Map (higher-order function)


== References =="
7d5536610a,Dynamics,
f446423d72,Khoury College of Computer Sciences,"The Khoury College of Computer Sciences is the computer science school of Northeastern University in Boston, Massachusetts. It was the first college in the United States dedicated to the field of computer science when it was founded in 1982.  In addition to computer science, it specializes in data science and cybersecurity. The college was also among the first to offer an information assurance degree program. 
Khoury College offers Bachelor of Science (B.S.), Bachelor of Arts (B.A.), Master of Science (M.S.) and doctoral degrees in computer science, as well as undergraduate and graduate degrees in interdisciplinary, computer-related fields. Some 1,000 master's and 133 doctoral candidates are enrolled in the college.


== History ==
Throughout the 1980s, Northeastern University made about 38 program and curriculum changes to improve the university. Between 1979 and 1981, Northeastern organized a blue-ribbon panel of educators and experts, including industry leaders from Bell Labs, University of California, Berkeley, Massachusetts Institute of Technology (MIT) and the Digital Equipment Corporation, to develop a plan to advance education and research in the emerging field of computer science. In 1982, Northeastern formally established the College of Computer Science (CCS), the first U.S. college devoted to computer science and the first new college at Northeastern in 17 years. Paul Kalaghan, director of Academic Computer Services, was named its first dean. The college was initially housed in Knowles-Volpe Hall, now known as the Asa S. Knowles Center, with 11 faculty members and 239 first-year students. Graduate degree programs were added in 1984. A year later, the college moved into the former Botolph Building, one of the oldest structures on campus, which reopened as the David and Margaret Fitzgerald Cullinane Hall. At the end of 1987, the CCS proposed the Law of Demeter, which was widely used in software development area. In 2004, the college moved into the newly constructed West Village H building, which consists of a six-story building and a 16-story tower containing the Khoury College of Computer Science and on-campus housing for 485 students.


=== Naming donation ===
On December 16, 2018, Northeastern University announced a $50 million gift from alumnus and board trustee, Amin Khoury, in order to ""support all aspects of the college's future focus."" In return, the College of Computer and Information Science was renamed the Khoury College of Computer Sciences.


== Northeastern Deans of Computer Science ==
Paul Kalaghan, 1982–1988
Alan Selman (acting), 1988–1990
Cynthia Brown, 1990–1994
Larry Finkelstein, 1994–2014
Carla Brodley, 2014–2021
Alan Mislove (interim), 2021–2022
Elizabeth Mynatt, 2022–present


== Academic programs ==
In addition to a traditional computer science curriculum, Khoury College offers numerous other information science programs at both the undergraduate and graduate levels.


=== Computer science ===
The computer science program at Khoury College focuses on the fundamentals of computer program design, software design, computer networking, computation theory, and other technical computer-related subjects.


==== Undergraduate degrees ====
The CS program offers both Bachelor of Science and Bachelor of Arts degrees. While both require a core curriculum of computer science, mathematics, science, and humanities coursework, the B.A. candidates are required to take more humanities coursework than B.S. candidates. The B.S. is thus the more technical of the two degrees, with the B.A. aimed at giving students a social science context with which to frame their understanding of computer science. Khoury College offers the following degrees:

B.S. in Computer Science
B.S. in Cybersecurity
B.A. in Computer Science
B.S. in Information Science
B.S. in Data Science


==== Combined majors ====
Khoury College offers multiple combined major degree options within its own programs:

B.S. in Computer Science and Information Science
B.S. and M.S. in Computer Science
B.S. and M.S. in Data ScienceThe combined B.S. and M.S. in Computer Science substitutes four master-level courses for their undergraduate equivalents. Students then have only to take four master-level electives to complete the program. This allows a student to graduate with both degrees on either a five-year track, or a six-year track with an additional co-op experience.In addition, the College partners with other colleges at Northeastern to offer several joint degrees, such as combining Computer Science with Journalism, Game Design or Interactive Media.


==== Information science ====
Information science—the interdisciplinary study of how humans use information technology—combines a technical understanding of computer science and system design with the behavior context of the social sciences. Coursework covers the fields of information architecture, information system design and development, programming design, database design, and social informatics, among others. A two-semester senior capstone project, designed to integrate the many skill sets developed in the program, is required. Currently, only the B.S. of Information Science is offered, though it may be offered in conjunction with another degree.


=== Graduate degrees ===
Khoury College offers both Master of Science and doctoral degrees. In 2018, Khoury College's graduate program in computer science was ranked 49th in the list of the ""Best Computer Science Graduate Schools."" The publication also ranked the graduate program 12th on its list of ""Best Programming Language Programs.""


==== Master's degrees ====
Khoury College offers the following master's degrees:

MS in Computer Science
Align MS in Computer Science (for people who did not study computer science as undergrads)
MS in Cybersecurity
MS in Data Science
MS in Artificial Intelligence
MS in Robotics
MS in Health Informatics
MS in Health Data Analytics
MS in Game Science and DesignCandidates for the MS in Computer Science can choose from the following concentrations:
Artificial intelligence
Human–computer interaction
Database management
Graphics
Information security
Networks
Programming languages
Software engineering
Systems
TheoryKhoury College began offering the M.S. in Information Assurance (now the MS in Cybersecurity) in 2006, for which it has gained recognition by the National Security Agency as both a National Center of Academic Excellence in Information Assurance Education and Center of Academic Excellence in Information Assurance Research. Masters candidates take coursework addressing the various technical, policy, and criminal justice-related issues involved in information assurance, preparing them for careers as corporate and government information executives. Full-time candidates for the M.S. in Cybersecurity typically finish the program in two years, with 32 semester hours required to earn the degree.


==== PhD program ====
The PhD program prepares students for research careers in government, industry, or academia. Candidates are required to take coursework in computer systems, principles of programming languages, advanced algorithms, and computation theory. Electives in these and other subjects are also available. Candidates are given a maximum of five years to complete this coursework and their doctoral thesis. Khoury College offers four PhD programs:

PhD in Computer Science
PhD in Network Science
PhD in Information Assurance
PhD in Personal Health InformaticsIn the 2011–2012 school year, the information assurance program began offering the Ph.D in Information Assurance, designed to be an interdisciplinary program with a focus on information assurance policy and research. Candidates for this doctoral degree take a core curriculum of computer networking, network security, hardware and software security, information security risk management, and information assurance policy. Elective coursework is then taken in one of three areas of concentration (or ""tracks""), namely:

Network/Communication Security
System Security
Policy/SocietyCandidates for the PhD in Information Assurance have a maximum of five years to complete their required coursework and doctoral thesis.The PhD in Personal Health Informatics is an interdisciplinary Doctoral Program in Personal Health Informatics prepares researchers to design and evaluate technologies that improve health and wellness with the potential to transform healthcare. The joint degree program combines a strong curriculum in human-computer interface technology and experimental design in health sciences.


== Student groups ==
The following student groups and organizations are part of the Khoury College community:

Association for Computing Machinery (ACM)[1]
Computer Science Mentoring Organization (CoSMO)
Undergraduate Experimental Systems Group (Crew), a volunteer student group supporting the Khoury IT systems staff
Upsilon Pi Epsilon Honor Society (UPE)
Northeastern University Women in Technology (NUWiT)
Northeastern Game Development Club [2]
Information Systems Security Association[3]
Out in Science, Technology, Engineering, and Mathematics (oSTEM)[4][5]
Northeastern University DATA ClubStudents of the college also participate in a variety of information security competitions, most notably the National Collegiate Cyber Defense Competition. The College's team won its regional qualifier, the Northeast Collegiate Cyber Defense Competition (""NECCDC""), in 2009, and took first place at the national competition in 2010. Khoury College was host to the Northeast Collegiate Cyber Defense Competition in 2011.


== Cooperative education within Khoury College ==
Students at Khoury College have the option of participating in Northeastern's Cooperative Education Program (""co-op program""). The co-op program allows students to take semester-long internships with public and private-sector organizations, exposing them to the real world application of the skills and knowledge taught in their academic major. Nearly two-thirds of Khoury College's graduating students are offered full-time positions by the companies for at which they worked a co-op.Companies that participate in this program range from small startups to large enterprises including Google, Microsoft, John Hancock, and Amazon.com. The college has been able to achieve 100% placement in the past 7 years for all students who choose to go on 5-year co-op program.


== Key people ==
Carla Brodley, Professor, Dean of Inclusive Computing, Northeastern University
Matthias Felleisen, Trustee Professor
William Clinger, Associate Professor Emeritus
David Lazer, Distinguished Professor
Albert-László Barabási, Distinguished Professor
Alessandro Vespignani, Distinguished Professor
Renée Miller, Distinguished Professor


== References ==


== External links ==
Khoury College of Computer Sciences website
Northeastern University website"
3725813a24,Inheritance (object-oriented programming),"In object-oriented programming, inheritance is the mechanism of basing an object or class upon another object (prototype-based inheritance) or class (class-based inheritance), retaining similar implementation. Also defined as deriving new classes (sub classes) from existing ones such as super class or base class and then forming them into a hierarchy of classes. In most class-based object-oriented languages, an object created through inheritance, a ""child object"", acquires all the properties and behaviors of the ""parent object"" , with the exception of: constructors, destructor, overloaded operators and friend functions of the base class. Inheritance allows programmers to create classes that are built upon existing classes, to specify a new implementation while maintaining the same behaviors (realizing an interface), to reuse code and to independently extend original software via public classes and interfaces. The relationships of objects or classes through inheritance give rise to a directed acyclic graph.
An inherited class is called a subclass of its parent class or super class. The term ""inheritance"" is loosely used for both class-based and prototype-based programming, but in narrow use the term is reserved for class-based programming (one class inherits from another), with the corresponding technique in prototype-based programming being instead called delegation (one object delegates to another). Class-modifying inheritance patterns can be pre-defined according to simple network interface parameters such that inter-language compatibility is preserved.Inheritance should not be confused with subtyping. In some languages inheritance and subtyping agree, whereas in others they differ; in general, subtyping establishes an is-a relationship, whereas inheritance only reuses implementation and establishes a syntactic relationship, not necessarily a semantic relationship (inheritance does not ensure behavioral subtyping). To distinguish these concepts, subtyping is sometimes referred to as interface inheritance (without acknowledging that the specialization of type variables also induces a subtyping relation), whereas inheritance as defined here is known as implementation inheritance or code inheritance. Still, inheritance is a commonly used mechanism for establishing subtype relationships.Inheritance is contrasted with object composition, where one object contains another object (or objects of one class contain objects of another class); see composition over inheritance. Composition implements a has-a relationship, in contrast to the is-a relationship of subtyping.


== History ==
In 1966, Tony Hoare presented some remarks on records, and in particular presented the idea of record subclasses, record types with common properties but discriminated by a variant tag and having fields private to the variant. Influenced by this, in 1967 Ole-Johan Dahl and Kristen Nygaard presented a design that allowed specifying objects that belonged to different classes but had common properties. The common properties were collected in a superclass, and each superclass could itself potentially have a superclass. The values of a subclass were thus compound objects, consisting of some number of prefix parts belonging to various superclasses, plus a main part belonging to the subclass. These parts were all concatenated together. The attributes of a compound object would be accessible by dot notation. This idea was first adopted in the Simula 67 programming language. The idea then spread to Smalltalk, C++, Java, Python, and many other languages.


== Types ==

There are various types of inheritance, based on paradigm and specific language.
Single inheritance
where subclasses inherit the features of one superclass. A class acquires the properties of another class.
Multiple inheritance
where one class can have more than one superclass and inherit features from all parent classes.
""Multiple inheritance ... was widely supposed to be very difficult to implement efficiently. For example, in a summary of C++ in his book on Objective C, Brad Cox actually claimed that adding multiple inheritance to C++ was impossible. Thus, multiple inheritance seemed more of a challenge. Since I had considered multiple inheritance as early as 1982 and found a simple and efficient implementation technique in 1984, I couldn't resist the challenge. I suspect this to be the only case in which fashion affected the sequence of events.""
Multilevel inheritance
where a subclass is inherited from another subclass. It is not uncommon that a class is derived from another derived class as shown in the figure ""Multilevel inheritance"".

The class A serves as a base class for the derived class B, which in turn serves as a base class for the derived class C. The class B is known as intermediate base class because it provides a link for the inheritance between A and C. The chain ABC is known as inheritance path.
A derived class with multilevel inheritance is declared as follows:

This process can be extended to any number of levels.
Hierarchical inheritance
This is where one class serves as a superclass (base class) for more than one sub class. For example, a parent class, A, can have two subclasses B and C. Both B and C's parent class is A, but B and C are two separate subclasses.
Hybrid inheritance
Hybrid inheritance is when a mix of two or more of the above types of inheritance occurs. An example of this is when class A has a subclass B which has two subclasses, C and D. This is a mixture of both multilevel inheritance and hierarchal inheritance.


== Subclasses and superclasses ==
Subclasses, derived classes, heir classes, or child classes are modular derivative classes that inherits one or more language entities from one or more other classes (called superclass, base classes, or parent classes). The semantics of class inheritance vary from language to language, but commonly the subclass automatically inherits the instance variables and member functions of its superclasses.
The general form of defining a derived class is:

The colon indicates that the subclass inherits from the superclass. The visibility is optional and, if present, may be either private or public. The default visibility is private. Visibility specifies whether the features of the base class are privately derived or publicly derived.Some languages support also the inheritance of other constructs. For example, in Eiffel, contracts that define the specification of a class are also inherited by heirs. The superclass establishes a common interface and foundational functionality, which specialized subclasses can inherit, modify, and supplement. The software inherited by a subclass is considered reused in the subclass. A reference to an instance of a class may actually be referring to one of its subclasses. The actual class of the object being referenced is impossible to predict at compile-time. A uniform interface is used to invoke the member functions of objects of a number of different classes. Subclasses may replace superclass functions with entirely new functions that must share the same method signature.


=== Non-subclassable classes ===
In some languages a class may be declared as non-subclassable by adding certain class modifiers to the class declaration. Examples include the final keyword in Java and C++11 onwards or the sealed keyword in C#. Such modifiers are added to the class declaration before the class keyword and the class identifier declaration. Such non-subclassable classes restrict reusability, particularly when developers only have access to precompiled binaries and not source code.
A non-subclassable class has no subclasses, so it can be easily deduced at compile time that references or pointers to objects of that class are actually referencing instances of that class and not instances of subclasses (they don't exist) or instances of superclasses (upcasting a reference type violates the type system). Because the exact type of the object being referenced is known before execution, early binding (also called static dispatch) can be used instead of late binding (also called dynamic dispatch), which requires one or more virtual method table lookups depending on whether multiple inheritance or only single inheritance are supported in the programming language that is being used.


=== Non-overridable methods ===
Just as classes may be non-subclassable, method declarations may contain method modifiers that prevent the method from being overridden (i.e. replaced with a new function with the same name and type signature in a subclass). A private method is un-overridable simply because it is not accessible by classes other than the class it is a member function of (this is not true for C++, though). A final method in Java, a sealed method in C# or a frozen feature in Eiffel cannot be overridden.


=== Virtual methods ===
If the superclass method is a virtual method, then invocations of the superclass method will be dynamically dispatched. Some languages require that methods be specifically declared as virtual (e.g. C++), and in others, all methods are virtual (e.g. Java). An invocation of a non-virtual method will always be statically dispatched (i.e. the address of the function call is determined at compile-time). Static dispatch is faster than dynamic dispatch and allows optimizations such as inline expansion.


== Visibility of inherited members ==
The following table shows which variables and functions get inherited dependent on the visibility given when deriving the class, using the terminology established by C++.


== Applications ==
Inheritance is used to co-relate two or more classes to each other. 


=== Overriding ===

Many object-oriented programming languages permit a class or object to replace the implementation of an aspect—typically a behavior—that it has inherited. This process is called overriding. Overriding introduces a complication: which version of the behavior does an instance of the inherited class use—the one that is part of its own class, or the one from the parent (base) class? The answer varies between programming languages, and some languages provide the ability to indicate that a particular behavior is not to be overridden and should behave as defined by the base class. For instance, in C#, the base method or property can only be overridden in a subclass if it is marked with the virtual, abstract, or override modifier, while in programming languages such as Java, different methods can be called to override other methods. An alternative to overriding is hiding the inherited code.


=== Code reuse ===
Implementation inheritance is the mechanism whereby a subclass re-uses code in a base class. By default the subclass retains all of the operations of the base class, but the subclass may override some or all operations, replacing the base-class implementation with its own.
In the following Python example, subclasses SquareSumComputer and CubeSumComputer override the transform() method of the base class SumComputer. The base class comprises operations to compute the sum of the squares between two integers. The subclass re-uses all of the functionality of the base class with the exception of the operation that transforms a number into its square, replacing it with an operation that transforms a number into its square and cube respectively. The subclasses therefore compute the sum of the squares/cubes between two integers.
Below is an example of Python.

In most quarters, class inheritance for the sole purpose of code reuse has fallen out of favor. The primary concern is that implementation inheritance does not provide any assurance of polymorphic substitutability—an instance of the reusing class cannot necessarily be substituted for an instance of the inherited class. An alternative technique, explicit delegation, requires more programming effort, but avoids the substitutability issue. In C++ private inheritance can be used as a form of implementation inheritance without substitutability. Whereas public inheritance represents an ""is-a"" relationship and delegation represents a ""has-a"" relationship, private (and protected) inheritance can be thought of as an ""is implemented in terms of"" relationship.Another frequent use of inheritance is to guarantee that classes maintain a certain common interface; that is, they implement the same methods. The parent class can be a combination of implemented operations and operations that are to be implemented in the child classes. Often, there is no interface change between the supertype and subtype- the child implements the behavior described instead of its parent class.


== Inheritance vs subtyping ==

Inheritance is similar to but distinct from subtyping.
Subtyping enables a given type to be substituted for another type or abstraction, and is said to establish an is-a relationship between the subtype and some existing abstraction, either implicitly or explicitly, depending on language support. The relationship can be expressed explicitly via inheritance in languages that support inheritance as a subtyping mechanism. For example, the following C++ code establishes an explicit inheritance relationship between classes B and A, where B is both a subclass and a subtype of A, and can be used as an A wherever a B is specified (via a reference, a pointer or the object itself).

In programming languages that do not support inheritance as a subtyping mechanism, the relationship between a base class and a derived class is only a relationship between implementations (a mechanism for code reuse), as compared to a relationship between types. Inheritance, even in programming languages that support inheritance as a subtyping mechanism, does not necessarily entail behavioral subtyping. It is entirely possible to derive a class whose object will behave incorrectly when used in a context where the parent class is expected; see the Liskov substitution principle.
 (Compare connotation/denotation.) In some OOP languages, the notions of code reuse and subtyping coincide because the only way to declare a subtype is to define a new class that inherits the implementation of another.


=== Design constraints ===
Using inheritance extensively in designing a program imposes certain constraints.
For example, consider a class Person that contains a person's name, date of birth, address and phone number. We can define a subclass of Person called Student that contains the person's grade point average and classes taken, and another subclass of Person called Employee that contains the person's job-title, employer, and salary.
In defining this inheritance hierarchy we have already defined certain restrictions, not all of which are desirable:

Singleness
Using single inheritance, a subclass can inherit from only one superclass. Continuing the example given above, a Person object can be either a Student or an Employee, but not both. Using multiple inheritance partially solves this problem, as one can then define a StudentEmployee class that inherits from both Student and Employee. However, in most implementations, it can still inherit from each superclass only once, and thus, does not support cases in which a student has two jobs or attends two institutions. The inheritance model available in Eiffel makes this possible through support for repeated inheritance.
Static
The inheritance hierarchy of an object is fixed at instantiation when the object's type is selected and does not change with time. For example, the inheritance graph does not allow a Student object to become an Employee object while retaining the state of its Person superclass. (This kind of behavior, however, can be achieved with the decorator pattern.) Some have criticized inheritance, contending that it locks developers into their original design standards.
Visibility
Whenever client code has access to an object, it generally has access to all the object's superclass data. Even if the superclass has not been declared public, the client can still cast the object to its superclass type. For example, there is no way to give a function a pointer to a Student's grade point average and transcript without also giving that function access to all of the personal data stored in the student's Person superclass. Many modern languages, including C++ and Java, provide a ""protected"" access modifier that allows subclasses to access the data, without allowing any code outside the chain of inheritance to access it.The composite reuse principle is an alternative to inheritance. This technique supports polymorphism and code reuse by separating behaviors from the primary class hierarchy and including specific behavior classes as required in any business domain class. This approach avoids the static nature of a class hierarchy by allowing behavior modifications at run time and allows one class to implement behaviors buffet-style, instead of being restricted to the behaviors of its ancestor classes.


== Issues and alternatives ==
Implementation inheritance is controversial among programmers and theoreticians of object-oriented programming since at least the 1990s. Among them are the authors of Design Patterns, who advocate interface inheritance instead, and favor composition over inheritance. For example, the decorator pattern (as mentioned above) has been proposed to overcome the static nature of inheritance between classes. As a more fundamental solution to the same problem, role-oriented programming introduces a distinct relationship, played-by, combining properties of inheritance and composition into a new concept.According to Allen Holub, the main problem with implementation inheritance is that it introduces unnecessary coupling in the form of the ""fragile base class problem"": modifications to the base class implementation can cause inadvertent behavioral changes in subclasses. Using interfaces avoids this problem because no implementation is shared, only the API. Another way of stating this is that ""inheritance breaks encapsulation"". The problem surfaces clearly in open object-oriented systems such as frameworks, where client code is expected to inherit from system-supplied classes and then substituted for the system's classes in its algorithms.Reportedly, Java inventor James Gosling has spoken against implementation inheritance, stating that he would not include it if he were to redesign Java. Language designs that decouple inheritance from subtyping (interface inheritance) appeared as early as 1990; a modern example of this is the Go programming language.
Complex inheritance, or inheritance used within an insufficiently mature design, may lead to the yo-yo problem.  When inheritance was used as a primary approach to structure programs in the late 1990s, developers tended to break code into more layers of inheritance as the system functionality grew.  If a development team combined multiple layers of inheritance with the single responsibility principle, this resulted in many very thin layers of code, with many layers consisting of only 1 or 2 lines of actual code.  Too many layers make debugging a significant challenge, as it becomes hard to determine which layer needs to be debugged.
Another issue with inheritance is that subclasses must be defined in code, which means that program users cannot add new subclasses at runtime. Other design patterns (such as Entity–component–system) allow program users to define variations of an entity at runtime.


== See also ==
Archetype pattern
Circle–ellipse problem
Defeasible reasoning – Reasoning that is rationally compelling, though not deductively valid
Interface (computing) – Concept of computer science; point of interaction between two things
Method overriding – Language feature in object-oriented programming
Mixin – programming conceptPages displaying wikidata descriptions as a fallback
Polymorphism (computer science) – Using one interface or symbol with regards to multiple different types
Protocol – structure type in object-oriented programmingPages displaying wikidata descriptions as a fallback
Role-oriented programming – Programming paradigm based on conceptual understanding of objects
Trait (computer programming) – Concept used in object-oriented programming
Virtual inheritance – in object-oriented programming, inheritance in which the superclass object is accessed through an additional layer of indirection, such that in diamond-shaped multiple inheritance, the common superclass appears only oncePages displaying wikidata descriptions as a fallback


== Notes ==


== References ==


== Further reading ==
Meyer, Bertrand (1997). ""24. Using Inheritance Well"". Object-Oriented Software Construction (2nd ed.). Prentice Hall. ISBN 0-13-629155-4.
Samokhin, Vadim (2017). ""Implementation Inheritance Is Evil"". HackerNoon. Medium."
cd96137df3,Unification (computer science),"In logic and computer science, unification is an algorithmic process of solving equations between symbolic expressions.
Depending on which expressions (also called terms) are allowed to occur in an equation set (also called unification problem), and which expressions are considered equal, several frameworks of unification are distinguished. If higher-order variables, that is, variables representing functions, are allowed in an expression, the process is called higher-order unification, otherwise first-order unification. If a solution is required to make both sides of each equation literally equal, the process is called syntactic or free unification, otherwise semantic or equational unification, or E-unification, or unification modulo theory.
A solution of a unification problem is denoted as a substitution, that is, a mapping assigning a symbolic value to each variable of the problem's expressions. A unification algorithm should compute for a given problem a complete and minimal substitution set, i.e., a set containing all of the problem's solutions and no redundant members. Depending on the framework, a complete and minimal substitution set may have at most one, at most finitely many, or possibly infinitely many members, or may not exist at all. In some frameworks it is generally impossible to decide whether any solution exists. For first-order syntactical unification, Martelli and Montanari gave an algorithm that reports unsolvability or computes a complete and minimal singleton substitution set containing the so-called most general unifier.
For example, using x,y,z as variables, the singleton equation set { cons(x,cons(x,nil)) = cons(2,y) } is a syntactic first-order unification problem that has the substitution { x ↦ 2, y ↦ cons(2,nil) } as its only solution.
The syntactic first-order unification problem { y = cons(2,y) } has no solution over the set of finite terms; however, it has the single solution { y ↦ cons(2,cons(2,cons(2,...))) } over the set of infinite trees.
The semantic first-order unification problem { a⋅x = x⋅a } has each substitution of the form { x ↦ a⋅...⋅a } as a solution in a semigroup, i.e. if (⋅) is considered associative; the same problem, viewed in an abelian group, where  (⋅) is considered also commutative, has any substitution at all as a solution.
The singleton set { a = y(x) } is a syntactic second-order unification problem, since y is a function variable.
One solution is { x ↦ a, y ↦ (identity function) }; another one is { y ↦ (constant function mapping each value to a), x ↦ (any value) }.
A unification algorithm was first discovered by Jacques Herbrand, while a first formal investigation can be attributed to John Alan Robinson, who used first-order syntactical unification as a basic building block of his resolution procedure for first-order logic, a great step forward in automated reasoning technology, as it eliminated one source of combinatorial explosion: searching for instantiation of terms. Today, automated reasoning is still the main application area of unification.
Syntactical first-order unification is used in logic programming and programming language type system implementation, especially in Hindley–Milner based type inference algorithms.
Semantic unification is used in SMT solvers, term rewriting algorithms and cryptographic protocol analysis.
Higher-order unification is used in proof assistants, for example Isabelle and Twelf, and restricted forms of higher-order unification (higher-order pattern unification) are used in some programming language implementations, such as lambdaProlog, as higher-order patterns are expressive, yet their associated unification procedure retains theoretical properties closer to first-order unification.


== Formal definition ==


=== Prerequisites ===
Formally, a unification approach presupposes

An infinite set 
  
    
      
        V
      
    
    {\displaystyle V}
   of variables. For higher-order unification, it is convenient to choose 
  
    
      
        V
      
    
    {\displaystyle V}
   disjoint from the set of lambda-term bound variables.
A set 
  
    
      
        T
      
    
    {\displaystyle T}
   of terms such that 
  
    
      
        V
        ⊆
        T
      
    
    {\displaystyle V\subseteq T}
  . For first-order unification, 
  
    
      
        T
      
    
    {\displaystyle T}
   is usually the set of first-order terms (terms built from variable and function symbols).  For higher-order unification 
  
    
      
        T
      
    
    {\displaystyle T}
   consists of first-order terms and lambda terms (terms containing some higher-order variables).
A mapping vars: 
  
    
      
        T
        →
      
    
    {\displaystyle T\rightarrow }
   
  
    
      
        
          P
        
      
    
    {\displaystyle \mathbb {P} }
  
  
    
      
        (
        V
        )
      
    
    {\displaystyle (V)}
  , assigning to each term 
  
    
      
        t
      
    
    {\displaystyle t}
   the set 
  
    
      
        
          vars
        
        (
        t
        )
        ⊊
        V
      
    
    {\displaystyle {\text{vars}}(t)\subsetneq V}
   of free variables occurring in 
  
    
      
        t
      
    
    {\displaystyle t}
  .
An equivalence relation 
  
    
      
        ≡
      
    
    {\displaystyle \equiv }
   on 
  
    
      
        T
      
    
    {\displaystyle T}
  , indicating which terms are considered equal. For first-order E-unification, 
  
    
      
        ≡
      
    
    {\displaystyle \equiv }
   reflects the background knowledge about certain function symbols; for example, if 
  
    
      
        ⊕
      
    
    {\displaystyle \oplus }
   is considered commutative, 
  
    
      
        t
        ≡
        u
      
    
    {\displaystyle t\equiv u}
   if 
  
    
      
        u
      
    
    {\displaystyle u}
   results from 
  
    
      
        t
      
    
    {\displaystyle t}
   by swapping the arguments of 
  
    
      
        ⊕
      
    
    {\displaystyle \oplus }
   at some (possibly all) occurrences.  In the most typical case that there is no background knowledge at all, then only literally, or syntactically, identical terms are considered equal. In this case, ≡ is called the free theory (because it is a free object), the empty theory (because the set of equational sentences, or the background knowledge, is empty), the theory of uninterpreted functions (because unification is done on uninterpreted terms), or the theory of constructors (because all function symbols just build up data terms, rather than operating on them). For higher-order unification, usually 
  
    
      
        t
        ≡
        u
      
    
    {\displaystyle t\equiv u}
   if 
  
    
      
        t
      
    
    {\displaystyle t}
   and 
  
    
      
        u
      
    
    {\displaystyle u}
   are alpha equivalent.


=== Substitution ===

A substitution is a mapping 
  
    
      
        σ
        :
        V
        →
        T
      
    
    {\displaystyle \sigma :V\rightarrow T}
   from variables to terms; the notation 
  
    
      
        {
        
          x
          
            1
          
        
        ↦
        
          t
          
            1
          
        
        ,
        .
        .
        .
        ,
        
          x
          
            k
          
        
        ↦
        
          t
          
            k
          
        
        }
      
    
    {\displaystyle \{x_{1}\mapsto t_{1},...,x_{k}\mapsto t_{k}\}}
   refers to a substitution mapping each variable 
  
    
      
        
          x
          
            i
          
        
      
    
    {\displaystyle x_{i}}
   to the term 
  
    
      
        
          t
          
            i
          
        
      
    
    {\displaystyle t_{i}}
  , for 
  
    
      
        i
        =
        1
        ,
        .
        .
        .
        ,
        k
      
    
    {\displaystyle i=1,...,k}
  , and every other variable to itself. Applying that substitution to a term 
  
    
      
        t
      
    
    {\displaystyle t}
   is written in postfix notation as 
  
    
      
        t
        {
        
          x
          
            1
          
        
        ↦
        
          t
          
            1
          
        
        ,
        .
        .
        .
        ,
        
          x
          
            k
          
        
        ↦
        
          t
          
            k
          
        
        }
      
    
    {\displaystyle t\{x_{1}\mapsto t_{1},...,x_{k}\mapsto t_{k}\}}
  ; it means to (simultaneously) replace every occurrence of each variable 
  
    
      
        
          x
          
            i
          
        
      
    
    {\displaystyle x_{i}}
   in the term 
  
    
      
        t
      
    
    {\displaystyle t}
   by 
  
    
      
        
          t
          
            i
          
        
      
    
    {\displaystyle t_{i}}
  . The result 
  
    
      
        t
        τ
      
    
    {\displaystyle t\tau }
   of applying a substitution 
  
    
      
        τ
      
    
    {\displaystyle \tau }
   to a term 
  
    
      
        t
      
    
    {\displaystyle t}
   is called an instance of that term 
  
    
      
        t
      
    
    {\displaystyle t}
  .
As a first-order example, applying the substitution { x ↦ h(a,y), z ↦ b } to the term 


=== Generalization, specialization ===
If a term 
  
    
      
        t
      
    
    {\displaystyle t}
   has an instance equivalent to a term 
  
    
      
        u
      
    
    {\displaystyle u}
  , that is, if 
  
    
      
        t
        σ
        ≡
        u
      
    
    {\displaystyle t\sigma \equiv u}
   for some substitution 
  
    
      
        σ
      
    
    {\displaystyle \sigma }
  , then 
  
    
      
        t
      
    
    {\displaystyle t}
   is called more general than 
  
    
      
        u
      
    
    {\displaystyle u}
  , and 
  
    
      
        u
      
    
    {\displaystyle u}
   is called more special than, or subsumed by, 
  
    
      
        t
      
    
    {\displaystyle t}
  . For example, 
  
    
      
        x
        ⊕
        a
      
    
    {\displaystyle x\oplus a}
   is more general than 
  
    
      
        a
        ⊕
        b
      
    
    {\displaystyle a\oplus b}
   if ⊕ is commutative, since then 
  
    
      
        (
        x
        ⊕
        a
        )
        {
        x
        ↦
        b
        }
        =
        b
        ⊕
        a
        ≡
        a
        ⊕
        b
      
    
    {\displaystyle (x\oplus a)\{x\mapsto b\}=b\oplus a\equiv a\oplus b}
  .
If ≡ is literal (syntactic) identity of terms, a term may be both more general and more special than another one only if both terms differ just in their variable names, not in their syntactic structure; such terms are called variants, or renamings of each other.
For example, 

  
    
      
        f
        (
        
          x
          
            1
          
        
        ,
        a
        ,
        g
        (
        
          z
          
            1
          
        
        )
        ,
        
          y
          
            1
          
        
        )
      
    
    {\displaystyle f(x_{1},a,g(z_{1}),y_{1})}
  
is a variant of 

  
    
      
        f
        (
        
          x
          
            2
          
        
        ,
        a
        ,
        g
        (
        
          z
          
            2
          
        
        )
        ,
        
          y
          
            2
          
        
        )
      
    
    {\displaystyle f(x_{2},a,g(z_{2}),y_{2})}
  ,
since

and

However, 
  
    
      
        f
        (
        
          x
          
            1
          
        
        ,
        a
        ,
        g
        (
        
          z
          
            1
          
        
        )
        ,
        
          y
          
            1
          
        
        )
      
    
    {\displaystyle f(x_{1},a,g(z_{1}),y_{1})}
   is not a variant of  
  
    
      
        f
        (
        
          x
          
            2
          
        
        ,
        a
        ,
        g
        (
        
          x
          
            2
          
        
        )
        ,
        
          x
          
            2
          
        
        )
      
    
    {\displaystyle f(x_{2},a,g(x_{2}),x_{2})}
  , since no substitution can transform the latter term into the former one.
The latter term is therefore properly more special than the former one.
For arbitrary 
  
    
      
        ≡
      
    
    {\displaystyle \equiv }
  , a term may be both more general and more special than a structurally different term.
For example, if ⊕ is idempotent, that is, if always 
  
    
      
        x
        ⊕
        x
        ≡
        x
      
    
    {\displaystyle x\oplus x\equiv x}
  , then the term 
  
    
      
        x
        ⊕
        y
      
    
    {\displaystyle x\oplus y}
   is more general than 
  
    
      
        z
      
    
    {\displaystyle z}
  , and vice versa, although 
  
    
      
        x
        ⊕
        y
      
    
    {\displaystyle x\oplus y}
   and 
  
    
      
        z
      
    
    {\displaystyle z}
   are of different structure.
A substitution 
  
    
      
        σ
      
    
    {\displaystyle \sigma }
   is more special than, or subsumed by, a substitution 
  
    
      
        τ
      
    
    {\displaystyle \tau }
   if 
  
    
      
        t
        σ
      
    
    {\displaystyle t\sigma }
   is more special than 
  
    
      
        t
        τ
      
    
    {\displaystyle t\tau }
   for each term 
  
    
      
        t
      
    
    {\displaystyle t}
  .  We also say that 
  
    
      
        τ
      
    
    {\displaystyle \tau }
   is more general than 
  
    
      
        σ
      
    
    {\displaystyle \sigma }
  .
For instance 
  
    
      
        {
        x
        ↦
        a
        ,
        y
        ↦
        a
        }
      
    
    {\displaystyle \{x\mapsto a,y\mapsto a\}}
   is more special than 
  
    
      
        τ
        =
        {
        x
        ↦
        y
        }
      
    
    {\displaystyle \tau =\{x\mapsto y\}}
  ,
but 

  
    
      
        σ
        =
        {
        x
        ↦
        a
        }
      
    
    {\displaystyle \sigma =\{x\mapsto a\}}
   is not,
as 
  
    
      
        f
        (
        x
        ,
        y
        )
        σ
        =
        f
        (
        a
        ,
        y
        )
      
    
    {\displaystyle f(x,y)\sigma =f(a,y)}
   is not more special than

  
    
      
        f
        (
        x
        ,
        y
        )
        τ
        =
        f
        (
        y
        ,
        y
        )
      
    
    {\displaystyle f(x,y)\tau =f(y,y)}
  .


=== Unification problem, solution set ===
A unification problem is a finite set { l1 ≐ r1, ..., ln ≐ rn } of potential equations, where li, ri ∈ T.
A substitution σ is a solution of that problem if liσ ≡ riσ for 
  
    
      
        i
        =
        1
        ,
        .
        .
        .
        ,
        n
      
    
    {\displaystyle i=1,...,n}
  . Such a substitution is also called a unifier of the unification problem.
For example, if ⊕ is associative, the unification problem { x ⊕ a ≐ a ⊕ x } has the solutions {x ↦ a}, {x ↦ a ⊕ a}, {x ↦ a ⊕ a ⊕ a}, etc., while the problem { x ⊕ a ≐ a } has no solution.
For a given unification problem, a set S of unifiers is called complete if each solution substitution is subsumed by some substitution σ ∈ S; the set S is called minimal if none of its members subsumes another one.


== Syntactic unification of first-order terms ==

Syntactic unification of first-order terms is the most widely used unification framework.
It is based on T being the set of first-order terms (over some given set V of variables, C of constants and Fn of n-ary function symbols) and on ≡ being syntactic equality.
In this framework, each solvable unification problem {l1 ≐ r1, ..., ln ≐ rn} has a complete, and obviously minimal, singleton solution set {σ}.
Its member σ is called the most general unifier (mgu) of the problem.
The terms on the left and the right hand side of each potential equation become syntactically equal when the mgu is applied i.e. l1σ = r1σ ∧ ... ∧ lnσ = rnσ.
Any unifier of the problem is subsumed by the mgu σ.
The mgu is unique up to variants: if S1 and S2 are both complete and minimal solution sets of the same syntactical unification problem, then S1 = { σ1 } and S2 = { σ2 } for some substitutions σ1 and σ2, and xσ1 is a variant of xσ2 for each variable x occurring in the problem.
For example, the unification problem { x ≐ z, y ≐ f(x) } has a unifier { x ↦ z, y ↦ f(z) }, because

This is also the most general unifier.
Other unifiers for the same problem are e.g. { x ↦ f(x1), y ↦ f(f(x1)), z ↦ f(x1) }, { x ↦ f(f(x1)), y ↦ f(f(f(x1))), z ↦ f(f(x1)) }, and so on; there are infinitely many similar unifiers.
As another example, the problem g(x,x) ≐ f(y) has no solution with respect to ≡ being literal identity, since any substitution applied to the left and right hand side will keep the outermost g and f, respectively, and terms with different outermost function symbols are syntactically different.


=== A unification algorithm ===

The first algorithm given by Robinson (1965) was rather inefficient; cf. box.
The following faster algorithm originated from Martelli, Montanari (1982).
This paper also lists preceding attempts to find an efficient syntactical unification algorithm, and states that linear-time algorithms were discovered independently by Martelli, Montanari (1976) and Paterson, Wegman (1976, 1978).Given a finite set 
  
    
      
        G
        =
        {
        
          s
          
            1
          
        
        ≐
        
          t
          
            1
          
        
        ,
        .
        .
        .
        ,
        
          s
          
            n
          
        
        ≐
        
          t
          
            n
          
        
        }
      
    
    {\displaystyle G=\{s_{1}\doteq t_{1},...,s_{n}\doteq t_{n}\}}
   of potential equations,
the algorithm applies rules to transform it to an equivalent set of equations of the form
{ x1 ≐ u1, ..., xm ≐ um }
where x1, ..., xm are distinct variables and u1, ..., um are terms containing none of the xi.
A set of this form can be read as a substitution.
If there is no solution the algorithm terminates with ⊥; other authors use ""Ω"", ""{}"", or ""fail"" in that case.
The operation of substituting all occurrences of variable x in problem G with term t is denoted G {x ↦ t}.
For simplicity, constant symbols are regarded as function symbols having zero arguments.


==== Occurs check ====

An attempt to unify a variable x with a term containing x as a strict subterm x ≐ f(..., x, ...) would lead to an infinite term as solution for x, since x would occur as a subterm of itself.
In the set of (finite) first-order terms as defined above, the equation x ≐ f(..., x, ...) has no solution; hence the eliminate rule may only be applied if x ∉ vars(t).
Since that additional check, called occurs check, slows down the algorithm, it is omitted e.g. in most Prolog systems.
From a theoretical point of view, omitting the check amounts to solving equations over infinite trees, see #Unification of infinite terms below.


==== Proof of termination ====
For the proof of termination of the algorithm consider a triple 
  
    
      
        ⟨
        
          n
          
            v
            a
            r
          
        
        ,
        
          n
          
            l
            h
            s
          
        
        ,
        
          n
          
            e
            q
            n
          
        
        ⟩
      
    
    {\displaystyle \langle n_{var},n_{lhs},n_{eqn}\rangle }
  
where nvar is the number of variables that occur more than once in the equation set, nlhs is the number of function symbols and constants
on the left hand sides of potential equations, and neqn is the number of equations.
When rule eliminate is applied, nvar decreases, since x is eliminated from G and kept only in { x ≐ t }.
Applying any other rule can never increase nvar again.
When rule decompose, conflict, or swap is applied, nlhs decreases, since at least the left hand side's outermost f disappears.
Applying any of the remaining rules delete or check can't increase nlhs, but decreases neqn.
Hence, any rule application decreases the triple 
  
    
      
        ⟨
        
          n
          
            v
            a
            r
          
        
        ,
        
          n
          
            l
            h
            s
          
        
        ,
        
          n
          
            e
            q
            n
          
        
        ⟩
      
    
    {\displaystyle \langle n_{var},n_{lhs},n_{eqn}\rangle }
   with respect to the lexicographical order, which is possible only a finite number of times.
Conor McBride observes that ""by expressing the structure which unification exploits"" in a dependently typed language such as Epigram, Robinson's unification algorithm can be made recursive on the number of variables, in which case a separate termination proof becomes unnecessary.


=== Examples of syntactic unification of first-order terms ===
In the Prolog syntactical convention a symbol starting with an upper case letter is a variable name; a symbol that starts with a lowercase letter is a function symbol; the comma is used as the logical and operator.
For mathematical notation, x,y,z are used as variables, f,g as function symbols, and a,b as constants.

The most general unifier of a syntactic first-order unification problem of size n may have a size of 2n. For example, the problem 
  
    
      
        (
        (
        (
        a
        ∗
        z
        )
        ∗
        y
        )
        ∗
        x
        )
        ∗
        w
        ≐
        w
        ∗
        (
        x
        ∗
        (
        y
        ∗
        (
        z
        ∗
        a
        )
        )
        )
      
    
    {\displaystyle (((a*z)*y)*x)*w\doteq w*(x*(y*(z*a)))}
   has the most general unifier 
  
    
      
        {
        z
        ↦
        a
        ,
        y
        ↦
        a
        ∗
        a
        ,
        x
        ↦
        (
        a
        ∗
        a
        )
        ∗
        (
        a
        ∗
        a
        )
        ,
        w
        ↦
        (
        (
        a
        ∗
        a
        )
        ∗
        (
        a
        ∗
        a
        )
        )
        ∗
        (
        (
        a
        ∗
        a
        )
        ∗
        (
        a
        ∗
        a
        )
        )
        }
      
    
    {\displaystyle \{z\mapsto a,y\mapsto a*a,x\mapsto (a*a)*(a*a),w\mapsto ((a*a)*(a*a))*((a*a)*(a*a))\}}
  , cf. picture. In order to avoid exponential time complexity caused by such blow-up, advanced unification algorithms work on directed acyclic graphs (dags) rather than trees.


=== Application: unification in logic programming ===
The concept of unification is one of the main ideas behind logic programming, best known through the language Prolog. It represents the mechanism of binding the contents of variables and can be viewed as a kind of one-time assignment. In Prolog, this operation is denoted by the equality symbol =, but is also done when instantiating variables (see below). It is also used in other languages by the use of the equality symbol =, but also in conjunction with many operations including +, -, *, /. Type inference algorithms are typically based on unification.
In Prolog:

A variable which is uninstantiated—i.e. no previous unifications were performed on it—can be unified with an atom, a term, or another uninstantiated variable, thus effectively becoming its alias. In many modern Prolog dialects and in first-order logic, a variable cannot be unified with a term that contains it; this is the so-called occurs check.
Two atoms can only be unified if they are identical.
Similarly, a term can be unified with another term if the top function symbols and arities of the terms are identical and if the parameters can be unified simultaneously. Note that this is a recursive behavior.


=== Application: type inference ===
Unification is used during type inference for languages with type systems based on Hindley-Milner, including the functional languages Haskell and ML. On one hand, the programmer does not need to provide type information for every function, on the other hand it is used to detect typing errors. The Haskell expression True : ['x', 'y', 'z'] is not correctly typed. The list construction function (:) is of type a -> [a] -> [a], and for the first argument True the polymorphic type variable a has to be unified with True's type, Bool. The second argument, ['x', 'y', 'z'], is of type [Char], but a cannot be both Bool and Char at the same time.
Like for Prolog, an algorithm for type inference can be given:

Any type variable unifies with any type expression, and is instantiated to that expression.  A specific theory might restrict this rule with an occurs check.
Two type constants unify only if they are the same type.
Two type constructions unify only if they are applications of the same type constructor and all of their component types recursively unify.Due to its declarative nature, the order in a sequence of unifications is (usually) unimportant.
Note that in the terminology of first-order logic, an atom is a basic proposition and is unified similarly to a Prolog term.


=== Application: Feature Structure Unification ===

Unification has been used in different research areas of computational linguistics.


== Order-sorted unification ==
Order-sorted logic allows one to assign a sort, or type, to each term, and to declare a sort s1 a subsort of another sort s2, commonly written as s1 ⊆ s2. For example, when reаsoning about biological creatures, it is useful to declare a sort dog to be a subsort of a sort animal. Wherever a term of some sort s is required, a term of any subsort of s may be supplied instead.
For example, assuming a function declaration mother: animal → animal, and a constant declaration lassie: dog, the term  mother(lassie) is perfectly valid and has the sort animal. In order to supply the information that the mother of a dog is a dog in turn, another declaration mother: dog → dog may be issued; this is called function overloading, similar to overloading in programming languages.
Walther gave a unification algorithm for terms in order-sorted logic, requiring for any two declared sorts s1, s2 their intersection s1 ∩ s2 to be declared, too: if x1 and x2 is a variable of sort s1 and s2, respectively, the equation x1 ≐ x2 has the solution { x1 = x, x2 = x }, where x: s1 ∩ s2.

After incorporating this algorithm into a clause-based automated theorem prover, he could solve a benchmark problem by translating it into order-sorted logic, thereby boiling it down an order of magnitude, as many unary predicates turned into sorts.
Smolka generalized order-sorted logic to allow for parametric polymorphism.

In his framework, subsort declarations are propagated to complex type expressions.
As a programming example, a parametric sort list(X) may be declared (with X being a type parameter as in a C++ template), and from a subsort declaration int ⊆ float the relation list(int) ⊆ list(float) is automatically inferred, meaning that each list of integers is also a list of floats.
Schmidt-Schauß generalized order-sorted logic to allow for term declarations.

As an example, assuming subsort declarations even ⊆ int and odd ⊆ int, a term declaration like ∀ i : int. (i + i) : even allows to declare a property of integer addition that could not be expressed by ordinary overloading.


== Unification of infinite terms ==
Background on infinite trees:

B. Courcelle (1983). ""Fundamental Properties of Infinite Trees"". Theoret. Comput. Sci. 25 (2): 95–169. doi:10.1016/0304-3975(83)90059-2.
Michael J. Maher (Jul 1988). ""Complete Axiomatizations of the Algebras of Finite, Rational and Infinite Trees"". Proc. IEEE 3rd Annual Symp. on Logic in Computer Science, Edinburgh. pp. 348–357.
Joxan Jaffar; Peter J. Stuckey (1986). ""Semantics of Infinite Tree Logic Programming"". Theoretical Computer Science. 46: 141–158. doi:10.1016/0304-3975(86)90027-7.Unification algorithm, Prolog II:

A. Colmerauer (1982).  K.L. Clark; S.-A. Tarnlund (eds.). Prolog and Infinite Trees. Academic Press.
Alain Colmerauer (1984). ""Equations and Inequations on Finite and Infinite Trees"".  In ICOT (ed.). Proc. Int. Conf. on Fifth Generation Computer Systems. pp. 85–99.Applications:

Francis Giannesini; Jacques Cohen (1984). ""Parser Generation and Grammar Manipulation using Prolog's Infinite Trees"". Journal of Logic Programming. 1 (3): 253–265. doi:10.1016/0743-1066(84)90013-X.


== E-unification ==
E-unification is the problem of finding solutions to a given set of equations,
taking into account some equational background knowledge E.
The latter is given as a set of universal equalities.
For some particular sets E, equation solving algorithms (a.k.a. E-unification algorithms) have been devised;
for others it has been proven that no such algorithms can exist.
For example, if a and b are distinct constants,
the equation 
  
    
      
        x
        ∗
        a
        ≐
        y
        ∗
        b
      
    
    {\displaystyle x*a\doteq y*b}
   has no solution
with respect to purely syntactic unification,
where nothing is known about the operator 
  
    
      
        ∗
      
    
    {\displaystyle *}
  .
However, if the 
  
    
      
        ∗
      
    
    {\displaystyle *}
   is known to be commutative,
then the substitution {x ↦ b, y ↦ a} solves the above equation,
since

The background knowledge E could state the commutativity of 
  
    
      
        ∗
      
    
    {\displaystyle *}
   by the universal equality
""
  
    
      
        u
        ∗
        v
        =
        v
        ∗
        u
      
    
    {\displaystyle u*v=v*u}
   for all u, v"".


=== Particular background knowledge sets E ===
It is said that unification is decidable for a theory, if a unification algorithm has been devised for it that terminates for any input problem.
It is said that unification is semi-decidable for a theory, if a unification algorithm has been devised for it that terminates for any solvable input problem, but may keep searching forever for solutions of an unsolvable input problem.
Unification is decidable for the following theories:

A
A,C
A,C,I
A,C,Nl
A,I
A,Nl,Nr (monoid)
C
Boolean rings
Abelian groups, even if the signature is expanded by arbitrary additional symbols (but not axioms)
K4 modal algebrasUnification is semi-decidable for the following theories:

A,Dl,Dr
A,C,Dl
Commutative rings


=== One-sided paramodulation ===
If there is a convergent term rewriting system R available for E,
the one-sided paramodulation algorithm
can be used to enumerate all solutions of given equations.

Starting with G being the unification problem to be solved and S being the identity substitution, rules are applied nondeterministically until the empty set appears as the actual G, in which case the actual S is a unifying substitution. Depending on the order the paramodulation rules are applied, on the choice of the actual equation from G, and on the choice of R's rules in mutate, different computations paths are possible. Only some lead to a solution, while others end at a G ≠ {} where no further rule is applicable (e.g. G = { f(...) ≐ g(...) }).

For an example, a term rewrite system R is used defining the append operator of lists built from cons and nil; where cons(x,y) is written in infix notation as x.y for brevity; e.g. app(a.b.nil,c.d.nil) → a.app(b.nil,c.d.nil) → a.b.app(nil,c.d.nil) → a.b.c.d.nil demonstrates the concatenation of the lists a.b.nil and c.d.nil, employing the rewrite rule 2,2, and 1. The equational theory E corresponding to R is the congruence closure of R, both viewed as binary relations on terms.
For example, app(a.b.nil,c.d.nil) ≡ a.b.c.d.nil ≡ app(a.b.c.d.nil,nil). The paramodulation algorithm enumerates solutions to equations with respect to that E when fed with the example R.
A successful example computation path for the unification problem { app(x,app(y,x)) ≐ a.a.nil } is shown below. To avoid variable name clashes, rewrite rules are consistently renamed each time before their use by rule mutate; v2, v3, ... are computer-generated variable names for this purpose. In each line, the chosen equation from G is highlighted in red. Each time the mutate rule is applied, the chosen rewrite rule (1 or 2) is indicated in parentheses. From the last line, the unifying substitution S = { y ↦ nil, x ↦  a.nil } can be obtained. In fact,
app(x,app(y,x)) {y↦nil, x↦ a.nil } = app(a.nil,app(nil,a.nil)) ≡ app(a.nil,a.nil) ≡ a.app(nil,a.nil) ≡ a.a.nil solves the given problem.
A second successful computation path, obtainable by choosing ""mutate(1), mutate(2), mutate(2), mutate(1)"" leads to the substitution S = { y ↦ a.a.nil, x ↦ nil }; it is not shown here. No other path leads to a success.


=== Narrowing ===

If R is a convergent term rewriting system for E,
an approach alternative to the previous section consists in successive application of ""narrowing steps"";
this will eventually enumerate all solutions of a given equation.
A narrowing step (cf. picture) consists in

choosing a nonvariable subterm of the current term,
syntactically unifying it with the left hand side of a rule from R, and
replacing the instantiated rule's right hand side into the instantiated term.Formally, if l → r is a renamed copy of a rewrite rule from R, having no variables in common with a term s, and the subterm s|p is not a variable and is unifiable with l via the mgu σ, then s can be narrowed to the term t = sσ[rσ]p, i.e. to the term sσ, with the subterm at p replaced by rσ. The situation that s can be narrowed to t is commonly denoted as s ↝ t.
Intuitively, a sequence of narrowing steps t1 ↝ t2 ↝ ... ↝ tn can be thought of as a sequence of rewrite steps t1 → t2 → ... → tn, but with the initial term t1 being further and further instantiated, as necessary to make each of the used rules applicable.
The above example paramodulation computation corresponds to the following narrowing sequence (""↓"" indicating instantiation here):

The last term, v2.v2.nil can be syntactically unified with the original right hand side term a.a.nil.
The narrowing lemma ensures that whenever an instance of a term s can be rewritten to a term t by a convergent term rewriting system, then s and t can be narrowed and rewritten to a term s′ and t′, respectively, such that t′ is an instance of s′.
Formally: whenever sσ →∗ t holds for some substitution σ, then there exist terms s′, t′ such that s ↝∗ s′ and t →∗ t′ and s′ τ = t′ for some substitution τ.


== Higher-order unification ==
Many applications require one to consider the unification of typed lambda-terms instead of first-order terms.  Such unification is often called higher-order unification. Higher-order unification is undecidable, and such unification problems do not have most general unifiers. For example, the unification problem { f(a,  b, a) ≐ d(b, a, c) }, where the only variable is f, has the
solutions {f ↦ λx.λy.λz.d(y, x, c)  }, {f ↦ λx.λy.λz.d(y, z, c)  },
{f ↦ λx.λy.λz.d(y, a, c)  }, {f ↦ λx.λy.λz.d(b, x, c)  },
{f ↦ λx.λy.λz.d(b, z, c)  } and {f ↦ λx.λy.λz.d(b, a, c)  }. A well studied branch of higher-order unification is the problem of unifying simply typed lambda terms modulo the equality determined by αβη conversions. Gérard Huet gave a semi-decidable (pre-)unification algorithm that allows a systematic search of the space of unifiers (generalizing the unification algorithm of Martelli-Montanari with rules for terms containing higher-order variables) that seems to work sufficiently well in practice.  Huet and Gilles Dowek have written articles surveying this topic.
Several subsets of higher-order unification are well-behaved, in that they are decidable and have a most-general unifier for solvable problems. One such subset is the previously described first-order terms. Higher-order pattern unification, due to Dale Miller, is another such subset. The higher-order logic programming languages λProlog and Twelf have switched from full higher-order unification to implementing only the pattern fragment; surprisingly pattern unification is sufficient for almost all programs, if each non-pattern unification problem is suspended until a subsequent substitution puts the unification into the pattern fragment. A superset of pattern unification called functions-as-constructors unification is also well-behaved. The Zipperposition theorem prover has an algorithm integrating these well-behaved subsets into a full higher-order unification algorithm.In computational linguistics, one of the most influential theories of elliptical construction is that ellipses are represented by free variables whose values are then determined using Higher-Order Unification (HOU). For instance, the semantic representation of ""Jon likes Mary and Peter does too"" is   like(j, m) ∧ R(p)  and the value of R (the semantic representation of the ellipsis) is determined by the equation  like(j, m) = R(j)  . The process of solving such equations is called Higher-Order Unification.Wayne Snyder gave a generalization of both higher-order unification and E-unification, i.e. an algorithm to unify lambda-terms modulo an equational theory.


== See also ==
Rewriting
Admissible rule
Explicit substitution in lambda calculus
Mathematical equation solving
Dis-unification: solving inequations between symbolic expression
Anti-unification: computing a least general generalization (lgg) of two terms, dual to computing a most general instance (mgu)
Subsumption lattice, a lattice having unification as meet and anti-unification as join
Ontology alignment (use unification with semantic equivalence)


== Notes ==


== References ==


== Further reading ==
Franz Baader and Wayne Snyder (2001). ""Unification Theory"" Archived 2015-06-08 at the Wayback Machine. In John Alan Robinson and Andrei Voronkov, editors, Handbook of Automated Reasoning, volume I, pages 447–533. Elsevier Science Publishers.
Gilles Dowek (2001). ""Higher-order Unification and Matching"". In Handbook of Automated Reasoning.
Franz Baader and Tobias Nipkow (1998). Term Rewriting and All That. Cambridge University Press.
Franz Baader and Jörg H. Siekmann (1993). ""Unification Theory"". In Handbook of Logic in Artificial Intelligence and Logic Programming.
Jean-Pierre Jouannaud and Claude Kirchner (1991). ""Solving Equations in Abstract Algebras: A Rule-Based Survey of Unification"". In Computational Logic: Essays in Honor of Alan Robinson.
Nachum Dershowitz and Jean-Pierre Jouannaud, Rewrite Systems, in: Jan van Leeuwen (ed.), Handbook of Theoretical Computer Science, volume B Formal Models and Semantics, Elsevier, 1990, pp. 243–320
Jörg H. Siekmann (1990). ""Unification Theory"". In Claude Kirchner (editor) Unification. Academic Press.
Kevin Knight (Mar 1989). ""Unification: A Multidisciplinary Survey"" (PDF). ACM Computing Surveys. 21 (1): 93–124. CiteSeerX 10.1.1.64.8967. doi:10.1145/62029.62030. S2CID 14619034.
Gérard Huet and Derek C. Oppen (1980). ""Equations and Rewrite Rules: A Survey"". Technical report. Stanford University.
Raulefs, Peter; Siekmann, Jörg; Szabó, P.; Unvericht, E. (1979). ""A short survey on the state of the art in matching and unification problems"". ACM SIGSAM Bulletin. 13 (2): 14–20. doi:10.1145/1089208.1089210. S2CID 17033087.
Claude Kirchner and Hélène Kirchner. Rewriting, Solving, Proving. In preparation."
149afd9c1b,Synchronization (computer science),"In computer science, synchronization refers to one of two distinct but related concepts: synchronization of processes, and synchronization of data. Process synchronization refers to the idea that multiple processes are to join up or handshake at a certain point, in order to reach an agreement or commit to a certain sequence of action. Data synchronization refers to the idea of keeping multiple copies of a dataset in coherence with one another, or to maintain data integrity. Process synchronization primitives are commonly used to implement data synchronization.


== The need for synchronization ==
The need for synchronization does not arise merely in multi-processor systems but for any kind of concurrent processes; even in single processor systems. Mentioned below are some of the main needs for synchronization:
Forks and Joins: When a job arrives at a fork point, it is split into N sub-jobs which are then serviced by n tasks. After being serviced, each sub-job waits until all other sub-jobs are done processing. Then, they are joined again and leave the system. Thus, parallel programming requires synchronization as all the parallel processes wait for several other processes to occur.
Producer-Consumer: In a producer-consumer relationship, the consumer process is dependent on the producer process till the necessary data has been produced.
Exclusive use resources: When multiple processes are dependent on a resource and they need to access it at the same time, the operating system needs to ensure that only one processor accesses it at a given point in time. This reduces  concurrency.


== Thread or process synchronization ==

Thread synchronization is defined as a mechanism which ensures that two or more concurrent processes or threads do not simultaneously execute some particular program segment known as critical section. Processes' access to critical section is controlled by using synchronization techniques. When one thread starts executing the critical section (serialized segment of the program) the other thread should wait until the first thread finishes. If proper synchronization techniques are not applied, it may cause a race condition where the values of variables may be unpredictable and vary depending on the timings of context switches of the processes or threads.
For example, suppose that there are three processes, namely 1, 2, and 3. All three of them are concurrently executing, and they need to share a common resource (critical section) as shown in Figure 1. Synchronization should be used here to avoid any conflicts for accessing this shared resource. Hence, when Process 1 and 2 both try to access that resource, it should be assigned to only one process at a time.  If it is assigned to Process 1, the other process (Process 2) needs to wait until Process 1 frees that resource (as shown in Figure 2).

Another synchronization requirement which needs to be considered is the order in which particular processes or threads should be executed. For example, one cannot board a plane before buying a ticket.  Similarly, one cannot check e-mails before validating the appropriate credentials (for example, user name and password). In the same way, an ATM will not provide any service until it receives a correct PIN.
Other than mutual exclusion, synchronization also deals with the following:

deadlock, which occurs when many processes are waiting for a shared resource (critical section) which is being held by some other process. In this case, the processes just keep waiting and execute no further;
starvation, which occurs when a process is waiting to enter the critical section, but other processes monopolize the critical section, and the first process is forced to wait indefinitely;
priority inversion, which occurs when a high-priority process is in the critical section, and it is interrupted by a medium-priority process. This violation of priority rules can happen under certain circumstances and may lead to serious consequences in real-time systems;
busy waiting, which occurs when a process frequently polls to determine if it has access to a critical section. This frequent polling robs processing time from other processes.


== Minimizing synchronization ==
One of the challenges for exascale algorithm design is to minimize or reduce synchronization. 
Synchronization takes more time than computation, especially in distributed computing. Reducing synchronization drew attention from computer scientists for decades. Whereas it becomes an increasingly significant problem recently as the gap between the improvement of computing and latency increases. Experiments have shown that (global) communications due to synchronization on distributed computers takes a dominated share in a sparse iterative solver. This problem is receiving increasing attention after the emergence of a new benchmark metric, the High Performance Conjugate Gradient(HPCG), for ranking the top 500 supercomputers.


=== Classic problems of synchronization ===
The following are some classic problems of synchronization:

The Producer–Consumer Problem (also called The Bounded Buffer Problem);
The Readers–Writers Problem;
The Dining Philosophers Problem.These problems are used to test nearly every newly proposed synchronization scheme or primitive.


=== Hardware synchronization ===
Many systems provide hardware support for critical section code.
A single processor or uniprocessor system could disable interrupts by executing currently running code without preemption, which is very inefficient on multiprocessor systems.
""The key ability we require to implement synchronization in a multiprocessor is a set of hardware primitives with the ability to atomically read and modify a memory location. Without such a capability, the cost of building basic synchronization primitives will be too high and will increase as the processor count increases. There are a number of alternative formulations of the basic hardware primitives, all of which provide the ability to atomically read and modify a location, together with some way to tell if the read and write were performed atomically. These hardware primitives are the basic building blocks that are used to build a wide variety of user-level synchronization operations, including things such as locks and barriers. In general, architects do not expect users to employ the basic hardware primitives, but instead expect that the primitives will be used by system programmers to build a synchronization library, a process that is often complex and tricky."" Many modern hardware provides special atomic hardware instructions by either test-and-set the memory word or compare-and-swap contents of two memory words.


=== Synchronization strategies in programming languages ===
In Java, to prevent thread interference and memory consistency errors, blocks of code are wrapped into synchronized (lock_object) sections. This forces any thread to acquire the said lock object before it can execute the block. The lock is automatically released when the thread which acquired the lock, and is then executing the block, leaves the block or enters the waiting state within the block. Any variable updates, made by a thread in a synchronized block, become visible to other threads when they similarly acquire the lock and execute the block.
Java synchronized blocks, in addition to enabling mutual exclusion and memory consistency,  enable signaling—i.e., sending events from threads which have acquired the lock and are executing the code block to those which are waiting for the lock within the block. This means that Java synchronized sections combine functionality of mutexes and events. Such primitive is known as synchronization monitor.
Any object may be used as a lock/monitor in Java. The declaring object is a lock object when the whole method is marked with synchronized.
The .NET Framework has synchronization primitives. ""Synchronization is designed to be cooperative, demanding that every thread or process follow the synchronization mechanism before accessing protected resources (critical section) for consistent results."" In .NET, locking, signaling, lightweight synchronization types, spinwait and interlocked operations are some of mechanisms related to synchronization.


=== Implementation of Synchronization ===


==== Spinlock ====

Another effective way of implementing synchronization is by using spinlocks. Before accessing any shared resource or piece of code, every processor checks a flag. If the flag is reset, then the processor sets the flag and continues executing the thread. But, if the flag is set (locked), the threads would keep spinning in a loop and keep checking if the flag is set or not. But, spinlocks are effective only if the flag is reset for lower cycles otherwise it can lead to performance issues as it wastes many processor cycles waiting.


==== Barriers ====

Barriers are simple to implement and provide good responsiveness. They are based on the concept of implementing wait cycles to provide synchronization. Consider three threads running simultaneously, starting from barrier 1. After time t, thread1 reaches barrier 2 but it still has to wait for thread 2 and 3 to reach barrier2 as it does not have the correct data. Once all the threads reach barrier 2 they all start again. After time t, thread 1 reaches barrier3 but it will have to wait for threads 2 and 3 and the correct data again.
Thus, in barrier synchronization of multiple threads there will always be a few threads that will end up waiting for other threads as in the above example thread 1 keeps waiting for thread 2 and 3. This results in severe degradation of the process performance.The barrier synchronization wait function for ith thread can be represented as:
(Wbarrier)i = f ((Tbarrier)i, (Rthread)i)
Where Wbarrier is the wait time for a thread, Tbarrier is the number of threads has arrived, and Rthread is the arrival rate of threads.Experiments show that 34% of the total execution time is spent in waiting for other slower threads.


==== Semaphores ====

Semaphores are signalling mechanisms which can allow one or more threads/processors to access a section. A Semaphore has a flag which has a certain fixed value associated with it and each time a thread wishes to access the section, it decrements the flag. Similarly, when the thread leaves the section, the flag is incremented. If the flag is zero, the thread cannot access the section and gets blocked if it chooses to wait.
Some semaphores would allow only one thread or process in the code section. Such Semaphores are called binary semaphore and are very similar to Mutex. Here, if the value of semaphore is 1, the thread is allowed to access and if the value is 0, the access is denied.


=== Mathematical foundations ===
Synchronization was originally a process-based concept whereby a lock could be obtained on an object. Its primary usage was in databases. There are two types of (file) lock; read-only and read–write. Read-only locks may be obtained by many processes or threads. Readers–writer locks are exclusive, as they may only be used by a single process/thread at a time.
Although locks were derived for file databases, data is also shared in memory between processes and threads. Sometimes more than one object (or file) is locked at a time. If they are not locked simultaneously they can overlap, causing a deadlock exception.
Java and Ada only have exclusive locks because they are thread based and rely on the compare-and-swap processor instruction.
An abstract mathematical foundation for synchronization primitives is given by the history monoid. There are also many higher-level theoretical devices, such as process calculi and Petri nets, which can be built on top of the history monoid.


=== Synchronization examples ===
Following are some synchronization examples with respect to different platforms.


==== Synchronization in Windows ====
Windows provides:

interrupt masks, which protect access to global resources (critical section) on uniprocessor systems;
spinlocks, which prevent, in multiprocessor systems, spinlocking-thread from being preempted;
dynamic dispatchers, which act like mutexes, semaphores, events, and timers.


==== Synchronization in Linux ====
Linux provides:

semaphores;
spinlock;
barriers;
mutex;
readers–writer locks, for the longer section of codes which are accessed very frequently but don't change very often;
read-copy-update (RCU).Enabling and disabling of kernel preemption replaced spinlocks on uniprocessor systems. Prior to kernel version 2.6, Linux disabled interrupt to implement short critical sections. Since version 2.6 and later, Linux is fully preemptive.


==== Synchronization in Solaris ====
Solaris provides:

semaphores;
condition variables;
adaptive mutexes, binary semaphores that are implemented differently depending upon the conditions;
readers–writer locks:
turnstiles, queue of threads which are waiting on acquired lock.


==== Pthreads synchronization ====
Pthreads is a platform-independent API that provides:

mutexes;
condition variables;
readers–writer locks;
spinlocks;
barriers.


== Data synchronization ==

A distinctly different (but related) concept is that of data synchronization. This refers to the need to update and keep multiple copies of a set of data coherent with one another or to maintain data integrity, Figure 3. For example, database replication is used to keep multiple copies of data synchronized with database servers that store data in different locations.
Examples include:

File synchronization, such as syncing a hand-held MP3 player to a desktop computer;
Cluster file systems, which are file systems that maintain data or indexes in a coherent fashion across a whole computing cluster;
Cache coherency, maintaining multiple copies of data in sync across multiple caches;
RAID, where data is written in a redundant fashion across multiple disks, so that the loss of any one disk does not lead to a loss of data;
Database replication, where copies of data on a database are kept in sync, despite possible large geographical separation;
Journaling, a technique used by many modern file systems to make sure that file metadata are updated on a disk in a coherent, consistent manner.


=== Challenges in data synchronization ===
Some of the challenges which user may face in data synchronization:

data formats complexity;
real-timeliness;
data security;
data quality;
performance.


==== Data formats complexity ====
Data formats tend to grow more complex with time as the organization grows and evolves. This results not only in building simple interfaces between the two applications (source and target), but also in a need to transform the data while passing them to the target application. ETL (extraction transformation loading) tools can be helpful at this stage for managing data format complexities.


==== Real-timeliness ====
In real-time systems, customers want to see the current status of their order in e-shop, the current status of a parcel delivery—a real time parcel tracking—, the current balance on their account, etc. This shows the need of a real-time system, which is being updated as well to enable smooth manufacturing process in real-time, e.g., ordering material when enterprise is running out stock, synchronizing customer orders with manufacturing process, etc. From real life, there exist so many examples where real-time processing gives successful and competitive advantage.


==== Data security ====
There are no fixed rules and policies to enforce data security. It may vary depending on the system which you are using. Even though the security is maintained correctly in the source system which captures the data, the security and information access privileges must be enforced on the target systems as well to prevent any potential misuse of the information. This is a serious issue and particularly when it comes for handling secret, confidential and personal information. So because of the sensitivity and confidentiality, data transfer and all in-between information must be encrypted.


==== Data quality ====
Data quality is another serious constraint. For better management and to maintain good quality of data, the common practice is to store the data at one location and share with different people and different systems and/or applications from different locations. It helps in preventing inconsistencies in the data.


==== Performance ====
There are five different phases involved in the data synchronization process:

data extraction from the source (or master, or main) system;
data transfer;
data transformation;
data load to the target system.
data updationEach of these steps is critical. In case of large amounts of data, the synchronization process needs to be carefully planned and executed to avoid any negative impact on performance.


== See also ==
Futures and promises, synchronization mechanisms in pure functional paradigms


== References ==

Schneider, Fred B. (1997). On concurrent programming. Springer-Verlag New York, Inc. ISBN 978-0-387-94942-0.


== External links ==
Anatomy of Linux synchronization methods at IBM developerWorks
The Little Book of Semaphores, by Allen B. Downey
Need of Process Synchronization"
06b6ace8ca,Identifier,"An identifier is a name that identifies (that is, labels the identity of) either a unique object or a unique class of objects, where the ""object"" or class may be an idea, physical countable object (or class thereof), or physical noncountable substance (or class thereof). The abbreviation Id often refers to identity, identification (the process of identifying), or an identifier (that is, an instance of identification). An identifier may be a word, number, letter, symbol, or any combination of those.
The words, numbers, letters, or symbols may follow an encoding system (wherein letters, digits, words, or symbols stand for [represent] ideas or longer names) or they may simply be arbitrary. When an identifier follows an encoding system, it is often referred to as a code or id code.  For instance the ISO/IEC 11179 metadata registry standard defines a code as system of valid symbols that substitute for longer values in contrast to identifiers without symbolic meaning. Identifiers that do not follow any encoding scheme are often said to be arbitrary Ids; they are arbitrarily assigned and have no greater meaning. (Sometimes identifiers are called ""codes"" even when they are actually arbitrary, whether because the speaker believes that they have deeper meaning or simply because they are speaking casually and imprecisely.)
The unique identifier (UID) is an identifier that refers to only one instance—only one particular object in the universe. A part number is an identifier, but it is not a unique identifier—for that, a serial number is needed, to identify each instance of the part design. Thus the identifier ""Model T"" identifies the class (model) of automobiles that Ford's Model T comprises; whereas the unique identifier ""Model T Serial Number 159,862"" identifies one specific member of that class—that is, one particular Model T car, owned by one specific person.
The concepts of name and identifier are denotatively equal, and the terms are thus denotatively synonymous; but they are not always connotatively synonymous, because code names and Id numbers are often connotatively distinguished from names in the sense of traditional natural language naming. For example, both ""Jamie Zawinski"" and ""Netscape employee number 20"" are identifiers for the same specific human being; but normal English-language connotation may consider ""Jamie Zawinski"" a ""name"" and not an ""identifier"", whereas it considers ""Netscape employee number 20"" an ""identifier"" but not a ""name."" This is an emic indistinction rather than an etic one.


== Metadata ==
In metadata, an identifier is a language-independent label, sign or token that uniquely identifies an object within an identification scheme. The suffix ""identifier"" is also used as a representation term when naming a data element.
ID codes may inherently carry metadata along with them. For example, when you know that the food package in front of you has the identifier ""2011-09-25T15:42Z-MFR5-P02-243-45"", you not only have that data, you also have the metadata that tells you that it was packaged on September 25, 2011, at 3:42pm UTC, manufactured by Licensed Vendor Number 5, at the Peoria, IL, USA plant, in Building 2, and was the 243rd package off the line in that shift, and was inspected by Inspector Number 45.
Arbitrary identifiers might lack metadata. For example, if a food package just says 100054678214, its ID may not tell anything except identity—no date, manufacturer name, production sequence rank, or inspector number. In some cases, arbitrary identifiers such as sequential serial numbers leak information (i.e. the German tank problem). Opaque identifiers—identifiers designed to avoid leaking even that small amount of information—include ""really opaque pointers"" and Version 4 UUIDs.


== In computer science ==
In computer science, identifiers (IDs) are lexical tokens that name entities. Identifiers are used extensively in virtually all information processing systems. Identifying entities makes it possible to refer to them, which is essential for any kind of symbolic processing.


=== In computer languages ===

In computer languages, identifiers are tokens (also called symbols) which name language entities. Some of the kinds of entities an identifier might denote include variables, types, labels, subroutines,  and packages.


== Ambiguity ==


=== Identifiers (IDs) versus Unique identifiers (UIDs) ===

A resource may carry multiple identifiers. Typical examples are:

One person with multiple names, nicknames, and forms of address (titles, salutations)
For example: One specific person may be identified by all of the following identifiers: Jane Smith; Jane Elizabeth Meredith Smith; Jane E. M. Smith; Jane E. Smith; Janie Smith; Janie; Little Janie (as opposed to her mother or sister or cousin, Big Janie); Aunt Jane; Auntie Janie; Mom; Grandmom; Nana; Kelly's mother; Billy's grandmother; Ms. Smith; Dr. Smith; Jane E. Smith, PhD; and Fuzzy (her jocular nickname at work).
One document with multiple versions
One substance with multiple names (for example, CAS index names versus IUPAC names; INN generic drug names versus USAN generic drug names versus brand names)The inverse is also possible, where multiple resources are represented with the same identifier (discussed below).


=== Implicit context and namespace conflicts ===

Many codes and nomenclatural systems originate within a small namespace. Over the years, some of them bleed into larger namespaces (as people interact in ways they formerly hadn't, e.g., cross-border trade, scientific collaboration, military alliance, and general cultural interconnection or assimilation). When such dissemination happens, the limitations of the original naming convention, which had formerly been latent and moot, become painfully apparent, often necessitating retronymy, synonymity,
translation/transcoding, and so on. Such limitations generally accompany the shift away from the original context to the broader one. Typically the system shows implicit context (context was formerly assumed, and narrow), lack of capacity (e.g., low number  of possible IDs, reflecting the outmoded narrow context), lack of extensibility (no features defined and reserved against future needs), and lack of specificity and disambiguating capability (related to the context shift, where longstanding uniqueness encounters novel nonuniqueness). Within computer science, this problem is called naming collision. The story of the origination and expansion of the CODEN system provides a good case example in a recent-decades, technical-nomenclature context. The capitalization variations seen with specific designators reveals an instance of this problem occurring in natural languages, where the proper noun/common noun distinction (and its complications) must be dealt with. A universe in which every object had a UID would not need any namespaces, which is to say that it would constitute one gigantic namespace; but human minds could never keep track of, or semantically interrelate, so many UIDs.


== Identifiers in various disciplines ==


== See also ==


== References =="
a820954211,List of computer science awards,"This list of computer science awards is an index to articles on notable awards related to computer science. It includes lists of awards by the Association for Computing Machinery, the Institute of Electrical and Electronics Engineers, other computer science and information science awards, and a list of computer science competitions.
The top computer science award is the ACM Turing Award, generally regarded as the Nobel Prize equivalent for Computer Science. Other highly regarded top computer science awards include IEEE John von Neumann Medal awarded by the IEEE Board of Directors, and the Japan Kyoto Prize for Information Science.


== Association for Computing Machinery ==
The Association for Computing Machinery (ACM) gives out many computer science awards, often run by one of their Special Interest Groups.


== IEEE ==
A number of awards are given by the Institute of Electrical and Electronics Engineers (IEEE), the IEEE Computer Society or the IEEE Information Theory Society.


== Other computer science awards ==


== Information science awards ==


== Competitions ==


== See also ==
Competitive programming
Lists of awards
Lists of science and technology awards
List of computer-related awards
List of engineering awards


== References =="
702c757e4d,Default (computer science),"A default, in computer science, refers to the preexisting value of a user-configurable setting that is assigned to a software application, computer program or device. Such settings are also called presets or factory presets, especially for electronic devices. 
Default values are standards values that are universal to all instances of the device or model and intended to make the device as accessible as possible ""out of the box"" without necessitating a lengthy configuration process prior to use. The user only has to modify the default settings according to their personal preferences. In many devices, the user has the option to restore these default settings for one or all options. Such an assignment makes the choice of that setting or value more likely, this is called the default effect.


== Examples ==


=== Application software preferences ===
One use of default parameters is for initial settings for application software. For example, the first time a user runs an application it may suggest that the user's delivery address is in the United States. This default might be appropriate if more users of that application were in the US than any other country. If the user selected a new country, it would override the default, and perhaps become the default for the next time the application is used on that computer or by that user. Changing the default for the next run would involve storing user information in some place, such as in cookies on the user's computer for an Internet application. In Microsoft Windows, default file associations associate applications with file types.


=== Television or computer monitor ===
A TV or computer monitor typically comes with a button to ""restore factory presets"". This allows the settings for brightness, contrast, color, etc., to be returned to the defaults recommended by the manufacturer. This button may be used when the settings get badly adjusted (say by a toddler playing with the controls). Some ""fine-tuning"" of the settings may still be needed from the factory settings, but they will likely be closer to the desired settings than random settings.


== In application software ==
Using a default involves two goals which sometimes conflict:

Minimal user interaction should be required. Setting defaults to the most commonly selected options serves this purpose.
Panel entry errors should be minimized. Using defaults will tend to increase errors, as users may leave incorrect default settings selected. In cases where the value can be verified, this is not a severe problem. For example, the delivery country can be checked against the street address or postal codes and any mismatch can generate an error panel displayed to the user, who will then presumably make the correction.In cases where there is no clear majority and the results cannot easily be verified by other available information, such as the gender of the individual, no default should be offered. Some software applications, however, require that default values be supplied.
A 1982 Apple Computer manual for developers warned: ""Please do not ever use the word default in a program designed for humans. Default is something the mortgage went into right before the evil banker stole the Widow Parson's house. There is an exhaustive list of substitutes (previous, automatic, standard, etc.)"".


== In computer languages ==
Many languages in the C family (but not C itself, as of C11) allow a function to have default parameters or default arguments, that are used if the function is called with omitted parameter specifications.
In C and programming languages based on its syntax, the switch statement (which dispatches among a number of alternatives) can make use of the default keyword to provide a case for when no other case matches.
In Fortran, the INIT parameter on a declaration defines an initial default value for that variable.
In Rust, types that implement the Default trait can produce a default value. For example, the primitive integer types in Rust implement the Default trait by returning 0.


== In operating systems ==
In operating systems using a command line interface, the user types short commands often followed by various parameters and options.


== See also ==
Principle of least astonishment
Convention over configuration


== References =="
c65f955367,Offset (computer science),"In computer science, an offset within an array or other data structure object is an integer indicating the distance (displacement) between the beginning of the object and a given element or point, presumably within the same object. The concept of a distance is valid only if all elements of the object are of the same size (typically given in bytes or words).
For example, if A is an array of characters containing ""abcdef"", the fourth element containing the character 'd' has an offset of three from the start of A.


== In assembly language ==
In computer engineering and low-level programming (such as assembly language), an offset usually denotes the number of address locations added to a base address in order to get to a specific absolute address. In this (original) meaning of offset, only the basic address unit, usually the 8-bit byte, is used to specify the offset's size. In this context an offset is sometimes called a relative address.
In IBM System/360 instructions, a 12-bit offset embedded within certain instructions provided a range of between 0 and 4096 bytes. For example, within an unconditional branch instruction (X'47F0Fxxx'), the xxx 12bit hexadecimal offset provided the byte offset from the base register (15) to branch to. An odd offset would cause a program check (unless the base register itself also contained an odd address)—since instructions had to be aligned on half-word boundaries to execute without a program or hardware interrupt.
The previous example describes an indirect way to address to a memory location in the format of segment:offset. For example, assume we want to refer to memory location 0xF867.  One way this can be accomplished is by first defining a segment with beginning address 0xF000, and then defining an offset of 0x0867.  Further, we are also allowed to shift the hexadecimal segment to reach the final absolute memory address. One thing to note here is that we can reach our final absolute address in many ways.
An offset is not always relative to the base address of the module, for example: If you have a class (GUI) and you want to retrieve the ""color"" attribute of this class, the offset may be 0x0100, but this offset has to be added 
to the offset of the class itself, not the base address. If the class's offset is 0xFF881 and the base address is 0x0A100, then to retrieve the ""color"" attribute both offsets are added to the base address. 0x0A100 (base) + 0xFF881 (class) + 0x0100 (attribute). Ultimately the attribute's address will be 0x109A81.


== See also ==
Array Index"
a24e9f338c,Variable (computer science),"In computer programming, a variable is an abstract storage location paired with an associated symbolic name, which contains some known or unknown quantity of information referred to as a value; or in simpler terms, a variable is a named container for a particular set of bits or type of data (like integer, float, string etc...). A variable can eventually be associated with or identified by a memory address. The variable name is the usual way to reference the stored value, in addition to referring to the variable itself, depending on the context. This separation of name and content allows the name to be used independently of the exact information it represents. The identifier in computer source code can be bound to a value during run time, and the value of the variable may thus change during the course of program execution.Variables in programming may not directly correspond to the concept of variables in mathematics. The latter is abstract, having no reference to a physical object such as storage location. The value of a computing variable is not necessarily part of an equation or formula as in mathematics. Variables in computer programming are frequently given long names to make them relatively descriptive of their use, whereas variables in mathematics often have terse, one- or two-character names for brevity in transcription and manipulation.
A variable's storage location may be referenced by several different identifiers, a situation known as aliasing. Assigning a value to the variable using one of the identifiers will change the value that can be accessed through the other identifiers.
Compilers have to replace variables' symbolic names with the actual locations of the data. While a variable's name, type, and location often remain fixed, the data stored in the location may be changed during program execution.


== Actions on a variable ==
In imperative programming languages, values can generally be accessed or changed at any time. In pure functional and logic languages, variables are bound to expressions and keep a single value during their entire lifetime due to the requirements of referential transparency. In imperative languages, the same behavior is exhibited by (named) constants (symbolic constants), which are typically contrasted with (normal) variables.
Depending on the type system of a programming language, variables may only be able to store a specified data type (e.g. integer or string). Alternatively, a datatype may be associated only with the current value, allowing a single variable to store anything supported by the programming language.
Variables are the containers for storing the values.
Variables and scope:

Automatic variables: Each local variable in a function comes into existence only when the function is called, and disappears when the function is exited. Such variables are known as automatic variables.
External variables: These are variables that are external to a function and can be accessed by name by any function. These variables remain in existence permanently; rather that appearing and disappearing as functions are called and exited, they retain their values even after the functions that set them have returned.


== Identifiers referencing a variable ==
An identifier referencing a variable can be used to access the variable in order to read out the value, or alter the value, or edit other attributes of the variable, such as access permission, locks, semaphores, etc.
For instance, a variable might be referenced by the identifier ""total_count"" and the variable can contain the number 1956. If the same variable is referenced by the identifier ""r"" as well, and if using this identifier ""r"", the value of the variable is altered to 2009, then reading the value using the identifier ""total_count"" will yield a result of 2009 and not 1956.
If a variable is only referenced by a single identifier, that identifier can simply be called the name of the variable; otherwise we can speak of it as one of the names of the variable. For instance, in the previous example the identifier ""total_count"" is a name of the variable in question, and ""r"" is another name of the same variable.


== Scope and extent ==

The scope of a variable describes where in a program's text the variable may be used, while the extent (also called lifetime) of a variable describes when in a program's execution the variable has a (meaningful) value. The scope of a variable affects its extent. The scope of a variable is actually a property of the name of the variable, and the extent is a property of the storage location of the variable. These should not be confused with context (also called environment), which is a property of the program, and varies by point in the program's text or execution—see scope: an overview. Further, object lifetime may coincide with variable lifetime, but in many cases is not tied to it.
Scope is an important part of the name resolution of a variable. Most languages define a specific scope for each variable (as well as any other named entity), which may differ within a given program. The scope of a variable is the portion of the program's text for which the variable's name has meaning and for which the variable is said to be ""visible"". Entrance into that scope typically begins a variable's lifetime (as it comes into context) and exit from that scope typically ends its lifetime (as it goes out of context). For instance, a variable with ""lexical scope"" is meaningful only within a certain function/subroutine, or more finely within a block of expressions/statements (accordingly with function scope or block scope); this is static resolution, performable at parse-time or compile-time. Alternatively, a variable with dynamic scope is resolved at run-time, based on a global binding stack that depends on the specific control flow. Variables only accessible within a certain functions are termed ""local variables"". A ""global variable"", or one with indefinite scope, may be referred to anywhere in the program.
Extent, on the other hand, is a runtime (dynamic) aspect of a variable. Each binding of a variable to a value can have its own extent at runtime. The extent of the binding is the portion of the program's execution time during which the variable continues to refer to the same value or memory location. A running program may enter and leave a given extent many times, as in the case of a closure.
Unless the programming language features garbage collection, a variable whose extent permanently outlasts its scope can result in a memory leak, whereby the memory allocated for the variable can never be freed since the variable which would be used to reference it for deallocation purposes is no longer accessible. However, it can be permissible for a variable binding to extend beyond its scope, as occurs in Lisp closures and C static local variables; when execution passes back into the variable's scope, the variable may once again be used. A variable whose scope begins before its extent does is said to be uninitialized and often has an undefined, arbitrary value if accessed (see wild pointer), since it has yet to be explicitly given a particular value. A variable whose extent ends before its scope may become a dangling pointer and deemed uninitialized once more since its value has been destroyed. Variables described by the previous two cases may be said to be out of extent or unbound. In many languages, it is an error to try to use the value of a variable when it is out of extent. In other languages, doing so may yield unpredictable results. Such a variable may, however, be assigned a new value, which gives it a new extent.
For space efficiency, a memory space needed for a variable may be allocated only when the variable is first used and freed when it is no longer needed. A variable is only needed when it is in scope, thus beginning each variable's lifetime when it enters scope may give space to unused variables. To avoid wasting such space, compilers often warn programmers if a variable is declared but not used.
It is considered good programming practice to make the scope of variables as narrow as feasible so that different parts of a program do not accidentally interact with each other by modifying each other's variables. Doing so also prevents action at a distance. Common techniques for doing so are to have different sections of a program use different name spaces, or to make individual variables ""private"" through either dynamic variable scoping or lexical variable scoping.
Many programming languages employ a reserved value (often named null or nil) to indicate an invalid or uninitialized variable.


== Typing ==

In statically typed languages such as Go or ML, a variable also has a type, meaning that only certain kinds of values can be stored in it. For example, a variable of type ""integer"" is prohibited from storing text values.
In dynamically typed languages such as Python, a variable's type is inferred by its value, and can change according to its value. In Common Lisp, both situations exist simultaneously: A variable is given a type (if undeclared, it is assumed to be T, the universal supertype) which exists at compile time. Values also have types, which can be checked and queried at runtime.
Typing of variables also allows polymorphisms to be resolved at compile time. However, this is different from the polymorphism used in object-oriented function calls (referred to as virtual functions in C++) which resolves the call based on the value type as opposed to the supertypes the variable is allowed to have.
Variables often store simple data, like integers and literal strings, but some programming languages allow a variable to store values of other datatypes as well. Such languages may also enable functions to be parametric polymorphic. These functions operate like variables to represent data of multiple types. For example, a function named length may determine the length of a list. Such a length function may be parametric polymorphic by including a type variable in its type signature, since the number of elements in the list is independent of the elements' types.


== Parameters ==
The formal parameters (or formal arguments) of functions are also referred to as variables. For instance, in this Python code segment,

the variable named x is a parameter because it is given a value when the function is called. The integer 5 is the argument which gives x its value. In most languages, function parameters have local scope. This specific variable named x can only be referred to within the addtwo function (though of course other functions can also have variables called x).


== Memory allocation ==
The specifics of variable allocation and the representation of their values vary widely, both among programming languages and among implementations of a given language. Many language implementations allocate space for local variables, whose extent lasts for a single function call on the call stack, and whose memory is automatically reclaimed when the function returns. More generally, in name binding, the name of a variable is bound to the address of some particular block (contiguous sequence) of bytes in memory, and operations on the variable manipulate that block. Referencing is more common for variables whose values have large or unknown sizes when the code is compiled. Such variables reference the location of the value instead of storing the value itself, which is allocated from a pool of memory called the heap.
Bound variables have values. A value, however, is an abstraction, an idea; in implementation, a value is represented by some data object, which is stored somewhere in computer memory. The program, or the runtime environment, must set aside memory for each data object and, since memory is finite, ensure that this memory is yielded for reuse when the object is no longer needed to represent some variable's value.
Objects allocated from the heap must be reclaimed—especially when the objects are no longer needed. In a garbage-collected language (such as C#, Java, Python, Golang and Lisp), the runtime environment automatically reclaims objects when extant variables can no longer refer to them. In non-garbage-collected languages, such as C, the program (and the programmer) must explicitly allocate memory, and then later free it, to reclaim its memory. Failure to do so leads to memory leaks, in which the heap is depleted as the program runs, risks eventual failure from exhausting available memory.
When a variable refers to a data structure created dynamically, some of its components may be only indirectly accessed through the variable. In such circumstances, garbage collectors (or analogous program features in languages that lack garbage collectors) must deal with a case where only a portion of the memory reachable from the variable needs to be reclaimed.


== Naming conventions ==

Unlike their mathematical counterparts, programming variables and constants commonly take multiple-character names, e.g. COST or total. Single-character names are most commonly used only for auxiliary variables; for instance, i, j, k for array index variables.
Some naming conventions are enforced at the language level as part of the language syntax which involves the format of valid identifiers. In almost all languages, variable names cannot start with a digit (0–9) and cannot contain whitespace characters. Whether or not punctuation marks are permitted in variable names varies from language to language; many languages only permit the underscore (""_"") in variable names and forbid all other punctuation. In some programming languages, sigils (symbols or punctuation) are affixed to variable identifiers to indicate the variable's datatype or scope.
Case-sensitivity of variable names also varies between languages and some languages require the use of a certain case in naming certain entities; Most modern languages are case-sensitive; some older languages are not. Some languages reserve certain forms of variable names for their own internal use; in many languages, names beginning with two underscores (""__"") often fall under this category.
However, beyond the basic restrictions imposed by a language, the naming of variables is largely a matter of style. At the machine code level, variable names are not used, so the exact names chosen do not matter to the computer. Thus names of variables identify them, for the rest they are just a tool for programmers to make programs easier to write and understand. Using poorly chosen variable names can make code more difficult to review than non-descriptive names, so names that are clear are often encouraged.Programmers often create and adhere to code style guidelines that offer guidance on naming variables or impose a precise naming scheme. Shorter names are faster to type but are less descriptive; longer names often make programs easier to read and the purpose of variables easier to understand. However, extreme verbosity in variable names can also lead to less comprehensible code.


== Variable types (based on lifetime) ==
We can classify variables based on their lifetime. The different types of variables are static, stack-dynamic, explicit heap-dynamic, and implicit heap-dynamic. A static variable is also known as global variable, it is bound to a memory cell before execution begins and remains to the same memory cell until termination. A typical example is the static variables in C and C++. A Stack-dynamic variable is known as local variable, which is bound when the declaration statement is executed, and it is deallocated when the procedure returns. The main examples are local variables in C subprograms and Java methods. Explicit Heap-Dynamic variables are nameless (abstract) memory cells that are allocated and deallocated by explicit run-time instructions specified by the programmer. The main examples are dynamic objects in C++ (via new and delete) and all objects in Java. Implicit Heap-Dynamic variables are bound to heap storage only when they are assigned values. Allocation and release occur when values are reassigned to variables. As a result, Implicit heap-dynamic variables have the highest degree of flexibility. The main examples are some variables in JavaScript, PHP and all variables in APL.


== See also ==
Control variable (programming)
Non-local variable
Temporary variable
Variable interpolation
Scalar (mathematics)


== Notes ==


== References =="
3c4b7a62e7,Field (computer science),"In computer science, data that has several parts, known as a record, can be divided into fields (data fields). Relational databases arrange data as sets of database records, so called rows. Each record consists of several fields; the fields of all records form the columns.
Examples of fields: name, gender, hair colour. 
In object-oriented programming, a field (also called data member or member variable) is a particular piece of data encapsulated within a class or object. In the case of a regular field (also called instance variable), for each instance of the object there is an instance variable: for example, an Employee class has a Name field and there is one distinct name per employee. A static field (also called class variable) is one variable, which is shared by all instances. Fields are abstracted by properties, which allow them to be read and written as if they were fields, but these can be translated to getter and setter method calls.


== Fixed length ==
Fields that contain a fixed number of bits are known as fixed length fields. A four byte field for example may contain a 31 bit binary integer plus a sign bit (32 bits in all). A 30 byte name field may contain a person's name typically padded with blanks at the end.
The disadvantage of using fixed length fields is that some part of the field may be wasted but space is still required for the maximum length case. Also, where fields are omitted, padding for the missing fields is still required to maintain fixed start positions within a record for instance.


== Variable length ==
A variable length field is not always the same physical size. 
Such fields are nearly always used for text fields that can be large, or fields that vary greatly
in length. For example, a bibliographical database like PubMed has many small fields such
as publication date and author name, but also has abstracts, which vary greatly in length. 
Reserving a fixed-length field of some length would be inefficient because it would enforce a
maximum length on abstracts, and because space would be wasted in most records (particularly if many articles lacked abstracts entirely).
Database implementations commonly store varying-length fields in special ways, in order to 
make all the records of a given type have a uniform small size. Doing so can help performance.
On the other hand, data in serialized forms such as stored in typical file systems, 
transmitted across networks, and so on usually uses quite different performance strategies.
The choice depends on factors such as the total size of records, performance characteristics of the
storage medium, and the expected patterns of access.
Database implementations typically store variable length fields in ways such as

a sequence of characters or bytes, followed by an end-marker that is prohibited within the string itself. This makes it slower to access later fields in the same record because the later fields are not always at the same physical distance from the start of the record.
a pointer to data in some other location, such as a URI, a file offset (and perhaps length), or a key identifying a record in some special place. This typically speeds up processes that do not need the contents of the variable length fields, but slows processes that do.
a length prefix followed by the specified number of characters or bytes. This avoids searches for an end-marker as in the first method, and avoids the loss of locality of reference as in the second method. On the other hand, it imposes a maximum length: the biggest number that can be represented using the (generally fixed length) prefix. In addition, records still vary in length, and must be traversed in order to reach later fields.If a varying-length field is often empty, additional optimizations come into play.


== Example ==
This Person java class has 3 fields: firstName, lastName, and heightInCentimeters.


== See also ==
Class variable
Data hierarchy
Instance variable
Mutator method


== References =="
bd9ab37768,Barrier (computer science),"In parallel computing, a barrier is a type of synchronization method. A barrier for a group of threads or processes in the source code means any thread/process must stop at this point and cannot proceed until all other threads/processes reach this barrier.
Many collective routines and directive-based parallel languages impose implicit barriers. For example, a parallel do loop in Fortran  with OpenMP will not be allowed to continue on any thread until the last iteration is completed. This is in case the program relies on the result of the loop immediately after its completion. In message passing, any global communication (such as reduction or scatter) may imply a barrier.
In concurrent computing, a barrier may be in a raised or lowered state. The term latch is sometimes used to refer to a barrier that starts in the raised state and cannot be re-raised once it is in the lowered state. The term count-down latch is sometimes used to refer to a latch that is automatically lowered once a pre-determined number of threads/processes have arrived.


== Implementation ==
The basic barrier has mainly two variables, one of which records the pass/stop state of the barrier, the other of which keeps the total number of threads that have entered in the barrier. The barrier state was initialized to be ""stop"" by the first threads coming into the barrier. Whenever a thread enters, based on the number of threads already in the barrier, only if it is the last one, the thread sets the barrier state to be ""pass"" so that all the threads can get out of the barrier. On the other hand, when the incoming thread is not the last one, it is trapped in the barrier and keeps testing if the barrier state has changed from ""stop"" to ""pass"", and it gets out only when the barrier state changes to ""pass"". The following C++ code demonstrates this procedure.

The potential problem is:

Due to all the threads repeatedly accessing the global variable for pass/stop, the communication traffic is rather high, which decreases the scalability.This problem can be resolved by regrouping the threads and using multi-level barrier, e.g. Combining Tree Barrier. Also hardware implementations may have the advantage of higher scalability.


=== Sense-Reversal Centralized Barrier ===
Instead of using the same value to represent pass/stop, sequential barriers use opposite values for pass/stop state. For example, if barrier 1 uses 0 to stop the threads, barrier 2 will use 1 to stop threads and barrier 3 will use 0 to stop threads again and so on. The following C++ code demonstrates this.


=== Combining Tree Barrier ===
A Combining Tree Barrier is a hierarchical way of implementing barrier to resolve the scalability by avoiding the case that all threads are spinning at the same location.In k-Tree Barrier, all threads are equally divided into subgroups of k threads and a first-round synchronizations are done within these subgroups. Once all subgroups have done their synchronizations, the first thread in each subgroup enters the second level for further synchronization. In the second level, like in the first level, the threads form new subgroups of k threads and synchronize within groups, sending out one thread in each subgroup to next level and so on. Eventually, in the final level there is only one subgroup to be synchronized. After the final-level synchronization, the releasing signal is transmitted to upper levels and all threads get past the barrier.


=== Hardware Barrier Implementation ===
The hardware barrier uses hardware to implement the above basic barrier model.The simplest hardware implementation uses dedicated wires to transmit signal to implement barrier. This dedicated wire performs OR/AND operation to act as the pass/block flags and thread counter. For small systems, such a model works and communication speed is not a major concern. In large multiprocessor systems this hardware design can make barrier implementation have high latency. The network connection among processors is one implementation to lower the latency, which is analogous to Combining Tree Barrier.


== See also ==
Fork–join model
Rendezvous (Plan 9)
Memory barrier


== References ==


== External links ==
""Parallel Programming with Barrier Synchronization"". sourceallies.com. March 2012."
d16723e94c,Computer Sciences Corporation,"Computer Sciences Corporation (CSC) was an American multinational corporation that provided information technology (IT) services and professional services. On April 3, 2017, it merged with the Enterprise Services line of business of HP Enterprise (formerly Electronic Data Systems) to create DXC Technology.


== History ==
CSC was founded in April 1959 in Los Angeles, California, by Roy Nutt and Fletcher Jones. CSC initially provided programming tools such as assembler and compiler software.In the 1960s, CSC provided software programming services to major computer manufacturers like IBM and Honeywell and secured their first contracts for the U.S. public sector with NASA (among others).By 1963, CSC became the largest software company in the United States and the first software company to be listed on the American Stock Exchange. By the end of 1968, CSC was listed on the New York Stock Exchange and had operations in Canada, India, the United Kingdom, Germany, Spain, Italy, Brazil, and the Netherlands.
In 1967, CSC set up Computicket Corp. to compete in the fledgling electronic ticket market competing with Ticketron but lost $13 million and discontinued the service in 1970.In the 1970s and 1980s, CSC expanded globally winning large contracts for the finance and defense industries and through acquisitions in Europe and Australia.
In 2000 CSC founded a joint-venture called Innovative Banking Solutions AG in Wiesbaden, Germany to market their newly developed SAP solution for mortgage companies.
Since its beginnings in 1959, company headquarters had been in California.  On March 29, 2008, the corporate headquarters of the company were relocated from El Segundo, California, to Falls Church, Virginia.
CSC has been a Fortune 500 Company since 1995, coming in at 162 in the 2012 rankings.In fiscal 2013, CSC acquired ServiceMesh (cloud management) for $282M, Infochimps (a big data platform) for $27M, 42Six (analytics for national intelligence) for $35 million, iSOFT (application solutions) for cash and debt, and AppLabs (application testing) for $171M.In May 2015, CSC announced plans to split the public sector business from its commercial and international business.  In August, it was announced that CSC's Government Service business would merge with SRA International to form a new company — CSRA—at the end of November 2015.In July 2015, CSC and HCL Technologies announced the signing of a joint venture agreement to form a banking software and services company, Celeriti FinTech.In September 2015, CSC closed the acquisition of Fixnetix, a provider of front-office managed trading solutions in capital markets. CSC also acquired Fruition Partners, a provider of technology-enabled solutions for the service-management sector during the month.In November 2015, CSC agreed to acquire the shares of UXC, an IT services company based in Australia in a deal valued at A$427.6 million (US$309 million).In December 2015, business technology and services provider, Xchanging, agreed to be purchased by CSC.In February 2016, CSC announced it was moving its headquarters to Tysons, Fairfax County's central business district, just a few miles from Annandale, Virginia.On April 3, 2017, it merged with  HPE Enterprise Services to create DXC Technology.


== Business ==
CSC once ranked among the leading IT service providers in the world. Geographically, CSC had major operations throughout North America, Europe, Asia, and Australia.
The company operated in three broad service lines or sectors until the 2015 divestment of NPS, its public sector:

North American Public Sector (NPS): Since 1961, CSC had been one of the major IT service providers for the  U.S. federal government. CSC provided services to the United States Department of Defense, law enforcement and intelligence agencies  (FBI, CIA, Homeland Security), aeronautics and aerospace agencies  (NASA). In 2012, U.S. federal contracts accounted for 36% of CSC total revenue.
Managed Services
Business Solutions and ServicesThe company  made several acquisitions, including DynCorp in 2003 and Covansys Corporation in 2007.


== Awards and recognition ==
In September 2012, CSC was ranked 8th in Software Magazine’s Software 500 ranking of the world’s largest software and service providers.


== Criticism ==
In June 2013, Margaret Hodge, chair of the Public Accounts Committee, a Select committee of the British House of Commons, described CSC as a ""rotten company providing a hopeless system"" with reference to their multibillion-pound contract to deliver the National Programme for IT Lorenzo contract.
In December 2011, the non-partisan organization Public Campaign criticized CSC for spending US$4.39 million on lobbying and not paying any taxes during 2008–10, instead getting US$305 million in tax rebates, despite making a profit of US$1.67 billion.
In February 2011, the U.S. Securities and Exchange Commission (SEC) launched a fraud investigation into CSC's accounting practices in Denmark and Australian business. CSC's CFO Mike Mancuso confirmed that accounting errors and intentional misconduct by certain personnel in Australia prompted SEC regulators to turn their gaze to Australia. Mancuso also stated that the alleged misconduct includes US$19 million in both intentional accounting irregularities and unintentional accounting errors. The SEC accused the former CEO Mike Laphen of fraud and clawed back $4,35 million
The company was accused of breaching human rights by arranging several illegal rendition flights for the CIA between 2003 and 2006, which also led to criticism of shareholders of the company, including the governments of Norway and Britain.
The company engaged in a number of activities that resulted in legal actions against it. These are:
Its so-called WorldBridge Service (Visa Services), which processed and issued millions of visa applications to enter Britain, did not involve British authorities.
In 1998, CSC was the prime contractor hired by the Internal Revenue Service to modernize its tax-filing system. They told the IRS it would meet a January 2006 deadline, but failed to do so, leaving the IRS with no system capable of detecting fraud. Its failure to meet the delivery deadline for developing an automated refund fraud detection system cost the IRS between US$200 million and US$300 million.


== See also ==
VP/MS (Visual Product Modeling System), a modeling language and product lifecycle management tool by CSC
Top 100 US Federal Contractors
CSRA Inc., formed by a merger of CSC's North American Public Sector and SRA International
Team CSC and other names 2003-2010. Professional cycling sponsorship under team owner Bjarne Riis.


== References ==


== External links ==
Official website
Computer Sciences Corporation SEC Filings"
d2074134e8,Bachelor of Science,"A Bachelor of Science (BS, BSc, SB, or ScB; from the Latin scientiae baccalaureus) is a bachelor's degree awarded for programs that generally last three to five years.The first university to admit a student to the degree of Bachelor of Science was the University of London in 1860. In the United States, the Lawrence Scientific School first conferred the degree in 1851, followed by the University of Michigan in 1855. Nathaniel Southgate Shaler, who was Harvard's Dean of Sciences, wrote in a private letter that ""the degree of Bachelor of Science came to be introduced into our system through the influence of Louis Agassiz, who had much to do in shaping the plans of this School."": 48 Whether Bachelor of Science or Bachelor of Arts degrees are awarded in particular subjects varies between universities. For example, an economics student may graduate as a Bachelor of Arts in one university but as a Bachelor of Science in another, and occasionally, both options are offered. Some universities follow the Oxford and Cambridge tradition that even graduates in mathematics and the sciences become Bachelors of Arts, while other institutions offer only the Bachelor of Science degree, even in non-science fields.At universities that offer both Bachelor of Arts and Bachelor of Science degrees in the same discipline, the Bachelor of Science degree is usually more focused on that particular discipline and is targeted toward students intending to pursue graduate school or a profession in that discipline.


== International differences ==
In some institutions, there are historical and traditional reasons that govern the granting of BS or BA degree regardless of the disciplines offered. Georgetown University's School of Foreign Service awards the Bachelor of Science in Foreign Service (BSFS) degrees to all of its undergraduates, although many students major in humanities-oriented fields such as international history or culture and politics. University of Pennsylvania's Wharton School awards the BS in Economics to all of its undergraduates, regardless if the candidates major in economics or not. The London School of Economics offers BSc degrees in practically all subject areas, even those normally associated with the arts and humanities.  Northwestern University's School of Communication grants the Bachelor of Science in Journalism degrees in all of its programs of study, including theater, dance, and radio/television/film. Meanwhile, the Oxbridge universities almost exclusively award the BA as a first degree.The decision to grant a BS or BA degree at some institutions also depends on the constituent colleges, even when the candidate pursues the same or similar subjects. For instance, Cornell University offers a BS degree in computer science from its College of Engineering and a BA degree in computer science from its College of Arts and Sciences. Likewise, for candidates majoring in computer science, Columbia University offers BS degrees for those enrolled in the School of Engineering and Applied Science but awards BA degrees for graduates of Columbia College. At Harvard University, the same undergraduate degree in computer science can be an A.B. if taken at Harvard College, an S.B. at the Harvard John A. Paulson School of Engineering and Applied Sciences, and an A.L.B. at Harvard Extension School.


=== Argentina ===
In Argentina most university degrees are given as a license in a discipline. They are specific to a field and awarded to students upon completion of a course of study which lasts at least four and usually five years. 
In most cases, at the end of a course and as a mandatory condition for its completion (and ultimately, to obtain a degree), students are compelled to produce an original research project related to their field. This project is usually referred to as a thesis (although the term actually corresponds to post graduate studies) and, unlike a thesis, it not mandatory to have it presented in front of an assessment board.


=== Australia, New Zealand and South Africa ===
In Australia, the BSc is generally a three to four-year degree. An honours year or a master's by research degree is required to progress on to the stage of Doctor of Philosophy (PhD).
In New Zealand, in some cases, the honours degree comprises an additional postgraduate qualification. In other cases, students with strong performance in their second or third year, are invited to extend their degree to an additional year, with a focus on research, granting access to doctoral programs.
In South Africa, the BSc is taken over three years, while the postgraduate BSc (Hons) entails an additional year of study. Admission to the honours degree is on the basis of a sufficiently high average in the BSc major; an honours degree is required for MSc level study, and admission to a doctorate is via the MSc.


=== Brazil ===
In Brazil, a Bachelor of Science degree is an undergraduate academic degree and is equivalent to a BSc (Hons). It could take from 4 to 6 years (8 to 12 periods) to complete, is also more specific and could be applied for Scientific Arts courses (like Engineering, Maths, Physics, etc.), somewhat is called Human Art courses in Brazil (like History, Portuguese and Literature and Lawyer studies for example) as well as for Health Arts (like Medicine, Nursery, Zootechnique, Veterinary and Biology for example). To be able to start the bachelor's degree in Brazil the candidate must prove to be proficient in different disciplines and have at least the accumulated Preliminary, Medium and High School degrees accomplished with the minimum merit of 60% to 70% of the degrees and a correspondent study period that can vary from 10 to 12 years minimum. The Bachelor of Science courses in Brazilian Universities normally have the first 1 to 2 years (first 2 to 4 periods) of basic fundamental disciplines (like for example Calculus I, II, III and IV for some engineering courses, Geometry basics and advanced, Analytical Laboratories experiments in Mechanics, Optics, Magnetism, etc.) and the last 2 to 3 years disciplines more related to the professional fields of that Bachelor of Science (for example Units Operations, Thermodynamics, Chemical Reactors, Industrial Processes, Kinetics for Chemical Engineering for example). Some disciplines are prerequisite to others and in some universities, the student is not allowed to course any discipline for the entire next period if he was unsuccessful in just one prerequisite discipline of the present period. Usually, the Bachelor of Science courses demand a one-year mandatory probation period by the end of the course (internship in the specific professional area, like a training period), followed by relatively elaborate written and oral evaluations. To get the certification as BSc, most universities require that the students achieve the accomplishment of 60% to 70% in all the ""obligatory disciplines"", plus the supervisioned and approved training period (like a supervisioned internship period), the final thesis of the course, and in some BSc programs, the final exam test. The final exam also is required so far. To be a professor, a Bachelor of Sciences is required to get a Licenciature degree, which lasts on top of the periods already studied until getting the BSc (Hons), plus 2 to 3 periods (1 to 1.5 years). With a master's degree (MSc) is also possible, which takes 3 to 5 periods more (1.5 to 2.5 years more).


=== Britain and Ireland ===
Commonly in British Commonwealth countries and Ireland graduands are admitted to the degree of Bachelor of Science after having completed a programme in one or more of the sciences. These programmes may take different lengths of time to complete.
A Bachelor of Science receives the designation BSc for an ordinary degree and BSc (Hons) for an honours degree. In England, Wales and Northern Ireland an honours degree is typically completed over a three-year period, though there are a few intensified two-year courses (with less vacation time). Bachelor's degrees (without honours) were typically completed in two years for most of the twentieth century. In Scotland, where access to university is possible after one less year of secondary education, degree courses have a foundation year making the total course length four years.
In Ireland, the former BS was changed to BSc (Hons), which is awarded after four years. The BSc (Ord) is awarded after three years. Formerly at the University of Oxford, the degree of BSc was a postgraduate degree; this former degree, still actively granted, has since been renamed MSc.


=== Chile ===
In Chile, the completion of a university program leads to an academic degree as well as a professional title. The academic degree equivalent to Bachelor of Science is ""Licenciado en Ciencias"", which can be obtained as a result of completing a 4–6 year program. However, in most cases, 4-year programs will grant a Bachelor of Applied Science (Spanish: ""Licenciatura en Ciencias Aplicadas"") degree, while other 4-year programs will not grant to an academic degree.


=== Continental Europe ===
Many universities in Europe are changing their systems into the BA/MA system and in doing so also offering the full equivalent of a BSc or MSc (see Bologna Process).


=== Czech Republic ===
Universities in the Czech Republic are changing their systems into the Bachelor of Science/Master of Science system and in doing so also offering the full equivalent of a BSc (Bc.) or MSc (Mgr./Ing.).


=== Germany ===
In Germany, there are two kinds of universities: Universitäten and Fachhochschulen (which are also called University of Applied Sciences). Universitäten and Fachhochschulen – both also called Hochschulen - are legally equal, but Fachhochschulen have the reputation of being more related to practice and have no legal right to offer PhD programmes.
The BSc in Germany is equivalent to the BSc(Hons) in the United Kingdom. Many universities in German-speaking countries are changing their systems to the BA/MA system and in doing so also offering the full equivalent of a BSc.
In Germany the BA normally lasts between three and four years (six to eight semesters) and between 180 and 240 ECTS must be earned.


=== India ===
Bachelor of Science (B.Sc) is usually a three-year graduate program in India offered by state and central universities. Some independent private colleges can also offer BS degrees with minimum changes in curriculum. B.Sc is different from Bachelor of Engineering (B.E) or Bachelor of Technology (B.Tech). Two exceptions are the B.Sc (Research) course offered by the Indian Institute of Science which lasts four years and the BS-MS course offered by the IISERs, both of which provide more research and interdisciplinary emphasis.


=== North America ===
In Canada, Mexico, and the United States, it is most often a four-year undergraduate degree, typically in engineering, computer science, mathematics, economics, finance, business, or the natural sciences.
There are, however, some colleges and universities, notably in the province of Quebec, that offer three-year degree programs.


== Typical completion period ==


=== Three years ===
Australia, Austria, Barbados, Belgium, Belize, Bosnia and Herzegovina (mostly three years, sometimes four), Cameroon, Canada (specifically  Quebec), Cote d'Ivoire, Croatia (mostly three years, sometimes four), Czech Republic (mostly three years, sometimes four), Denmark, England (three or four years with a one-year placement in industry), Estonia, Finland, France, Germany (mostly three years, but can be up to four years), Hungary, Iceland, India (three-year BSc in arts and pure sciences excluding engineering, Agriculture and medicine, four years for engineering program ""Bachelor of Engineering"" Four year for Agriculture program  ""Bachelor of Agriculture""and five years for medicine program ""Bachelor of Medicine and Bachelor of Surgery""), Ireland (Ordinary), Israel (for most subjects), Italy, Jamaica (three or four years), Latvia (three or four years), Lebanon (three or four years, five years for Bachelor of Engineering), Malaysia, New Zealand, the Netherlands (three years for research universities, four years for universities of applied sciences), Northern Ireland, Norway, Poland, Portugal, Romania, Scotland (Ordinary), Singapore (honours degree takes 4 years), Slovakia, Slovenia, South Africa (honours degree takes 4 years), Sweden, Switzerland, Trinidad and Tobago, Uganda (mostly three years, sometimes four), United Arab Emirates, Wales, and Zimbabwe.


=== Four years ===
Afghanistan, Albania (four or five years), Armenia (four or five years), Australia (honours degree), Azerbaijan (four or five years), Bahrain, Bangladesh (four or five years), Belarus, Belize, Bosnia and Herzegovina, Brazil (four to five years), Brunei (three or four years), Bulgaria, Canada (except Quebec), China, Cyprus, the Dominican Republic, Egypt (four or five years), Ethiopia (engineering, five years), Finland (engineering, practice in industry not included), Georgia, Ghana (three or four years), Greece (four or five years), Guatemala, Haiti (three or four years), Hong Kong (starting from 2012, three years originally), India (four-year BS, Bsc (hons.) Agriculture, Engineering), Indonesia, Iran (four or five years), Iraq, Ireland (Honours Degree), Israel (engineering degree), Japan, Jordan (four to five years), Kazakhstan, Kenya, Kuwait, Libya, Lithuania, North Macedonia (three, four or five years), Malawi (four or five years), Malta, Mexico, Montenegro (three or four years), Myanmar, Nepal (previously three, now four years), the Netherlands (three years for research universities, four years for universities of applied sciences), New Zealand (honours degree), Nigeria, Pakistan (four or five years), the Philippines (four or five years), Romania, Russia, Saudi Arabia, Scotland (Honours Degree), Serbia (three or four years), Spain, South Africa (fourth year is elective — to obtain an Honours degree, which is normally a requirement for selection into a master's degree program), South Korea, Sri Lanka (three, four, or five (specialized) years), Taiwan, Tajikistan (four or five years), Thailand, Romania, Tunisia (only a Bachelor of Science in Business Administration is available, solely awarded by Tunis Business School), Turkey, Ukraine, the United States, Uruguay (four, five, six, or seven years), Yemen, and Zambia (four or five years).


=== Five years ===
Cuba (five years), Greece (four or five years), Peru, Argentina, Colombia (starting to change to 4 years), Brazil (five years), Mexico (4.5 years), Chile, Venezuela (five years), Egypt (four or five years), Haiti (four or five years).
Nigeria (four to five years), 6 months dedicated to SIWES (Students Industrial Work Exchange Scheme) but for most sciences and all engineering courses only. A semester for project work/thesis not excluding course work during the bachelor thesis. Excluding 1 year for the compulsory National Youth Service Corps (NYSC), para-military and civil service.
North Macedonia, Sierra Leone (four years dedicated to coursework), Slovenia (four or five years), Sudan (five years for BSc honours degree and four years for BSc ordinary degree), and Syria.
In Algeria, the student presents a thesis in front of a Jury at the end of the fifth year.
Some universities in Canada (such as University of British Columbia and Vancouver Island University) have most of their science and applied science students extend their degree by a year compared to other institutions.


=== Six years ===
In Chile, some undergraduate majors such as engineering and geology are designed as 6-year programs. However, in practice it is not uncommon for students to complete such programs over the course of 10 years, while studying full-time without leaves of absence. This is in part due to a strict grading system where the highest grade of a typical class can be as low as 60% (C-) and the high frequency of protests and strikes organized by student federations and teacher unions, such as the 2011–13 Chilean student protests.
There are studies that suggest a direct correlation between reduced social mobility and differences unique to the Chilean higher education system.


== See also ==
British undergraduate degree classification
British degree abbreviations
List of tagged degrees
Master of Science


== Notes ==


== References =="
19da0f2288,Value (computer science),"In computer science and software programming, a value is the representation of some entity that can be manipulated by a program. The members of a type are the values of that type.The ""value of a variable"" is given by the corresponding mapping in the environment. In languages with assignable variables, it becomes necessary to distinguish between the r-value (or contents) and the l-value (or location) of a variable.In declarative (high-level) languages, values have to be referentially transparent. This means that the resulting value is independent of the location of the expression needed to compute the value. Only the contents of the location (the bits, whether they are 1 or 0) and their interpretation are significant.


== Value category ==
Despite its name, in the C++ language standards this terminology is used to categorize expressions, not values.: 8.2.1 


=== Assignment: l-values and r-values ===
Some languages use the idea of l-values and r-values, deriving from the typical mode of evaluation on the left and right-hand side of an assignment statement. An l-value refers to an object that persists beyond a single expression. An r-value is a temporary value that does not persist beyond the expression that uses it.The notion of l-values and r-values was introduced by Combined Programming Language (CPL). The notions in an expression of r-value, l-value, and r-value/l-value are analogous to the parameter modes of input parameter (has a value), output parameter (can be assigned), and input/output parameter (has a value and can be assigned), though the technical details differ between contexts and languages.


=== R-values and addresses ===
In many languages, notably the C family, l-values have storage addresses that are programmatically accessible to the running program (e.g., via some address-of operator like ""&"" in C/C++), meaning that they are variables or de-referenced references to a certain memory location. R-values can be l-values (see below) or non-l-values—a term only used to distinguish from l-values. Consider the C expression 4 + 9. When executed, the computer generates an integer value of 13, but because the program has not explicitly designated where in the computer this 13 is stored, the expression is a non l-value. On the other hand, if a C program declares a variable x and assigns the value of 13 to x, then the expression x has a value of 13 and is an l-value.
In C, the term l-value originally meant something that could be assigned to (hence the name, indicating it is on the left side of the assignment operator), but since the reserved word const (constant) was added to the language, the term is now 'modifiable l-value'. In C++11 a special semantic-glyph && exists ( not to be confused with the && operator used for logical operations ), to denote the use/access of the expression's address for the compiler only; i.e., the address cannot be retrieved using the address-of & operator during the run-time of the program (see the use of move semantics). The addition of move semantics complicated the value classification taxonomy by adding to it the concept of an xvalue(expiring value) which refers to an object near the end of its lifetime whose resources can be reused (typically by moving them). This also lead to the creation of the categories glvalue(generalized lvalue) which are lvalues and xvalues and prvalues(pure rvalues) which are rvalues that are not xvalues.This type of reference can be applied to all r-values including non-l-values as well as l-values. Some processors provide one or more instructions which take an immediate value, sometimes referred to as ""immediate"" for short. An immediate value is stored as part of the instruction which employs it, usually to load into, add to, or subtract from, a register. The other parts of the instruction are the opcode, and destination. The latter may be implicit. (A non-immediate value may reside in a register, or be stored elsewhere in memory, requiring the instruction to contain a direct or indirect address [e.g., index register address] to the value.)
The l-value expression designates (refers to) an object. A non-modifiable l-value is addressable, but not assignable. A modifiable l-value allows the designated object to be changed as well as examined. An r-value is any expression, a non-l-value is any expression that is not an l-value. One example is an ""immediate value"" (see above) and consequently not addressable..


== In assembly language ==
A value can be virtually any kind of data by a given data type, for instance a string, a digit, a single letter.
Processors often support more than one size of immediate data, e.g. 8 or 16 bit, employing a unique opcode and mnemonic for each instruction variant. If a programmer supplies a data value that will not fit, the assembler issues an ""Out of range"" error message. Most assemblers allow an immediate value to be expressed as ASCII, decimal, hexadecimal, octal, or binary data. Thus, the ASCII character 'A' is the same as 65 or 0x41. The byte order of strings may differ between processors, depending on the assembler and computer architecture.


== Notes ==


== References ==
Mitchell, John C. (1996). Foundations for Programming Languages. The MIT Press. ISBN 0-262-13321-0.
Strachey, Christopher (2000). ""Fundamental Concepts in Programming Languages"". Higher-Order and Symbolic Computation. 13: 11–49. doi:10.1023/A:1010000313106. S2CID 14124601.


== External links ==
Value Object
Transfer Object Pattern"
535f94d95c,Fiber (computer science),"In computer science, a fiber is a particularly lightweight thread of execution.
Like threads, fibers share address space. However, fibers use cooperative multitasking while threads use preemptive multitasking. Threads often depend on the kernel's thread scheduler to preempt a busy thread and resume another thread; fibers yield themselves to run another fiber while executing.


== Threads, fibers and coroutines ==
The key difference between fibers and kernel threads is that fibers use cooperative context switching, instead of preemptive time-slicing. In effect, fibers extend the concurrency taxonomy:

on a single computer, multiple processes can run
within a single process, multiple threads can run
within a single thread, multiple fibers can runFibers (sometimes called stackful coroutines or user mode cooperatively scheduled threads) and stackless coroutines (compiler synthesized state machines) represent two distinct programming facilities with vast performance and functionality differences.


== Advantages and disadvantages ==
Because fibers multitask cooperatively, thread safety is less of an issue than with preemptively scheduled threads, and synchronization constructs including spinlocks and atomic operations are unnecessary when writing fibered code, as they are implicitly synchronized.  However, many libraries yield a fiber implicitly as a method of conducting non-blocking I/O; as such, some caution and documentation reading is advised. A disadvantage is that fibers cannot utilize multiprocessor machines without also using preemptive threads; however, an M:N threading model with no more preemptive threads than CPU cores can be more efficient than either pure fibers or pure preemptive threading.
In some server programs fibers are used to soft block themselves to allow their single-threaded parent programs to continue working. In this design, fibers are used mostly for I/O access which does not need CPU processing. This allows the main program to continue with what it is doing. Fibers yield control to the single-threaded main program, and when the I/O operation is completed fibers continue where they left off.


== Operating system support ==
Less support from the operating system is needed for fibers than for threads. They can be implemented in modern Unix systems using the library functions getcontext, setcontext and swapcontext in ucontext.h, as in GNU Portable Threads, or in assembler as boost.fiber.
On Microsoft Windows, fibers are created using the ConvertThreadToFiber and CreateFiber calls; a fiber that is currently suspended may be resumed in any thread. Fiber-local storage, analogous to thread-local storage, may be used to create unique copies of variables.Symbian OS used a similar concept to fibers in its Active Scheduler. An active object contained one fiber to be executed by the Active Scheduler when one of several outstanding asynchronous calls completed. Several Active objects could be waiting to execute (based on priority) and each one had to restrict its own execution time.


== Fiber implementation examples ==
Fibers can be implemented without operating system support, although some operating systems or libraries provide explicit support for them.

Win32 supplies a fiber API (Windows NT 3.51 SP3 and later)
The C++ Boost libraries have a fiber class since Boost version 1.62
Ruby had Green threads (before version 1.9)
Netscape Portable Runtime (includes a user-space fibers implementation)
ribs2
PHP since version 8.1


== See also ==
setcontext/getcontext library routines
Green threads
call-with-current-continuation


== References ==


== External links ==
GNU Portable threads
""Portable Coroutine Library"". Freecode.
Fiber Pool A multicore-capable C++ framework based on fibers for Microsoft Windows.
State Threads
Protothreads
ribs2
boost.fiber"
816cb66214,Computer program,"A computer program is a sequence or set of instructions in a programming language for a computer to execute. Computer programs are one component of software, which also includes documentation and other intangible components.A computer program in its human-readable form is called source code. Source code needs another computer program to execute because computers can only execute their native machine instructions. Therefore, source code may be translated to machine instructions using the language's compiler. (Assembly language programs are translated using an assembler.) The resulting file is called an executable. Alternatively, source code may execute within the language's interpreter.If the executable is requested for execution, then the operating system loads it into memory and starts a process. The central processing unit will soon switch to this process so it can fetch, decode, and then execute each machine instruction.If the source code is requested for execution, then the operating system loads the corresponding interpreter into memory and starts a process. The interpreter then loads the source code into memory to translate and execute each statement. Running the source code is slower than running an executable. Moreover, the interpreter must be installed on the computer.


== Example computer program ==

The ""Hello, World!"" program is used to illustrate a language's basic syntax. The syntax of the language BASIC (1964) was intentionally limited to make the language easy to learn. For example, variables are not declared before being used. Also, variables are automatically initialized to zero. Here is an example computer program, in Basic, to average a list of numbers:

Once the mechanics of basic computer programming are learned, more sophisticated and powerful languages are available to build large computer systems.


== History ==

Improvements in software development are the result of improvements in computer hardware. At each stage in hardware's history, the task of computer programming changed dramatically.


=== Analytical Engine ===

In 1837, Charles Babbage was inspired by Jacquard's loom to attempt to build the Analytical Engine.
The names of the components of the calculating device were borrowed from the textile industry. In the textile industry, yarn was brought from the store to be milled. The device had a ""store"" which consisted of memory to hold 1,000 numbers of 50 decimal digits each. Numbers from the ""store"" were transferred to the ""mill"" for processing. It was programmed using two sets of perforated cards. One set directed the operation and the other set inputted the variables. However, after more than 17,000 pounds of the British government's money, the thousands of cogged wheels and gears never fully worked together.Ada Lovelace worked for Charles Babbage to create a description of the Analytical Engine (1843). The description contained Note G which completely detailed a method for calculating Bernoulli numbers using the Analytical Engine. This note is recognized by some historians as the world's first computer program.


=== Universal Turing machine ===

In 1936, Alan Turing introduced the Universal Turing machine, a theoretical device that can model every computation.
It is a finite-state machine that has an infinitely long read/write tape. The machine can move the tape back and forth, changing its contents as it performs an algorithm. The machine starts in the initial state, goes through a sequence of steps, and halts when it encounters the halt state. All present-day computers are Turing complete.


=== ENIAC ===

The Electronic Numerical Integrator And Computer (ENIAC) was built between July 1943 and Fall 1945. It was a Turing complete, general-purpose computer that used 17,468 vacuum tubes to create the circuits. At its core, it was a series of Pascalines wired together. Its 40 units weighed 30 tons, occupied 1,800 square feet (167 m2), and consumed $650 per hour (in 1940s currency) in electricity when idle. It had 20 base-10 accumulators. Programming the ENIAC took up to two months. Three function tables were on wheels and needed to be rolled to fixed function panels. Function tables were connected to function panels by plugging heavy black cables into plugboards. Each function table had 728 rotating knobs. Programming the ENIAC also involved setting some of the 3,000 switches. Debugging a program took a week. It ran from 1947 until 1955 at Aberdeen Proving Ground, calculating hydrogen bomb parameters, predicting weather patterns, and producing firing tables to aim artillery guns.


=== Stored-program computers ===
Instead of plugging in cords and turning switches, a stored-program computer loads its instructions into memory just like it loads its data into memory. As a result, the computer could be programmed quickly and perform calculations at very fast speeds. Presper Eckert and John Mauchly built the ENIAC. The two engineers introduced the stored-program concept in a three-page memo dated February 1944. Later, in September 1944, Dr. John von Neumann began working on the ENIAC project. On June 30, 1945, von Neumann published the First Draft of a Report on the EDVAC which equated the structures of the computer with the structures of the human brain. The design became known as the von Neumann architecture. The architecture was simultaneously deployed in the constructions of the EDVAC and EDSAC computers in 1949.The IBM System/360 (1964) was a family of computers, each having the same instruction set architecture. The Model 20 was the smallest and least expensive. Customers could upgrade and retain the same application software. The Model 195 was the most premium.  Each System/360 model featured multiprogramming—having multiple processes in memory at once. When one process was waiting for input/output, another could compute.
IBM planned for each model to be programmed using PL/1. A committee was formed that included COBOL, Fortran and ALGOL programmers. The purpose was to develop a language that was comprehensive, easy to use, extendible, and would replace Cobol and Fortran. The result was a large and complex language that took a long time to compile.

Computers manufactured until the 1970s had front-panel switches for manual programming. The computer program was written on paper for reference. An instruction was represented by a configuration of on/off settings. After setting the configuration, an execute button was pressed. This process was then repeated. Computer programs also were automatically inputted via paper tape, punched cards or magnetic-tape. After the medium was loaded, the starting address was set via switches, and the execute button was pressed.


=== Very Large Scale Integration ===

A major milestone in software development was the invention of the Very Large Scale Integration (VLSI) circuit (1964). Following World War II, tube-based technology was replaced with point-contact transistors (1947) and bipolar junction transistors (late 1950s) mounted on a circuit board. During the 1960s, the aerospace industry replaced the circuit board with an integrated circuit chip.Robert Noyce, co-founder of Fairchild Semiconductor (1957) and Intel (1968), achieved a technological improvement to refine the production of field-effect transistors (1963). The goal is to alter the electrical resistivity and conductivity of a semiconductor junction. First, naturally occurring silicate minerals are converted into polysilicon rods using the Siemens process. The Czochralski process then converts the rods into a monocrystalline silicon, boule crystal. The crystal is then thinly sliced to form a wafer substrate. The planar process of photolithography then integrates unipolar transistors, capacitors, diodes, and resistors onto the wafer to build a matrix of metal–oxide–semiconductor (MOS) transistors. The MOS transistor is the primary component in integrated circuit chips.Originally, integrated circuit chips had their function set during manufacturing. During the 1960s, controlling the electrical flow migrated to programming a matrix of read-only memory (ROM). The matrix resembled a two-dimensional array of fuses. The process to embed instructions onto the matrix was to burn out the unneeded connections. There were so many connections, firmware programmers wrote a computer program on another chip to oversee the burning. The technology became known as Programmable ROM. In 1971, Intel installed the computer program onto the chip and named it the Intel 4004 microprocessor.

The terms microprocessor and central processing unit (CPU) are now used interchangeably. However, CPUs predate microprocessors. For example, the IBM System/360 (1964) had a CPU made from circuit boards containing discrete components on ceramic substrates.


=== Sac State 8008 ===

The Intel 4004 (1971) was a 4-bit microprocessor designed to run the Busicom calculator. Five months after its release, Intel released the Intel 8008, an 8-bit microprocessor. Bill Pentz led a team at Sacramento State to build the first microcomputer using the Intel 8008: the Sac State 8008 (1972). Its purpose was to store patient medical records. The computer supported a disk operating system to run a Memorex, 3-megabyte, hard disk drive. It had a color display and keyboard that was packaged in a single console. The disk operating system was programmed using IBM's Basic Assembly Language (BAL). The medical records application was programmed using a BASIC interpreter. However, the computer was an evolutionary dead-end because it was extremely expensive. Also, it was built at a public university lab for a specific purpose. Nonetheless, the project contributed to the development of the Intel 8080 (1974) instruction set.


=== x86 series ===

In 1978, the modern software development environment began when Intel upgraded the Intel 8080 to the Intel 8086. Intel simplified the Intel 8086 to manufacture the cheaper Intel 8088. IBM embraced the Intel 8088 when they entered the personal computer market (1981). As consumer demand for personal computers increased, so did Intel's microprocessor development. The succession of development is known as the x86 series. The x86 assembly language is a family of backward-compatible machine instructions. Machine instructions created in earlier microprocessors were retained throughout microprocessor upgrades. This enabled consumers to purchase new computers without having to purchase new application software.  The major categories of instructions are:
Memory instructions to set and access numbers and strings in random-access memory.
Integer arithmetic logic unit (ALU) instructions to perform the primary arithmetic operations on integers.
Floating point ALU instructions to perform the primary arithmetic operations on real numbers.
Call stack instructions to push and pop words needed to allocate memory and interface with functions.
Single instruction, multiple data (SIMD) instructions to increase speed when multiple processors are available to perform the same algorithm on an array of data.


=== Changing programming environment ===

VLSI circuits enabled the programming environment to advance from a computer terminal (until the 1990s) to a graphical user interface (GUI) computer. Computer terminals limited programmers to a single shell running in a command-line environment. During the 1970s, full-screen source code editing became possible through a text-based user interface. Regardless of the technology available, the goal is to program in a programming language.


== Programming paradigms and languages ==
Programming language features exist to provide building blocks to be combined to express programming ideals. Ideally, a programming language should:
express ideas directly in the code.
express independent ideas independently.
express relationships among ideas directly in the code.
combine ideas freely.
combine ideas only where combinations make sense.
express simple ideas simply.The programming style of a programming language to provide these building blocks may be categorized into programming paradigms. For example, different paradigms may differentiate:
procedural languages, functional languages, and logical languages.
different levels of data abstraction.
different levels of class hierarchy.
different levels of input datatypes, as in container types and generic programming.Each of these programming styles has contributed to the synthesis of different programming languages.A programming language is a set of keywords, symbols, identifiers, and rules by which programmers can communicate instructions to the computer. They follow a set of rules called a syntax.
Keywords are reserved words to form declarations and statements.
Symbols are characters to form operations, assignments, control flow, and delimiters.
Identifiers are words created by programmers to form constants, variable names, structure names, and function names.
Syntax Rules are defined in the Backus–Naur form.Programming languages get their basis from formal languages. The purpose of defining a solution in terms of its formal language is to generate an algorithm to solve the underlining problem. An algorithm is a sequence of simple instructions that solve a problem.


=== Generations of programming language ===

The evolution of programming language began when the EDSAC (1949) used the first stored computer program in its von Neumann architecture. Programming the EDSAC was in the first generation of programming language.

The first generation of programming language is machine language. Machine language requires the programmer to enter instructions using instruction numbers called machine code. For example, the ADD operation on the PDP-11 has instruction number 24576.The second generation of programming language is assembly language. Assembly language allows the programmer to use mnemonic instructions instead of remembering instruction numbers. An assembler translates each assembly language mnemonic into its machine language number. For example, on the PDP-11, the operation 24576 can be referenced as ADD in the source code. The four basic arithmetic operations have assembly instructions like ADD, SUB, MUL, and DIV. Computers also have instructions like DW (Define Word) to reserve memory cells. Then the MOV instruction can copy integers between registers and memory.The basic structure of an assembly language statement is a label, operation, operand, and comment.Labels allow the programmer to work with variable names. The assembler will later translate labels into physical memory addresses.
Operations allow the programmer to work with mnemonics. The assembler will later translate mnemonics into instruction numbers.
Operands tell the assembler which data the operation will process.
Comments allow the programmer to articulate a narrative because the instructions alone are vague.
The key characteristic of an assembly language program is it forms a one-to-one mapping to its corresponding machine language target.The third generation of programming language uses compilers and interpreters to execute computer programs. The distinguishing feature of a third generation language is its independence from particular hardware. Early languages include Fortran (1958), COBOL (1959), ALGOL (1960), and BASIC (1964). In 1973, the C programming language emerged as a high-level language that produced efficient machine language instructions. Whereas third-generation languages historically generated many machine instructions for each statement, C has statements that may generate a single machine instruction. Moreover, an optimizing compiler might overrule the programmer and produce fewer machine instructions than statements. Today, an entire paradigm of languages fill the imperative, third generation spectrum.The fourth generation of programming language emphasizes what output results are desired, rather than how programming statements should be constructed. Declarative languages attempt to limit side effects and allow programmers to write code with relatively few errors. One popular fourth generation language is called Structured Query Language (SQL). Database developers no longer need to process each database record one at a time. Also, a simple instruction can generate output records without having to understand how it's retrieved.


=== Imperative languages ===

Imperative languages specify a sequential algorithm using declarations, expressions, and statements:
A declaration introduces a variable name to the computer program and assigns it to a datatype – for example: var x: integer;
An expression yields a value – for example: 2 + 2 yields 4
A statement might assign an expression to a variable or use the value of a variable to alter the program's control flow – for example: x := 2 + 2; if x = 4 then do_something();


==== Fortran ====
FORTRAN (1958) was unveiled as ""The IBM Mathematical FORmula TRANslating system."" It was designed for scientific calculations, without string handling facilities. Along with declarations, expressions, and statements, it supported:

arrays.
subroutines.
""do"" loops.It succeeded because:

programming and debugging costs were below computer running costs.
it was supported by IBM.
applications at the time were scientific.However, non-IBM vendors also wrote Fortran compilers, but with a syntax that would likely fail IBM's compiler. The American National Standards Institute (ANSI) developed the first Fortran standard in 1966. In 1978, Fortran 77 became the standard until 1991. Fortran 90 supports:

records.
pointers to arrays.


==== COBOL ====
COBOL (1959) stands for ""COmmon Business Oriented Language."" Fortran manipulated symbols. It was soon realized that symbols didn't need to be numbers, so strings were introduced. The US Department of Defense influenced COBOL's development, with Grace Hopper being a major contributor. The statements were English-like and verbose. The goal was to design a language so managers could read the programs. However, the lack of structured statements hindered this goal.COBOL's development was tightly controlled, so dialects didn't emerge to require ANSI standards. As a consequence, it wasn't changed for 15 years until 1974. The 1990s version did make consequential changes, like object-oriented programming.


==== Algol ====
ALGOL (1960) stands for ""ALGOrithmic Language."" It had a profound influence on programming language design. Emerging from a committee of European and American programming language experts, it used standard mathematical notation and had a readable structured design. Algol was first to define its syntax using the Backus–Naur form. This led to syntax-directed compilers. It added features like:

block structure, where variables were local to their block.
arrays with variable bounds.
""for"" loops.
functions.
recursion.Algol's direct descendants include Pascal, Modula-2, Ada, Delphi and Oberon on one branch. On another branch the descendants include C, C++ and Java.


==== Basic ====
BASIC (1964) stands for ""Beginner's All-Purpose Symbolic Instruction Code."" It was developed at Dartmouth College for all of their students to learn. If a student didn't go on to a more powerful language, the student would still remember Basic. A Basic interpreter was installed in the microcomputers manufactured in the late 1970s. As the microcomputer industry grew, so did the language.Basic pioneered the interactive session. It offered operating system commands within its environment:

The 'new' command created an empty slate.
Statements evaluated immediately.
Statements could be programmed by preceding them with a line number.
The 'list' command displayed the program.
The 'run' command executed the program.However, the Basic syntax was too simple for large programs. Recent dialects added structure and object-oriented extensions. Microsoft's Visual Basic is still widely used and produces a graphical user interface.


==== C ====
C programming language (1973) got its name because the language BCPL was replaced with B, and AT&T Bell Labs called the next version ""C."" Its purpose was to write the UNIX operating system. C is a relatively small language, making it easy to write compilers. Its growth mirrored the hardware growth in the 1980s. Its growth also was because it has the facilities of assembly language, but uses a high-level syntax. It added advanced features like:

inline assembler.
arithmetic on pointers.
pointers to functions.
bit operations.
freely combining complex operators.
C allows the programmer to control which region of memory data is to be stored. Global variables and static variables require the fewest clock cycles to store. The stack is automatically used for the standard variable declarations. Heap memory is returned to a pointer variable from the malloc() function.

The global and static data region is located just above the program region. (The program region is technically called the text region. It's where machine instructions are stored.)The global and static data region is technically two regions. One region is called the initialized data segment, where variables declared with default values are stored. The other region is called the block started by segment, where variables declared without default values are stored.
Variables stored in the global and static data region have their addresses set at compile-time. They retain their values throughout the life of the process.The global and static region stores the global variables that are declared on top of (outside) the main() function. Global variables are visible to main() and every other function in the source code.On the other hand, variable declarations inside of main(), other functions, or within { } block delimiters are local variables. Local variables also include formal parameter variables. Parameter variables are enclosed within the parenthesis of function definitions. They provide an interface to the function.Local variables declared using the static prefix are also stored in the global and static data region. Unlike global variables, static variables are only visible within the function or block. Static variables always retain their value. An example usage would be the function int increment_counter(){ static int counter = 0; counter++; return counter;}The stack region is a contiguous block of memory located near the top memory address. Variables placed in the stack are populated from top to bottom. A stack pointer is a special-purpose register that keeps track of the last memory address populated. Variables are placed into the stack via the assembly language PUSH instruction. Therefore, the addresses of these variables are set during runtime. The method for stack variables to lose their scope is via the POP instruction.Local variables declared without the static prefix, including formal parameter variables, are called automatic variables and are stored in the stack. They are visible inside the function or block and lose their scope upon exiting the function or block.The heap region is located below the stack. It is populated from the bottom to the top. The operating system manages the heap using a heap pointer and a list of allocated memory blocks. Like the stack, the addresses of heap variables are set during runtime. An out of memory error occurs when the heap pointer and the stack pointer meet.C provides the malloc() library function to allocate heap memory. Populating the heap with data is an additional copy function. Variables stored in the heap are economically passed to functions using pointers. Without pointers, the entire block of data would have to be passed to the function via the stack.


==== C++ ====
In the 1970s, software engineers needed language support to break large projects down into modules. One obvious feature was to decompose large projects physically into separate files. A less obvious feature was to decompose large projects logically into abstract datatypes. At the time, languages supported concrete (scalar) datatypes like integer numbers, floating-point numbers, and strings of characters. Concrete datatypes have their representation as part of their name. Abstract datatypes are structures of concrete datatypes, with a new name assigned. For example, a list of integers could be called integer_list.
In object-oriented jargon, abstract datatypes are called classes. However, a class is only a definition; no memory is allocated. When memory is allocated to a class, it's called an object.Object-oriented imperative languages developed by combining the need for classes and the need for safe functional programming. A function, in an object-oriented language, is assigned to a class. An assigned function is then referred to as a method, member function, or operation. Object-oriented programming is executing operations on objects.Object-oriented languages support a syntax to model subset/superset relationships. In set theory, an element of a subset inherits all the attributes contained in the superset. For example, a student is a person. Therefore, the set of students is a subset of the set of persons. As a result, students inherit all the attributes common to all persons. Additionally, students have unique attributes that other people don't have. Object-oriented languages model subset/superset relationships using inheritance. Object-oriented programming became the dominant language paradigm by the late 1990s.C++ (1985) was originally called ""C with Classes."" It was designed to expand C's capabilities by adding the object-oriented facilities of the language Simula.An object-oriented module is composed of two files. The definitions file is called the header file. Here is a C++ header file for the GRADE class in a simple school application:

A constructor operation is a function with the same name as the class name. It is executed when the calling operation executes the new statement.
A module's other file is the source file. Here is a C++ source file for the GRADE class in a simple school application:

Here is a C++ header file for the PERSON class in a simple school application:

Here is a C++ source file for the PERSON class in a simple school application:

Here is a C++ header file for the STUDENT class in a simple school application:

Here is a C++ source file for the STUDENT class in a simple school application:

Here is a driver program for demonstration:

Here is a makefile to compile everything:


=== Declarative languages ===

Imperative languages have one major criticism: assigning an expression to a non-local variable may produce an unintended side effect. Declarative languages generally omit the assignment statement and the control flow. They describe what computation should be performed and not how to compute it. Two broad categories of declarative languages are functional languages and logical languages.
The principle behind a functional language is to use lambda calculus as a guide for a well defined semantic. In mathematics, a function is a rule that maps elements from an expression to a range of values. Consider the function:
times_10(x) = 10 * x
The expression 10 * x is mapped by the function times_10() to a range of values. One value happens to be 20. This occurs when x is 2. So, the application of the function is mathematically written as:
times_10(2) = 20
A functional language compiler will not store this value in a variable. Instead, it will push the value onto the computer's stack before setting the program counter back to the calling function. The calling function will then pop the value from the stack.Imperative languages do support functions. Therefore, functional programming can be achieved in an imperative language, if the programmer uses discipline. However, a functional language will force this discipline onto the programmer through its syntax. Functional languages have a syntax tailored to emphasize the what.A functional program is developed with a set of primitive functions followed by a single driver function. Consider the snippet:
function max(a,b){/* code omitted */}
function min(a,b){/* code omitted */}
function difference_between_largest_and_smallest(a,b,c) {

return max(a,max(b,c)) - min(a, min(b,c));}
The primitives are max() and min(). The driver function is difference_between_largest_and_smallest(). Executing:
put(difference_between_largest_and_smallest(10,4,7)); will output 6.
Functional languages are used in computer science research to explore new language features. Moreover, their lack of side-effects have made them popular in parallel programming and concurrent programming. However, application developers prefer the object-oriented features of imperative languages.


==== Lisp ====
Lisp (1958) stands for ""LISt Processor."" It is tailored to process lists. A full structure of the data is formed by building lists of lists. In memory, a tree data structure is built. Internally, the tree structure lends nicely for recursive functions. The syntax to build a tree is to enclose the space-separated elements within parenthesis. The following is a list of three elements. The first two elements are themselves lists of two elements:
((A B) (HELLO WORLD) 94)
Lisp has functions to extract and reconstruct elements. The function head() returns a list containing the first element in the list. The function tail() returns a list containing everything but the first element. The function cons() returns a list that is the concatenation of other lists. Therefore, the following expression will return the list x:
cons(head(x), tail(x))
One drawback of Lisp is when many functions are nested, the parentheses may look confusing. Modern Lisp environments help ensure parenthesis match. As an aside, Lisp does support the imperative language operations of the assignment statement and goto loops. Also, Lisp is not concerned with the datatype of the elements at compile time. Instead, it assigns (and may reassign) the datatypes at runtime. Assigning the datatype at runtime is called dynamic binding. Whereas dynamic binding increases the language's flexibility, programming errors may linger until late in the software development process.Writing large, reliable, and readable Lisp programs requires forethought. If properly planned, the program may be much shorter than an equivalent imperative language program. Lisp is widely used in artificial intelligence. However, its usage has been accepted only because it has imperative language operations, making unintended side-effects possible.


==== ML ====
ML (1973) stands for ""Meta Language."" ML checks to make sure only data of the same type are compared with one another. For example, this function has one input parameter (an integer) and returns an integer:

ML is not parenthesis-eccentric like Lisp. The following is an application of times_10():

times_10 2

It returns ""20 : int"". (Both the results and the datatype are returned.)
Like Lisp, ML is tailored to process lists. Unlike Lisp, each element is the same datatype. Moreover, ML assigns the datatype of an element at compile-time. Assigning the datatype at compile-time is called static binding. Static binding increases reliability because the compiler checks the context of variables before they are used.


==== Prolog ====
Prolog (1972) stands for ""PROgramming in LOgic."" It was designed to process natural languages. The building blocks of a Prolog program are objects and their relationships to other objects. Objects are built by stating true facts about them.Set theory facts are formed by assigning objects to sets. The syntax is setName(object).

Cat is an animal.animal(cat).Mouse is an animal.animal(mouse).Tom is a cat.cat(tom).Jerry is a mouse.mouse(jerry).Adjective facts are formed using adjective(object).

Cat is big.big(cat).Mouse is small.small(mouse).Relationships are formed using multiple items inside the parentheses. In our example we have verb(object,object) and verb(adjective,adjective).

Mouse eats cheese.eat(mouse,cheese).Big animals eat small animals.eat(big,small).After all the facts and relationships are entered, then a question can be asked:

Will Tom eat Jerry?
?- eat(tom,jerry).Prolog's usage has expanded to become a goal-oriented language. In a goal-oriented application, the goal is defined by providing a list of subgoals. Then each subgoal is defined by further providing a list of its subgoals, etc. If a path of subgoals fails to find a solution, then that subgoal is backtracked and another path is systematically attempted. Practical applications include solving the shortest path problem and producing family trees.


=== Object-oriented programming ===
Object-oriented programming is a programming method to execute operations (functions) on objects. The basic idea is to group the characteristics of a phenomenon into an object container and give the container a name. The operations on the phenomenon are also grouped into the container. Object-oriented programming developed by combining the need for containers and the need for safe functional programming. This programming method need not be confined to an object-oriented language. In an object-oriented language, an object container is called a class. In a non-object-oriented language, a data structure (which is also known as a record) may become an object container. To turn a data structure into an object container, operations need to be written specifically for the structure. The resulting structure is called an abstract datatype. However, inheritance will be missing. Nonetheless, this shortcoming can be overcome.
Here is a C programming language header file for the GRADE abstract datatype in a simple school application:

The grade_new() function performs the same algorithm as the C++ constructor operation.
Here is a C programming language source file for the GRADE abstract datatype in a simple school application:

In the constructor, the function calloc() is used instead of malloc() because each memory cell will be set to zero.
Here is a C programming language header file for the PERSON abstract datatype in a simple school application:

Here is a C programming language source file for the PERSON abstract datatype in a simple school application:

Here is a C programming language header file for the STUDENT abstract datatype in a simple school application:

Here is a C programming language source file for the STUDENT abstract datatype in a simple school application:

Here is a driver program for demonstration:

Here is a makefile to compile everything:

The formal strategy to build object-oriented objects is to:
Identify the objects. Most likely these will be nouns.
Identify each object's attributes. What helps to describe the object?
Identify each object's actions. Most likely these will be verbs.
Identify the relationships from object to object. Most likely these will be verbs.For example:

A person is a human identified by a name.
A grade is an achievement identified by a letter.
A student is a person who earns a grade.


=== Syntax and semantics ===
The syntax of a programming language is a list of production rules which govern its form. A programming language's form is the correct placement of its declarations, expressions, and statements. Complementing the syntax of a language are its semantics. The semantics describe the meanings attached to various syntactic constructs. A syntactic construct may need a semantic description because a form may have an invalid interpretation. Also, different languages might have the same syntax; however, their behaviors may be different.
The syntax of a language is formally described by listing the production rules. Whereas the syntax of a natural language is extremely complicated, a subset of the English language can have this production rule listing:
a sentence is made up of a noun-phrase followed by a verb-phrase;
a noun-phrase is made up of an article followed by an adjective followed by a noun;
a verb-phrase is made up of a verb followed by a noun-phrase;
an article is 'the';
an adjective is 'big' or
an adjective is 'small';
a noun is 'cat' or
a noun is 'mouse';
a verb is 'eats';The words in bold-face are known as ""non-terminals"". The words in 'single quotes' are known as ""terminals"".From this production rule listing, complete sentences may be formed using a series of replacements. The process is to replace non-terminals with either a valid non-terminal or a valid terminal. The replacement process repeats until only terminals remain. One valid sentence is:

sentence
noun-phrase verb-phrase
article adjective noun verb-phrase
the adjective noun verb-phrase
the big noun verb-phrase
the big cat verb-phrase
the big cat verb noun-phrase
the big cat eats noun-phrase
the big cat eats article adjective noun
the big cat eats the adjective noun
the big cat eats the small noun
the big cat eats the small mouseHowever, another combination results in an invalid sentence:

the small mouse eats the big catTherefore, a semantic is necessary to correctly describe the meaning of an eat activity.
One production rule listing method is called the Backus–Naur form (BNF). BNF describes the syntax of a language and itself has a syntax. This recursive definition is an example of a meta-language. The syntax of BNF includes:

::= which translates to is made up of a[n] when a non-terminal is to its right. It translates to is when a terminal is to its right.
| which translates to or.
< and > which surround non-terminals.Using BNF, a subset of the English language can have this production rule listing:

Using BNF, a signed-integer has the production rule listing:

Notice the recursive production rule:

This allows for an infinite number of possibilities. Therefore, a semantic is necessary to describe a limitation of the number of digits.
Notice the leading zero possibility in the production rules:

Therefore, a semantic is necessary to describe that leading zeros need to be ignored.
Two formal methods are available to describe semantics. They are denotational semantics and axiomatic semantics.


== Software engineering and computer programming ==

Software engineering is a variety of techniques to produce quality software. Computer programming is the process of writing or editing source code. In a formal environment, a systems analyst will gather information from managers about all the organization's processes to automate. This professional then prepares a detailed plan for the new or modified system. The plan is analogous to an architect's blueprint.


=== Performance objectives ===
The systems analyst has the objective to deliver the right information to the right person at the right time. The critical factors to achieve this objective are:
The quality of the output. Is the output useful for decision-making?
The accuracy of the output. Does it reflect the true situation?
The format of the output. Is the output easily understood?
The speed of the output. Time-sensitive information is important when communicating with the customer in real time.


=== Cost objectives ===
Achieving performance objectives should be balanced with all of the costs, including:
Development costs.
Uniqueness costs. A reusable system may be expensive. However, it might be preferred over a limited-use system.
Hardware costs.
Operating costs.Applying a systems development process will mitigate the axiom: the later in the process an error is detected, the more expensive it is to correct.


=== Waterfall model ===
The waterfall model is an implementation of a systems development process. As the waterfall label implies, the basic phases overlap each other:
The investigation phase is to understand the underlying problem.
The analysis phase is to understand the possible solutions.
The design phase is to plan the best solution.
The implementation phase is to program the best solution.
The maintenance phase lasts throughout the life of the system. Changes to the system after it's deployed may be necessary. Faults may exist, including specification faults, design faults, or coding faults. Improvements may be necessary. Adaption may be necessary to react to a changing environment.


=== Computer programmer ===
A computer programmer is a specialist responsible for writing or modifying the source code to implement the detailed plan. A programming team is likely to be needed because most systems are too large to be completed by a single programmer. However, adding programmers to a project may not shorten the completion time. Instead, it may lower the quality of the system. To be effective, program modules need to be defined and distributed to team members. Also, team members must interact with one another in a meaningful and effective way.Computer programmers may be programming-in-the-small: programming within a single module. Chances are a module will execute modules located in other source code files. Therefore, computer programmers may be programming-in-the-large: programming modules so they will effectively couple with each other. Programming-in-the-large includes contributing to the application programming interface (API).


=== Program modules ===
Modular programming is a technique to refine imperative language programs. Refined programs may reduce the software size, separate responsibilities, and thereby mitigate software aging. A program module is a sequence of statements that are bounded within a block and together identified by a name. Modules have a function, context, and logic:
The function of a module is what it does.
The context of a module are the elements being performed upon.
The logic of a module is how it performs the function.The module's name should be derived first by its function, then by its context. Its logic should not be part of the name. For example, function compute_square_root( x ) or function compute_square_root_integer( i : integer ) are appropriate module names. However, function compute_square_root_by_division( x ) is not.
The degree of interaction within a module is its level of cohesion. Cohesion is a judgment of the relationship between a module's name and its function. The degree of interaction between modules is the level of coupling. Coupling is a judgement of the relationship between a module's context and the elements being performed upon.


=== Cohesion ===
The levels of cohesion from worst to best are:
Coincidental Cohesion: A module has coincidental cohesion if it performs multiple functions, and the functions are completely unrelated. For example, function read_sales_record_print_next_line_convert_to_float(). Coincidental cohesion occurs in practice if management enforces silly rules. For example, ""Every module will have between 35 and 50 executable statements.""
Logical Cohesion: A module has logical cohesion if it has available a series of functions, but only one of them is executed. For example, function perform_arithmetic( perform_addition, a, b ).
Temporal Cohesion: A module has temporal cohesion if it performs functions related to time. One example, function initialize_variables_and_open_files(). Another example, stage_one(), stage_two(), ...
Procedural Cohesion: A module has procedural cohesion if it performs multiple loosely related functions. For example, function read_part_number_update_employee_record().
Communicational Cohesion: A module has communicational cohesion if it performs multiple closely related functions. For example, function read_part_number_update_sales_record().
Informational Cohesion: A module has informational cohesion if it performs multiple functions, but each function has its own entry and exit points. Moreover, the functions share the same data structure. Object-oriented classes work at this level.
Functional Cohesion: a module has functional cohesion if it achieves a single goal working only on local variables. Moreover, it may be reusable in other contexts.


=== Coupling ===
The levels of coupling from worst to best are:
Content Coupling: A module has content coupling if it modifies a local variable of another function. COBOL used to do this with the alter verb.
Common Coupling: A module has common coupling if it modifies a global variable.
Control Coupling: A module has control coupling if another module can modify its control flow. For example, perform_arithmetic( perform_addition, a, b ). Instead, control should be on the makeup of the returned object.
Stamp Coupling: A module has stamp coupling if an element of a data structure passed as a parameter is modified. Object-oriented classes work at this level.
 Data Coupling: A module has data coupling if all of its input parameters are needed and none of them are modified. Moreover, the result of the function is returned as a single object.


=== Data flow analysis ===

Data flow analysis is a design method used to achieve modules of functional cohesion and data coupling. The input to the method is a data-flow diagram. A data-flow diagram is a set of ovals representing modules. Each module's name is displayed inside its oval. Modules may be at the executable level or the function level.
The diagram also has arrows connecting modules to each other. Arrows pointing into modules represent a set of inputs. Each module should have only one arrow pointing out from it to represent its single output object. (Optionally, an additional exception arrow points out.) A daisy chain of ovals will convey an entire algorithm. The input modules should start the diagram. The input modules should connect to the transform modules. The transform modules should connect to the output modules.


== Functional categories ==

Computer programs may be categorized along functional lines. The main functional categories are application software and system software. System software includes the operating system, which couples computer hardware with application software. The purpose of the operating system is to provide an environment where application software executes in a convenient and efficient manner. Both application software and system software execute utility programs. At the hardware level, a microcode program controls the circuits throughout the central processing unit.


=== Application software ===

Application software is the key to unlocking the potential of the computer system. Enterprise application software bundles accounting, personnel, customer, and vendor applications. Examples include enterprise resource planning, customer relationship management, and supply chain management software.
Enterprise applications may be developed in-house as a one-of-a-kind proprietary software. Alternatively, they may be purchased as off-the-shelf software. Purchased software may be modified to provide custom software. If the application is customized, then either the company's resources are used or the resources are outsourced. Outsourced software development may be from the original software vendor or a third-party developer.The potential advantages of in-house software are features and reports may be developed exactly to specification. Management may also be involved in the development process and offer a level of control. Management may decide to counteract a competitor's new initiative or implement a customer or vendor requirement.  A merger or acquisition may necessitate enterprise software changes. The potential disadvantages of in-house software are time and resource costs may be extensive. Furthermore, risks concerning features and performance may be looming.
The potential advantages of off-the-shelf software are upfront costs are identifiable, the basic needs should be fulfilled, and its performance and reliability have a track record. The potential disadvantages of off-the-shelf software are it may have unnecessary features that confuse end users, it may lack features the enterprise needs, and the data flow may not match the enterprise's work processes.One approach to economically obtaining a customized enterprise application is through an application service provider. Specialty companies provide hardware, custom software, and end-user support. They may speed the development of new applications because they possess skilled information system staff. The biggest advantage is it frees in-house resources from staffing and managing complex computer projects. Many application service providers target small, fast-growing companies with limited information system resources. On the other hand, larger companies with major systems will likely have their technical infrastructure in place. One risk is having to trust an external organization with sensitive information. Another risk is having to trust the provider's infrastructure reliability.


=== Operating system ===

An operating system is the low-level software that supports a computer's basic functions, such as scheduling processes and controlling peripherals.In the 1950s, the programmer, who was also the operator, would write a program and run it. After the program finished executing, the output may have been printed, or it may have been punched onto paper tape or cards for later processing. More often than not the program did not work. The programmer then looked at the console lights and fiddled with the console switches. If less fortunate, a memory printout was made for further study. In the 1960s, programmers reduced the amount of wasted time by automating the operator's job. A program called an operating system was kept in the computer at all times.The term operating system may refer to two levels of software. The operating system may refer to the kernel program that manages the processes, memory, and devices. More broadly, the operating system may refer to the entire package of the central software. The package includes a kernel program, command-line interpreter, graphical user interface, utility programs, and editor.


==== Kernel Program ====

The kernel's main purpose is to manage the limited resources of a computer:

The kernel program should perform process scheduling. The kernel creates a process control block when a program is selected for execution. However, an executing program gets exclusive access to the central processing unit only for a time slice. To provide each user with the appearance of continuous access, the kernel quickly preempts each process control block to execute another one. The goal for system developers is to minimize dispatch latency.
The kernel program should perform memory management.When the kernel initially loads an executable into memory, it divides the address space logically into regions. The kernel maintains a master-region table and many per-process-region (pregion) tables—one for each running process. These tables constitute the virtual address space. The master-pregion table is used to determine where its contents are located in physical memory. The pregion tables allow each process to have its own program (text) pregion, data pregion, and stack pregion.
The program pregion stores machine instructions. Since machine instructions don't change, the program pregion may be shared by many processes of the same executable.
To save time and memory, the kernel may load only blocks of execution instructions from the disk drive, not the entire execution file completely.
The kernel is responsible for translating virtual addresses into physical addresses. The kernel may request data from the memory controller and, instead, receive a page fault. If so, the kernel accesses the memory management unit to populate the physical data region and translate the address.
The kernel allocates memory from the heap upon request by a process. When the process is finished with the memory, the process may request for it to be freed. If the process exits without requesting all allocated memory to be freed, then the kernel performs garbage collection to free the memory.
The kernel also ensures that a process only accesses its own memory, and not that of the kernel or other processes.The kernel program should perform file system management. The kernel has instructions to create, retrieve, update, and delete files.
The kernel program should perform device management. The kernel provides programs to standardize and simplify the interface to the mouse, keyboard, disk drives, printers, and other devices. Moreover, the kernel should arbitrate access to a device if two processes request it at the same time.
The kernel program should perform network management. The kernel transmits and receives packets on behalf of processes. One key service is to find an efficient route to the target system.
The kernel program should provide system level functions for programmers to use.Programmers access files through a relatively simple interface that in turn executes a relatively complicated low-level I/O interface. The low-level interface includes file creation, file descriptors, file seeking, physical reading, and physical writing.
Programmers create processes through a relatively simple interface that in turn executes a relatively complicated low-level interface.
Programmers perform date/time arithmetic through a relatively simple interface that in turn executes a relatively complicated low-level time interface.
The kernel program should provide a communication channel between executing processes. For a large software system, it may be desirable to engineer the system into smaller processes. Processes may communicate with one another by sending and receiving signals.Originally, operating systems were programmed in assembly; however, modern operating systems are typically written in higher-level languages like C, Objective-C, and Swift.


=== Utility program ===
A utility program is designed to aid system administration and software execution. Operating systems execute hardware utility programs to check the status of disk drives, memory, speakers, and printers. A utility program may optimize the placement of a file on a crowded disk. System utility programs monitor hardware and network performance. When a metric is outside an acceptable range, a trigger alert is generated.Utility programs include compression programs so data files are stored on less disk space. Compressed programs also save time when data files are transmitted over the network. Utility programs can sort and merge data sets. Utility programs detect computer viruses.


=== Microcode program ===

A microcode program is the bottom-level interpreter that controls the data path of software-driven computers.
(Advances in hardware have migrated these operations to hardware execution circuits.) Microcode instructions allow the programmer to more easily implement the digital logic level—the computer's real hardware. The digital logic level is the boundary between computer science and computer engineering.A logic gate is a tiny transistor that can return one of two signals: on or off.
Having one transistor forms the NOT gate.
Connecting two transistors in series forms the NAND gate.
Connecting two transistors in parallel forms the NOR gate.
Connecting a NOT gate to a NAND gate forms the AND gate.
Connecting a NOT gate to a NOR gate forms the OR gate.These five gates form the building blocks of binary algebra—the digital logic functions of the computer.
Microcode instructions are mnemonics programmers may use to execute digital logic functions instead of forming them in binary algebra. They are stored in a central processing unit's (CPU) control store.
These hardware-level instructions move data throughout the data path.
The micro-instruction cycle begins when the microsequencer uses its microprogram counter to fetch the next machine instruction from random-access memory. The next step is to decode the machine instruction by selecting the proper output line to the hardware module.
The final step is to execute the instruction using the hardware module's set of gates.

Instructions to perform arithmetic are passed through an arithmetic logic unit (ALU). The ALU has circuits to perform elementary operations to add, shift, and compare integers. By combining and looping the elementary operations through the ALU, the CPU performs its complex arithmetic.
Microcode instructions move data between the CPU and the memory controller. Memory controller microcode instructions manipulate two registers. The memory address register is used to access each memory cell's address. The memory data register is used to set and read each cell's contents.Microcode instructions move data between the CPU and the many computer buses. The disk controller bus writes to and reads from hard disk drives. Data is also moved between the CPU and other functional units via the peripheral component interconnect express bus.


== Notes ==


== References =="
3eb2b24221,Information technology,"Information technology (IT) is the use of computers to create, process, store, retrieve and exchange all kinds of data and information. IT forms part of information and communications technology (ICT). An information technology system (IT system) is generally an information system, a communications system, or, more specifically speaking, a computer system — including all hardware, software, and peripheral equipment — operated by a limited group of IT users.
Although humans have been storing, retrieving, manipulating, and communicating information since the earliest writing systems were developed, the term information technology in its modern sense first appeared in a 1958 article published in the Harvard Business Review; authors Harold J. Leavitt and Thomas L. Whisler commented that ""the new technology does not yet have a single established name. We shall call it information technology (IT)."" Their definition consists of three categories: techniques for processing, the application of statistical and mathematical methods to decision-making, and the simulation of higher-order thinking through computer programs.The term is commonly used as a synonym for computers and computer networks, but it also encompasses other information distribution technologies such as television and telephones. Several products or services within an economy are associated with information technology, including computer hardware, software, electronics, semiconductors, internet, telecom equipment, and e-commerce.Based on the storage and processing technologies employed, it is possible to distinguish four distinct phases of IT development: pre-mechanical (3000 BC — 1450 AD), mechanical (1450—1840), electromechanical (1840—1940), and electronic (1940 to present).Information technology is also a branch of computer science, which can be defined as the overall study of procedure, structure, and the processing of various types of data.  As this field continues to evolve across the world, the overall priority and importance has also grown, which is where we begin to see the introduction of computer science-related courses in K-12 education.


== History ==

Ideas of computer science were first mentioned before the 1950s under the Massachusetts Institute of Technology (MIT) and Harvard University, where they had discussed and began thinking of computer circuits and numerical calculations.  As time went on, the field of information technology and computer science became more complex and was able to handle the processing of more data.  Scholarly articles began to be published from different organizations.Looking at early computing, Alan Turing, J. Presper Eckert, and John Mauchly were considered to be some of the major pioneers of computer technology in the mid-1900s. Giving them such credit for their developments, most of their efforts were focused on designing the first digital computer. Along with that, topics such as artificial intelligence began to be brought up as Turing was beginning to question such technology of the time period.Devices have been used to aid computation for thousands of years, probably initially in the form of a tally stick. The Antikythera mechanism, dating from about the beginning of the first century BC, is generally considered to be the earliest known mechanical analog computer, and the earliest known geared mechanism. Comparable geared devices did not emerge in Europe until the 16th century, and it was not until 1645 that the first mechanical calculator capable of performing the four basic arithmetical operations was developed.Electronic computers, using either relays or valves, began to appear in the early 1940s. The electromechanical Zuse Z3, completed in 1941, was the world's first programmable computer, and by modern standards one of the first machines that could be considered a complete computing machine. During the Second World War, Colossus developed the first electronic digital computer to decrypt German messages. Although it was programmable, it was not general-purpose, being designed to perform only a single task. It also lacked the ability to store its program in memory; programming was carried out using plugs and switches to alter the internal wiring. The first recognizably modern electronic digital stored-program computer was the Manchester Baby, which ran its first program on 21 June 1948.The development of transistors in the late 1940s at Bell Laboratories allowed a new generation of computers to be designed with greatly reduced power consumption. The first commercially available stored-program computer, the Ferranti Mark I, contained 4050 valves and had a power consumption of 25 kilowatts. By comparison, the first transistorized computer developed at the University of Manchester and operational by November 1953, consumed only 150 watts in its final version.Several other breakthroughs in semiconductor technology include the integrated circuit (IC) invented by Jack Kilby at Texas Instruments and Robert Noyce at Fairchild Semiconductor in 1959, the metal–oxide–semiconductor field-effect transistor (MOSFET) invented by Mohamed Atalla and Dawon Kahng at Bell Laboratories in 1959, and the microprocessor invented by Ted Hoff, Federico Faggin, Masatoshi Shima, and Stanley Mazor at Intel in 1971. These important inventions led to the development of the personal computer (PC) in the 1970s, and the emergence of information and communications technology (ICT).By the year of 1984, according to the National Westminster Bank Quarterly Review, the term information technology had been redefined as ""The development of cable television was made possible by the convergence of telecommunications and computing technology (…generally known in Britain as information technology).""  We then begin to see the appearance of the term in 1990 contained within documents for the International Organization for Standardization (ISO).Innovations in technology have already revolutionized the world by the twenty-first century as people were able to access different online services. This has changed the workforce drastically as thirty percent of U.S. workers were already in careers in this profession. 136.9 million people were personally connected to the Internet, which was equivalent to 51 million households. Along with the Internet, new types of technology were also being introduced across the globe, which has improved efficiency and made things easier across the globe.
Along with technology revolutionizing society, millions of processes could be done in seconds. Innovations in communication were also crucial as people began to rely on the computer to communicate through telephone lines and cable. The introduction of the email was a really big thing as ""companies in one part of the world could communicate by e-mail with suppliers and buyers in another part of the world...""Not only personally, computers and technology have also revolutionized the marketing industry, resulting in more buyers of their products. During the year of 2002, Americans exceeded $28 billion in goods just over the Internet alone while e-commerce a decade later resulted in $289 billion in sales. And as computers are rapidly becoming more sophisticated by the day, they are becoming more used as people are becoming more reliant on them during the twenty-first century.


== Data processing ==


=== Storage ===

Early electronic computers such as Colossus made use of punched tape, a long strip of paper on which data was represented by a series of holes, a technology now obsolete. Electronic data storage, which is used in modern computers, dates from World War II, when a form of delay-line memory was developed to remove the clutter from radar signals, the first practical application of which was the mercury delay line. The first random-access digital storage device was the Williams tube, which was based on a standard cathode ray tube. However, the information stored in it and delay-line memory was volatile in the fact that it had to be continuously refreshed, and thus was lost once power was removed. The earliest form of non-volatile computer storage was the magnetic drum, invented in 1932 and used in the Ferranti Mark 1, the world's first commercially available general-purpose electronic computer.IBM introduced the first hard disk drive in 1956, as a component of their 305 RAMAC computer system.: 6  Most digital data today is still stored magnetically on hard disks, or optically on media such as CD-ROMs.: 4–5  Until 2002 most information was stored on analog devices, but that year digital storage capacity exceeded analog for the first time. As of 2007, almost 94% of the data stored worldwide was held digitally: 52% on hard disks, 28% on optical devices, and 11% on digital magnetic tape. It has been estimated that the worldwide capacity to store information on electronic devices grew from less than 3 exabytes in 1986 to 295 exabytes in 2007, doubling roughly every 3 years.


==== Databases ====

Database Management Systems (DMS) emerged in the 1960s to address the problem of storing and retrieving large amounts of data accurately and quickly. An early such system was IBM's Information Management System (IMS), which is still widely deployed more than 50 years later. IMS stores data hierarchically, but in the 1970s Ted Codd proposed an alternative relational storage model based on set theory and predicate logic and the familiar concepts of tables, rows, and columns. In 1981, the first commercially available relational database management system (RDBMS) was released by Oracle.All DMS consist of components, they allow the data they store to be accessed simultaneously by many users while maintaining its integrity. All databases are common in one point that the structure of the data they contain is defined and stored separately from the data itself, in a database schema.In recent years, the extensible markup language (XML) has become a popular format for data representation. Although XML data can be stored in normal file systems, it is commonly held in relational databases to take advantage of their ""robust implementation verified by years of both theoretical and practical effort."" As an evolution of the Standard Generalized Markup Language (SGML), XML's text-based structure offers the advantage of being both machine- and human-readable.


=== Transmission ===

Data transmission has three aspects: transmission, propagation, and reception. It can be broadly categorized as broadcasting, in which information is transmitted unidirectionally downstream, or telecommunications, with bidirectional upstream and downstream channels.XML has been increasingly employed as a means of data interchange since the early 2000s, particularly for machine-oriented interactions such as those involved in web-oriented protocols such as SOAP, describing ""data-in-transit rather than... data-at-rest"".


=== Manipulation ===
Hilbert and Lopez identify the exponential pace of technological change (a kind of Moore's law): machines' application-specific capacity to compute information per capita roughly doubled every 14 months between 1986 and 2007; the per capita capacity of the world's general-purpose computers doubled every 18 months during the same two decades; the global telecommunication capacity per capita doubled every 34 months; the world's storage capacity per capita required roughly 40 months to double (every 3 years); and per capita broadcast information has doubled every 12.3 years.Massive amounts of data are stored worldwide every day, but unless it can be analyzed and presented effectively it essentially resides in what have been called data tombs: ""data archives that are seldom visited"". To address that issue, the field of data mining — ""the process of discovering interesting patterns and knowledge from large amounts of data"" — emerged in the late 1980s.


== Services ==


=== Email ===
The technology and services it provides for sending and receiving electronic messages (called ""letters"" or ""electronic letters"") over a distributed (including global) computer network. In terms of the composition of elements and the principle of operation, electronic mail practically repeats the system of regular (paper) mail, borrowing both terms (mail, letter, envelope, attachment, box, delivery, and others) and characteristic features — ease of use, message transmission delays, sufficient reliability and at the same time no guarantee of delivery. The advantages of e-mail are: easily perceived and remembered by a person addresses of the form user_name@domain_name (for example, somebody@example.com); the ability to transfer both plain text and formatted, as well as arbitrary files; independence of servers (in the general case, they address each other directly); sufficiently high reliability of message delivery; ease of use by humans and programs.
Disadvantages of e-mail: the presence of such a phenomenon as spam (massive advertising and viral mailings); the theoretical impossibility of guaranteed delivery of a particular letter; possible delays in message delivery (up to several days); limits on the size of one message and on the total size of messages in the mailbox (personal for users).


=== Search system ===
A software and hardware complex with a web interface that provides the ability to search for information on the Internet. A search engine usually means a site that hosts the interface (front-end) of the system. The software part of a search engine is a search engine (search engine) — a set of programs that provides the functionality of a search engine and is usually a trade secret of the search engine developer company. Most search engines look for information on World Wide Web sites, but there are also systems that can look for files on FTP servers, items in online stores, and information on Usenet newsgroups. Improving search is one of the priorities of the modern Internet (see the Deep Web article about the main problems in the work of search engines).


== Commercial effects ==
Companies in the information technology field are often discussed as a group as the ""tech sector"" or the ""tech industry.""  These titles can be misleading at times and should not be mistaken for ""tech companies;"" which are generally large scale, for-profit corporations that sell consumer technology and software.  It is also worth noting that from a business perspective, Information Technology departments are a ""cost center"" the majority of the time.  A cost center is a department or staff which incurs expenses, or ""costs,"" within a company rather than generating profits or revenue streams. Modern businesses rely heavily on technology for their day-to-day operations, so the expenses delegated to cover technology that facilitates business in a more efficient manner are usually seen as ""just the cost of doing business.""  IT departments are allocated funds by senior leadership and must attempt to achieve the desired deliverables while staying within that budget. Government and the private sector might have different funding mechanisms, but the principles are more-or-less the same. This is an often overlooked reason for the rapid interest in automation and Artificial Intelligence, but the constant pressure to do more with less is opening the door for automation to take control of at least some minor operations in large companies.
Many companies now have IT departments for managing the computers, networks, and other technical areas of their businesses. Companies have also sought to integrate IT with business outcomes and decision-making through a BizOps or business operations department.In a business context, the Information Technology Association of America has defined information technology as ""the study, design, development, application, implementation, support, or management of computer-based information systems"". The responsibilities of those working in the field include network administration, software development and installation, and the planning and management of an organization's technology life cycle, by which hardware and software are maintained, upgraded, and replaced.


=== Information services ===
Information services is a term somewhat loosely applied to a variety of IT-related services offered by commercial companies, as well as data brokers.

		
		
		
		


=== Ethics ===

The field of information ethics was established by mathematician Norbert Wiener in the 1940s.: 9  Some of the ethical issues associated with the use of information technology include:: 20–21 
Breaches of copyright by those downloading files stored without the permission of the copyright holders
Employers monitoring their employees' emails and other Internet usage
Unsolicited emails
Hackers accessing online databases
Web sites installing cookies or spyware to monitor a user's online activities, which may be used by data brokers


== See also ==
Information and communications technology (ICT)
Outline of information technology
Knowledge society


== References ==


=== Notes ===


=== Citations ===


=== Bibliography ===


== Further reading ==
Allen, T.; Morton, M. S. Morton, eds. (1994), Information Technology and the Corporation of the 1990s, Oxford University Press.
Gitta, Cosmas and South, David (2011). Southern Innovator Magazine Issue 1: Mobile Phones and Information Technology: United Nations Office for South-South Cooperation. ISSN 2222-9280.
Gleick, James (2011).The Information: A History, a Theory, a Flood. New York: Pantheon Books.
Price, Wilson T. (1981), Introduction to Computer Data Processing, Holt-Saunders International Editions, ISBN 978-4-8337-0012-2.
Shelly, Gary, Cashman, Thomas, Vermaat, Misty, and Walker, Tim. (1999). Discovering Computers 2000: Concepts for a Connected World. Cambridge, Massachusetts: Course Technology.
Webster, Frank, and Robins, Kevin. (1986). Information Technology — A Luddite Analysis. Norwood, NJ: Ablex.


== External links ==
 Learning materials related to Information technology at Wikiversity
 Media related to Information technology at Wikimedia Commons
 Quotations related to Information technology at Wikiquote"
9dbc888c00,Lecture Notes in Computer Science,"Lecture Notes in Computer Science is a series of computer science books published by Springer Science+Business Media since 1973.


== Overview ==
The series contains proceedings, post-proceedings, monographs, and Festschrifts. In addition, tutorials, state-of-the-art surveys, and ""hot topics"" are increasingly being included.The series is indexed by DBLP.


== See also ==
Monographiae Biologicae, another monograph series published by Springer Science+Business Media
Lecture Notes in Physics
Lecture Notes in Mathematics
Electronic Workshops in Computing, published by the British Computer Society


== References ==


== External links ==
Official website"
994deef3c1,Guard (computer science),"In computer programming, a guard is a boolean expression that must evaluate to true if the program execution is to continue in the branch in question. Regardless of which programming language is used, a guard clause, guard code, or guard statement, is a check of integrity preconditions used to avoid errors during execution.


== Uses ==
A typical example is checking that a reference about to be processed is not null, which avoids null-pointer failures.

Other uses include using a boolean field for idempotence (so subsequent calls are nops), as in the dispose pattern.


== Flatter code with less nesting ==
The guard provides an early exit from a subroutine, and is a commonly used deviation from structured programming, removing one level of nesting and resulting in flatter code: replacing if guard { ... } with if not guard: return; ....
Using guard clauses can be a refactoring technique to improve code. In general, less nesting is good, as it simplifies the code and reduces cognitive burden.
For example, in Python:


== Terminology ==
The term is used with specific meaning in APL, Haskell, Clean, Erlang, occam, Promela, OCaml, Swift, Python from version 3.10, and Scala programming languages. In Mathematica, guards are called constraints. Guards are the fundamental concept in Guarded Command Language, a language in formal methods. Guards can be used to augment pattern matching with the possibility to skip a pattern even if the structure matches. Boolean expressions in conditional statements usually also fit this definition of a guard although they are called conditions.


== Mathematics ==
In the following Haskell example, the guards occur between each pair of ""|"" and ""="":

This is similar to the respective mathematical notation:

  
    
      
        f
        (
        x
        )
        =
        
          {
          
            
              
                
                  1
                
                
                  
                    
                      if 
                    
                  
                  x
                  >
                  0
                
              
              
                
                  0
                
                
                  
                    
                      otherwise
                    
                  
                
              
            
          
          
        
      
    
    {\displaystyle f(x)=\left\{{\begin{matrix}1&{\mbox{if }}x>0\\0&{\mbox{otherwise}}\end{matrix}}\right.}
  
In this case the guards are in the ""if"" and ""otherwise"" clauses.


== Multiple guards ==
If there are several parallel guards, they are normally tried in a top-to-bottom order, and the branch of the first to pass is chosen. Guards in a list of cases are typically parallel.
However, in Haskell list comprehensions the guards are in series, and if any of them fails, the list element is not produced. This would be the same as combining the separate guards with logical AND, except that there can be other list comprehension clauses among the guards.


== Evolution ==
A simple conditional expression, already present in CPL in 1963, has a guard on first sub-expression, and another sub-expression to use in case the first one cannot be used. Some common ways to write this:

(x>0) -> 1/x; 0
x>0 ? 1/x : 0

If the second sub-expression can be a further simple conditional expression, we can give more alternatives to try before the last fall-through:

(x>0) -> 1/x; (x<0) -> -1/x; 0

In 1966 ISWIM had a form of conditional expression without an obligatory fall-through case, thus separating guard from the concept of choosing either-or. In the case of ISWIM, if none of the alternatives could be used, the value was to be undefined, which was defined to never compute into a value.
KRC, a ""miniaturized version"" of SASL (1976), was one of the first programming languages to use the term ""guard"". Its function definitions could have several clauses, and the one to apply was chosen based on the guards that followed each clause:

Use of guard clauses, and the term ""guard clause"", dates at least to Smalltalk practice in the 1990s, as codified by Kent Beck.
In 1996, Dyalog APL adopted an alternative pure functional style in which the guard is the only control structure. This example, in APL, computes the parity of the input number:


== Pattern guard ==
In addition to a guard attached to a pattern, pattern guard can refer to the use of pattern matching in the context of a guard. In effect, a match of the pattern is taken to mean pass. This meaning was introduced in a proposal for Haskell by Simon Peyton Jones titled A new view of guards in April 1997 and was used in the implementation of the proposal. The feature provides the ability to use patterns in the guards of a pattern.
An example in extended Haskell:

This would read: ""Clunky for an environment and two variables, in case the lookups of the variables from the environment produce values, is the sum of the values. ..."" As in list comprehensions, the guards are in series, and if any of them fails the branch is not taken.


== See also ==
Assertion
Guarded suspension
Iverson bracket
Logical conditional
Sentinel node, an object to represent the end of a data structure
Switch statement


== References ==


== External links ==
Guard in Free On-Line Dictionary of Computing - FOLDOC, Denis Howe (editor).
Guard Clause, WikiWikiWeb
The Haskell 98 Report, chapter 3 Expressions.
The Mathematica Book, section 2.3.5 Putting Constraints on Patterns
The Glorious Glasgow Haskell Compilation System User's Guide, Version 6.4, section 7.3.2. Pattern guards"
ee503fe576,Data type,"In computer science and computer programming, a data type (or simply type) is a collection or grouping of data values, usually specified by a set of possible values, a set of allowed operations on these values, and/or a representation of these values as machine types. A data type specification in a program constrains the possible values that an expression, such as a variable or a function call, might take. On literal data, it tells the compiler or interpreter how the programmer intends to use the data. Most programming languages support basic data types of integer numbers (of varying sizes), floating-point numbers (which approximate real numbers), characters and Booleans.


== Concept ==
A data type may be specified for many reasons: similarity, convenience, or to focus the attention. It is frequently a matter of good organization
that aids the understanding of complex definitions. Almost all programming languages explicitly include the notion of data type, though the possible data types are often restricted by considerations of simplicity, computability, or regularity. An explicit data type declaration typically allows the compiler to choose an efficient machine representation, but the conceptual organization offered by data types should not be discounted.Different languages may use different data types or similar types with different semantics. For example, in the Python programming language, int represents an arbitrary-precision integer which has the traditional numeric operations such as addition, subtraction, and multiplication. However in the Java programming language, the type int represents the set of 32-bit integers ranging in value from −2,147,483,648 to 2,147,483,647, with arithmetic operations that wrap on overflow. In Rust this 32-bit integer type is denoted i32 and panics on overflow in debug mode.Most programming languages also allow the programmer to define additional data types, usually by combining multiple elements of other types and defining the valid operations of the new data type.  For example, a programmer might create a new data type named ""complex number"" that would include real and imaginary parts, or a color data type represented by three bytes denoting the amounts each of red, green, and blue, and a string representing the color's name.
Data types are used within type systems, which offer various ways of defining, implementing, and using them. In a type system, a data type represents a constraint placed upon the interpretation of data, describing representation, interpretation and structure of values or objects stored in computer memory. The type system uses data type information to check correctness of computer programs that access or manipulate the data. A compiler may use the static type of a value to optimize the storage it needs and the choice of algorithms for operations on the value. In many C compilers the float data type, for example, is represented in 32 bits, in accord with the IEEE specification for single-precision floating point numbers. They will thus use floating-point-specific microprocessor operations on those values (floating-point addition, multiplication, etc.).
Most data types in statistics have comparable types in computer programming, and vice versa, as shown in the following table:


== Definition ==
Parnas, Shore & Weiss (1976) identified five definitions of a ""type"" that were used—sometimes implicitly—in the literature:

Syntactic
A type is a purely syntactic label associated with a variable when it is declared. Although useful for advanced type systems such as substructural type systems, such definitions provide no intuitive meaning of the types.
Representation
A type is defined in terms of a composition of more primitive types—often machine types.
Representation and behaviour
A type is defined as its representation and a set of operators manipulating these representations.
Value space
A type is a set of possible values which a variable can possess. Such definitions make it possible to speak about (disjoint) unions or Cartesian products of types.
Value space and behaviour
A type is a set of values which a variable can possess and a set of functions that one can apply to these values.The definition in terms of a representation was often done in imperative languages such as ALGOL and Pascal, while the definition in terms of a value space and behaviour was used in higher-level languages such as Simula and CLU. Types including behavior align more closely with object-oriented models, whereas a structured programming model would tend to not include code, and are called plain old data structures.


== Classification ==
Data types may be categorized according to several factors:

Primitive data types or built-in data types are types that are built-in to a language implementation. User-defined data types are non-primitive types. For example, Java's numeric types are primitive, while classes are user-defined.
A value of an atomic type is a single data item that cannot be broken into component parts. A value of a composite type  or aggregate type is a collection of data items that can be accessed individually. For example, an integer is generally considered atomic, although it consists of a sequence of bits, while an array of integers is certainly composite.
Basic data types or fundamental data types are defined axiomatically from fundamental notions or by enumeration of their elements. Generated data types or derived data types are specified, and partly defined, in terms of other data types. All basic types are atomic. For example, integers are a basic type defined in mathematics, while an array of integers is the result of applying an array type generator to the integer type.The terminology varies - in the literature, primitive, built-in, basic, atomic, and fundamental may be used interchangeably.


== Examples ==


=== Machine data types ===
All data in computers based on digital electronics is represented as bits (alternatives 0 and 1) on the lowest level. The smallest addressable unit of data is usually a group of bits called a byte (usually an octet, which is 8 bits). The unit processed by machine code instructions is called a word (as of 2011, typically 32 or 64 bits).
Machine data types expose or make available fine-grained control over hardware, but this can also expose implementation details that make code less portable. Hence machine types are mainly used in systems programming or low-level programming languages. In higher-level languages most data types are abstracted in that they do not have a language-defined machine representation. The C programming language, for instance, supplies types such as booleans, integers, floating-point numbers, etc., but the precise bit representations of these types are implementation-defined. The only C type with a precise machine representation is the char type that represents a byte.


=== Boolean type ===
The Boolean type represents the values true and false. Although only two values are possible, they are more often represented as a word rather as a single bit as it requires more machine instructions to store and retrieve an individual bit. Many programming languages do not have an explicit Boolean type, instead using an integer type and interpreting (for instance) 0 as false and other values as true.
Boolean data refers to the logical structure of how the language is interpreted to the machine language. In this case a Boolean 0 refers to the logic False. True is always a non zero, especially a one which is known as Boolean 1.


=== Numeric types ===
Almost all programming languages supply one or more integer data types. They may either supply a small number of predefined subtypes restricted to certain ranges (such as short and long and their corresponding unsigned variants in C/C++); or allow users to freely define subranges such as 1..12 (e.g. Pascal/Ada). If a corresponding native type does not exist on the target platform, the compiler will break them down into code using types that do exist. For instance, if a 32-bit integer is requested on a 16 bit platform, the compiler will tacitly treat it as an array of two 16 bit integers.
Floating point data types represent certain fractional values (rational numbers, mathematically). Although they have predefined limits on both their maximum values and their precision, they are sometimes misleadingly called reals (evocative of mathematical real numbers). They are typically stored internally in the form a × 2b (where a and b are integers), but displayed in familiar decimal form.
Fixed point data types are convenient for representing monetary values. They are often implemented internally as integers, leading to predefined limits.
For independence from architecture details, a Bignum or arbitrary precision numeric type might be supplied. This represents an integer or rational to a precision limited only by the available memory and computational resources on the system. Bignum implementations of arithmetic operations on machine-sized values are significantly slower than the corresponding machine operations.


=== Enumerations ===
The enumerated type has distinct values, which can be compared and assigned, but which do not necessarily have any particular concrete representation in the computer's memory; compilers and interpreters can represent them arbitrarily. For example, the four suits in a deck of playing cards may be four enumerators named CLUB, DIAMOND, HEART, SPADE, belonging to an enumerated type named suit.  If a variable V is declared having suit as its data type, one can assign any of those four values to it. Some implementations allow programmers to assign integer values to the enumeration values, or even treat them as type-equivalent to integers.


=== String and text types ===
Strings are a sequence of characters used to store words or plain text, most often textual markup languages representing formatted text. Characters may be a letter of some alphabet, a digit, a blank space, a punctuation mark, etc. Characters are drawn from a character set such as ASCII. Character and string types can have different subtypes according to the character encoding. The original 7-bit wide ASCII was found to be limited, and superseded by 8, 16 and 32-bit sets, which can encode a wide variety of non-Latin alphabets (such as Hebrew and Chinese) and other symbols. Strings may be of either variable length or fixed length, and some programming languages have both types. They may also be subtyped by their maximum size.
Since most character sets include the digits, it is possible to have a numeric string, such as ""1234"". These numeric strings are usually considered distinct from numeric values such as 1234, although some languages automatically convert between them.


=== Union types ===

A union type definition will specify which of a number of permitted subtypes may be stored in its instances, e.g. ""float or long integer"". In contrast with a record, which could be defined to contain a float and an integer, a union may only contain one subtype at a time.
A tagged union (also called a variant, variant record, discriminated union, or disjoint union) contains an additional field indicating its current type for enhanced type safety.


=== Algebraic data types ===

An algebraic data type (ADT) is a possibly recursive sum type of product types. A value of an ADT consists of a constructor tag together with zero or more field values, with the number and type of the field values fixed by the constructor. The set of all possible values of an ADT is the set-theoretic disjoint union (sum), of the sets of all possible values of its variants (product of fields). Values of algebraic types are analyzed with pattern matching, which identifies a value's constructor and extracts the fields it contains.
If there is only one constructor, then the ADT corresponds to a product type similar to a tuple or record. A constructor with no fields corresponds to the empty product (unit type). If all constructors have no fields then the ADT corresponds to an enumerated type.
One common ADT is the option type, defined in Haskell as data Maybe a = Nothing | Just a.


=== Data structures ===
Some types are very useful for storing and retrieving data and are called data structures. Common data structures include:

An array (also called vector, list, or sequence) stores a number of elements and provides random access to individual elements. The elements of an array are typically (but not in all contexts) required to be of the same type. Arrays may be fixed-length or expandable. Indices into an array are typically required to be integers (if not, one may stress this relaxation by speaking about an associative array) from a specific range (if not all indices in that range correspond to elements, it may be a sparse array).
Record (also called tuple or struct) Records are among the simplest data structures. A record is a value that contains other values, typically in fixed number and sequence and typically indexed by names. The elements of records are usually called fields or members.
An object contains a number of data fields, like a record, and also offers a number of subroutines for accessing or modifying them, called methods.
the singly linked list, which can be used to implement a queue and is defined in Haskell as the ADT data List a = Nil | Cons a (List a), and
the binary tree, which allows fast searching, and can be defined in Haskell as the ADT data BTree a = Nil | Node (BTree a) a (BTree a)


=== Abstract data types ===

An abstract data type is a data type that does not specify the concrete representation of the data.  Instead, a formal specification based on the data type's operations is used to describe it. Any implementation of a specification must fulfill the rules given. For example, a stack has push/pop operations that follow a Last-In-First-Out rule, and can be concretely implemented using either a list or an array. Another example is a set which stores values, without any particular order, and no repeated values. Values themselves are not retrieved from sets, rather one tests a value for membership to obtain a boolean ""in"" or ""not in"".
Abstract data types are used in formal semantics and program verification and, less strictly, in design. Beyond verification, a specification might immediately be turned into an implementation. The OBJ family of programming languages for instance bases on this option using equations for specification and rewriting to run them. Algebraic specification was an important subject of research in CS around 1980 and almost a synonym for abstract data types at that time. It has a mathematical foundation in universal algebra. The specification language can be made more expressive by allowing other formulas than only equations.
A more involved example is the Boom hierarchy of the binary tree, list, bag and set abstract data types. All these data types can be declared by three operations: null, which constructs the empty container, single, which constructs a container from a single element and append, which combines two containers of the same type. The complete specification for the four data types can then be given by successively adding the following rules over these operations:

Access to the data can be specified by pattern-matching over the three operations, e.g. a member function for these containers by:

Care must be taken to ensure that the function is invariant under the relevant rules for the data type. Within each of the equivalence classes implied by the chosen subset of equations, it has to yield the same result for all of its members.


=== Pointers and references ===

The main non-composite, derived type is the pointer, a data type whose value refers directly to (or ""points to"") another value stored elsewhere in the computer memory using its address. It is a primitive kind of reference. (In everyday terms, a page number in a book could be considered a piece of data that refers to another one). Pointers are often stored in a format similar to an integer; however, attempting to dereference or ""look up"" a pointer whose value was never a valid memory address would cause a program to crash. To ameliorate this potential problem, pointers are considered a separate type to the type of data they point to, even if the underlying representation is the same.


=== Function types ===

Functional programming languages treat functions as a distinct datatype and allow values of this type to be stored in variables and passed to functions. Some multi-paradigm languages such as JavaScript also have mechanisms for treating functions as data. Most contemporary type systems go beyond JavaScript's simple type ""function object"" and have a family of function types differentiated by argument and return types, such as the type Int -> Bool denoting functions taking an integer and returning a boolean. In C, a function is not a first-class data type but function pointers can be manipulated by the program. Java and C++ originally did not have function values but have added them in C++11 and Java 8.
In mathematical logic, first-order logic does not allow the application of quantifiers on function or predicate names, although second-order logic does.


=== Type constructors ===

A type constructor builds new types from old ones, and can be thought of as an operator taking zero or more types as arguments and producing a type. Product types, function types, power types and list types can be made into type constructors.


=== Quantified types ===
Universally-quantified and existentially-quantified types are based on predicate logic. Universal quantification is written as 
  
    
      
        ∀
        x
        .
        f
        (
        x
        )
      
    
    {\displaystyle \forall x.f(x)}
   or forall x. f x and is the intersection over all types x of the body f x, i.e. the value is of type f x for every x. Existential quantification written as 
  
    
      
        ∃
        x
        .
        f
        (
        x
        )
      
    
    {\displaystyle \exists x.f(x)}
   or exists x. f x and is the union over all types x of the body f x, i.e. the value is of type f x for some x.
In Haskell, universal quantification is commonly used, but existential types must be encoded by transforming exists a. f a to forall r. (forall a. f a -> r) -> r or a similar type.


=== Refinement types ===

A refinement type is a type endowed with a predicate which is assumed to hold for any element of the refined type. For instance, the type of natural numbers greater than 5 may be written as 
  
    
      
        {
        n
        ∈
        
          N
        
        
        
          |
        
        
        n
        >
        5
        }
      
    
    {\displaystyle \{n\in \mathbb {N} \,|\,n>5\}}
  


=== Dependent types ===

A dependent type is a type whose definition depends on a value. Two common examples of dependent types are dependent functions and dependent pairs. The return type of a dependent function may depend on the value (not just type) of one of its arguments. A dependent pair may have a second value of which the type depends on the first value.


=== Meta types ===

Some programming languages represent the type information as data, enabling type introspection and reflection. In contrast, higher order type systems, while allowing types to be constructed from other types and passed to functions as values, typically avoid basing computational decisions on them.


=== Convenience types ===
For convenience, high-level languages and databases may supply ready-made ""real world"" data types, for instance times, dates, and monetary values (currency). These may be built-in to the language or implemented as composite types in a library.


== See also ==
C data types
Data dictionary
Functional programming
Kind
Type (model theory)
Type theory for the mathematical models of types
Type system for different choices in programming language typing
Type conversion
ISO/IEC 11404, General Purpose Datatypes


== References ==


== Further reading ==
Parnas, David L.; Shore, John E.; Weiss, David (1976). ""Abstract types defined as classes of variables"". Proceedings of the 1976 Conference on Data: Abstraction, Definition and Structure: 149–154. doi:10.1145/800237.807133. S2CID 14448258.
Cardelli, Luca; Wegner, Peter (December 1985). ""On Understanding Types, Data Abstraction, and Polymorphism"" (PDF). ACM Computing Surveys. 17 (4): 471–523. CiteSeerX 10.1.1.117.695. doi:10.1145/6041.6042. ISSN 0360-0300. S2CID 2921816. Archived (PDF) from the original on 2008-12-03.
Cleaveland, J. Craig (1986). An Introduction to Data Types. Addison-Wesley. ISBN 978-0201119404.


== External links ==
 Media related to Data types at Wikimedia Commons"
a75ce796a1,List of pioneers in computer science,"This is a list of people who made transformative breakthroughs in the creation, development and imagining of what computers could do.


== Pioneers ==
To arrange the list either chronologically by year or alphabetically by person (ascending or descending), click that column's small ""up-down"" icon.~ Items marked with a tilde are circa dates.


== See also ==
Computer Pioneer Award
IEEE John von Neumann Medal
Grace Murray Hopper Award
History of computing
History of computing hardware
History of computing hardware (1960s–present)
History of software
List of computer science awards
List of computer scientists
List of Internet pioneers
List of people considered father or mother of a field § Computing
The Man Who Invented the Computer (2010 book)
List of Russian IT developers
List of Women in Technology International Hall of Fame inductees
Timeline of computing
Turing Award
Women in computing


== References ==


=== Sources ===
Hamming, Richard W. (1950). ""Error detecting and error correcting codes"" (PDF). Bell System Technical Journal. 29 (2): 147–160. doi:10.1002/j.1538-7305.1950.tb00463.x. MR 0035935. S2CID 61141773. Archived from the original (PDF) on 2006-05-25.
Ling, San; Xing, Chaoping (2004). Coding Theory: a First Course. Cambridge: Cambridge University Press. ISBN 978-0-521-82191-9.
Pless, Vera (1982). Introduction to the Theory of Error-Correcting Codes. New York: Wiley. ISBN 978-0-471-08684-0.
Morgan, Samuel P. (September 1998). ""Richard Wesley Hamming (1915–1998)"" (PDF). Notices of the AMS. 45 (8): 972–977. ISSN 0002-9920. Retrieved 2014-08-30.


== External links ==
Internet pioneers"
555489db3a,Software design pattern,"In software engineering, a software design pattern is a general, reusable solution to a commonly occurring problem within a given context in software design. It is not a finished design that can be transformed directly into source or machine code. Rather, it is a description or template for how to solve a problem that can be used in many different situations. Design patterns are formalized best practices that the programmer can use to solve common problems when designing an application or system.
Object-oriented design patterns typically show relationships and interactions between classes or objects, without specifying the final application classes or objects that are involved. Patterns that imply mutable state may be unsuited for functional programming languages. Some patterns can be rendered unnecessary in languages that have built-in support for solving the problem they are trying to solve, and object-oriented patterns are not necessarily suitable for non-object-oriented languages.
Design patterns may be viewed as a structured approach to computer programming intermediate between the levels of a programming paradigm and a concrete algorithm.


== History ==
Patterns originated as an architectural concept by Christopher Alexander as early as 1977 (c.f. ""The Pattern of Streets,"" JOURNAL OF THE AIP, September, 1966, Vol. 32, No. 5, pp. 273–278). In 1987, Kent Beck and Ward Cunningham began experimenting with the idea of applying patterns to programming – specifically pattern languages – and presented their results at the OOPSLA conference that year. In the following years, Beck, Cunningham and others followed up on this work.
Design patterns gained popularity in computer science after the book Design Patterns: Elements of Reusable Object-Oriented Software was published in 1994  by the so-called ""Gang of Four"" (Gamma et al.), which is frequently abbreviated as ""GoF"". That same year, the first Pattern Languages of Programming Conference was held, and the following year the Portland Pattern Repository was set up for documentation of design patterns. The scope of the term remains a matter of dispute. Notable books in the design pattern genre include:

Gamma, Erich; Helm, Richard; Johnson, Ralph; Vlissides, John (1994). Design Patterns: Elements of Reusable Object-Oriented Software. Addison-Wesley. ISBN 978-0-201-63361-0.
Brinch Hansen, Per (1995). Studies in Computational Science: Parallel Programming Paradigms. Prentice Hall. ISBN 978-0-13-439324-7.
Buschmann, Frank; Meunier, Regine; Rohnert, Hans; Sommerlad, Peter (1996). Pattern-Oriented Software Architecture, Volume 1: A System of Patterns. John Wiley & Sons. ISBN 978-0-471-95869-7.
Beck, Kent (1997). Smalltalk Best Practice Patterns. Prentice Hall. ISBN 978-0134769042.
Schmidt, Douglas C.; Stal, Michael; Rohnert, Hans; Buschmann, Frank (2000). Pattern-Oriented Software Architecture, Volume 2: Patterns for Concurrent and Networked Objects. John Wiley & Sons. ISBN 978-0-471-60695-6.
Fowler, Martin (2002). Patterns of Enterprise Application Architecture. Addison-Wesley. ISBN 978-0-321-12742-6.
Hohpe, Gregor; Woolf, Bobby (2003). Enterprise Integration Patterns: Designing, Building, and Deploying Messaging Solutions. Addison-Wesley. ISBN 978-0-321-20068-6.
Freeman, Eric T.; Robson, Elisabeth; Bates, Bert; Sierra, Kathy (2004). Head First Design Patterns. O'Reilly Media. ISBN 978-0-596-00712-6.
Larman, Craig (2004). Applying UML and Patterns (3rd Ed, 1st Ed 1995). Pearson. ISBN 978-0131489066.Although design patterns have been applied practically for a long time, formalization of the concept of design patterns languished for several years.


== Practice ==
Design patterns can speed up the development process by providing tested, proven development paradigms. Effective software design requires considering issues that may not become visible until later in the implementation. Freshly written code can often have hidden subtle issues that take time to be detected, issues that sometimes can cause major problems down the road. Reusing design patterns helps to prevent such subtle issues, and it also improves code readability for coders and architects who are familiar with the patterns.
In order to achieve flexibility, design patterns usually introduce additional levels of indirection, which in some cases may complicate the resulting designs and hurt application performance.
By definition, a pattern must be programmed anew into each application that uses it. Since some authors see this as a step backward from software reuse as provided by components, researchers have worked to turn patterns into components. Meyer and Arnout were able to provide full or partial componentization of two-thirds of the patterns they attempted.Software design techniques are difficult to apply to a broader range of problems. Design patterns provide general solutions, documented in a format that does not require specifics tied to a particular problem.


== Structure ==
Design patterns are composed of several sections (see § Documentation below). Of particular interest are the Structure, Participants, and Collaboration sections. These sections describe a design motif: a prototypical micro-architecture that developers copy and adapt to their particular designs to solve the recurrent problem described by the design pattern. A micro-architecture is a set of program constituents (e.g., classes, methods...) and their relationships. Developers use the design pattern by introducing in their designs this prototypical micro-architecture, which means that micro-architectures in their designs will have structure and organization similar to the chosen design motif.


=== Domain-specific patterns ===
Efforts have also been made to codify design patterns in particular domains, including use of existing design patterns as well as domain-specific design patterns. Examples include user interface design patterns, information visualization, secure design, ""secure usability"", Web design  and business model design.The annual Pattern Languages of Programming Conference proceedings  include many examples of domain-specific patterns.


== Classification and list ==
Design patterns had originally been categorized into 3 sub-classifications based on what kind of problem they solve. Creational patterns provide the capability to create objects based on a required criterion and in a controlled way. Structural patterns are about organizing different classes and objects to form larger structures and provide new functionality. Finally, behavioral patterns are about identifying common communication patterns between objects and realizing these patterns.


=== Creational patterns ===


=== Structural patterns ===


=== Behavioral patterns ===


=== Concurrency patterns ===


== Documentation ==
The documentation for a design pattern describes the context in which the pattern is used, the forces within the context that the pattern seeks to resolve, and the suggested solution. There is no single, standard format for documenting design patterns. Rather, a variety of different formats have been used by different pattern authors. However, according to Martin Fowler, certain pattern forms have become more well-known than others, and consequently become common starting points for new pattern-writing efforts. One example of a commonly used documentation format is the one used by Erich Gamma, Richard Helm, Ralph Johnson, and John Vlissides in their book Design Patterns. It contains the following sections:

Pattern Name and Classification: A descriptive and unique name that helps in identifying and referring to the pattern.
Intent: A description of the goal behind the pattern and the reason for using it.
Also Known As: Other names for the pattern.
Motivation (Forces): A scenario consisting of a problem and a context in which this pattern can be used.
Applicability: Situations in which this pattern is usable; the context for the pattern.
Structure: A graphical representation of the pattern. Class diagrams and Interaction diagrams may be used for this purpose.
Participants: A listing of the classes and objects used in the pattern and their roles in the design.
Collaboration: A description of how classes and objects used in the pattern interact with each other.
Consequences: A description of the results, side effects, and trade offs caused by using the pattern.
Implementation: A description of an implementation of the pattern; the solution part of the pattern.
Sample Code: An illustration of how the pattern can be used in a programming language.
Known Uses: Examples of real usages of the pattern.
Related Patterns: Other patterns that have some relationship with the pattern; discussion of the differences between the pattern and similar patterns.


== Criticism ==
It has been observed that design patterns may just be a sign that some features are missing in a given programming language (Java or C++ for instance). Peter Norvig demonstrates that 16 out of the 23 patterns in the Design Patterns book (which is primarily focused on C++) are simplified or eliminated (via direct language support) in Lisp or Dylan. Related observations were made by Hannemann and Kiczales who implemented several of the 23 design patterns using an aspect-oriented programming language (AspectJ) and showed that code-level dependencies were removed from the implementations of 17 of the 23 design patterns and that aspect-oriented programming could simplify the implementations of design patterns.
See also Paul Graham's essay ""Revenge of the Nerds"".Inappropriate use of patterns may unnecessarily increase complexity.


== See also ==


== References ==


== Further reading =="
8adaacc3f7,Branches of science,"The branches of science, also referred to as sciences, scientific fields or scientific disciplines, are commonly divided into three major groups:

Formal sciences: the study of formal systems, such as those under the branches of logic and mathematics, which use an a priori, as opposed to empirical, methodology.
Natural sciences: the study of natural phenomena (including cosmological, geological, physical, chemical, and biological factors of the universe). Natural science can be divided into two main branches: physical science and life science (or biology).
Social sciences: the study of human behavior in its social and cultural aspects.Scientific knowledge must be based on observable phenomena and must be capable of being verified by other researchers working under the same conditions. This verifiability may well vary even within a scientific discipline.Natural, social, and formal science make up the fundamental sciences, which form the basis of interdisciplinarity- and applied sciences such as engineering and medicine. Specialized scientific disciplines that exist in multiple categories may include parts of other scientific disciplines but often possess their own terminologies and expertises.


== Formal sciences ==

The formal sciences are the branches of science that are concerned with formal systems, such as logic, mathematics, theoretical computer science, information theory, systems theory, decision theory, statistics.
Unlike other branches, the formal sciences are not concerned with the validity of theories based on observations in the real world (empirical knowledge), but rather with the properties of formal systems based on definitions and rules.  Hence there is disagreement on whether the formal sciences actually constitute as a science.  Methods of the formal sciences are, however, essential to the construction and testing of scientific models dealing with observable reality, and major advances in formal sciences have often enabled major advances in the empirical sciences.


=== Logic ===

Logic (from Greek: λογική, logikḗ, 'possessed of reason, intellectual, dialectical, argumentative') is the systematic study of valid rules of inference, i.e. the relations that lead to the acceptance of one proposition (the conclusion) on the basis of a set of other propositions (premises). More broadly, logic is the analysis and appraisal of arguments.It has traditionally included the classification of arguments; the systematic exposition of the logical forms; the validity and soundness of deductive reasoning; the strength of inductive reasoning; the study of formal proofs and inference (including paradoxes and fallacies); and the study of syntax and semantics.
Historically, logic has been studied in philosophy (since ancient times) and mathematics (since the mid-19th century).  More recently, logic has been studied in cognitive science, which draws on computer science, linguistics, philosophy and psychology, among other disciplines.


=== Data science ===


=== Information science ===
Information science is an academic field which is primarily concerned with analysis, collection, classification, manipulation, storage, retrieval, movement, dissemination, and protection of information. Practitioners within and outside the field study the application and the usage of knowledge in organizations in addition to the interaction between people, organizations, and any existing information systems with the aim of creating, replacing, improving, or understanding the information systems.


=== Mathematics ===

Mathematics, in the broadest sense, is just a synonym of formal science; but traditionally mathematics means more specifically the coalition of four areas: arithmetic, algebra, geometry, and analysis, which are, to some degree, the study of quantity, structure, space, and change respectively.


=== Statistics ===

Statistics is the study of the collection, organization, and interpretation of data. It deals with all aspects of this, including the planning of data collection in terms of the design of surveys and experiments.A statistician is someone who is particularly well versed in the ways of thinking necessary for the successful application of statistical analysis. Such people have often gained this experience through working in any of a wide number of fields. There is also a discipline called mathematical statistics, which is concerned with the theoretical basis of the subject.
The word statistics, when referring to the scientific discipline, is singular, as in ""Statistics is an art."" This should not be confused with the word statistic, referring to a quantity (such as mean or median) calculated from a set of data, whose plural is statistics (""this statistic seems wrong"" or ""these statistics are misleading"").


=== Systems theory ===

Systems theory is the transdisciplinary study of systems in general, to elucidate principles that can be applied to all types of systems in all fields of research. The term does not yet have a well-established, precise meaning, but systems theory can reasonably be considered a specialization of systems thinking and a generalization of systems science. The term originates from Bertalanffy's General System Theory (GST) and is used in later efforts in other fields, such as the action theory of Talcott Parsons and the sociological autopoiesis of Niklas Luhmann.
In this context the word systems is used to refer specifically to self-regulating systems, i.e. that are self-correcting through feedback. Self-regulating systems are found in nature, including the physiological systems of our body, in local and global ecosystems, and climate.


=== Decision theory ===

Decision theory (or the theory of choice not to be confused with choice theory) is the study of an agent's choices. Decision theory can be broken into two branches: normative decision theory, which analyzes the outcomes of decisions or determines the optimal decisions given constraints and assumptions, and descriptive decision theory, which analyzes how agents actually make the decisions they do.
Decision theory is closely related to the field of game theory and is an interdisciplinary topic, studied by economists, statisticians, psychologists, biologists, political and other social scientists, philosophers, and computer scientists.
Empirical applications of this rich theory are usually done with the help of statistical and econometric methods.


=== Theoretical computer science ===

Theoretical computer science (TCS) is a subset of general computer science and mathematics that focuses on more mathematical topics of computing, and includes the theory of computation.
It is difficult to circumscribe the theoretical areas precisely. The ACM's Special Interest Group on Algorithms and Computation Theory (SIGACT) provides the following description:
TCS covers a wide variety of topics including algorithms, data structures, computational complexity, parallel and distributed computation, probabilistic computation, quantum computation, automata theory, information theory, cryptography, program semantics and verification, machine learning, computational biology, computational economics, computational geometry, and computational number theory and algebra. Work in this field is often distinguished by its emphasis on mathematical technique and rigor.


== Natural sciences ==

Natural science is a branch of science concerned with the description, prediction, and understanding of natural phenomena, based on empirical evidence from observation and experimentation. Mechanisms such as peer review and repeatability of findings are used to try to ensure the validity of scientific advances.
Natural science can be divided into two main branches: life science and physical science. Life science is alternatively known as biology, and physical science is subdivided into branches: physics, chemistry, astronomy and Earth science. These branches of natural science may be further divided into more specialized branches (also known as fields)


=== Physical science ===

Physical science is an encompassing term for the branches of natural science that study non-living systems, in contrast to the life sciences. However, the term ""physical"" creates an unintended, somewhat arbitrary distinction, since many branches of physical science also study biological phenomena. There is a difference between physical science and physics.


==== Physics ====

Physics (from Ancient Greek: φύσις, romanized: physis, lit. 'nature') is a natural science that involves the study of matter and its motion through spacetime, along with related concepts such as energy and force. More broadly, it is the general analysis of nature, conducted in order to understand how the universe behaves.Physics is one of the oldest academic disciplines, perhaps the oldest through its inclusion of astronomy. Over the last two millennia, physics was a part of natural philosophy along with chemistry, certain branches of mathematics, and biology, but during the Scientific Revolution in the 16th century, the natural sciences emerged as unique research programs in their own right. Certain research areas are interdisciplinary, such as biophysics and quantum chemistry, which means that the boundaries of physics are not rigidly defined. In the nineteenth and twentieth centuries physicalism emerged as a major unifying feature of the philosophy of science as physics provides fundamental explanations for every observed natural phenomenon. New ideas in physics often explain the fundamental mechanisms of other sciences, while opening to new research areas in mathematics and philosophy.


==== Chemistry ====

Chemistry (the etymology of the word has been much disputed) is the science of matter and the changes it undergoes. The science of matter is also addressed by physics, but while physics takes a more general and fundamental approach, chemistry is more specialized, being concerned by the composition, behavior (or reaction), structure, and properties of matter, as well as the changes it undergoes during chemical reactions. It is a physical science which studies various substances, atoms, molecules, and matter (especially carbon based).  Example sub-disciplines of chemistry include: biochemistry, the study of substances found in biological organisms; physical chemistry, the study of chemical processes using physical concepts such as thermodynamics and quantum mechanics; and analytical chemistry, the analysis of material samples to gain an understanding of their chemical composition and structure. Many more specialized disciplines have emerged in recent years, e.g. neurochemistry the chemical study of the nervous system.


==== Earth science ====

Earth science (also known as geoscience, the geosciences or the Earth sciences) is an all-embracing term for the sciences related to the planet Earth. It is arguably a special case in planetary science, the Earth being the only known life-bearing planet. There are both reductionist and holistic approaches to Earth sciences. The formal discipline of Earth sciences may include the study of the atmosphere, hydrosphere, lithosphere, and biosphere, as well as the solid earth. Typically Earth scientists will use tools from physics, chemistry, biology, geography, chronology and mathematics to build a quantitative understanding of how the Earth system works, and how it evolved to its current state.


===== Geology =====

Geology (from the Ancient Greek γῆ, gē (""earth"") and -λoγία, -logia, (""study of"", ""discourse"")) is an Earth science concerned with the solid Earth, the rocks of which it is composed, and the processes by which they change over time. Geology can also include the study of the solid features of any terrestrial planet or natural satellite such as Mars or the Moon. Modern geology significantly overlaps all other Earth sciences, including hydrology and the atmospheric sciences, and so is treated as one major aspect of integrated Earth system science and planetary science.


===== Oceanography =====

Oceanography, or marine science, is the branch of Earth science that studies the ocean. It covers a wide range of topics, including marine organisms and ecosystem dynamics; ocean currents, waves, and geophysical fluid dynamics; plate tectonics and the geology of the seafloor; and fluxes of various chemical substances and physical properties within the ocean and across its boundaries. These diverse topics reflect multiple disciplines that oceanographers blend to further knowledge of the world ocean and understanding of processes within it: biology, chemistry, geology, meteorology, and physics as well as geography.


===== Meteorology =====

Meteorology is the interdisciplinary scientific study of the atmosphere. Studies in the field stretch back millennia, though significant progress in meteorology did not occur until the 17th century. The 19th century saw breakthroughs occur after observing networks developed across several countries. After the development of the computer in the latter half of the 20th century, breakthroughs in weather forecasting were achieved.


==== Astronomy ====

Space science is the study of everything in outer space. This has sometimes been called astronomy, but recently astronomy has come to be regarded as a division of broader space science, which has grown to include other related fields, such as studying issues related to space travel and space exploration (including space medicine), space archaeology and science performed in outer space (see space research).


=== Biology ===

Life science, also known as biology, is the natural science that studies life such as microorganisms, plants, and animals including human beings, – including their physical structure, chemical processes, molecular interactions, physiological mechanisms, development, and evolution. Despite the complexity of the science, certain unifying concepts consolidate it into a single, coherent field. Biology recognizes the cell as the basic unit of life, genes as the basic unit of heredity, and evolution as the engine that propels the creation and extinction of species. Living organisms are open systems that survive by transforming energy and decreasing their local entropy to maintain a stable and vital condition defined as homeostasis.


==== Biochemistry ====

Biochemistry, or biological chemistry, is the study of chemical processes within and relating to living organisms.  It is a sub-discipline of both biology and chemistry, and from a reductionist point of view it is fundamental in biology.  Biochemistry is closely related to molecular biology, cell biology, genetics, and physiology.


==== Microbiology ====

Microbiology is the study of microorganisms, those being unicellular (single cell), multicellular (cell colony), or acellular (lacking cells).  Microbiology encompasses numerous sub-disciplines including virology, bacteriology, protistology, mycology, immunology and parasitology.


==== Botany ====

Botany, also called plant science(s), plant biology or phytology, is the science of plant life and a branch of biology.  Traditionally, botany has also included the study of fungi and algae by mycologists and phycologists respectively, with the study of these three groups of organisms remaining within the sphere of interest of the International Botanical Congress. Nowadays, botanists (in the strict sense) study approximately 410,000 species of land plants of which some 391,000 species are vascular plants (including approximately 369,000 species of flowering plants), and approximately 20,000 are bryophytes.


==== Zoology ====

Zoology () is the branch of biology that studies the animal kingdom, including the structure, embryology, evolution, classification, habits, and distribution of all animals, both living and extinct, and how they interact with their ecosystems. The term is derived from Ancient Greek ζῷον, zōion, i.e. ""animal"" and λόγος, logos, i.e. ""knowledge, study"". Some branches of zoology include: anthrozoology, arachnology, archaeozoology, cetology, embryology, entomology, helminthology, herpetology, histology, ichthyology, malacology, mammalogy, morphology, nematology, ornithology, palaeozoology, pathology, primatology, protozoology, taxonomy, and zoogeography.


==== Ecology ====

Ecology (from Greek: οἶκος, ""house"", or ""environment""; -λογία, ""study of"") is a branch of biology concerning interactions among organisms and their biophysical environment, which includes both biotic and abiotic components. Topics of interest include the biodiversity, distribution, biomass, and populations of organisms, as well as cooperation and competition within and between species. Ecosystems are dynamically interacting systems of organisms, the communities they make up, and the non-living components of their environment. Ecosystem processes, such as primary production, pedogenesis, nutrient cycling, and niche construction, regulate the flux of energy and matter through an environment. These processes are sustained by organisms with specific life history traits.


== Social sciences ==

Social science is the branch of science devoted to the study of societies and the relationships among individuals within those societies. The term was formerly used to refer to the field of sociology, the original ""science of society"", established in the 19th century. In addition to sociology, it now encompasses a wide array of academic disciplines, including anthropology, archaeology, economics, human geography, linguistics, political science, and psychology.
Positivist social scientists use methods resembling those of the natural sciences as tools for understanding society, and so define science in its stricter modern sense. Interpretivist social scientists, by contrast, may use social critique or symbolic interpretation rather than constructing empirically falsifiable theories. In modern academic practice, researchers are often eclectic, using multiple methodologies (for instance, by combining both quantitative and qualitative research). The term ""social research"" has also acquired a degree of autonomy as practitioners from various disciplines share in its aims and methods.


== Applied sciences ==

Applied science is the use of existing scientific knowledge to achieve practical goals, like technology or inventions.
Within natural science, disciplines that are basic science develop basic information to explain and perhaps predict phenomena in the natural world. Applied science is the use of scientific processes and knowledge as the means to achieve a particularly practical or useful result. This includes a broad range of applied science-related fields, including engineering and medicine.
Applied science can also apply formal science, such as statistics and probability theory, as in epidemiology. Genetic epidemiology is an applied science applying both biological and statistical methods.


== Relationships between the branches ==
The relationships between the branches of science are summarized by the  table


== Visualizations and metascience ==
OpenAlex and Scholia can be used to visualize and explore scientific fields and research topics. Metascience refers to or includes a field of science that is about science itself.


== See also ==
Index of branches of science
List of words ending in ology
Outline of science
Exact sciences
Basic research
Hard and soft science
Branches of philosophy
Philosophy of science
Engineering physics
Human science


== Notes ==


== References ==


=== Footnotes ===


=== Works cited ===


== External links ==
Branches of Science, sciencemirror"
fdf3c3f738,Software engineering,"Software engineering is an engineering-based approach to software development.
A software engineer is a person who applies the engineering design process to design, develop, maintain, test, and evaluate computer software. The term programmer is sometimes used as a synonym, but may also refer more to implementation rather than design and can also lack connotations of engineering education or skills.Engineering techniques are used to inform the software development process, which involves the definition, implementation, assessment, measurement, management, change, and improvement of the software life cycle process itself. It heavily uses software configuration management, which is about systematically controlling changes to the configuration, and maintaining the integrity and traceability of the configuration and code throughout the system life cycle. Modern processes use software versioning.


== History ==

Beginning in the 1960s, software engineering was seen as its own type of engineering. Additionally, the development of software engineering was seen as a struggle. It was difficult to keep up with the hardware which caused many problems for software engineers. Problems included software that was over budget, exceeded deadlines, required extensive de-bugging and maintenance, and unsuccessfully met the needs of consumers or was never even completed. In 1968 NATO held the first Software Engineering conference where issues related to software were addressed: guidelines and best practices for the development of software were established.The origins of the term ""software engineering"" have been attributed to various sources. The term ""software engineering"" appeared in a list of services offered by companies in the June 1965 issue of COMPUTERS and AUTOMATION and was used more formally in the August 1966 issue of Communications of the ACM (Volume 9, number 8) “letter to the ACM membership” by the ACM President Anthony A. Oettinger,  it is also associated with the title of a NATO conference in 1968 by Professor Friedrich L. Bauer, the first conference on software engineering. Margaret Hamilton described the discipline ""software engineering"" during the Apollo missions to give what they were doing legitimacy.  At the time there was perceived to be a ""software crisis"". The 40th International Conference on Software Engineering (ICSE 2018) celebrates 50 years of ""Software Engineering"" with the Plenary Sessions' keynotes of Frederick Brooks and Margaret Hamilton.In 1984, the Software Engineering Institute (SEI) was established as a federally funded research and development center headquartered on the campus of Carnegie Mellon University in Pittsburgh, Pennsylvania, United States. Watts Humphrey founded the SEI Software Process Program, aimed at understanding and managing the software engineering process.  The Process Maturity Levels introduced would become the Capability Maturity Model Integration for Development(CMMI-DEV), which has defined how the US Government evaluates the abilities of a software development team.
Modern, generally accepted best-practices for software engineering have been collected by the ISO/IEC JTC 1/SC 7 subcommittee and published as the Software Engineering Body of Knowledge (SWEBOK). Software engineering is considered one of major computing disciplines.


== Definitions and terminology ==
Notable definitions of software engineering include:

""The systematic application of scientific and technological knowledge, methods, and experience to the design, implementation, testing, and documentation of software""—The Bureau of Labor Statistics—IEEE Systems and software engineering – Vocabulary
""The application of a systematic, disciplined, quantifiable approach to the development, operation, and maintenance of software""—IEEE Standard Glossary of Software Engineering Terminology
""an engineering discipline that is concerned with all aspects of software production""—Ian Sommerville
""the establishment and use of sound engineering principles in order to economically obtain software that is reliable and works efficiently on real machines""—Fritz Bauer
""a branch of computer science that deals with the design, implementation, and maintenance of complex computer programs""—Merriam-Webster
""'software engineering' encompasses not just the act of writing code, but all of the tools and processes an organization uses to build and maintain that code over time. [...] Software engineering can be thought of as 'programming integrated over time.'""—Software Engineering at GoogleThe term has also been used less formally:

as the informal contemporary term for the broad range of activities that were formerly called computer programming and systems analysis;
as the broad term for all aspects of the practice of computer programming, as opposed to the theory of computer programming, which is formally studied as a sub-discipline of computer science;
as the term embodying the advocacy of a specific approach to computer programming, one that urges that it be treated as an engineering discipline rather than an art or a craft, and advocates the codification of recommended practices.


=== Etymology of ""software engineer"" ===
Margaret Hamilton promoted the term ""software engineering"" during her work on the Apollo program. The term ""engineering"" was used to acknowledge that the work should be taken just as seriously as other contributions toward the advancement of technology. Hamilton details her use of the term:When I first came up with the term, no one had heard of it before, at least in our world. It was an ongoing joke for a long time. They liked to kid me about my radical ideas. It was a memorable day when one of the most respected hardware gurus explained to everyone in a meeting that he agreed with me that the process of building software should also be considered an engineering discipline, just like with hardware. Not because of his acceptance of the new ""term"" per se, but because we had earned his and the acceptance of the others in the room as being in an engineering field in its own right.


=== Suitability of the term ===
Individual commentators have disagreed sharply on how to define software engineering or its legitimacy as an engineering discipline. David Parnas has said that software engineering is, in fact, a form of engineering. Steve McConnell has said that it is not, but that it should be. Donald Knuth has said that programming is an art and a science. Edsger W. Dijkstra claimed that the terms software engineering and software engineer have been misused  and should be considered harmful, particularly in the United States.


== Tasks in large scale projects ==


=== Software requirements ===

Requirements engineering is about the elicitation, analysis, specification, and validation of requirements for software. Software requirements can be of three different types. There are functional requirements, non-functional requirements, and domain requirements. The operation of the software should be performed and the proper output should be expected for the user to use. Non-functional requirements deal with issues like portability, security, maintainability, reliability, scalability, performance, reusability, and flexibility. They are classified into the following types: interface constraints, performance constraints (such as response time, security, storage space, etc.), operating constraints, life cycle constraints (maintainability, portability, etc.), and economic constraints. Knowledge of how the system or software works is needed when it comes to specifying non-functional requirements. Domain requirements have to do with the characteristic of a certain category or domain of projects.


=== Software design ===

Software design is about the process of defining the architecture, components, interfaces, and other characteristics of a system or component. This is also called software architecture. Software design is divided into three different levels of design. The three levels are interface design, architectural design, and detailed design. Interface design is the interaction between a system and its environment. This happens at a high level of abstraction along with the inner workings of the system. Architectural design has to do with the major components of a system and their responsibilities, properties, interfaces, and their relationships and interactions that occur between them. Detailed design is the internal elements of all the major system components, their properties, relationships, processing, and usually their algorithms and the data structures.


=== Software construction ===

Software construction, the main activity of software development, is the combination of programming, unit testing, integration testing, and debugging so as to implement the design. Testing during this phase is generally performed by the programmer while the software is under construction, to verify what was just written and decide when the code is ready to be sent to the next step.


=== Software testing ===

Software testing is an empirical, technical investigation conducted to provide stakeholders with information about the quality of the product or service under test, with different approaches such as unit testing and integration testing. It is one aspect of software quality. As a separate phase in software development, it is typically performed by quality assurance staff or a developer other than the one who wrote the code.


=== Software analysis ===

Software analysis is the process of analyzing the behavior of computer programs regarding a property such as performance, robustness, and security It can be performed without executing the program (static program analysis), during runtime (dynamic program analysis) or in a combination of both.


=== Software maintenance ===

Software maintenance refers to the activities required to provide cost-effective support after shipping the software product. Software maintenance is modifying and updating software applications after distribution to correct faults and to improve its performance. Software has a lot to do with the real world and when the real world changes, software maintenance is required. Software maintenance includes: error correction, optimization, deletion of unused and discarded features, and enhancement of features that already exist. Usually, maintenance takes up about 40% to 80% of the project cost therefore, focusing on maintenance keeps the costs down.


== Education ==
Knowledge of computer programming is a prerequisite for becoming a software engineer. In 2004 the IEEE Computer Society produced the SWEBOK, which has been published as ISO/IEC Technical Report 1979:2005, describing the body of knowledge that they recommend to be mastered by a graduate software engineer with four years of experience.
Many software engineers enter the profession by obtaining a university degree or training at a vocational school. One standard international curriculum for undergraduate software engineering degrees was defined by the Joint Task Force on Computing Curricula of the IEEE Computer Society and the Association for Computing Machinery, and updated in 2014. A number of universities have Software Engineering degree programs; as of 2010, there were 244 Campus Bachelor of Software Engineering programs, 70 Online programs, 230 Masters-level programs, 41 Doctorate-level programs, and 69 Certificate-level programs in the United States.
In addition to university education, many companies sponsor internships for students wishing to pursue careers in information technology. These internships can introduce the student to interesting real-world tasks that typical software engineers encounter every day. Similar experience can be gained through military service in software engineering.


=== Software engineering degree programs ===
Half of all practitioners today have degrees in computer science, information systems, or information technology. A small, but growing, number of practitioners have software engineering degrees. In 1987, the Department of Computing at Imperial College London introduced the first three-year software engineering Bachelor's degree in the UK and the world; in the following year, the University of Sheffield established a similar program.  In 1996, the Rochester Institute of Technology established the first software engineering bachelor's degree program in the United States, however, it did not obtain ABET accreditation until 2003, the same time as Rice University, Clarkson University, Milwaukee School of Engineering and Mississippi State University obtained theirs. In 1997, PSG College of Technology in Coimbatore, India was the first to start a five-year integrated Master of Science degree in Software Engineering.Since then, software engineering undergraduate degrees have been established at many universities. A standard international curriculum for undergraduate software engineering degrees, SE2004, was defined by a steering committee between 2001 and 2004 with funding from the Association for Computing Machinery and the IEEE Computer Society. As of 2004, in the U.S., about 50 universities offer software engineering degrees, which teach both computer science and engineering principles and practices. The first software engineering Master's degree was established at Seattle University in 1979. Since then graduate software engineering degrees have been made available from many more universities.  Likewise in Canada, the Canadian Engineering Accreditation Board (CEAB) of the Canadian Council of Professional Engineers has recognized several software engineering programs.
In 1998, the US Naval Postgraduate School (NPS) established the first doctorate program in Software Engineering in the world. Additionally, many online advanced degrees in Software Engineering have appeared such as the Master of Science in Software Engineering (MSE) degree offered through the Computer Science and Engineering Department at California State University, Fullerton. Steve McConnell opines that because most universities teach computer science rather than software engineering, there is a shortage of true software engineers. ETS (École de technologie supérieure) University and UQAM (Université du Québec à Montréal) were mandated by IEEE to develop the Software Engineering Body of Knowledge (SWEBOK), which has become an ISO standard describing the body of knowledge covered by a software engineer.


== Profession ==

Legal requirements for the licensing or certification of professional software engineers vary around the world. In the UK, there is no licensing or legal requirement to assume or use the job title Software Engineer.  In some areas of Canada, such as Alberta, British Columbia, Ontario, and Quebec, software engineers can hold the Professional Engineer (P.Eng) designation and/or the Information Systems Professional (I.S.P.) designation. In Europe, Software Engineers can obtain the European Engineer (EUR ING) professional title.
In the United States, the NCEES began offering a Professional Engineer exam for Software Engineering in 2013, thereby allowing Software Engineers to be licensed and recognized. NCEES ended the exam after April 2019 due to lack of participation. Mandatory licensing is currently still largely debated, and perceived as controversial. In some parts of the US such as Texas, the use of the term Engineer is regulated by law and reserved only for use by individuals who have a Professional Engineer license.The IEEE Computer Society and the ACM, the two main US-based professional organizations of software engineering, publish guides to the profession of software engineering. The IEEE's Guide to the Software Engineering Body of Knowledge – 2004 Version, or SWEBOK, defines the field and describes the knowledge the IEEE expects a practicing software engineer to have. The most current SWEBOK v3 is an updated version and was released in 2014. The IEEE also promulgates a ""Software Engineering Code of Ethics"".


=== Employment ===

There are an estimated 26.9 million professional software engineers in the world as of 2022, up from 21 million in 2016.Many software engineers work as employees or contractors. Software engineers work with businesses, government agencies (civilian or military), and non-profit organizations. Some software engineers work for themselves as freelancers. Some organizations have specialists to perform each of the tasks in the software development process. Other organizations require software engineers to do many or all of them. In large projects, people may specialize in only one role. In small projects, people may fill several or all roles at the same time. Many companies hire interns, often university or college students during a summer break, or externships. Specializations include analysts, architects, developers, testers, technical support, middleware analysts, project managers, educators, and researchers.
Most software engineers and programmers work 40 hours a week, but about 15 percent of software engineers and 11 percent of programmers worked more than 50 hours a week in 2008. Potential injuries in these occupations are possible because like other workers who spend long periods sitting in front of a computer terminal typing at a keyboard, engineers and programmers are susceptible to eyestrain, back discomfort, and hand and wrist problems such as carpal tunnel syndrome.


==== United States ====
The U. S. Bureau of Labor Statistics (BLS) counted 1,365,500 software developers holding jobs in the U.S. in 2018. Due to its relative newness as a field of study, formal education in software engineering is often taught as part of a computer science curriculum, and many software engineers hold computer science degrees. The BLS estimates from 2014 to 2024 that computer software engineering would increase by 17% . This is down from the 2012 to 2022 BLS estimate of 22% for software engineering. And, is further down from their 30% 2010 to 2020 BLS estimate. Due to this trend, job growth may not be as fast as during the last decade, as jobs that would have gone to computer software engineers in the United States would instead be outsourced to computer software engineers in countries such as India and other foreign countries. In addition, the BLS Job Outlook for Computer Programmers, 2014–24 predicts an −8% (a decline, in their words), then a decline in the Job Outlook, 2019-29 of -9%, and a 10% decline for 2021-2031 for those who program computers. Furthermore, women in many software fields has also been declining over the years as compared to other engineering fields. However, this trend may change or slow in the future as many current software engineers in the U.S. market leave the profession or age out of the market in the next few decades.


=== Certification ===
The Software Engineering Institute offers certifications on specific topics like security, process improvement and software architecture. IBM, Microsoft and other companies also sponsor their own certification examinations. Many IT certification programs are oriented toward specific technologies, and managed by the vendors of these technologies. These certification programs are tailored to the institutions that would employ people who use these technologies.
Broader certification of general software engineering skills is available through various professional societies. As of 2006, the IEEE had certified over 575 software professionals as a Certified Software Development Professional (CSDP). In 2008 they added an entry-level certification known as the Certified Software Development Associate (CSDA). The ACM had a professional certification program in the early 1980s, which was discontinued due to lack of interest. The ACM examined the possibility of professional certification of software engineers in the late 1990s, but eventually decided that such certification was inappropriate for the professional industrial practice of software engineering.In the U.K. the British Computer Society has developed a legally recognized professional certification called Chartered IT Professional (CITP), available to fully qualified members (MBCS). Software engineers may be eligible for membership of the Institution of Engineering and Technology and so qualify for Chartered Engineer status. In Canada the Canadian Information Processing Society has developed a legally recognized professional certification called Information Systems Professional (ISP). In Ontario, Canada, Software Engineers who graduate from a Canadian Engineering Accreditation Board (CEAB) accredited program, successfully complete PEO's (Professional Engineers Ontario) Professional Practice Examination (PPE) and have at least 48 months of acceptable engineering experience are eligible to be licensed through the Professional Engineers Ontario and can become Professional Engineers P.Eng. The PEO does not recognize any online or distance education however; and does not consider Computer Science programs to be equivalent to software engineering programs despite the tremendous overlap between the two. This has sparked controversy and a certification war. It has also held the number of P.Eng holders for the profession exceptionally low. The vast majority of working professionals in the field hold a degree in CS, not SE. Given the difficult certification path for holders of non-SE degrees, most never bother to pursue the license.


=== Impact of globalization ===
The initial impact of outsourcing, and the relatively lower cost of international human resources in developing third world countries led to a massive migration of software development activities from corporations in North America and Europe to India and later: China, Russia, and other developing countries. This approach had some flaws, mainly the distance / time zone difference that prevented human interaction between clients and developers and the massive job transfer. This had a negative impact on many aspects of the software engineering profession. For example, some students in the developed world avoid education related to software engineering because of the fear of offshore outsourcing (importing software products or services from other countries) and of being displaced by foreign visa workers. Although statistics do not currently show a threat to software engineering itself; a related career, computer programming does appear to have been affected. Nevertheless, the ability to smartly leverage offshore and near-shore resources via the follow-the-sun workflow has improved the overall operational capability of many organizations. When North Americans are leaving work, Asians are just arriving to work. When Asians are leaving work, Europeans are arriving to work. This provides a continuous ability to have human oversight on business-critical processes 24 hours per day, without paying overtime compensation or disrupting a key human resource, sleep patterns.
While global outsourcing has several advantages, global – and generally distributed – development can run into serious difficulties resulting from the distance between developers. This is due to the key elements of this type of distance that have been identified as geographical, temporal, cultural and communication (that includes the use of different languages and dialects of English in different locations). Research has been carried out in the area of global software development over the last 15 years and an extensive body of relevant work published that highlights the benefits and problems associated with the complex activity. As with other aspects of software engineering research is ongoing in this and related areas.


=== Prizes ===
There are several prizes in the field of software engineering:
The Codie awards is a yearly award issued by the Software and Information Industry Association for excellence in software development within the software industry.
Jolt Awards are awards in the software industry.
Stevens Award is a software engineering award given in memory of Wayne Stevens.
Harlan Mills Award for ""contributions to the theory and practice of the information sciences, focused on software engineering"".


== Criticism ==
Software engineering sees its practitioners as individuals who follow well-defined engineering approaches to problem-solving. These approaches are specified in various software engineering books and research papers, always with the connotations of predictability, precision, mitigated risk and professionalism. This perspective has led to calls for licensing, certification and codified bodies of knowledge as mechanisms for spreading the engineering knowledge and maturing the field.
Software engineering extends engineering and draws on the engineering model, i.e. engineering process, engineering project management, engineering requirements, engineering design, engineering construction, and engineering validation. The concept is so new that it is rarely understood, and it is widely misinterpreted, including in software engineering textbooks, papers, and among the communities of programmers and crafters.
One of the core issues in software engineering is that its approaches are not empirical enough because a real-world validation of approaches is usually absent, or very limited and hence software engineering is often misinterpreted as feasible only in a ""theoretical environment.""
Edsger Dijkstra, the founder of many of the concepts used within software development today, rejected the idea of ""software engineering"" up until his death in 2002, arguing that those terms were poor analogies for what
he called the ""radical novelty"" of computer science:

A number of these phenomena have been bundled under the name ""Software Engineering"". As economics is known as ""The Miserable Science"", software engineering should be known as ""The Doomed Discipline"", doomed because it cannot even approach its goal since its goal is self-contradictory. Software engineering, of course, presents itself as another worthy cause, but that is eyewash: if you carefully read its literature and analyse what its devotees actually do, you will discover that software engineering has accepted as its charter ""How to program if you cannot.""


== See also ==


=== Study and practice ===
Computer science
Data engineering
Software craftsmanship
Software development
Release engineering


=== Roles ===
Programmer
Systems analyst
Systems architect


=== Professional aspects ===
Bachelor of Science in Information Technology
Bachelor of Software Engineering
List of software engineering conferences
List of computer science journals (including software engineering journals)
Software Engineering Institute


== References ==


=== Citations ===


=== Sources ===


== Further reading ==
Guide to the Software Engineering Body of Knowledge (SWEBOK Guide): Version 3.0. Pierre Bourque, Richard E. Fairley (eds.). IEEE Computer Society. 2014. ISBN 978-0-7695-5166-1.{{cite book}}:  CS1 maint: others (link)
Pressman, Roger S (2009). Software Engineering: A Practitioner's Approach (7th ed.). Boston, Mass: McGraw-Hill. ISBN 978-0-07-337597-7.
Sommerville, Ian (2010) [2010]. Software Engineering (9th ed.). Harlow, England: Pearson Education. ISBN 978-0-13-703515-1.
Jalote, Pankaj (2005) [1991]. An Integrated Approach to Software Engineering (3rd ed.). Springer. ISBN 978-0-387-20881-7.
Bruegge, Bernd; Dutoit, Allen (2009). Object-oriented software engineering : using UML, patterns, and Java (3rd ed.). Prentice Hall. ISBN 978-0-13-606125-0.
Oshana, Robert (2019-06-21). Software engineering for embedded systems : methods, practical techniques, and applications (Second ed.). Kidlington, Oxford, United Kingdom. ISBN 978-0-12-809433-4.


== External links ==

Guide to the Software Engineering Body of Knowledge
The Open Systems Engineering and Software Development Life Cycle Framework Archived 2010-07-18 at the Wayback Machine OpenSDLC.org the integrated Creative Commons SDLC
Software Engineering Institute Carnegie Mellon"
6e51068fde,Doctor of Computer Science,"The degree of Doctor of Computer Science (DCS, DCompSci, DSc.Comp, D.C.Sc.) is an applied research doctorate in computer science awarded on the basis of advanced study and research in the field of computer science. While it is considered a terminal degree and requires coursework and research beyond the masters' level, the DCS is not considered equivalent to a Ph.D. or a Doctor of Science (D.Sc or Sc.D) in computer science.


== Structure ==
Typical entry requirements include master's degrees in computer science or a related field. The degree is intended for those who will make meaningful contributions to either the theory or practice of computing and as such involves both research and taught courses beyond master's degree level. Applied doctorates such as the DCS are aimed at practitioners with professional careers in the field rather than at those aiming for research careers in academia. The DCS is normally completed in three years, with a split of approximately two years of coursework and one year equivalent (36 credits out of a total of 96) spent on the dissertation.


== Relationship to the Ph.D. ==
Structurally, the Doctor of Computer Science differs from the PhD in that the DCS has, as noted above, a three year duration, with only one year equivalent on the dissertation, while an American Ph.D. normally requires a minimum of four years, with at least three years spent on the dissertation.There are two active definitions of what comprises a research doctorate or similar in the U.S. The National Center for Education Statistics defines a Doctor's degree-research/scholarship as ""A Ph.D. or other doctor's degree that requires advanced work beyond the master's level, including the preparation and defense of a dissertation based on original research, or the planning and execution of an original project demonstrating substantial artistic or scholarly achievement."" The awarding institution defines which degrees meet this description themselves. The National Science Foundation defines a research doctorate as ""a doctoral degree that (1) requires completion of an original intellectual contribution in the form of a dissertation or an equivalent culminating project (e.g., musical composition) and (2) is not primarily intended as a degree for the practice of a profession."" Under this definition, the 
DCS, which (as noted above) is intended for professionals in the field of computer science, is not recognized by the National Science Foundation as a research doctorate equivalent to a Ph.D in Computer Science.


== References =="
0759768f6f,Information system,"An information system (IS) is a formal, sociotechnical, organizational system designed to collect, process, store, and distribute information. From a sociotechnical perspective, information systems are composed by four components: task, people, structure (or roles), and technology. Information systems can be defined as an integration of components for collection, storage and processing of data of which the data is used to provide information, contribute to knowledge as well as digital products that facilitate decision making.A computer information system is a system that is composed of people and computers that processes or interprets information. The term is also sometimes used to simply refer to a computer system with software installed.
""Information systems"" is also an academic field study about systems with a specific reference to information and the complementary networks of computer hardware and software that people and organizations use to collect, filter, process, create and also distribute data. An emphasis is placed on an information system having a definitive boundary, users, processors, storage, inputs, outputs and the aforementioned communication networks.In many organizations, the department or unit responsible for information systems and data processing is known as ""information services"".Any specific information system aims to support operations, management and decision-making. An information system is the information and communication technology (ICT) that an organization uses, and also the way in which people interact with this technology in support of business processes.Some authors make a clear distinction between information systems, computer systems, and business processes. Information systems typically include an ICT component but are not purely concerned with ICT, focusing instead on the end-use of information technology. Information systems are also different from business processes. Information systems help to control the performance of business processes.Alter argues for advantages of viewing an information system as a special type of work system. A work system is a system in which humans or machines perform processes and activities using resources to produce specific products or services for customers. An information system is a work system whose activities are devoted to capturing, transmitting, storing, retrieving, manipulating and displaying information.As such, information systems inter-relate with data systems on the one hand and activity systems on the other. An information system is a form of communication system in which data represent and are processed as a form of social memory. An information system can also be considered a semi-formal language which supports human decision making and action.
Information systems are the primary focus of study for organizational informatics.


== Overview ==
Silver et al. (1995) provided two views on IS that includes software, hardware, data, people, and procedures.The Association for Computing Machinery defines ""Information systems specialists [as] focus[ing] on integrating information technology solutions and business processes to meet the information needs of businesses and other enterprises.""There are various types of information systems, for example: transaction processing systems, decision support systems, knowledge management systems, learning management systems, database management systems, and office information systems. Critical to most information systems are information technologies, which are typically designed to enable humans to perform tasks for which the human brain is not well suited, such as: handling large amounts of information, performing complex calculations, and controlling many simultaneous processes.
Information technologies are a very important and malleable resource available to executives. Many companies have created a position of chief information officer (CIO) that sits on the executive board with the chief executive officer (CEO), chief financial officer (CFO), chief operating officer (COO), and chief technical officer (CTO). The CTO may also serve as CIO, and vice versa. The chief information security officer (CISO) focuses on information security management.


=== Six components ===
The six components that must come together in order to produce an information system are:
Hardware: The term hardware refers to machinery and equipment. In a modern information system, this category includes the computer itself and all of its support equipment. The support equipment includes input and output devices, storage devices and communications devices. In pre-computer information systems, the hardware might include ledger books and ink.
Software: The term software refers to computer programs and the manuals (if any) that support them. Computer programs are machine-readable instructions that direct the circuitry within the hardware parts of the system to function in ways that produce useful information from data. Programs are generally stored on some input/output medium, often a disk or tape. The ""software"" for pre-computer information systems included how the hardware was prepared for use (e.g., column headings in the ledger book) and instructions for using them (the guidebook for a card catalog).
Data: Data are facts that are used by systems to produce useful information. In modern information systems, data are generally stored in machine-readable form on disk or tape until the computer needs them. In pre-computer information systems, the data are generally stored in human-readable form.
Procedures: Procedures are the policies that govern the operation of an information system. ""Procedures are to people what software is to hardware"" is a common analogy that is used to illustrate the role of procedures in a system.
People: Every system needs people if it is to be useful. Often the most overlooked element of the system is the people, probably the component that most influence the success or failure of information systems. This includes ""not only the users, but those who operate and service the computers, those who maintain the data, and those who support the network of computers"".
Internet: The internet is a combination of data and people. (Although this component isn't necessary to function.)Data is the bridge between hardware and people. This means that the data we collect is only data until we involve people. At that point, data is now information.


== Types ==

The ""classic"" view of Information systems found in textbooks in the 1980s was a pyramid of systems that reflected the hierarchy of the organization, usually transaction processing systems at the bottom of the pyramid, followed by management information systems, decision support systems, and ending with executive information systems at the top. Although the pyramid model remains useful since it was first formulated, a number of new technologies have been developed and new categories of information systems have emerged, some of which no longer fit easily into the original pyramid model.
Some examples of such systems are:

intelligent system
computing platform
data warehouses
decision support system
enterprise systems
enterprise resource planning
expert systems
geographic information system
global information system
management information system
multimedia information system
process control system
social information systems
search engines
office automation.A computer(-based) information system is essentially an IS using computer technology to carry out some or all of its planned tasks. The basic components of computer-based information systems are:

Hardware are the devices like the monitor, processor, printer, and keyboard, all of which work together to accept, process, show data, and information.
Software are the programs that allow the hardware to process the data.
Databases are the gathering of associated files or tables containing related data.
Networks are a connecting system that allows diverse computers to distribute resources.
Procedures are the commands for combining the components above to process information and produce the preferred output.The first four components (hardware, software, database, and network) make up what is known as the information technology platform.
Information technology workers could then use these components to create information systems that watch over safety measures, risk and the management of data. These actions are known as information technology services.Certain information systems support parts of organizations, others support entire organizations, and still others, support groups of organizations. Each department or functional area within an organization has its own collection of application programs or information systems. These functional area information systems (FAIS) are supporting pillars for more general IS namely, business intelligence systems and dashboards. As the name suggests, each FAIS supports a particular function within the organization, e.g.: accounting IS, finance IS, production-operation management (POM) IS, marketing IS, and human resources IS. In finance and accounting, managers use IT systems to forecast revenues and business activity, to determine the best sources and uses of funds, and to perform audits to ensure that the organization is fundamentally sound and that all financial reports and documents are accurate.
Other types of organizational information systems are FAIS, transaction processing systems, enterprise resource planning, office automation system, management information system, decision support system, expert system, executive dashboard, supply chain management system, and electronic commerce system. Dashboards are a special form of IS that support all managers of the organization. They provide rapid access to timely information and direct access to structured information in the form of reports. Expert systems attempt to duplicate the work of human experts by applying reasoning capabilities, knowledge, and expertise within a specific domain.


== Development ==
Information technology departments in larger organizations tend to strongly influence the development, use, and application of information technology in the business.
A series of methodologies and processes can be used to develop and use an information system. Many developers use a systems engineering approach such as the system development life cycle (SDLC), to systematically develop an information system in stages. The stages of the system development lifecycle are planning, system analysis, and requirements, system design, development, integration and testing, implementation and operations, and maintenance.
Recent research aims at enabling and measuring the ongoing, collective development of such systems within an organization by the entirety of human actors themselves.
An information system can be developed in house (within the organization) or outsourced. This can be accomplished by outsourcing certain components or the entire system. A specific case is the geographical distribution of the development team (offshoring, global information system).
A computer-based information system, following a definition of Langefors, is a technologically implemented medium for recording, storing, and disseminating linguistic expressions, as well as for drawing conclusions from such expressions.
Geographic information systems, land information systems, and disaster information systems are examples of emerging information systems, but they can be broadly considered as spatial information systems.
System development is done in stages which include:
Problem recognition and specification
Information gathering
Requirements specification for the new system
System design
System construction
System implementation
Review and maintenance


== As an academic discipline ==

The field of study called information systems encompasses a variety of topics including systems analysis and design, computer networking, information security, database management, and decision support systems. Information management deals with the practical and theoretical problems of collecting and analyzing information in a business function area including business productivity tools, applications programming and implementation, electronic commerce, digital media production, data mining, and decision support. Communications and networking deals with telecommunication technologies.
Information systems bridges business and computer science using the theoretical foundations of information and computation to study various business models and related algorithmic processes  on building the IT systems  within a computer science discipline. Computer information systems (CIS) is a field studying computers and algorithmic processes, including their principles, their software and hardware designs, their applications, and their impact on society, whereas IS emphasizes functionality over design.Several IS scholars have debated the nature and foundations of information systems which have its roots in other reference disciplines such as computer science, engineering, mathematics, management science, cybernetics, and others. Information systems also can be defined as a collection of hardware, software, data, people, and procedures that work together to produce quality information.


=== Related terms ===

Similar to computer science, other disciplines can be seen as both related and foundation disciplines of IS. The domain of study of IS involves the study of theories and practices related to the social and technological phenomena, which determine the development, use, and effects of information systems in organizations and society. But, while there may be considerable overlap of the disciplines at the boundaries, the disciplines are still differentiated by the focus, purpose, and orientation of their activities.In a broad scope, information systems is a scientific field of study that addresses the range of strategic, managerial, and operational activities involved in the gathering, processing, storing, distributing, and use of information and its associated technologies in society and organizations. The term information systems is also used to describe an organizational function that applies IS knowledge in the industry, government agencies, and not-for-profit organizations.Information systems often refers to the interaction between algorithmic processes and technology. This interaction can occur within or across organizational boundaries. An information system is a technology an organization uses and also the way in which the organizations interact with the technology and the way in which the technology works with the organization's business processes. Information systems are distinct from information technology (IT) in that an information system has an information technology component that interacts with the processes' components.
One problem with that approach is that it prevents the IS field from being interested in non-organizational use of ICT, such as in social networking, computer gaming, mobile personal usage, etc. A different way of differentiating the IS field from its neighbours is to ask, ""Which aspects of reality are most meaningful in the IS field and other fields?"" This approach, based on philosophy, helps to define not just the focus, purpose, and orientation, but also the dignity, destiny and, responsibility of the field among other fields.Business informatics is a related discipline that is well-established in several countries, especially in Europe. While Information systems has been said to have an ""explanation-oriented"" focus, business informatics has a more ""solution-oriented"" focus and includes information technology elements and construction and implementation-oriented elements.


== Career pathways ==
Information systems workers enter a number of different careers:

Information system strategy
Management information systems – A management information system (MIS) is an information system used for decision-making, and for the coordination, control, analysis, and visualization of information in an organization.
Project management – Project management is the practice of initiating, planning, executing, controlling, and closing the work of a team to achieve specific goals and meet specific success criteria at the specified time.
Enterprise architecture – A well-defined practice for conducting enterprise analysis, design, planning, and implementation, using a comprehensive approach at all times, for the successful development and execution of strategy.
IS development
IS organization
IS consulting
IS security
IS auditingThere is a wide variety of career paths in the information systems discipline. ""Workers with specialized technical knowledge and strong communications skills will have the best prospects. Workers with management skills and an understanding of business practices and principles will have excellent opportunities, as companies are increasingly looking to technology to drive their revenue.""Information technology is important to the operation of contemporary businesses, it offers many employment opportunities. The information systems field includes the people in organizations who design and build information systems, the people who use those systems, and the people responsible for managing those systems.
The demand for traditional IT staff such as programmers, business analysts, systems analysts, and designer is significant. Many well-paid jobs exist in areas of Information technology. At the top of the list is the chief information officer (CIO).
The CIO is the executive who is in charge of the IS function. In most organizations, the CIO works with the chief executive officer (CEO), the chief financial officer (CFO), and other senior executives. Therefore, he or she actively participates in the organization's strategic planning process.


== Research ==
Information systems research is generally interdisciplinary concerned with the study of the effects of information systems on the behaviour of individuals, groups, and organizations. Hevner et al. (2004) categorized research in IS into two scientific paradigms including behavioural science which is to develop and verify theories that explain or predict human or organizational behavior and design science which extends the boundaries of human and organizational capabilities by creating new and innovative artifacts.
Salvatore March and Gerald Smith proposed a framework for researching different aspects of information technology including outputs of the research (research outputs) and activities to carry out this research (research activities). They identified research outputs as follows:

Constructs which are concepts that form the vocabulary of a domain. They constitute a conceptualization used to describe problems within the domain and to specify their solutions.
A model which is a set of propositions or statements expressing relationships among constructs.
A method which is a set of steps (an algorithm or guideline) used to perform a task. Methods are based on a set of underlying constructs and a representation (model) of the solution space.
An instantiation is the realization of an artefact in its environment.Also research activities including:

Build an artefact to perform a specific task.
Evaluate the artefact to determine if any progress has been achieved.
Given an artefact whose performance has been evaluated, it is important to determine why and how the artefact worked or did not work within its environment. Therefore, theorize and justify theories about IT artefacts.Although Information Systems as a discipline has been evolving for over 30 years now, the core focus or identity of IS research is still subject to debate among scholars. There are two main views around this debate: a narrow view focusing on the IT artifact as the core subject matter of IS research, and a broad view that focuses on the interplay between social and technical aspects of IT that is embedded into a dynamic evolving context. A third view calls on IS scholars to pay balanced attention to both the IT artifact and its context.
Since the study of information systems is an applied field, industry practitioners expect information systems research to generate findings that are immediately applicable in practice. This is not always the case however, as information systems researchers often explore behavioral issues in much more depth than practitioners would expect them to do. This may render information systems research results difficult to understand, and has led to criticism.In the last ten years, the business trend is represented by the considerable increase of Information Systems Function (ISF) role, especially with regard to the enterprise strategies and operations supporting. It became a key factor to increase productivity and to support value creation. To study an information system itself, rather than its effects, information systems models are used, such as EATPUT.
The international body of Information Systems researchers, the Association for Information Systems (AIS), and its Senior Scholars Forum Subcommittee on Journals (23 April 2007), proposed a 'basket' of journals that the AIS deems as 'excellent', and nominated: Management Information Systems Quarterly (MISQ), Information Systems Research (ISR), Journal of the Association for Information Systems (JAIS), Journal of Management Information Systems (JMIS), European Journal of Information Systems (EJIS), and Information Systems Journal (ISJ).A number of annual information systems conferences are run in various parts of the world, the majority of which are peer reviewed. The AIS directly runs the International Conference on Information Systems (ICIS) and the Americas Conference on Information Systems (AMCIS), while AIS affiliated conferences include the Pacific Asia Conference on Information Systems (PACIS), European Conference on Information Systems (ECIS), the Mediterranean Conference on Information Systems (MCIS), the International Conference on Information Resources Management (Conf-IRM) and the Wuhan International Conference on E-Business (WHICEB). AIS chapter conferences include Australasian Conference on Information Systems (ACIS), Information Systems Research Conference in Scandinavia (IRIS), Information Systems International Conference (ISICO), Conference of the Italian Chapter of AIS (itAIS), Annual Mid-Western AIS Conference (MWAIS) and Annual Conference of the Southern AIS (SAIS). EDSIG, which is the special interest group on education of the AITP, organizes the Conference on Information Systems and Computing Education and the Conference on Information Systems Applied Research which are both held annually in November.


== See also ==


== References ==


== Further reading ==
Rainer, R. Kelly and Cegielski, Casey G. (2009). ""Introduction to Information Systems: Enabling and Transforming Business, 3rd Edition"" Archived 2010-06-28 at the Wayback Machine
Kroenke, David (2008). Using MIS – 2nd Edition.
Lindsay, John (2000). Information Systems – Fundamentals and Issues. Kingston University, School of Information Systems
Dostal, J. School information systems (Skolni informacni systemy). In Infotech 2007 – modern information and communication technology in education. Olomouc, EU: Votobia, 2007. s. 540 – 546. ISBN 978-80-7220-301-7.
O'Leary, Timothy and Linda. (2008). Computing Essentials Introductory 2008. McGraw-Hill on Computing2008.com
Imperial College London – Information Systems Engineering degree – Information Systems Engineering
Sage, S.M. ""Information Systems: A brief look into history"", Datamation, 63–69, Nov. 1968. – Overview of the early history of IS.


== External links ==

Association for Information Systems (AIS)
IS History website by AIS
Center for Information Systems Research – Massachusetts Institute of Technology
European Research Center for Information Systems"
d2d0663714,Science,"Science is a systematic endeavor that builds and organizes knowledge in the form of testable explanations and predictions about the universe.The earliest written records of identifiable predecessors to modern science come from Ancient Egypt and Mesopotamia from around 3000 to 1200 BCE. Their contributions to mathematics, astronomy, and medicine entered and shaped the Greek natural philosophy of classical antiquity, whereby formal attempts were made to provide explanations of events in the physical world based on natural causes.: 12  After the fall of the Western Roman Empire, knowledge of Greek conceptions of the world deteriorated in Western Europe during the early centuries (400 to 1000 CE) of the Middle Ages, but was preserved in the Muslim world during the Islamic Golden Age and later by the efforts of Byzantine Greek scholars who brought Greek manuscripts from the dying Byzantine Empire to Western Europe in the Renaissance.
The recovery and assimilation of Greek works and Islamic inquiries into Western Europe from the 10th to 13th century revived ""natural philosophy"", which was later transformed by the Scientific Revolution that began in the 16th century as new ideas and discoveries departed from previous Greek conceptions and traditions. The scientific method soon played a greater role in knowledge creation and it was not until the 19th century that many of the institutional and professional features of science began to take shape, along with the changing of ""natural philosophy"" to ""natural science"".Modern science is typically divided into three major branches: natural sciences (e.g., biology, chemistry, and physics), which study the physical world; the social sciences (e.g., economics, psychology, and sociology), which study individuals and societies; and the formal sciences (e.g., logic, mathematics, and theoretical computer science), which study formal systems, governed by axioms and rules. There is disagreement whether the formal sciences are science disciplines, because they do not rely on empirical evidence. Applied sciences are disciplines that use scientific knowledge for practical purposes, such as in engineering and medicine.New knowledge in science is advanced by research from scientists who are motivated by curiosity about the world and a desire to solve problems. Contemporary scientific research is highly collaborative and is usually done by teams in academic and research institutions, government agencies, and companies. The practical impact of their work has led to the emergence of science policies that seek to influence the scientific enterprise by prioritizing the ethical and moral development of commercial products, armaments, health care, public infrastructure, and environmental protection.


== Etymology ==

The word science has been used in Middle English since the 14th century in the sense of ""the state of knowing"". The word was borrowed from the Anglo-Norman language as the suffix -cience, which was borrowed from the Latin word scientia, meaning ""knowledge, awareness, understanding"". It is a noun derivative of the Latin sciens meaning ""knowing"", and undisputedly derived from the Latin sciō, the present participle scīre, meaning ""to know"".There are many hypotheses for science's ultimate word origin. According to Michiel de Vaan, Dutch linguist and Indo-Europeanist, sciō may have its origin in the Proto-Italic language as *skije- or *skijo- meaning ""to know"", which may originate from Proto-Indo-European language as *skh1-ie, *skh1-io, meaning ""to incise"". The Lexikon der indogermanischen Verben proposed sciō is a back-formation of nescīre, meaning ""to not know, be unfamiliar with"", which may derive from Proto-Indo-European *sekH- in Latin secāre, or *skh2-, from *sḱʰeh2(i)- meaning ""to cut"".In the past, science was a synonym for ""knowledge"" or ""study"", in keeping with its Latin origin. A person who conducted scientific research was called a ""natural philosopher"" or ""man of science"". In 1834, William Whewell introduced the term scientist in a review of Mary Somerville's book On the Connexion of the Physical Sciences, crediting it to ""some ingenious gentleman"" (possibly himself).


== History ==


=== Early history ===

Science has no single origin. Rather, systematic methods emerged gradually over the course of tens of thousands of years, taking different forms around the world, and few details are known about the very earliest developments. Women likely played a central role in prehistoric science, as did religious rituals. Some scholars use the term ""protoscience"" to label activities in the past that resemble modern science in some but not all features; however, this label has also been criticized as denigrating or too suggestive of presentism, thinking about those activities only in relation to modern categories.Direct evidence for scientific processes becomes clearer with the advent of writing systems in early civilizations like Ancient Egypt and Mesopotamia, creating the earliest written records in the history of science in around 3000 to 1200 BCE.: 12–15  Although the words and concepts of ""science"" and ""nature"" were not part of the conceptual landscape at the time, the ancient Egyptians and Mesopotamians made contributions that would later find a place in Greek and medieval science: mathematics, astronomy, and medicine.: 12  From the 3rd millennium BCE, the ancient Egyptians developed a decimal numbering system, solved practical problems using geometry, and developed a calendar. Their healing therapies involved drug treatments and the supernatural, such as prayers, incantations, and rituals.: 9 The ancient Mesopotamians used knowledge about the properties of various natural chemicals for manufacturing pottery, faience, glass, soap, metals, lime plaster, and waterproofing. They studied animal physiology, anatomy, behavior, and astrology for divinatory purposes. The Mesopotamians had an intense interest in medicine and the earliest medical prescriptions appeared in Sumerian during the Third Dynasty of Ur. They seem to study scientific subjects which have practical or religious applications and have little interest of satisfying curiosity.


=== Classical antiquity ===

In classical antiquity, there is no real ancient analog of a modern scientist. Instead, well-educated, usually upper-class, and almost universally male individuals performed various investigations into nature whenever they could afford the time. Before the invention or discovery of the concept of phusis or nature by the pre-Socratic philosophers, the same words tend to be used to describe the natural ""way"" in which a plant grows, and the ""way"" in which, for example, one tribe worships a particular god. For this reason, it is claimed that these men were the first philosophers in the strict sense and the first to clearly distinguish ""nature"" and ""convention"".The early Greek philosophers of the Milesian school, which was founded by Thales of Miletus and later continued by his successors Anaximander and Anaximenes, were the first to attempt to explain natural phenomena without relying on the supernatural. The Pythagoreans developed a complex number philosophy: 467–68  and contributed significantly to the development of mathematical science.: 465  The theory of atoms was developed by the Greek philosopher Leucippus and his student Democritus. Later, Epicurus would develop a full natural cosmology based on atomism, and would adopt a ""canon"" (ruler, standard) which established physical criteria or standards of scientific truth. The Greek doctor Hippocrates established the tradition of systematic medical science and is known as ""The Father of Medicine"".A turning point in the history of early philosophical science was Socrates' example of applying philosophy to the study of human matters, including human nature, the nature of political communities, and human knowledge itself. The Socratic method as documented by Plato's dialogues is a dialectic method of hypothesis elimination: better hypotheses are found by steadily identifying and eliminating those that lead to contradictions. The Socratic method searches for general commonly-held truths that shape beliefs and scrutinizes them for consistency. Socrates criticized the older type of study of physics as too purely speculative and lacking in self-criticism.Aristotle in the 4th century BCE created a systematic program of teleological philosophy. In the 3rd century BCE, Greek astronomer Aristarchus of Samos was the first to propose a heliocentric model of the universe, with the Sun at the center and all the planets orbiting it. Aristarchus's model was widely rejected because it was believed to violate the laws of physics, while Ptolemy's Almagest, which contains a geocentric description of the Solar System, was accepted through the early Renaissance instead. The inventor and mathematician Archimedes of Syracuse made major contributions to the beginnings of calculus. Pliny the Elder was a Roman writer and polymath, who wrote the seminal encyclopedia Natural History.Positional notation for representing numbers likely emerged between the 3rd and 5th centuries CE along Indian trade routes. This numeral system made efficient arithmetic operations more accessible and would eventually become standard for mathematics worldwide.


=== Middle Ages ===

Due to the collapse of the Western Roman Empire, the 5th century saw an intellectual decline and knowledge of Greek conceptions of the world deteriorated in  Western Europe.: 194  During the period, Latin encyclopedists such as Isidore of Seville preserved the majority of general ancient knowledge. In contrast, because the Byzantine Empire resisted attacks from invaders, they were able to preserve and improve prior learning.: 159  John Philoponus, a Byzantine scholar in the 500s, started to question Aristotle's teaching of physics, introducing the theory of impetus.: 307, 311, 363, 402  His criticism served as an inspiration to medieval scholars and Galileo Galilei, who extensively cited his works ten centuries later.: 307–308 During late antiquity and the early Middle Ages, natural phenomena were mainly examined via the Aristotelian approach. The approach includes Aristotle's four causes: material, formal, moving, and final cause. Many Greek classical texts were preserved by the Byzantine empire and Arabic translations were done by groups such as the Nestorians and the Monophysites. Under the Caliphate, these Arabic translations were later improved and developed by Arabic scientists. By the 6th and 7th centuries, the neighboring Sassanid Empire established the medical Academy of Gondeshapur, which is considered by Greek, Syriac, and Persian physicians as the most important medical center of the ancient world.The House of Wisdom was established in Abbasid-era Baghdad, Iraq, where the Islamic study of Aristotelianism flourished until the Mongol invasions in the 13th century. Ibn al-Haytham, better known as Alhazen, began experimenting as a means to gain knowledge and disproved Ptolemy's theory of vision: Book I, [6.54]. p. 372  Avicenna's compilation of the Canon of Medicine, a medical encyclopedia, is considered to be one of the most important publications in medicine and was used until the 18th century.By the eleventh century, most of Europe had become Christian,: 204  and in 1088, the University of Bologna emerged as the first university in Europe. As such, demand for Latin translation of ancient and scientific texts grew,: 204  a major contributor to the Renaissance of the 12th century. Renaissance scholasticism in western Europe flourished, with experiments done by observing, describing, and classifying subjects in nature. In the 13rd century, medical teachers and students at Bologna began opening human bodies, leading to the first anatomy textbook based on human dissection by Mondino de Luzzi.


=== Renaissance ===

New developments in optics played a role in the inception of the Renaissance, both by challenging long-held metaphysical ideas on perception, as well as by contributing to the improvement and development of technology such as the camera obscura and the telescope. At the start of the Renaissance, Roger Bacon, Vitello, and John Peckham each built up a scholastic ontology upon a causal chain beginning with sensation, perception, and finally apperception of the individual and universal forms of Aristotle.: Book I  A model of vision later known as perspectivism was exploited and studied by the artists of the Renaissance. This theory uses only three of Aristotle's four causes: formal, material, and final.In the sixteenth century, Nicolaus Copernicus formulated a heliocentric model of the Solar System, stating that the planets revolve around the Sun, instead of the geocentric model where the planets and the Sun revolve around the Earth. This was based on a theorem that the orbital periods of the planets are longer as their orbs are farther from the center of motion, which he found not to agree with Ptolemy's model.Johannes Kepler and others challenged the notion that the only function of the eye is perception, and shifted the main focus in optics from the eye to the propagation of light. Kepler is best known, however, for improving Copernicus' heliocentric model through the discovery of Kepler's laws of planetary motion. Kepler did not reject Aristotelian metaphysics and described his work as a search for the Harmony of the Spheres. Galileo had made significant contributions to astronomy, physics and engineering. However, he became persecuted after Pope Urban VIII sentenced him for writing about the heliocentric model.The printing press was widely used to publish scholarly arguments, including some that disagreed widely with contemporary ideas of nature. Francis Bacon and René Descartes published philosophical arguments in favor of a new type of non-Aristotelian science. Bacon emphasized the importance of experiment over contemplation, questioned the Aristotelian concepts of formal and final cause, promoted the idea that science should study the laws of nature and the improvement of all human life. Descartes emphasized individual thought and argued that mathematics rather than geometry should be used to study nature.


=== Age of Enlightenment ===

At the start of the Age of Enlightenment, Isaac Newton formed the foundation of classical mechanics by his Philosophiæ Naturalis Principia Mathematica, greatly influencing future physicists. Gottfried Wilhelm Leibniz incorporated terms from Aristotelian physics, now used in a new non-teleological way. This implied a shift in the view of objects: objects were now considered as having no innate goals. Leibniz assumed that different types of things all work according to the same general laws of nature, with no special formal or final causes.During this time, the declared purpose and value of science became producing wealth and inventions that would improve human lives, in the materialistic sense of having more food, clothing, and other things. In Bacon's words, ""the real and legitimate goal of sciences is the endowment of human life with new inventions and riches"", and he discouraged scientists from pursuing intangible philosophical or spiritual ideas, which he believed contributed little to human happiness beyond ""the fume of subtle, sublime or pleasing [speculation]"".Science during the Enlightenment was dominated by scientific societies and academies, which had largely replaced universities as centers of scientific research and development. Societies and academies were the backbones of the maturation of the scientific profession. Another important development was the popularization of science among an increasingly literate population. Enlightenment philosophers chose a short history of scientific predecessors – Galileo, Boyle, and Newton principally – as the guides to every physical and social field of the day.The 18th century saw significant advancements in the practice of medicine and physics; the development of biological taxonomy by Carl Linnaeus; a new understanding of magnetism and electricity; and the maturation of chemistry as a discipline. Ideas on human nature, society, and economics evolved during the Enlightenment. Hume and other Scottish Enlightenment thinkers developed A Treatise of Human Nature, which was expressed historically in works by authors including James Burnett, Adam Ferguson, John Millar and William Robertson, all of whom merged a scientific study of how humans behaved in ancient and primitive cultures with a strong awareness of the determining forces of modernity. Modern sociology largely originated from this movement. In 1776, Adam Smith published The Wealth of Nations, which is often considered the first work on modern economics.


=== 19th century ===

During the nineteenth century, many distinguishing characteristics of contemporary modern science began to take shape. These included the transformation of the life and physical sciences, frequent use of precision instruments, emergence of terms such as ""biologist"", ""physicist"", ""scientist"", increased professionalization of those studying nature, scientists gained cultural authority over many dimensions of society, industrialization of numerous countries, thriving of popular science writings and emergence of science journals. During the late 19th century, psychology emerged as a separate discipline from philosophy when Wilhelm Wundt founded the first laboratory for psychological research in 1879.During the mid-19th century, Charles Darwin and Alfred Russel Wallace independently proposed the theory of evolution by natural selection in 1858, which explained how different plants and animals originated and evolved. Their theory was set out in detail in Darwin's book On the Origin of Species, published in 1859. Separately, Gregor Mendel presented his paper, ""Experiments on Plant Hybridization"" in 1865, which outlined the principles of biological inheritance, serving as the basis for modern genetics.Early in the 19th century, John Dalton suggested the modern atomic theory, based on Democritus's original idea of indivisible particles called atoms. The laws of conservation of energy, conservation of momentum and conservation of mass suggested a highly stable universe where there could be little loss of resources. However, with the advent of the steam engine and the industrial revolution there was an increased understanding that not all forms of energy have the same energy qualities, the ease of conversion to useful work or to another form of energy. This realization led to the development of the laws of thermodynamics, in which the free energy of the universe is seen as constantly declining: the entropy of a closed universe increases over time.The electromagnetic theory was established in the 19th century by the works of Hans Christian Ørsted, André-Marie Ampère, Michael Faraday, James Clerk Maxwell, Oliver Heaviside, and Heinrich Hertz. The new theory raised questions that could not easily be answered using Newton's framework. The discovery of X-rays inspired the discovery of radioactivity by Henri Becquerel and Marie Curie in 1896, Marie Curie then became the first person to win two Nobel prizes. In the next year came the discovery of the first subatomic particle, the electron.


=== 20th century ===

In the first half of the century, the development of antibiotics and artificial fertilizers improved human living standards globally. Harmful environmental issues such as ozone depletion, ocean acidification, eutrophication and climate change came to the public's attention and caused the onset of environmental studies.During this period, scientific experimentation became increasingly larger in scale and funding. The extensive technological innovation stimulated by World War I, World War II, and the Cold War led to competitions between global powers, such as the Space Race and nuclear arms race. Substantial international collaborations were also made, despite armed conflicts.In the late 20th century, active recruitment of women and elimination of sex discrimination greatly increased the number of women scientists, but large gender disparities remained in some fields. The discovery of the cosmic microwave background in 1964 led to a rejection of the steady-state model of the universe in favor of the Big Bang theory of Georges Lemaître.The century saw fundamental changes within science disciplines. Evolution became a unified theory in the early 20th-century when the modern synthesis reconciled Darwinian evolution with classical genetics. Albert Einstein's theory of relativity and the development of quantum mechanics complement classical mechanics to describe physics in extreme length, time and gravity. Widespread use of integrated circuits in the last quarter of the 20th century combined with communications satellites led to a revolution in information technology and the rise of the global internet and mobile computing, including smartphones. The need for mass systematization of long, intertwined causal chains and large amounts of data led to the rise of the fields of systems theory and computer-assisted scientific modeling.


=== 21st century ===

The Human Genome Project was completed in 2003 by identifying and mapping all of the genes of the human genome. The first induced pluripotent human stem cells were made in 2006, allowing adult cells to be transformed into stem cells and turn to any cell type found in the body. With the affirmation of the Higgs boson discovery in 2013, the last particle predicted by the Standard Model of particle physics was found. In 2015, gravitational waves, predicted by general relativity a century before, were first observed. In 2019, the international collaboration Event Horizon Telescope presented the first direct image of a black hole's accretion disk.


== Branches ==

Modern science is commonly divided into three major branches: natural science, social science, and formal science. Each of these branches comprises various specialized yet overlapping scientific disciplines that often possess their own nomenclature and expertise. Both natural and social sciences are empirical sciences, as their knowledge is based on empirical observations and is capable of being tested for its validity by other researchers working under the same conditions.


=== Natural science ===
Natural science is the study of the physical world. It can be divided into two main branches: life science and physical science. These two branches may be further divided into more specialized disciplines. For example, physical science can be subdivided into physics, chemistry, astronomy, and earth science. Modern natural science is the successor to the natural philosophy that began in Ancient Greece. Galileo, Descartes, Bacon, and Newton debated the benefits of using approaches which were more mathematical and more experimental in a methodical way. Still, philosophical perspectives, conjectures, and presuppositions, often overlooked, remain necessary in natural science. Systematic data collection, including discovery science, succeeded natural history, which emerged in the 16th century by describing and classifying plants, animals, minerals, and so on. Today, ""natural history"" suggests observational descriptions aimed at popular audiences.


=== Social science ===

Social science is the study of human behavior and functioning of societies. It has many disciplines that include, but are not limited to anthropology, economics, history, human geography, political science, psychology, and sociology. In the social sciences, there are many competing theoretical perspectives, many of which are extended through competing research programs such as the functionalists, conflict theorists, and interactionists in sociology. Due to the limitations of conducting controlled experiments involving large groups of individuals or complex situations, social scientists may adopt other research methods such as the historical method, case studies, and cross-cultural studies. Moreover, if quantitative information is available, social scientists may rely on statistical approaches to better understand social relationships and processes.


=== Formal science ===
Formal science is an area of study that generates knowledge using formal systems. A formal system is an abstract structure used for inferring theorems from axioms according to a set of rules. It includes mathematics, systems theory, and theoretical computer science. The formal sciences share similarities with the other two branches by relying on objective, careful, and systematic study of an area of knowledge. They are, however, different from the empirical sciences as they rely exclusively on deductive reasoning, without the need for empirical evidence, to verify their abstract concepts. The formal sciences are therefore a priori disciplines and because of this, there is disagreement on whether they constitute a science. Nevertheless, the formal sciences play an important role in the empirical sciences. Calculus, for example, was initially invented to understand motion in physics. Natural and social sciences that rely heavily on mathematical applications include mathematical physics, chemistry, biology, finance, and economics.


=== Applied science ===

Applied science is the use of the scientific method and knowledge to attain practical goals and includes a broad range of disciplines such as engineering and medicine. Engineering is the use of scientific principles to invent, design and build machines, structures and technologies. Science may contribute to the development of new technologies. Medicine is the practice of caring for patients by maintaining and restoring health through the prevention, diagnosis, and treatment of injury or disease. The applied sciences are often contrasted with the basic sciences, which are focused on advancing scientific theories and laws that explain and predict events in the natural world.Computational science applies computing power to simulate real-world situations, enabling a better understanding of scientific problems than formal mathematics alone can achieve. The use of machine learning and artificial intelligence is becoming a central feature of computational contributions to science for example in agent-based computational economics, random forests, topic modeling and various forms of prediction. However, machines alone rarely advance knowledge as they require human guidance and capacity to reason; and they can introduce bias against certain social groups or sometimes underperform against humans.


=== Interdisciplinary science ===
Interdisciplinary science involves the combination of two or more disciplines into one, such as bioinformatics, a combination of biology and computer science or cognitive sciences.  The concept has existed since the ancient Greek and it became popular again in the 20th century.


== Scientific research ==
Scientific research can be labeled as either basic or applied research. Basic research is the search for knowledge and applied research is the search for solutions to practical problems using this knowledge. Most understanding comes from basic research, though sometimes applied research targets specific practical problems. This leads to technological advances that were not previously imaginable.


=== Scientific method ===

Scientific research involves using the scientific method, which seeks to objectively explain the events of nature in a reproducible way. Scientists usually take for granted a set of basic assumptions that are needed to justify the scientific method: there is an objective reality shared by all rational observers; this objective reality is governed by natural laws; these laws were discovered by means of systematic observation and experimentation. Mathematics is essential in the formation of hypotheses, theories, and laws, because it is used extensively in quantitative modeling, observing, and collecting measurements. Statistics is used to summarize and analyze data, which allows scientists to assess the reliability of experimental results.In the scientific method, an explanatory thought experiment or hypothesis is put forward as an explanation using parsimony principles and is expected to seek consilience – fitting with other accepted facts related to an observation or scientific question. This tentative explanation is used to make falsifiable predictions, which are typically posted before being tested by experimentation. Disproof of a prediction is evidence of progress.: 4–5  Experimentation is especially important in science to help establish causal relationships to avoid the correlation fallacy, though in some sciences such as astronomy or geology, a predicted observation might be more appropriate.When a hypothesis proves unsatisfactory, it is modified or discarded. If the hypothesis survived testing, it may become adopted into the framework of a scientific theory, a logically reasoned, self-consistent model or framework for describing the behavior of certain natural events. A theory typically describes the behavior of much broader sets of observations than a hypothesis; commonly, a large number of hypotheses can be logically bound together by a single theory. Thus a theory is a hypothesis explaining various other hypotheses. In that vein, theories are formulated according to most of the same scientific principles as hypotheses. Scientists may generate a model, an attempt to describe or depict an observation in terms of a logical, physical or mathematical representation and to generate new hypotheses that can be tested by experimentation.While performing experiments to test hypotheses, scientists may have a preference for one outcome over another. Eliminating the bias can be achieved by transparency, careful experimental design, and a thorough peer review process of the experimental results and conclusions. After the results of an experiment are announced or published, it is normal practice for independent researchers to double-check how the research was performed, and to follow up by performing similar experiments to determine how dependable the results might be. Taken in its entirety, the scientific method allows for highly creative problem solving while minimizing the effects of subjective and confirmation bias. Intersubjective verifiability, the ability to reach a consensus and reproduce results, is fundamental to the creation of all scientific knowledge.


=== Scientific literature ===

Scientific research is published in a range of literature. Scientific journals communicate and document the results of research carried out in universities and various other research institutions, serving as an archival record of science. The first scientific journals, Journal des sçavans followed by Philosophical Transactions, began publication in 1665. Since that time the total number of active periodicals has steadily increased. In 1981, one estimate for the number of scientific and technical journals in publication was 11,500.Most scientific journals cover a single scientific field and publish the research within that field; the research is normally expressed in the form of a scientific paper. Science has become so pervasive in modern societies that it is considered necessary to communicate the achievements, news, and ambitions of scientists to a wider population.


=== Challenges ===
The replication crisis is an ongoing methodological crisis that affects parts of the social and life sciences. In subsequent investigations, the results of many scientific studies are proven to be unrepeatable. The crisis has long-standing roots; the phrase was coined in the early 2010s as part of a growing awareness of the problem. The replication crisis represents an important body of research in metascience, which aims to improve the quality of all scientific research while reducing waste.An area of study or speculation that masquerades as science in an attempt to claim a legitimacy that it would not otherwise be able to achieve is sometimes referred to as pseudoscience, fringe science, or junk science. Physicist Richard Feynman coined the term ""cargo cult science"" for cases in which researchers believe and at a glance looks like they are doing science, but lack the honesty allowing their results to be rigorously evaluated. Various types of commercial advertising, ranging from hype to fraud, may fall into these categories. Science has been described as ""the most important tool"" for separating valid claims from invalid ones.There can also be an element of political or ideological bias on all sides of scientific debates. Sometimes, research may be characterized as ""bad science,"" research that may be well-intended but is incorrect, obsolete, incomplete, or over-simplified expositions of scientific ideas. The term ""scientific misconduct"" refers to situations such as where researchers have intentionally misrepresented their published data or have purposely given credit for a discovery to the wrong person.


== Philosophy of science ==

There are different schools of thought in the philosophy of science. The most popular position is empiricism, which holds that knowledge is created by a process involving observation; scientific theories generalize observations. Empiricism generally encompasses inductivism, a position that explains how general theories can be made from the finite amount of empirical evidence available. Many versions of empiricism exist, with the predominant ones being Bayesianism and the hypothetico-deductive method.Empiricism has stood in contrast to rationalism, the position originally associated with Descartes, which holds that knowledge is created by the human intellect, not by observation. Critical rationalism is a contrasting 20th-century approach to science, first defined by Austrian-British philosopher Karl Popper. Popper rejected the way that empiricism describes the connection between theory and observation. He claimed that theories are not generated by observation, but that observation is made in the light of theories:  that the only way theory A can be affected by observation is after theory A were to conflict with observation, but theory B were to survive the observation.
Popper proposed replacing verifiability with falsifiability as the landmark of scientific theories,  replacing induction with falsification as the empirical method. Popper further claimed that there is actually only one universal method, not specific to science: the negative method of criticism, trial and error, covering all products of the human mind, including science, mathematics, philosophy, and art.Another approach, instrumentalism, emphasizes the utility of theories as instruments for explaining and predicting phenomena. It views scientific theories as black boxes with only their input (initial conditions) and output (predictions) being relevant. Consequences, theoretical entities, and logical structure are claimed to be something that should be ignored. Close to instrumentalism is constructive empiricism, according to which the main criterion for the success of a scientific theory is whether what it says about observable entities is true.Thomas Kuhn argued that the process of observation and evaluation takes place within a paradigm, a logically consistent ""portrait"" of the world that is consistent with observations made from its framing. He characterized normal science as the process of observation and ""puzzle solving"" which takes place within a paradigm, whereas revolutionary science occurs when one paradigm overtakes another in a paradigm shift. Each paradigm has its own distinct questions, aims, and interpretations. The choice between paradigms involves setting two or more ""portraits"" against the world and deciding which likeness is most promising. A paradigm shift occurs when a significant number of observational anomalies arise in the old paradigm and a new paradigm makes sense of them. That is, the choice of a new paradigm is based on observations, even though those observations are made against the background of the old paradigm. For Kuhn, acceptance or rejection of a paradigm is a social process as much as a logical process. Kuhn's position, however, is not one of relativism.Finally, another approach often cited in debates of scientific skepticism against controversial movements like ""creation science"" is methodological naturalism. Naturalists maintain that a difference should be made between natural and supernatural, and science should be restricted to natural explanations. Methodological naturalism maintains that science requires strict adherence to empirical study and independent verification.


== Scientific community ==
The scientific community is a network of interacting scientists who conducts scientific research. The community consists of smaller groups working in scientific fields. By having peer review, through discussion and debate within journals and conferences, scientists maintain the quality of research methodology and objectivity when interpreting results.


=== Scientists ===

Scientists are individuals who conduct scientific research to advance knowledge in an area of interest. In modern times, many professional scientists are trained in an academic setting and upon completion, attain an academic degree, with the highest degree being a doctorate such as a Doctor of Philosophy or PhD. Many scientists pursue careers in various sectors of the economy such as academia, industry, government, and nonprofit organizations.Scientists exhibit a strong curiosity about reality and a desire to apply scientific knowledge for the benefit of health, nations, the environment, or industries. Other motivations include recognition by their peers and prestige. In modern times, many scientists have advanced degrees in an area of science and pursue careers in various sectors of the economy such as academia, industry, government, and nonprofit environments.
Science has historically been a male-dominated field, with notable exceptions. Women in science faced considerable discrimination in science, much as they did in other areas of male-dominated societies. For example, women were frequently being passed over for job opportunities and denied credit for their work. The achievements of women in science have been attributed to the defiance of their traditional role as laborers within the domestic sphere. Lifestyle choice plays a major role in female engagement in science; female graduate students' interest in careers in research declines dramatically throughout graduate school, whereas that of their male colleagues remains unchanged.


=== Learned societies ===

Learned societies for the communication and promotion of scientific thought and experimentation have existed since the Renaissance. Many scientists belong to a learned society that promotes their respective scientific discipline, profession, or group of related disciplines. Membership may either be open to all, require possession of scientific credentials, or conferred by election. Most scientific societies are non-profit organizations, and many are professional associations. Their activities typically include holding regular conferences for the presentation and discussion of new research results and publishing or sponsoring academic journals in their discipline. Some societies act as professional bodies, regulating the activities of their members in the public interest or the collective interest of the membership.The professionalization of science, begun in the 19th century, was partly enabled by the creation of national distinguished academies of sciences such as the Italian Accademia dei Lincei in 1603, the British Royal Society in 1660, the French Academy of Sciences in 1666, the American National Academy of Sciences in 1863, the German Kaiser Wilhelm Society in 1911, and the Chinese Academy of Sciences in 1949. International scientific organizations, such as the International Science Council, are devoted to international cooperation for science advancement.


=== Awards ===
Science awards are usually given to individuals or organizations that have made significant contributions to a discipline. They are often given by prestigious institutions, thus it is considered a great honor for a scientist receiving them. Since the early Renaissance, scientists are often awarded medals, money, and titles. The Nobel Prize, a widely regarded prestigious award, is awarded annually to those who have achieved scientific advances in the fields of medicine, physics, and chemistry.


== Society ==


=== Funding and policies ===

Scientific research is often funded through a competitive process in which potential research projects are evaluated and only the most promising receive funding. Such processes, which are run by government, corporations, or foundations, allocate scarce funds. Total research funding in most developed countries is between 1.5% and 3% of GDP. In the OECD, around two-thirds of research and development in scientific and technical fields is carried out by industry, and 20% and 10% respectively by universities and government. The government funding proportion in certain fields is higher, and it dominates research in social science and humanities. In the lesser-developed nations, government provides the bulk of the funds for their basic scientific research.Many governments have dedicated agencies to support scientific research, such as the National Science Foundation in the United States, the National Scientific and Technical Research Council in Argentina, Commonwealth Scientific and Industrial Research Organization in Australia, National Centre for Scientific Research in France, the Max Planck Society in Germany, and National Research Council in Spain. In commercial research and development, all but the most research-oriented corporations focus more heavily on near-term commercialization possibilities rather than research driven by curiosity.Science policy is concerned with policies that affect the conduct of the scientific enterprise, including research funding, often in pursuance of other national policy goals such as technological innovation to promote commercial product development, weapons development, health care, and environmental monitoring. Science policy sometimes refers to the act of applying scientific knowledge and consensus to the development of public policies. In accordance with public policy being concerned about the well-being of its citizens, science policy's goal is to consider how science and technology can best serve the public. Public policy can directly affect the funding of capital equipment and intellectual infrastructure for industrial research by providing tax incentives to those organizations that fund research.


=== Education and awareness ===

Science education for the general public is embedded in the school curriculum, and is supplemented by online pedagogical content (for example, YouTube and Khan Academy), museums, and science magazines and blogs. Scientific literacy is chiefly concerned with an understanding of the scientific method, units and methods of measurement, empiricism, a basic understanding of statistics (correlations, qualitative versus quantitative observations, aggregate statistics), as well as a basic understanding of core scientific fields, such as physics, chemistry, biology, ecology, geology and computation. As a student advances into higher stages of formal education, the curriculum becomes more in depth. Traditional subjects usually included in the curriculum are natural and formal sciences, although recent movements include social and applied science as well.The mass media face pressures that can prevent them from accurately depicting competing scientific claims in terms of their credibility within the scientific community as a whole. Determining how much weight to give different sides in a scientific debate may require considerable expertise regarding the matter. Few journalists have real scientific knowledge, and even beat reporters who are knowledgeable about certain scientific issues may be ignorant about other scientific issues that they are suddenly asked to cover.Science magazines such as New Scientist, Science & Vie, and Scientific American cater to the needs of a much wider readership and provide a non-technical summary of popular areas of research, including notable discoveries and advances in certain fields of research. Science fiction genre, primarily speculative fiction, can transmit the ideas and methods of science to the general public. Recent efforts to intensify or develop links between science and non-scientific disciplines, such as literature or poetry, include the Creative Writing Science resource developed through the Royal Literary Fund.


=== Anti-science attitudes ===

While the scientific method is broadly accepted in the scientific community, some fractions of society reject certain scientific positions or are skeptical about science. Examples are the common notion that COVID-19 is not a major health threat to the US (held by 39% of Americans in August 2021) or the belief that climate change is not a major threat to the US (also held by 40% of Americans, in late 2019 and early 2020). Psychologists have pointed to four factors driving rejection of scientific results:
Scientific authorities are sometimes seen as inexpert, untrustworthy, or biased.
Some marginalized social groups hold anti-science attitudes, in part because these groups have often been exploited in unethical experiments.
Messages from scientists may contradict deeply-held existing beliefs or morals.
The delivery of a scientific message may not be appropriately targeted to a recipient's learning style.Anti-science attitudes seem to be often caused by fear of rejection in social groups. For instance, climate change is perceived as a threat by only 22% of Americans on the right side of the political spectrum, but by 85% on the left. That is, if someone on the left would not consider climate change as a threat, this person may face contempt and be rejected in that social group. In fact, people may rather deny a scientifically accepted fact than lose or jeopardize their social status.


=== Politics ===
Attitudes towards science are often determined by political opinions and goals. Government, business and advocacy groups have been known to use legal and economic pressure to influence scientific researchers. Many factors can act as facets of the politicization of science such as anti-intellectualism, perceived threats to religious beliefs, and fear for business interests. Politicization of science is usually accomplished when scientific information is presented in a way that emphasizes the uncertainty associated with the scientific evidence. Tactics such as shifting conversation, failing to acknowledge facts, and capitalizing on doubt of scientific consensus have been used to gain more attention for views that have been undermined by scientific evidence. Examples of issues that have involved the politicization of science include the global warming controversy, health effects of pesticides, and health effects of tobacco.


== See also ==
List of scientific occupations
List of years in science


== Notes ==


== References ==


== External links ==
 Media related to Science at Wikimedia Commons"
955dd95299,Software framework,"In computer programming, a software framework is an abstraction in which software, providing generic functionality, can be selectively changed by additional user-written code, thus providing application-specific software. It provides a standard way to build and deploy applications and is a universal, reusable software environment that provides particular functionality as part of a larger software platform to facilitate the development of software applications, products and solutions. 
Software frameworks may include support programs, compilers, code libraries, toolsets, and application programming interfaces (APIs) that bring together all the different components to enable development of a project or system.
Frameworks have key distinguishing features that separate them from normal libraries:

inversion of control: In a framework, unlike in libraries or in standard user applications, the overall program's flow of control is not dictated by the caller, but by the framework. This is usually achieved with the Template Method Pattern.
default behaviour: This can be provided with the invariant methods of the Template Method Pattern in an abstract class which is provided by the framework.
extensibility: A user can extend the framework–usually by selective overriding–or programmers can add specialized user code to provide specific functionality. This is usually achieved by a hook method in a subclass that overrides a template method in the superclass.
non-modifiable framework code: The framework code, in general, is not supposed to be modified, while accepting user-implemented extensions. In other words, users can extend the framework, but cannot modify its code.


== Rationale ==
The designers of software frameworks aim to facilitate software developments by allowing designers and programmers to devote their time to meeting software requirements rather than dealing with the more standard low-level details of providing a working system, thereby reducing overall development time. For example, a team using a web framework to develop a banking website can focus on writing code particular to banking rather than the mechanics of request handling and state management.
Frameworks often add to the size of programs, a phenomenon termed ""code bloat"". Due to customer-demand-driven applications needs, both competing and complementary frameworks sometimes end up in a product.  Further, due to the complexity of their APIs, the intended reduction in overall development time may not be achieved due to the need to spend additional time learning to use the framework; this criticism is clearly valid when a special or new framework is first encountered by development staff. If such a framework is not used in subsequent job taskings, the time invested in learning the framework can cost more than purpose-written code familiar to the project's staff; many programmers keep copies of useful boilerplate code for common needs.
However, once a framework is learned, future projects can be faster and easier to complete; the concept of a framework is to make a one-size-fits-all solution set, and with familiarity, code production should logically rise. There are no such claims made about the size of the code eventually bundled with the output product, nor its relative efficiency and conciseness. Using any library solution necessarily pulls in extras and unused extraneous assets unless the software is a compiler-object linker making a tight (small, wholly controlled, and specified) executable module.
The issue continues, but a decade-plus of industry experience has shown that the most effective frameworks turn out to be those that evolve from re-factoring the common code of the enterprise, instead of using a generic ""one-size-fits-all"" framework developed by third parties for general purposes. An example of that would be how the user interface in such an application package as an office suite grows to have common look, feel, and data-sharing attributes and methods, as the once disparate bundled applications, grow unified into a suite that is tighter and smaller; the newer/evolved suite can be a product that shares integral utility libraries and user interfaces.
This trend in the controversy brings up an important issue about frameworks. Creating a framework that is elegant, versus one that merely solves a problem, is still rather a craft than a science. ""Software elegance"" implies clarity, conciseness, and little waste (extra or extraneous functionality, much of which is user-defined). For those frameworks that generate code, for example, ""elegance"" would imply the creation of code that is clean and comprehensible to a reasonably knowledgeable programmer (and which is therefore readily modifiable), versus one that merely generates correct code. The elegance issue is why relatively few software frameworks have stood the test of time: the best frameworks have been able to evolve gracefully as the underlying technology on which they were built advanced. Even there, having evolved, many such packages will retain legacy capabilities bloating the final software as otherwise replaced methods have been retained in parallel with the newer methods.


== Examples ==

Software frameworks typically contain considerable housekeeping and utility code in order to help bootstrap user applications, but generally focus on specific problem domains, such as:

Artistic drawing, music composition, and mechanical CAD
Financial modeling applications
Earth system modeling applications
Decision support systems
Media playback and authoring
Web framework
Middleware
Cactus Framework – High performance scientific computing.
Application framework – General GUI applications.
Enterprise Architecture framework
Oracle Application Development Framework
Laravel (PHP Framework)
Malware, for example Pipedream
Php4delphi


== Architecture ==
According to Pree, software frameworks consist of frozen spots and hot spots. Frozen spots define the overall architecture of a software system, that is to say its basic components and the relationships between them. These remain unchanged (frozen) in any instantiation of the application framework. Hot spots represent those parts where the programmers using the framework add their own code to add the functionality specific to their own project.
In an object-oriented environment, a framework consists of abstract and concrete classes. Instantiation of such a framework consists of composing and subclassing the existing classes.The necessary functionality can be implemented by using the Template Method Pattern in which the frozen spots are known as invariant methods and the hot spots are known as variant or hook methods. The invariant methods in the superclass provide default behaviour while the hook methods in each subclass provide custom behaviour.
When developing a concrete software system with a software framework, developers utilize the hot spots according to the specific needs and requirements of the system. Software frameworks rely on the Hollywood Principle: ""Don't call us, we'll call you."" This means that the user-defined classes (for example, new subclasses) receive messages from the predefined framework classes. Developers usually handle this by implementing superclass abstract methods.


== See also ==
Class (computer science)
Design pattern (computer science)
Don't repeat yourself
Implicit invocation
Software engine


== References ==


== External links ==
 The dictionary definition of software framework at Wiktionary
 Media related to Software frameworks at Wikimedia Commons"
e42f38772c,Pool (computer science),"In computer science, a pool is a collection of resources that are kept, in memory, ready to use, rather than the memory acquired on use and the memory released afterwards.  In this context, resources can refer to system resources such as file handles, which are external to a process, or internal resources such as objects.  A pool client requests a resource from the pool and performs desired operations on the returned resource.  When the client finishes its use of the resource, it is returned to the pool rather than released and lost.The pooling of resources can offer a significant response-time boost in situations that have high cost associated with resource acquiring, high rate of the requests for resources, and a low overall count of simultaneously used resources. Pooling is also useful when the latency is a concern, because a pool offers predictable times required to obtain resources since they have already been acquired. These benefits are mostly true for system resources that require a system call, or remote resources that require a network communication, such as database connections, socket connections, threads, and memory allocation. Pooling is also useful for expensive-to-compute data, notably large graphic objects like fonts or bitmaps, acting essentially as a data cache or a memoization technique.
Special cases of pools are connection pools, thread pools, and memory pools.


== Object pools ==

Pools can also be used for objects, in which context a pool refers to a design pattern for implementing pools in object-oriented languages, such as in the object pool pattern. Objects themselves hold no external resources and only occupy memory, although an already created object avoids the memory allocation required on object creation.  Object pools are useful when the cost of object creation is high, but in certain situations this simple object pooling may not be efficient and could in fact decrease performance.


== References =="
c6a8e0e4b7,Interface (computing),"In computing, an interface is a shared boundary across which two or more separate components of a computer system exchange information. The exchange can be between software, computer hardware, peripheral devices, humans, and combinations of these. Some computer hardware devices, such as a touchscreen, can both send and receive data through the interface, while others such as a mouse or microphone may only provide an interface to send data to a given system.


== Hardware interfaces ==

Hardware interfaces exist in many components, such as the various buses, storage devices, other I/O devices, etc. A hardware interface is described by the mechanical, electrical, and logical signals at the interface and the protocol for sequencing them (sometimes called signaling). A standard interface, such as SCSI, decouples the design and introduction of computing hardware, such as I/O devices, from the design and introduction of other components of a computing system, thereby allowing users and manufacturers great flexibility in the implementation of computing systems. Hardware interfaces can be parallel with several electrical connections carrying parts of the data simultaneously or serial where data are sent one bit at a time.


== Software interfaces ==

A software interface may refer to a wide range of different types of interface at different ""levels"". For example, an operating system may interface with pieces of hardware. Applications or programs running on the operating system may need to interact via data streams, filters, and pipelines. In object oriented programs, objects within an application may need to interact via methods.


=== In practice ===
A key principle of design is to prohibit access to all resources by default, allowing access only through well-defined entry points, i.e., interfaces. Software interfaces provide access to computer resources (such as memory, CPU, storage, etc.) of the underlying computer system; direct access (i.e., not through well-designed interfaces) to such resources by software can have major ramifications—sometimes disastrous ones—for functionality and stability.Interfaces between software components can provide constants, data types, types of procedures, exception specifications, and method signatures. Sometimes, public variables are also defined as part of an interface.The interface of a software module A is deliberately defined separately from the implementation of that module. The latter contains the actual code of the procedures and methods described in the interface, as well as other ""private"" variables, procedures, etc. Another software module B, for example the client to A, that interacts with A is forced to do so only through the published interface. One practical advantage of this arrangement is that replacing the implementation of A with another implementation of the same interface should not cause B to fail—how A internally meets the requirements of the interface is not relevant to B, which is only concerned with the specifications of the interface. (See also Liskov substitution principle.)


=== In object-oriented languages ===

In some object-oriented languages, especially those without full multiple inheritance, the term interface is used to define an abstract type that contains no data but defines behaviours as method signatures. A class having code and data for all the methods corresponding to that interface and declaring so is said to implement that interface. Furthermore, even in single-inheritance-languages, one can implement multiple interfaces, and hence can be of different types at the same time.An interface is thus a type definition; anywhere an object can be exchanged (for example, in a function or method call) the type of the object to be exchanged can be defined in terms of one of its implemented interfaces or base-classes rather than specifying the specific class. This approach means that any class that implements that interface can be used. For example, a dummy implementation may be used to allow development to progress before the final implementation is available. In another case, a fake or mock implementation may be substituted during testing. Such stub implementations are replaced by real code later in the development process.
Usually a method defined in an interface contains no code and thus cannot itself be called; it must be implemented by non-abstract code to be run when it is invoked. An interface called ""Stack"" might define two methods: push() and pop(). It can be implemented in different ways, for example, FastStack and GenericStack—the first being fast, working with a data structure of fixed size, and the second using a data structure that can be resized, but at the cost of somewhat lower speed.
Though interfaces can contain many methods they may contain only one or even none at all. For example, the Java language defines the interface Readable that has the single read() method; various implementations are used for different purposes, including BufferedReader, FileReader, InputStreamReader, PipedReader, and StringReader. Marker interfaces like Serializable contain no methods at all and serve to provide run-time information to generic processing using Reflection.


=== Programming to the interface ===
The use of interfaces allows for a programming style called programming to the interface. The idea behind this approach is to base programming logic on the interfaces of the objects used, rather than on internal implementation details. Programming to the interface reduces dependency on implementation specifics and makes code more reusable.Pushing this idea to the extreme, inversion of control leaves the context to inject the code with the specific implementations of the interface that will be used to perform the work.


== User interfaces ==

A user interface is a point of interaction between a computer and humans; it includes any number of modalities of interaction (such as graphics, sound, position, movement, etc.) where data is transferred between the user and the computer system.


== See also ==
Abstraction inversion
Application binary interface
Application programming interface
Business Interoperability Interface
Computer bus
Hard disk drive interface
Implementation (computer science)
Implementation inheritance
Interoperability
Inheritance semantics
Modular programming
Software componentry
Virtual inheritance


== References =="
cd7bdd308f,Simulation (computer science),"In theoretical computer science a simulation is a relation between state transition systems associating systems that behave in the same way in the sense that one system simulates the other.
Intuitively, a system simulates another system if it can match all of its moves.
The basic definition relates states within one transition system, but this is easily adapted to relate two separate transition systems by building a system consisting of the disjoint union of the corresponding components.


== Formal definition ==
Given a labelled state transition system (
  
    
      
        S
      
    
    {\displaystyle S}
  , 
  
    
      
        Λ
      
    
    {\displaystyle \Lambda }
  , →),
where 
  
    
      
        S
      
    
    {\displaystyle S}
   is a set of states, 
  
    
      
        Λ
      
    
    {\displaystyle \Lambda }
   is a set of labels and → is a set of labelled transitions (i.e., a subset of 
  
    
      
        S
        ×
        Λ
        ×
        S
      
    
    {\displaystyle S\times \Lambda \times S}
  ),
a relation 
  
    
      
        R
        ⊆
        S
        ×
        S
      
    
    {\displaystyle R\subseteq S\times S}
   is a simulation if and only if for every pair of states 
  
    
      
        (
        p
        ,
        q
        )
      
    
    {\displaystyle (p,q)}
   in 
  
    
      
        R
      
    
    {\displaystyle R}
   and all labels α in 
  
    
      
        Λ
      
    
    {\displaystyle \Lambda }
  :

if 
  
    
      
        p
        
          
            →
            α
          
        
        
          p
          ′
        
      
    
    {\displaystyle p{\overset {\alpha }{\rightarrow }}p'}
  , then there is 
  
    
      
        q
        
          
            →
            α
          
        
        
          q
          ′
        
      
    
    {\displaystyle q{\overset {\alpha }{\rightarrow }}q'}
   such that 
  
    
      
        (
        
          p
          ′
        
        ,
        
          q
          ′
        
        )
        ∈
        R
      
    
    {\displaystyle (p',q')\in R}
  Equivalently, in terms of relational composition:

  
    
      
        
          R
          
            −
            1
          
        
        
        ;
        
        
          
            →
            α
          
        
        
        
          ⊆
        
        
        
          
            →
            α
          
        
        
        ;
        
        
          R
          
            −
            1
          
        
      
    
    {\displaystyle R^{-1}\,;\,{\overset {\alpha }{\rightarrow }}\quad {\subseteq }\quad {\overset {\alpha }{\rightarrow }}\,;\,R^{-1}}
  Given two states 
  
    
      
        p
      
    
    {\displaystyle p}
   and 
  
    
      
        q
      
    
    {\displaystyle q}
   in 
  
    
      
        S
      
    
    {\displaystyle S}
  , 
  
    
      
        p
      
    
    {\displaystyle p}
   can be simulated by 
  
    
      
        q
      
    
    {\displaystyle q}
  , written 
  
    
      
        p
        
        ≤
        
        q
      
    
    {\displaystyle p\,\leq \,q}
  , if and only if there is a simulation 
  
    
      
        R
      
    
    {\displaystyle R}
   such that 
  
    
      
        (
        p
        ,
        q
        )
        ∈
        R
      
    
    {\displaystyle (p,q)\in R}
  . The relation 
  
    
      
        ≤
      
    
    {\displaystyle \leq }
   is called the simulation preorder, and it is the union of all simulations: 
  
    
      
        (
        p
        ,
        q
        )
        ∈
        
        ≤
        
      
    
    {\displaystyle (p,q)\in \,\leq \,}
   precisely when 
  
    
      
        (
        p
        ,
        q
        )
        ∈
        R
      
    
    {\displaystyle (p,q)\in R}
   for some simulation 
  
    
      
        R
      
    
    {\displaystyle R}
  .
The set of simulations is closed under union; therefore, the simulation preorder is itself a simulation. Since it is the union of all simulations, it is the unique largest simulation. Simulations are also closed under reflexive and transitive closure; therefore, the largest simulation must be reflexive and transitive. From this follows that the largest simulation — the simulation preorder — is indeed a preorder relation. Note that there can be more than one relation which is both a simulation and a preorder; the term simulation preorder refers to the largest one of them (which is a superset of all the others).
Two states 
  
    
      
        p
      
    
    {\displaystyle p}
   and 
  
    
      
        q
      
    
    {\displaystyle q}
   are said to be similar, written 
  
    
      
        p
        ≤≥
        q
      
    
    {\displaystyle p\leq \geq q}
  , if and only if 
  
    
      
        p
      
    
    {\displaystyle p}
   can be simulated by 
  
    
      
        q
      
    
    {\displaystyle q}
   and 
  
    
      
        q
      
    
    {\displaystyle q}
   can be simulated by 
  
    
      
        p
      
    
    {\displaystyle p}
  . Similarity is thus the maximal symmetric subset of the simulation preorder, which means it is reflexive, symmetric, and transitive; hence an equivalence relation. However, it is not necessarily a simulation, and precisely in those cases when it is not a simulation, it is strictly coarser than bisimilarity (meaning it is a superset of bisimilarity).
To witness, consider a similarity which is a simulation. Since it is symmetric, it is a bisimulation. It must then be a subset of bisimilarity, which is the union of all bisimulations. Yet it is easy to see that similarity is always a superset of bisimilarity. From this follows that if similarity is a simulation, it equals bisimilarity. And if it equals bisimilarity, it is naturally a simulation (since bisimilarity is a simulation). Therefore, similarity is a simulation if and only if it equals bisimilarity. If it does not, it must be its strict superset; hence a strictly coarser equivalence relation.


== Similarity of separate transition systems ==
When comparing two different transition systems (S', Λ', →') and (S"", Λ"", →""), the basic notions of simulation and similarity can be used by forming the disjoint composition of the two machines, (S, Λ, →) with S = S' ∐ S"", Λ = Λ' ∪ Λ"" and → = →' ∪ →"", where ∐ is the disjoint union operator between sets.


== See also ==
State transition system
Bisimulation
Coinduction
Operational semantics


== References ==
Park, David (1981). ""Concurrency and Automata on Infinite Sequences"" (PDF).  In Deussen, Peter (ed.). Proceedings of the 5th GI-Conference, Karlsruhe. Lecture Notes in Computer Science. Vol. 104. Springer-Verlag. pp. 167–183. doi:10.1007/BFb0017309. ISBN 978-3-540-10576-3.
van Glabbeek, R. J. (2001). ""The Linear Time – Branching Time Spectrum I: The Semantics of Concrete, Sequential Processes"". Handbook of Process Algebra. Elsevier. pp. 3–99."
fa5359591c,State space (computer science),"In computer science, a state space is a discrete space representing the set of all possible configurations of a ""system"". It is a useful abstraction for reasoning about the behavior of a given system and is widely used in the fields of artificial intelligence and game theory.
For instance, the toy problem Vacuum World has a discrete finite state space in which there are a limited set of configurations that the vacuum and dirt can be in. A ""counter"" system, where states are the natural numbers starting at 1 and are incremented over time has an infinite discrete state space. The angular position of an undamped pendulum is a continuous (and therefore infinite) state space.


== Definition ==
State spaces are useful in computer science as a simple model of machines. Formally, a state space can be defined as a tuple [N, A, S, G] where:

N is a set of states
A is a set of arcs connecting the states
S is a nonempty subset of N that contains start states
G is a nonempty subset of N that contains the goal states.


== Properties ==

A state space has some common properties:

complexity, where branching factor is important
structure of the space, see also graph theory:
directionality of arcs
tree
rooted graphFor example, the Vacuum World has a branching factor of 4, as the vacuum cleaner can end up in 1 of 4 adjacent squares after moving (assuming it cannot stay in the same square nor move diagonally). The arcs of Vacuum World are bidirectional, since any square can be reached from any adjacent square, and the state space is not a tree since it is possible to enter a loop by moving between any 4 adjacent squares.
State spaces can be either infinite or finite, and discrete or continuous. 


=== Size ===
The size of the state space for a given system is the number of possible configurations of the space.


==== Finite ====
If the size of the state space is finite, calculating the size of the state space is a combinatorial problem. For example, in the Eight queens puzzle, the state space can be calculated by counting all possible ways to place 8 pieces on an 8x8 chessboard. This is the same as choosing 8 positions without replacement from a set of 64, or

  
    
      
        
          
            
              (
            
            
              64
              8
            
            
              )
            
          
        
        =
        4
        ,
        426
        ,
        165
        ,
        368
      
    
    {\displaystyle {\binom {64}{8}}=4,426,165,368}
  This is significantly greater than the number of legal configurations of the queens, 92. In many games the effective state space is small compared to all reachable/legal states. This property is also observed in Chess, where the effective state space is the set of positions that can be reached by game-legal moves.  This is far smaller than the set of positions that can be achieved by placing combinations of the available chess pieces directly on the board.


==== Infinite ====
All continuous state spaces can be described by a corresponding continuous function and are therefore infinite. Discrete state spaces can also have (countably) infinite size, such as the state space of the time-dependent ""counter"" system, similar to the system in queueing theory defining the number of customers in a line, which would have state space {0, 1, 2, 3, ...}.


== Exploration ==

Exploring a state space is the process of enumerating possible states in search of a goal state. The state space of Pacman, for example, contains a goal state whenever all food pellets have been eaten, and is explored by moving Pacman around the board.


=== Search States ===
A search state is a compressed representation of a world state in a state space, and is used for exploration. Search states are used because a state space often encodes more information than is necessary to explore the space. Compressing each world state to only information needed for exploration improves efficiency by reducing the number of states in the search. For example, a state in the Pacman space includes information about the direction Pacman is facing (up, down, left, or right). Since it does not cost anything to change directions in Pacman, search states for Pacman would not include this information and reduce the size of the search space by a factor of 4, one for each direction Pacman could be facing.


=== Methods ===
Standard search algorithms are effective in exploring discrete state spaces. The following algorithms exhibit both completeness and optimality in searching a state space.
Breadth-First Search
A* Search
Uniform Cost SearchThese methods do not extend naturally to exploring continuous state spaces. Exploring a continuous state space in search of a given goal state is equivalent to optimizing an arbitrary continuous function which is not always possible, see mathematical optimization.


== See also ==


== References =="
e0e4f002f6,Philosophy of computer science,"The philosophy of computer science is concerned with the philosophical questions that arise within the study of computer science. There is still no common understanding of the content, aim, focus, or topic of the philosophy of computer science, despite some attempts to develop a philosophy of computer science like the philosophy of physics or the philosophy of mathematics. Due to the abstract nature of computer programs and the technological ambitions of computer science, many of the conceptual questions of the philosophy of computer science are also comparable to the philosophy of science, philosophy of mathematics, and the philosophy of technology.


== Overview ==
Many of the central philosophical questions of computer science are centered on the logical, ontological and epistemological issues that concern it. Some of these questions may include:

What is computation?
Does the Church–Turing thesis capture the mathematical notion of an effective method in logic and mathematics?
What are the philosophical consequences of the P vs NP problem?
What is information?


== Church–Turing thesis ==
The Church–Turing thesis and its variations are central to the theory of computation. Since, as an informal notion, the concept of effective calculability does not have a formal definition, the thesis, although it has near-universal acceptance, cannot be formally proven. The implications of this thesis is also of philosophical concern. Philosophers have interpreted the Church–Turing thesis as having implications for the philosophy of mind.


== P versus NP problem ==
The P versus NP problem is an unsolved problem in computer science and mathematics. It asks whether every problem whose solution can be verified in polynomial time (and so defined to belong to the class NP) can also be solved in polynomial time (and so defined to belong to the class P). Most computer scientists believe that P ≠ NP. Apart from the reason that after decades of studying these problems no one has been able to find a polynomial-time algorithm for any of more than 3000 important known NP-complete problems, philosophical reasons that concern its implications may have motivated this belief.
For instance, according to Scott Aaronson, the American computer scientist then at MIT:

If P = NP, then the world would be a profoundly different place than we usually assume it to be. There would be no special value in ""creative leaps"", no fundamental gap between solving a problem and recognizing the solution once it's found. Everyone who could appreciate a symphony would be Mozart; everyone who could follow a step-by-step argument would be Gauss.


== See also ==
Computer-assisted proof: Philosophical objections
Philosophy of artificial intelligence
Philosophy of information
Philosophy of mathematics
Philosophy of science
Philosophy of technology


== References ==


== Further reading ==
Matti Tedre (2014). The Science of Computing: Shaping a Discipline. Chapman Hall.
Scott Aaronson. ""Why Philosophers Should Care About Computational Complexity"". In Computability: Gödel, Turing, Church, and beyond.
Timothy Colburn. Philosophy and Computer Science. Explorations in Philosophy. M.E. Sharpe, 1999. ISBN 1-56324-991-X.
A.K. Dewdney. New Turing Omnibus: 66 Excursions in Computer Science
Luciano Floridi (editor). The Blackwell Guide to the Philosophy of Computing and Information, 2004.
Luciano Floridi (editor). Philosophy of Computing and Information: 5 Questions. Automatic Press, 2008.
Luciano Floridi. Philosophy and Computing: An Introduction, Routledge, 1999.
Christian Jongeneel. The informatical worldview, an inquiry into the methodology of computer science.
Jan van Leeuwen. ""Towards a philosophy of the information and computing sciences"", NIAS Newsletter 42, 2009.
Moschovakis, Y. (2001). What is an algorithm? In Enquist, B. and Schmid, W., editors, Mathematics unlimited — 2001 and beyond, pages 919–936. Springer.
Alexander Ollongren, Jaap van den Herik. Filosofie van de informatica. London and New York: Routledge, 1999. ISBN 0-415-19749-X
Tedre, Matti (2014), The Science of Computing: Shaping a Discipline, ISBN 9781482217698 Taylor and Francis.
Ray Turner and Nicola Angius. ""The Philosophy of Computer Science"". Stanford Encyclopedia of Philosophy.
Matti Tedre (2011). Computing as a Science: A Survey of Competing Viewpoints. Minds & Machines 21, 3, 361–387.
Ray Turner. Computational Artefacts-Towards a Philosophy of Computer Science. Springer. [1]


== External links ==
The International Association for Computing and Philosophy
Philosophy of Computing and Information at PhilPapers
Philosophy of Computation at Berkeley
Rapaport, William J. (2020-07-27). ""Philosophy of Computer Science (draft version)"" (PDF). Archived from the original (PDF) on 2021-10-26."
